{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model selection and evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vFY2CSxT-EhN",
        "Xfe4MC9n_CBQ",
        "JWxM4Ts4qicG",
        "X27ZZYKyr4LX",
        "ci7DMLSkIkw7",
        "b1uGILMm4h1z",
        "z4570YUKiS60",
        "JQMEbgnAue7o"
      ],
      "authorship_tag": "ABX9TyPQQpfduKB6IZkR5I5atPV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afrah1994/Prediction-of-Housing-Prices/blob/master/Model_selection_and_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFY2CSxT-EhN",
        "colab_type": "text"
      },
      "source": [
        "# Splitting the dataset into training and validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHVdrQyh-Why",
        "colab_type": "text"
      },
      "source": [
        "For the sake of simpliticity I decided to delete the address column (Last column) from my csv file so I don't have to keep dropping the column everytime.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHZQx9YH99T4",
        "colab_type": "code",
        "outputId": "da29f146-36aa-4d20-e7b8-399dc7f89236",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-984368c4-487d-4503-8ae7-9e051e8172d0\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-984368c4-487d-4503-8ae7-9e051e8172d0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving USA_Housing_project.csv to USA_Housing_project.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLiPmzIL-kKa",
        "colab_type": "code",
        "outputId": "4858f713-9373-4698-e746-bb9a53289edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('USA_Housing_project.csv', delimiter=',')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79545.45857</td>\n",
              "      <td>5.682861</td>\n",
              "      <td>7.009188</td>\n",
              "      <td>4.09</td>\n",
              "      <td>23086.80050</td>\n",
              "      <td>1.059034e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79248.64245</td>\n",
              "      <td>6.002900</td>\n",
              "      <td>6.730821</td>\n",
              "      <td>3.09</td>\n",
              "      <td>40173.07217</td>\n",
              "      <td>1.505891e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61287.06718</td>\n",
              "      <td>5.865890</td>\n",
              "      <td>8.512727</td>\n",
              "      <td>5.13</td>\n",
              "      <td>36882.15940</td>\n",
              "      <td>1.058988e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63345.24005</td>\n",
              "      <td>7.188236</td>\n",
              "      <td>5.586729</td>\n",
              "      <td>3.26</td>\n",
              "      <td>34310.24283</td>\n",
              "      <td>1.260617e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59982.19723</td>\n",
              "      <td>5.040555</td>\n",
              "      <td>7.839388</td>\n",
              "      <td>4.23</td>\n",
              "      <td>26354.10947</td>\n",
              "      <td>6.309435e+05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Avg. Area Income  Avg. Area House Age  ...  Area Population         Price\n",
              "0       79545.45857             5.682861  ...      23086.80050  1.059034e+06\n",
              "1       79248.64245             6.002900  ...      40173.07217  1.505891e+06\n",
              "2       61287.06718             5.865890  ...      36882.15940  1.058988e+06\n",
              "3       63345.24005             7.188236  ...      34310.24283  1.260617e+06\n",
              "4       59982.19723             5.040555  ...      26354.10947  6.309435e+05\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIPRn8rx-nXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "dataset = np.genfromtxt('USA_Housing_project.csv', delimiter=\",\", skip_header = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4lZfL3S-rJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "np.random.shuffle(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB01JNNh-4Tb",
        "colab_type": "text"
      },
      "source": [
        "I decided to do a 70%-30% split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvW35fxe-tSV",
        "colab_type": "code",
        "outputId": "565791e7-acde-457a-c05b-0f33e7578e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Index for 30%\n",
        "index_30percent = int(0.3 * len(dataset[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation\n",
        "XVALID = dataset[:index_30percent, [0,1,2,3,4]]\n",
        "YVALID = dataset[:index_30percent, 5]\n",
        "XTRAIN = dataset[index_30percent:, [0,1,2,3,4]]\n",
        "YTRAIN = dataset[index_30percent:, 5]\n",
        "#print(XVALID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL9tXre1-w7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Applying mean and std from xtrain to xvalid\n",
        "mean = XTRAIN.mean(axis = 0)\n",
        "XTRAIN -= mean\n",
        "std = XTRAIN.std(axis = 0)\n",
        "XTRAIN /= std\n",
        "\n",
        "XVALID -= mean\n",
        "XVALID /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW9beirk-zOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rescaling\n",
        "#Ymax = YTRAIN.max()\n",
        "#YTRAIN = YTRAIN/ Ymax\n",
        "YTRAIN1 = np.log(YTRAIN)\n",
        "YTRAIN2 = np.log(YTRAIN)\n",
        "YTRAIN3 = np.log(YTRAIN)\n",
        "YTRAIN4 = np.log(YTRAIN)\n",
        "YTRAIN5 = np.log(YTRAIN)\n",
        "YTRAIN6 = np.log(YTRAIN)\n",
        "YTRAIN7 = np.log(YTRAIN)\n",
        "YTRAIN8 = np.log(YTRAIN)\n",
        "YTRAIN9 = np.log(YTRAIN)\n",
        "YTRAIN10 = np.log(YTRAIN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNUcakYD-1A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rescaling Y Valid\n",
        "#YVALID /= Ymax\n",
        "YVALID1 = np.log(YVALID)\n",
        "YVALID2 = np.log(YVALID)\n",
        "YVALID3 = np.log(YVALID)\n",
        "YVALID4 = np.log(YVALID)\n",
        "YVALID5 = np.log(YVALID)\n",
        "YVALID6 = np.log(YVALID)\n",
        "YVALID7 = np.log(YVALID)\n",
        "YVALID8 = np.log(YVALID)\n",
        "YVALID9 = np.log(YVALID)\n",
        "YVALID10 = np.log(YVALID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sJEPVp5KX9V",
        "colab_type": "code",
        "outputId": "edb4b758-6935-4da3-b04d-084563aa0ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(YTRAIN)\n",
        "print(YVALID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14.155146   14.25540077 13.99987397 ... 13.89622717 14.01962743\n",
            " 14.20510844]\n",
            "[14.18781735 14.13775022 14.35822482 ... 13.45222284 13.89541857\n",
            " 13.70323965]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCtqjv-KKztM",
        "colab_type": "code",
        "outputId": "27cd09d7-99e5-4a4b-fc4e-ce5debf15cfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "t=YTRAIN.mean()\n",
        "ttemp=math.exp(t)\n",
        "print(ttemp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1168362.850785694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfe4MC9n_CBQ",
        "colab_type": "text"
      },
      "source": [
        "# Comparing neural network models with a linear regression and logistic regression models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5QV5jylDIUI",
        "colab_type": "text"
      },
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdFj7ZxS-8xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim =5, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTAfJdr3DVFs",
        "colab_type": "code",
        "outputId": "72c2eda6-039a-41c2-ec9d-ed46b2da92d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='mse', optimizer = 'rmsprop', metrics=['mae'])\n",
        "h=model.fit(XTRAIN, YTRAIN1,validation_data=(XVALID, YVALID1), epochs = 500, batch_size=100, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 181.6570 - mae: 13.4691 - val_loss: 181.6207 - val_mae: 13.4676\n",
            "Epoch 2/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 181.4767 - mae: 13.4624 - val_loss: 181.4512 - val_mae: 13.4614\n",
            "Epoch 3/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 181.3043 - mae: 13.4561 - val_loss: 181.2813 - val_mae: 13.4551\n",
            "Epoch 4/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 181.1314 - mae: 13.4497 - val_loss: 181.1106 - val_mae: 13.4488\n",
            "Epoch 5/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 180.9558 - mae: 13.4433 - val_loss: 180.9353 - val_mae: 13.4424\n",
            "Epoch 6/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 180.7770 - mae: 13.4367 - val_loss: 180.7566 - val_mae: 13.4359\n",
            "Epoch 7/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 180.5939 - mae: 13.4300 - val_loss: 180.5723 - val_mae: 13.4291\n",
            "Epoch 8/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 180.4067 - mae: 13.4232 - val_loss: 180.3831 - val_mae: 13.4223\n",
            "Epoch 9/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 180.2122 - mae: 13.4161 - val_loss: 180.1866 - val_mae: 13.4151\n",
            "Epoch 10/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 180.0136 - mae: 13.4089 - val_loss: 179.9858 - val_mae: 13.4078\n",
            "Epoch 11/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 179.8107 - mae: 13.4015 - val_loss: 179.7780 - val_mae: 13.4002\n",
            "Epoch 12/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 179.5993 - mae: 13.3938 - val_loss: 179.5610 - val_mae: 13.3923\n",
            "Epoch 13/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 179.3828 - mae: 13.3859 - val_loss: 179.3399 - val_mae: 13.3843\n",
            "Epoch 14/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 179.1591 - mae: 13.3778 - val_loss: 179.1093 - val_mae: 13.3759\n",
            "Epoch 15/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 178.9290 - mae: 13.3694 - val_loss: 178.8712 - val_mae: 13.3673\n",
            "Epoch 16/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 178.6922 - mae: 13.3608 - val_loss: 178.6286 - val_mae: 13.3584\n",
            "Epoch 17/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 178.4529 - mae: 13.3520 - val_loss: 178.3809 - val_mae: 13.3494\n",
            "Epoch 18/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 178.2064 - mae: 13.3430 - val_loss: 178.1266 - val_mae: 13.3401\n",
            "Epoch 19/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 177.9574 - mae: 13.3339 - val_loss: 177.8691 - val_mae: 13.3307\n",
            "Epoch 20/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 177.7055 - mae: 13.3247 - val_loss: 177.6118 - val_mae: 13.3212\n",
            "Epoch 21/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 177.4550 - mae: 13.3155 - val_loss: 177.3520 - val_mae: 13.3117\n",
            "Epoch 22/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 177.2038 - mae: 13.3063 - val_loss: 177.0936 - val_mae: 13.3022\n",
            "Epoch 23/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 176.9569 - mae: 13.2972 - val_loss: 176.8435 - val_mae: 13.2930\n",
            "Epoch 24/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 176.7115 - mae: 13.2882 - val_loss: 176.5916 - val_mae: 13.2837\n",
            "Epoch 25/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 176.4742 - mae: 13.2794 - val_loss: 176.3523 - val_mae: 13.2748\n",
            "Epoch 26/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 176.2427 - mae: 13.2708 - val_loss: 176.1159 - val_mae: 13.2661\n",
            "Epoch 27/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 176.0149 - mae: 13.2624 - val_loss: 175.8855 - val_mae: 13.2575\n",
            "Epoch 28/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 175.7954 - mae: 13.2542 - val_loss: 175.6660 - val_mae: 13.2494\n",
            "Epoch 29/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 175.5861 - mae: 13.2464 - val_loss: 175.4565 - val_mae: 13.2415\n",
            "Epoch 30/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 175.3847 - mae: 13.2389 - val_loss: 175.2548 - val_mae: 13.2340\n",
            "Epoch 31/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 175.1901 - mae: 13.2316 - val_loss: 175.0599 - val_mae: 13.2267\n",
            "Epoch 32/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 175.0040 - mae: 13.2246 - val_loss: 174.8759 - val_mae: 13.2198\n",
            "Epoch 33/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 174.8249 - mae: 13.2179 - val_loss: 174.6971 - val_mae: 13.2131\n",
            "Epoch 34/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 174.6513 - mae: 13.2113 - val_loss: 174.5247 - val_mae: 13.2066\n",
            "Epoch 35/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 174.4831 - mae: 13.2050 - val_loss: 174.3575 - val_mae: 13.2003\n",
            "Epoch 36/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 174.3193 - mae: 13.1988 - val_loss: 174.1950 - val_mae: 13.1941\n",
            "Epoch 37/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 174.1597 - mae: 13.1928 - val_loss: 174.0362 - val_mae: 13.1881\n",
            "Epoch 38/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 174.0040 - mae: 13.1869 - val_loss: 173.8817 - val_mae: 13.1823\n",
            "Epoch 39/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 173.8521 - mae: 13.1811 - val_loss: 173.7312 - val_mae: 13.1766\n",
            "Epoch 40/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 173.7034 - mae: 13.1755 - val_loss: 173.5841 - val_mae: 13.1710\n",
            "Epoch 41/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 173.5585 - mae: 13.1700 - val_loss: 173.4404 - val_mae: 13.1655\n",
            "Epoch 42/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 173.4164 - mae: 13.1646 - val_loss: 173.3001 - val_mae: 13.1602\n",
            "Epoch 43/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 173.2778 - mae: 13.1593 - val_loss: 173.1628 - val_mae: 13.1550\n",
            "Epoch 44/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 173.1420 - mae: 13.1542 - val_loss: 173.0288 - val_mae: 13.1499\n",
            "Epoch 45/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 173.0097 - mae: 13.1491 - val_loss: 172.8978 - val_mae: 13.1449\n",
            "Epoch 46/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.8801 - mae: 13.1442 - val_loss: 172.7700 - val_mae: 13.1400\n",
            "Epoch 47/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.7537 - mae: 13.1394 - val_loss: 172.6450 - val_mae: 13.1353\n",
            "Epoch 48/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.6304 - mae: 13.1347 - val_loss: 172.5231 - val_mae: 13.1306\n",
            "Epoch 49/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.5097 - mae: 13.1301 - val_loss: 172.4040 - val_mae: 13.1261\n",
            "Epoch 50/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.3923 - mae: 13.1256 - val_loss: 172.2879 - val_mae: 13.1216\n",
            "Epoch 51/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.2774 - mae: 13.1212 - val_loss: 172.1747 - val_mae: 13.1173\n",
            "Epoch 52/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.1655 - mae: 13.1170 - val_loss: 172.0643 - val_mae: 13.1131\n",
            "Epoch 53/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.0565 - mae: 13.1128 - val_loss: 171.9568 - val_mae: 13.1090\n",
            "Epoch 54/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.9501 - mae: 13.1087 - val_loss: 171.8519 - val_mae: 13.1050\n",
            "Epoch 55/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.8465 - mae: 13.1048 - val_loss: 171.7498 - val_mae: 13.1011\n",
            "Epoch 56/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.7458 - mae: 13.1009 - val_loss: 171.6503 - val_mae: 13.0973\n",
            "Epoch 57/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.6474 - mae: 13.0972 - val_loss: 171.5535 - val_mae: 13.0936\n",
            "Epoch 58/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.5518 - mae: 13.0935 - val_loss: 171.4592 - val_mae: 13.0900\n",
            "Epoch 59/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.4585 - mae: 13.0900 - val_loss: 171.3674 - val_mae: 13.0865\n",
            "Epoch 60/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.3680 - mae: 13.0865 - val_loss: 171.2781 - val_mae: 13.0831\n",
            "Epoch 61/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.2797 - mae: 13.0831 - val_loss: 171.1912 - val_mae: 13.0797\n",
            "Epoch 62/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.1939 - mae: 13.0799 - val_loss: 171.1066 - val_mae: 13.0765\n",
            "Epoch 63/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.1105 - mae: 13.0767 - val_loss: 171.0244 - val_mae: 13.0734\n",
            "Epoch 64/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.0293 - mae: 13.0735 - val_loss: 170.9445 - val_mae: 13.0703\n",
            "Epoch 65/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.9506 - mae: 13.0705 - val_loss: 170.8668 - val_mae: 13.0673\n",
            "Epoch 66/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.8738 - mae: 13.0676 - val_loss: 170.7913 - val_mae: 13.0644\n",
            "Epoch 67/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.7992 - mae: 13.0647 - val_loss: 170.7180 - val_mae: 13.0616\n",
            "Epoch 68/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.7269 - mae: 13.0620 - val_loss: 170.6467 - val_mae: 13.0589\n",
            "Epoch 69/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.6564 - mae: 13.0593 - val_loss: 170.5774 - val_mae: 13.0562\n",
            "Epoch 70/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.5883 - mae: 13.0567 - val_loss: 170.5102 - val_mae: 13.0537\n",
            "Epoch 71/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.5220 - mae: 13.0541 - val_loss: 170.4449 - val_mae: 13.0512\n",
            "Epoch 72/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.4576 - mae: 13.0517 - val_loss: 170.3816 - val_mae: 13.0487\n",
            "Epoch 73/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.3951 - mae: 13.0493 - val_loss: 170.3201 - val_mae: 13.0464\n",
            "Epoch 74/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.3344 - mae: 13.0469 - val_loss: 170.2604 - val_mae: 13.0441\n",
            "Epoch 75/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.2756 - mae: 13.0447 - val_loss: 170.2025 - val_mae: 13.0419\n",
            "Epoch 76/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.2184 - mae: 13.0425 - val_loss: 170.1463 - val_mae: 13.0397\n",
            "Epoch 77/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.1629 - mae: 13.0403 - val_loss: 170.0918 - val_mae: 13.0376\n",
            "Epoch 78/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.1093 - mae: 13.0383 - val_loss: 170.0388 - val_mae: 13.0356\n",
            "Epoch 79/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.0571 - mae: 13.0363 - val_loss: 169.9875 - val_mae: 13.0336\n",
            "Epoch 80/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.0066 - mae: 13.0344 - val_loss: 169.9378 - val_mae: 13.0317\n",
            "Epoch 81/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.9575 - mae: 13.0325 - val_loss: 169.8896 - val_mae: 13.0299\n",
            "Epoch 82/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.9100 - mae: 13.0306 - val_loss: 169.8428 - val_mae: 13.0281\n",
            "Epoch 83/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.8639 - mae: 13.0289 - val_loss: 169.7975 - val_mae: 13.0263\n",
            "Epoch 84/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.8193 - mae: 13.0272 - val_loss: 169.7536 - val_mae: 13.0246\n",
            "Epoch 85/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.7759 - mae: 13.0255 - val_loss: 169.7110 - val_mae: 13.0230\n",
            "Epoch 86/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.7340 - mae: 13.0239 - val_loss: 169.6697 - val_mae: 13.0214\n",
            "Epoch 87/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.6934 - mae: 13.0223 - val_loss: 169.6298 - val_mae: 13.0199\n",
            "Epoch 88/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.6540 - mae: 13.0208 - val_loss: 169.5911 - val_mae: 13.0184\n",
            "Epoch 89/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.6159 - mae: 13.0193 - val_loss: 169.5537 - val_mae: 13.0170\n",
            "Epoch 90/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.5789 - mae: 13.0179 - val_loss: 169.5173 - val_mae: 13.0156\n",
            "Epoch 91/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.5431 - mae: 13.0165 - val_loss: 169.4821 - val_mae: 13.0142\n",
            "Epoch 92/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.5085 - mae: 13.0152 - val_loss: 169.4480 - val_mae: 13.0129\n",
            "Epoch 93/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.4749 - mae: 13.0139 - val_loss: 169.4150 - val_mae: 13.0116\n",
            "Epoch 94/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.4424 - mae: 13.0127 - val_loss: 169.3831 - val_mae: 13.0104\n",
            "Epoch 95/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.4110 - mae: 13.0115 - val_loss: 169.3522 - val_mae: 13.0092\n",
            "Epoch 96/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.3804 - mae: 13.0103 - val_loss: 169.3222 - val_mae: 13.0081\n",
            "Epoch 97/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.3509 - mae: 13.0092 - val_loss: 169.2932 - val_mae: 13.0069\n",
            "Epoch 98/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.3224 - mae: 13.0081 - val_loss: 169.2651 - val_mae: 13.0059\n",
            "Epoch 99/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.2947 - mae: 13.0070 - val_loss: 169.2380 - val_mae: 13.0048\n",
            "Epoch 100/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.2680 - mae: 13.0060 - val_loss: 169.2117 - val_mae: 13.0038\n",
            "Epoch 101/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.2421 - mae: 13.0050 - val_loss: 169.1863 - val_mae: 13.0028\n",
            "Epoch 102/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.2170 - mae: 13.0040 - val_loss: 169.1617 - val_mae: 13.0019\n",
            "Epoch 103/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.1929 - mae: 13.0031 - val_loss: 169.1379 - val_mae: 13.0010\n",
            "Epoch 104/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.1694 - mae: 13.0022 - val_loss: 169.1148 - val_mae: 13.0001\n",
            "Epoch 105/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.1467 - mae: 13.0013 - val_loss: 169.0925 - val_mae: 12.9992\n",
            "Epoch 106/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.1247 - mae: 13.0005 - val_loss: 169.0709 - val_mae: 12.9984\n",
            "Epoch 107/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.1035 - mae: 12.9996 - val_loss: 169.0500 - val_mae: 12.9976\n",
            "Epoch 108/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.0829 - mae: 12.9988 - val_loss: 169.0298 - val_mae: 12.9968\n",
            "Epoch 109/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.0630 - mae: 12.9981 - val_loss: 169.0103 - val_mae: 12.9961\n",
            "Epoch 110/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.0438 - mae: 12.9973 - val_loss: 168.9914 - val_mae: 12.9953\n",
            "Epoch 111/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.0251 - mae: 12.9966 - val_loss: 168.9731 - val_mae: 12.9946\n",
            "Epoch 112/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.0072 - mae: 12.9959 - val_loss: 168.9554 - val_mae: 12.9939\n",
            "Epoch 113/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.9898 - mae: 12.9953 - val_loss: 168.9384 - val_mae: 12.9933\n",
            "Epoch 114/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.9729 - mae: 12.9946 - val_loss: 168.9218 - val_mae: 12.9926\n",
            "Epoch 115/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.9567 - mae: 12.9940 - val_loss: 168.9058 - val_mae: 12.9920\n",
            "Epoch 116/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.9409 - mae: 12.9934 - val_loss: 168.8904 - val_mae: 12.9914\n",
            "Epoch 117/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.9257 - mae: 12.9928 - val_loss: 168.8754 - val_mae: 12.9909\n",
            "Epoch 118/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.9110 - mae: 12.9922 - val_loss: 168.8610 - val_mae: 12.9903\n",
            "Epoch 119/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.8968 - mae: 12.9917 - val_loss: 168.8470 - val_mae: 12.9898\n",
            "Epoch 120/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.8829 - mae: 12.9912 - val_loss: 168.8334 - val_mae: 12.9892\n",
            "Epoch 121/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.8697 - mae: 12.9906 - val_loss: 168.8204 - val_mae: 12.9887\n",
            "Epoch 122/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.8568 - mae: 12.9901 - val_loss: 168.8077 - val_mae: 12.9882\n",
            "Epoch 123/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.8444 - mae: 12.9897 - val_loss: 168.7955 - val_mae: 12.9878\n",
            "Epoch 124/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.8323 - mae: 12.9892 - val_loss: 168.7837 - val_mae: 12.9873\n",
            "Epoch 125/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.8207 - mae: 12.9888 - val_loss: 168.7723 - val_mae: 12.9869\n",
            "Epoch 126/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.8095 - mae: 12.9883 - val_loss: 168.7612 - val_mae: 12.9865\n",
            "Epoch 127/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7986 - mae: 12.9879 - val_loss: 168.7506 - val_mae: 12.9860\n",
            "Epoch 128/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7881 - mae: 12.9875 - val_loss: 168.7402 - val_mae: 12.9857\n",
            "Epoch 129/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7779 - mae: 12.9871 - val_loss: 168.7303 - val_mae: 12.9853\n",
            "Epoch 130/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.7681 - mae: 12.9867 - val_loss: 168.7207 - val_mae: 12.9849\n",
            "Epoch 131/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7587 - mae: 12.9864 - val_loss: 168.7113 - val_mae: 12.9845\n",
            "Epoch 132/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7495 - mae: 12.9860 - val_loss: 168.7023 - val_mae: 12.9842\n",
            "Epoch 133/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7406 - mae: 12.9857 - val_loss: 168.6936 - val_mae: 12.9839\n",
            "Epoch 134/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7321 - mae: 12.9853 - val_loss: 168.6852 - val_mae: 12.9835\n",
            "Epoch 135/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7238 - mae: 12.9850 - val_loss: 168.6771 - val_mae: 12.9832\n",
            "Epoch 136/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7158 - mae: 12.9847 - val_loss: 168.6693 - val_mae: 12.9829\n",
            "Epoch 137/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7081 - mae: 12.9844 - val_loss: 168.6617 - val_mae: 12.9826\n",
            "Epoch 138/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7006 - mae: 12.9841 - val_loss: 168.6543 - val_mae: 12.9823\n",
            "Epoch 139/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6934 - mae: 12.9838 - val_loss: 168.6472 - val_mae: 12.9821\n",
            "Epoch 140/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6864 - mae: 12.9836 - val_loss: 168.6404 - val_mae: 12.9818\n",
            "Epoch 141/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6796 - mae: 12.9833 - val_loss: 168.6337 - val_mae: 12.9815\n",
            "Epoch 142/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6731 - mae: 12.9831 - val_loss: 168.6273 - val_mae: 12.9813\n",
            "Epoch 143/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6668 - mae: 12.9828 - val_loss: 168.6211 - val_mae: 12.9811\n",
            "Epoch 144/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6607 - mae: 12.9826 - val_loss: 168.6152 - val_mae: 12.9808\n",
            "Epoch 145/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6549 - mae: 12.9824 - val_loss: 168.6094 - val_mae: 12.9806\n",
            "Epoch 146/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6491 - mae: 12.9821 - val_loss: 168.6038 - val_mae: 12.9804\n",
            "Epoch 147/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6437 - mae: 12.9819 - val_loss: 168.5984 - val_mae: 12.9802\n",
            "Epoch 148/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6384 - mae: 12.9817 - val_loss: 168.5932 - val_mae: 12.9800\n",
            "Epoch 149/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6332 - mae: 12.9815 - val_loss: 168.5882 - val_mae: 12.9798\n",
            "Epoch 150/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6283 - mae: 12.9813 - val_loss: 168.5833 - val_mae: 12.9796\n",
            "Epoch 151/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6235 - mae: 12.9812 - val_loss: 168.5786 - val_mae: 12.9794\n",
            "Epoch 152/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6189 - mae: 12.9810 - val_loss: 168.5741 - val_mae: 12.9792\n",
            "Epoch 153/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6144 - mae: 12.9808 - val_loss: 168.5697 - val_mae: 12.9791\n",
            "Epoch 154/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6101 - mae: 12.9806 - val_loss: 168.5654 - val_mae: 12.9789\n",
            "Epoch 155/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6059 - mae: 12.9805 - val_loss: 168.5613 - val_mae: 12.9788\n",
            "Epoch 156/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.6018 - mae: 12.9803 - val_loss: 168.5574 - val_mae: 12.9786\n",
            "Epoch 157/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5980 - mae: 12.9802 - val_loss: 168.5535 - val_mae: 12.9785\n",
            "Epoch 158/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5942 - mae: 12.9800 - val_loss: 168.5499 - val_mae: 12.9783\n",
            "Epoch 159/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5906 - mae: 12.9799 - val_loss: 168.5463 - val_mae: 12.9782\n",
            "Epoch 160/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5871 - mae: 12.9797 - val_loss: 168.5428 - val_mae: 12.9780\n",
            "Epoch 161/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5836 - mae: 12.9796 - val_loss: 168.5395 - val_mae: 12.9779\n",
            "Epoch 162/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5804 - mae: 12.9795 - val_loss: 168.5363 - val_mae: 12.9778\n",
            "Epoch 163/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5772 - mae: 12.9794 - val_loss: 168.5332 - val_mae: 12.9777\n",
            "Epoch 164/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5741 - mae: 12.9793 - val_loss: 168.5302 - val_mae: 12.9776\n",
            "Epoch 165/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5712 - mae: 12.9791 - val_loss: 168.5273 - val_mae: 12.9774\n",
            "Epoch 166/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5683 - mae: 12.9790 - val_loss: 168.5244 - val_mae: 12.9773\n",
            "Epoch 167/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5656 - mae: 12.9789 - val_loss: 168.5217 - val_mae: 12.9772\n",
            "Epoch 168/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5629 - mae: 12.9788 - val_loss: 168.5191 - val_mae: 12.9771\n",
            "Epoch 169/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5603 - mae: 12.9787 - val_loss: 168.5166 - val_mae: 12.9770\n",
            "Epoch 170/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5578 - mae: 12.9786 - val_loss: 168.5142 - val_mae: 12.9769\n",
            "Epoch 171/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5554 - mae: 12.9785 - val_loss: 168.5118 - val_mae: 12.9768\n",
            "Epoch 172/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5531 - mae: 12.9784 - val_loss: 168.5095 - val_mae: 12.9768\n",
            "Epoch 173/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5509 - mae: 12.9784 - val_loss: 168.5073 - val_mae: 12.9767\n",
            "Epoch 174/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5487 - mae: 12.9783 - val_loss: 168.5052 - val_mae: 12.9766\n",
            "Epoch 175/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5466 - mae: 12.9782 - val_loss: 168.5031 - val_mae: 12.9765\n",
            "Epoch 176/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5446 - mae: 12.9781 - val_loss: 168.5011 - val_mae: 12.9764\n",
            "Epoch 177/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5427 - mae: 12.9780 - val_loss: 168.4992 - val_mae: 12.9764\n",
            "Epoch 178/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5408 - mae: 12.9780 - val_loss: 168.4974 - val_mae: 12.9763\n",
            "Epoch 179/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5389 - mae: 12.9779 - val_loss: 168.4956 - val_mae: 12.9762\n",
            "Epoch 180/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5372 - mae: 12.9778 - val_loss: 168.4938 - val_mae: 12.9762\n",
            "Epoch 181/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5355 - mae: 12.9778 - val_loss: 168.4922 - val_mae: 12.9761\n",
            "Epoch 182/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5338 - mae: 12.9777 - val_loss: 168.4906 - val_mae: 12.9760\n",
            "Epoch 183/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5322 - mae: 12.9776 - val_loss: 168.4890 - val_mae: 12.9760\n",
            "Epoch 184/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5307 - mae: 12.9776 - val_loss: 168.4875 - val_mae: 12.9759\n",
            "Epoch 185/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5292 - mae: 12.9775 - val_loss: 168.4860 - val_mae: 12.9759\n",
            "Epoch 186/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5278 - mae: 12.9775 - val_loss: 168.4846 - val_mae: 12.9758\n",
            "Epoch 187/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5264 - mae: 12.9774 - val_loss: 168.4832 - val_mae: 12.9757\n",
            "Epoch 188/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5251 - mae: 12.9774 - val_loss: 168.4819 - val_mae: 12.9757\n",
            "Epoch 189/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5238 - mae: 12.9773 - val_loss: 168.4807 - val_mae: 12.9756\n",
            "Epoch 190/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5225 - mae: 12.9773 - val_loss: 168.4795 - val_mae: 12.9756\n",
            "Epoch 191/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5213 - mae: 12.9772 - val_loss: 168.4783 - val_mae: 12.9756\n",
            "Epoch 192/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5201 - mae: 12.9772 - val_loss: 168.4771 - val_mae: 12.9755\n",
            "Epoch 193/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5190 - mae: 12.9771 - val_loss: 168.4760 - val_mae: 12.9755\n",
            "Epoch 194/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5179 - mae: 12.9771 - val_loss: 168.4750 - val_mae: 12.9754\n",
            "Epoch 195/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5169 - mae: 12.9770 - val_loss: 168.4740 - val_mae: 12.9754\n",
            "Epoch 196/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5159 - mae: 12.9770 - val_loss: 168.4730 - val_mae: 12.9753\n",
            "Epoch 197/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5149 - mae: 12.9770 - val_loss: 168.4720 - val_mae: 12.9753\n",
            "Epoch 198/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5140 - mae: 12.9769 - val_loss: 168.4710 - val_mae: 12.9753\n",
            "Epoch 199/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5130 - mae: 12.9769 - val_loss: 168.4702 - val_mae: 12.9752\n",
            "Epoch 200/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5121 - mae: 12.9769 - val_loss: 168.4693 - val_mae: 12.9752\n",
            "Epoch 201/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5113 - mae: 12.9768 - val_loss: 168.4684 - val_mae: 12.9752\n",
            "Epoch 202/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5105 - mae: 12.9768 - val_loss: 168.4676 - val_mae: 12.9751\n",
            "Epoch 203/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5097 - mae: 12.9768 - val_loss: 168.4669 - val_mae: 12.9751\n",
            "Epoch 204/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5089 - mae: 12.9767 - val_loss: 168.4661 - val_mae: 12.9751\n",
            "Epoch 205/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5082 - mae: 12.9767 - val_loss: 168.4654 - val_mae: 12.9751\n",
            "Epoch 206/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5074 - mae: 12.9767 - val_loss: 168.4647 - val_mae: 12.9750\n",
            "Epoch 207/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5068 - mae: 12.9767 - val_loss: 168.4640 - val_mae: 12.9750\n",
            "Epoch 208/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5061 - mae: 12.9766 - val_loss: 168.4633 - val_mae: 12.9750\n",
            "Epoch 209/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5054 - mae: 12.9766 - val_loss: 168.4627 - val_mae: 12.9750\n",
            "Epoch 210/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5048 - mae: 12.9766 - val_loss: 168.4621 - val_mae: 12.9749\n",
            "Epoch 211/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5042 - mae: 12.9766 - val_loss: 168.4615 - val_mae: 12.9749\n",
            "Epoch 212/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5036 - mae: 12.9765 - val_loss: 168.4609 - val_mae: 12.9749\n",
            "Epoch 213/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5031 - mae: 12.9765 - val_loss: 168.4604 - val_mae: 12.9749\n",
            "Epoch 214/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5025 - mae: 12.9765 - val_loss: 168.4598 - val_mae: 12.9748\n",
            "Epoch 215/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5020 - mae: 12.9765 - val_loss: 168.4593 - val_mae: 12.9748\n",
            "Epoch 216/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5015 - mae: 12.9764 - val_loss: 168.4588 - val_mae: 12.9748\n",
            "Epoch 217/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5010 - mae: 12.9764 - val_loss: 168.4583 - val_mae: 12.9748\n",
            "Epoch 218/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5005 - mae: 12.9764 - val_loss: 168.4579 - val_mae: 12.9748\n",
            "Epoch 219/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5001 - mae: 12.9764 - val_loss: 168.4574 - val_mae: 12.9748\n",
            "Epoch 220/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4996 - mae: 12.9764 - val_loss: 168.4570 - val_mae: 12.9747\n",
            "Epoch 221/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4992 - mae: 12.9764 - val_loss: 168.4566 - val_mae: 12.9747\n",
            "Epoch 222/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4988 - mae: 12.9763 - val_loss: 168.4562 - val_mae: 12.9747\n",
            "Epoch 223/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4984 - mae: 12.9763 - val_loss: 168.4558 - val_mae: 12.9747\n",
            "Epoch 224/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4980 - mae: 12.9763 - val_loss: 168.4554 - val_mae: 12.9747\n",
            "Epoch 225/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4976 - mae: 12.9763 - val_loss: 168.4550 - val_mae: 12.9747\n",
            "Epoch 226/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4973 - mae: 12.9763 - val_loss: 168.4547 - val_mae: 12.9746\n",
            "Epoch 227/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4969 - mae: 12.9763 - val_loss: 168.4544 - val_mae: 12.9746\n",
            "Epoch 228/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4966 - mae: 12.9763 - val_loss: 168.4540 - val_mae: 12.9746\n",
            "Epoch 229/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4963 - mae: 12.9762 - val_loss: 168.4537 - val_mae: 12.9746\n",
            "Epoch 230/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4960 - mae: 12.9762 - val_loss: 168.4534 - val_mae: 12.9746\n",
            "Epoch 231/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4957 - mae: 12.9762 - val_loss: 168.4531 - val_mae: 12.9746\n",
            "Epoch 232/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4954 - mae: 12.9762 - val_loss: 168.4528 - val_mae: 12.9746\n",
            "Epoch 233/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4951 - mae: 12.9762 - val_loss: 168.4525 - val_mae: 12.9746\n",
            "Epoch 234/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4948 - mae: 12.9762 - val_loss: 168.4523 - val_mae: 12.9746\n",
            "Epoch 235/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4946 - mae: 12.9762 - val_loss: 168.4520 - val_mae: 12.9745\n",
            "Epoch 236/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4943 - mae: 12.9762 - val_loss: 168.4518 - val_mae: 12.9745\n",
            "Epoch 237/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4941 - mae: 12.9762 - val_loss: 168.4515 - val_mae: 12.9745\n",
            "Epoch 238/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4938 - mae: 12.9762 - val_loss: 168.4513 - val_mae: 12.9745\n",
            "Epoch 239/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4936 - mae: 12.9761 - val_loss: 168.4511 - val_mae: 12.9745\n",
            "Epoch 240/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4934 - mae: 12.9761 - val_loss: 168.4509 - val_mae: 12.9745\n",
            "Epoch 241/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4932 - mae: 12.9761 - val_loss: 168.4507 - val_mae: 12.9745\n",
            "Epoch 242/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4930 - mae: 12.9761 - val_loss: 168.4505 - val_mae: 12.9745\n",
            "Epoch 243/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4928 - mae: 12.9761 - val_loss: 168.4503 - val_mae: 12.9745\n",
            "Epoch 244/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4925 - mae: 12.9761 - val_loss: 168.4501 - val_mae: 12.9745\n",
            "Epoch 245/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4924 - mae: 12.9761 - val_loss: 168.4499 - val_mae: 12.9745\n",
            "Epoch 246/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4922 - mae: 12.9761 - val_loss: 168.4497 - val_mae: 12.9745\n",
            "Epoch 247/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4920 - mae: 12.9761 - val_loss: 168.4495 - val_mae: 12.9744\n",
            "Epoch 248/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4919 - mae: 12.9761 - val_loss: 168.4494 - val_mae: 12.9744\n",
            "Epoch 249/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4917 - mae: 12.9761 - val_loss: 168.4492 - val_mae: 12.9744\n",
            "Epoch 250/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4916 - mae: 12.9761 - val_loss: 168.4491 - val_mae: 12.9744\n",
            "Epoch 251/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4914 - mae: 12.9761 - val_loss: 168.4489 - val_mae: 12.9744\n",
            "Epoch 252/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4913 - mae: 12.9761 - val_loss: 168.4488 - val_mae: 12.9744\n",
            "Epoch 253/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4911 - mae: 12.9760 - val_loss: 168.4486 - val_mae: 12.9744\n",
            "Epoch 254/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4910 - mae: 12.9760 - val_loss: 168.4485 - val_mae: 12.9744\n",
            "Epoch 255/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4909 - mae: 12.9760 - val_loss: 168.4484 - val_mae: 12.9744\n",
            "Epoch 256/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4907 - mae: 12.9760 - val_loss: 168.4483 - val_mae: 12.9744\n",
            "Epoch 257/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4906 - mae: 12.9760 - val_loss: 168.4481 - val_mae: 12.9744\n",
            "Epoch 258/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4905 - mae: 12.9760 - val_loss: 168.4480 - val_mae: 12.9744\n",
            "Epoch 259/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4904 - mae: 12.9760 - val_loss: 168.4479 - val_mae: 12.9744\n",
            "Epoch 260/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4902 - mae: 12.9760 - val_loss: 168.4478 - val_mae: 12.9744\n",
            "Epoch 261/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4901 - mae: 12.9760 - val_loss: 168.4477 - val_mae: 12.9744\n",
            "Epoch 262/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4900 - mae: 12.9760 - val_loss: 168.4476 - val_mae: 12.9744\n",
            "Epoch 263/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4899 - mae: 12.9760 - val_loss: 168.4475 - val_mae: 12.9744\n",
            "Epoch 264/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4898 - mae: 12.9760 - val_loss: 168.4474 - val_mae: 12.9744\n",
            "Epoch 265/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4898 - mae: 12.9760 - val_loss: 168.4473 - val_mae: 12.9744\n",
            "Epoch 266/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4897 - mae: 12.9760 - val_loss: 168.4472 - val_mae: 12.9744\n",
            "Epoch 267/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4896 - mae: 12.9760 - val_loss: 168.4471 - val_mae: 12.9744\n",
            "Epoch 268/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4895 - mae: 12.9760 - val_loss: 168.4471 - val_mae: 12.9743\n",
            "Epoch 269/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4894 - mae: 12.9760 - val_loss: 168.4470 - val_mae: 12.9743\n",
            "Epoch 270/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4893 - mae: 12.9760 - val_loss: 168.4469 - val_mae: 12.9743\n",
            "Epoch 271/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4893 - mae: 12.9760 - val_loss: 168.4468 - val_mae: 12.9743\n",
            "Epoch 272/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4892 - mae: 12.9760 - val_loss: 168.4467 - val_mae: 12.9743\n",
            "Epoch 273/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4891 - mae: 12.9760 - val_loss: 168.4467 - val_mae: 12.9743\n",
            "Epoch 274/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4890 - mae: 12.9760 - val_loss: 168.4466 - val_mae: 12.9743\n",
            "Epoch 275/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4890 - mae: 12.9760 - val_loss: 168.4465 - val_mae: 12.9743\n",
            "Epoch 276/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4889 - mae: 12.9760 - val_loss: 168.4465 - val_mae: 12.9743\n",
            "Epoch 277/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4889 - mae: 12.9760 - val_loss: 168.4464 - val_mae: 12.9743\n",
            "Epoch 278/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4888 - mae: 12.9760 - val_loss: 168.4464 - val_mae: 12.9743\n",
            "Epoch 279/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4888 - mae: 12.9760 - val_loss: 168.4463 - val_mae: 12.9743\n",
            "Epoch 280/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4887 - mae: 12.9760 - val_loss: 168.4462 - val_mae: 12.9743\n",
            "Epoch 281/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4887 - mae: 12.9760 - val_loss: 168.4462 - val_mae: 12.9743\n",
            "Epoch 282/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4886 - mae: 12.9760 - val_loss: 168.4462 - val_mae: 12.9743\n",
            "Epoch 283/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4886 - mae: 12.9760 - val_loss: 168.4461 - val_mae: 12.9743\n",
            "Epoch 284/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4885 - mae: 12.9759 - val_loss: 168.4461 - val_mae: 12.9743\n",
            "Epoch 285/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4885 - mae: 12.9759 - val_loss: 168.4460 - val_mae: 12.9743\n",
            "Epoch 286/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4884 - mae: 12.9759 - val_loss: 168.4460 - val_mae: 12.9743\n",
            "Epoch 287/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4884 - mae: 12.9759 - val_loss: 168.4459 - val_mae: 12.9743\n",
            "Epoch 288/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4883 - mae: 12.9759 - val_loss: 168.4459 - val_mae: 12.9743\n",
            "Epoch 289/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4883 - mae: 12.9759 - val_loss: 168.4458 - val_mae: 12.9743\n",
            "Epoch 290/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4882 - mae: 12.9759 - val_loss: 168.4458 - val_mae: 12.9743\n",
            "Epoch 291/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4882 - mae: 12.9759 - val_loss: 168.4458 - val_mae: 12.9743\n",
            "Epoch 292/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4882 - mae: 12.9759 - val_loss: 168.4457 - val_mae: 12.9743\n",
            "Epoch 293/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4881 - mae: 12.9759 - val_loss: 168.4457 - val_mae: 12.9743\n",
            "Epoch 294/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4881 - mae: 12.9759 - val_loss: 168.4457 - val_mae: 12.9743\n",
            "Epoch 295/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4880 - mae: 12.9759 - val_loss: 168.4456 - val_mae: 12.9743\n",
            "Epoch 296/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4880 - mae: 12.9759 - val_loss: 168.4456 - val_mae: 12.9743\n",
            "Epoch 297/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4880 - mae: 12.9759 - val_loss: 168.4456 - val_mae: 12.9743\n",
            "Epoch 298/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4880 - mae: 12.9759 - val_loss: 168.4455 - val_mae: 12.9743\n",
            "Epoch 299/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4880 - mae: 12.9759 - val_loss: 168.4455 - val_mae: 12.9743\n",
            "Epoch 300/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4879 - mae: 12.9759 - val_loss: 168.4455 - val_mae: 12.9743\n",
            "Epoch 301/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4879 - mae: 12.9759 - val_loss: 168.4455 - val_mae: 12.9743\n",
            "Epoch 302/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4879 - mae: 12.9759 - val_loss: 168.4454 - val_mae: 12.9743\n",
            "Epoch 303/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4879 - mae: 12.9759 - val_loss: 168.4454 - val_mae: 12.9743\n",
            "Epoch 304/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4878 - mae: 12.9759 - val_loss: 168.4454 - val_mae: 12.9743\n",
            "Epoch 305/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4878 - mae: 12.9759 - val_loss: 168.4454 - val_mae: 12.9743\n",
            "Epoch 306/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4878 - mae: 12.9759 - val_loss: 168.4454 - val_mae: 12.9743\n",
            "Epoch 307/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4877 - mae: 12.9759 - val_loss: 168.4453 - val_mae: 12.9743\n",
            "Epoch 308/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4877 - mae: 12.9759 - val_loss: 168.4453 - val_mae: 12.9743\n",
            "Epoch 309/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4877 - mae: 12.9759 - val_loss: 168.4453 - val_mae: 12.9743\n",
            "Epoch 310/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4877 - mae: 12.9759 - val_loss: 168.4453 - val_mae: 12.9743\n",
            "Epoch 311/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4877 - mae: 12.9759 - val_loss: 168.4453 - val_mae: 12.9743\n",
            "Epoch 312/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4876 - mae: 12.9759 - val_loss: 168.4452 - val_mae: 12.9743\n",
            "Epoch 313/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4876 - mae: 12.9759 - val_loss: 168.4452 - val_mae: 12.9743\n",
            "Epoch 314/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4876 - mae: 12.9759 - val_loss: 168.4452 - val_mae: 12.9743\n",
            "Epoch 315/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4876 - mae: 12.9759 - val_loss: 168.4452 - val_mae: 12.9743\n",
            "Epoch 316/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4876 - mae: 12.9759 - val_loss: 168.4452 - val_mae: 12.9743\n",
            "Epoch 317/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4452 - val_mae: 12.9743\n",
            "Epoch 318/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4451 - val_mae: 12.9743\n",
            "Epoch 319/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4451 - val_mae: 12.9743\n",
            "Epoch 320/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4451 - val_mae: 12.9743\n",
            "Epoch 321/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4451 - val_mae: 12.9743\n",
            "Epoch 322/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4451 - val_mae: 12.9743\n",
            "Epoch 323/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4451 - val_mae: 12.9743\n",
            "Epoch 324/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4451 - val_mae: 12.9743\n",
            "Epoch 325/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 326/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4875 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 327/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 328/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 329/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 330/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 331/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 332/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 333/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 334/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 335/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 336/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4450 - val_mae: 12.9743\n",
            "Epoch 337/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 338/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 339/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 340/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 341/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 342/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 343/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 344/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 345/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 346/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 347/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 348/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 349/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 350/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4873 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 351/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 352/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 353/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 354/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 355/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 356/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 357/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 358/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 359/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 360/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 361/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 362/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 363/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 364/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 365/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 366/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 367/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 368/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 369/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 370/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 371/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 372/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 373/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 374/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 375/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 376/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 377/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 378/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 379/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 380/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 381/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 382/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 383/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 384/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 385/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 386/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 387/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 388/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 389/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 390/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 391/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 392/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 393/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 394/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 395/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 396/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 397/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 398/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 399/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 400/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 401/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 402/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 403/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 404/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 405/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 406/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 407/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 408/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 409/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 410/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 411/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 412/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 413/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 414/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 415/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 416/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 417/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 418/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 419/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 420/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 421/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 422/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 423/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 424/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 425/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 426/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 427/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 428/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 429/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 430/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 431/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 432/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 433/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 434/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 435/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 436/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 437/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 438/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 439/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 440/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 441/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 442/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 443/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 444/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 445/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 446/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 447/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 448/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 449/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 450/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 451/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 452/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 453/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 454/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 455/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 456/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 457/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 458/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 459/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 460/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 461/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 462/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 463/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 464/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 465/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 466/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 467/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 468/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 469/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 470/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 471/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 472/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 473/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 474/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 475/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 476/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 477/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 478/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 479/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 480/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 481/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 482/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 483/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 484/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 485/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 486/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 487/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 488/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 489/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 490/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 491/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 492/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 493/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 494/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 495/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 496/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 497/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 498/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 499/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 500/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WIRhc6AGfw0",
        "colab_type": "code",
        "outputId": "d79a4d0a-a87b-4433-b128-5065c70e3a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "import math\n",
        "P1 = model.predict(XVALID)\n",
        "YVALID1=np.exp(YVALID1)\n",
        "P1=np.exp(P1)\n",
        "MAE1 = abs(YVALID1 - P1)\n",
        "print(MAE1)\n",
        "M1=MAE1.mean()\n",
        "print(\"M1=\",M1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 590196.45391825 1091476.84171825 1591185.62971826 ... 1129580.11971825\n",
            "  1364829.28471825  786255.06431825]\n",
            " [ 590196.45391825 1091476.84171825 1591185.62971826 ... 1129580.11971825\n",
            "  1364829.28471825  786255.06431825]\n",
            " [ 590196.45391825 1091476.84171825 1591185.62971826 ... 1129580.11971825\n",
            "  1364829.28471825  786255.06431825]\n",
            " ...\n",
            " [ 590196.45391825 1091476.84171825 1591185.62971826 ... 1129580.11971825\n",
            "  1364829.28471825  786255.06431825]\n",
            " [ 590196.45391825 1091476.84171825 1591185.62971826 ... 1129580.11971825\n",
            "  1364829.28471825  786255.06431825]\n",
            " [ 590196.45391825 1091476.84171825 1591185.62971826 ... 1129580.11971825\n",
            "  1364829.28471825  786255.06431825]]\n",
            "M1= 1232766.2617315208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjQNnDYgkrMv",
        "colab_type": "code",
        "outputId": "477f8b80-30d4-4bb7-d092-89b1ec05b10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "import matplotlib.pyplot as plt \n",
        "plt.figure(figsize=(15, 13))\n",
        "plt.plot(h.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(h.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "min(h.history['val_loss'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x936 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168.44471740722656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yYYMaeSLY_B",
        "colab_type": "text"
      },
      "source": [
        "## Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iFdoP6ZLdaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Dense(1,input_dim = 5, activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIITLpjvLpE8",
        "colab_type": "code",
        "outputId": "006c77c3-0c1a-481c-dc7b-99e083761327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model3.compile(loss='mse', optimizer = 'rmsprop', metrics=['mae'])\n",
        "h3=model3.fit(XTRAIN, YTRAIN2,validation_data=(XVALID, YVALID2), epochs = 500, batch_size=100, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 194.9560 - mae: 13.9517 - val_loss: 194.3430 - val_mae: 13.9298\n",
            "Epoch 2/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 193.9162 - mae: 13.9150 - val_loss: 193.3492 - val_mae: 13.8947\n",
            "Epoch 3/500\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 192.9280 - mae: 13.8799 - val_loss: 192.3622 - val_mae: 13.8596\n",
            "Epoch 4/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 191.9461 - mae: 13.8449 - val_loss: 191.3791 - val_mae: 13.8246\n",
            "Epoch 5/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 190.9678 - mae: 13.8101 - val_loss: 190.4012 - val_mae: 13.7895\n",
            "Epoch 6/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 189.9919 - mae: 13.7750 - val_loss: 189.4236 - val_mae: 13.7545\n",
            "Epoch 7/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 189.0187 - mae: 13.7402 - val_loss: 188.4511 - val_mae: 13.7195\n",
            "Epoch 8/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 188.0483 - mae: 13.7052 - val_loss: 187.4804 - val_mae: 13.6845\n",
            "Epoch 9/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 187.0814 - mae: 13.6702 - val_loss: 186.5161 - val_mae: 13.6495\n",
            "Epoch 10/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 186.1182 - mae: 13.6351 - val_loss: 185.5525 - val_mae: 13.6144\n",
            "Epoch 11/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 185.1592 - mae: 13.6003 - val_loss: 184.5913 - val_mae: 13.5794\n",
            "Epoch 12/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 184.2013 - mae: 13.5653 - val_loss: 183.6345 - val_mae: 13.5444\n",
            "Epoch 13/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 183.2454 - mae: 13.5302 - val_loss: 182.6778 - val_mae: 13.5093\n",
            "Epoch 14/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 182.2926 - mae: 13.4953 - val_loss: 181.7267 - val_mae: 13.4744\n",
            "Epoch 15/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 181.3419 - mae: 13.4603 - val_loss: 180.7744 - val_mae: 13.4393\n",
            "Epoch 16/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 180.3948 - mae: 13.4253 - val_loss: 179.8271 - val_mae: 13.4043\n",
            "Epoch 17/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 179.4496 - mae: 13.3904 - val_loss: 178.8816 - val_mae: 13.3692\n",
            "Epoch 18/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 178.5073 - mae: 13.3554 - val_loss: 177.9405 - val_mae: 13.3342\n",
            "Epoch 19/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 177.5677 - mae: 13.3204 - val_loss: 177.0004 - val_mae: 13.2992\n",
            "Epoch 20/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 176.6309 - mae: 13.2853 - val_loss: 176.0640 - val_mae: 13.2642\n",
            "Epoch 21/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 175.6978 - mae: 13.2504 - val_loss: 175.1326 - val_mae: 13.2292\n",
            "Epoch 22/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 174.7675 - mae: 13.2154 - val_loss: 174.2029 - val_mae: 13.1942\n",
            "Epoch 23/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 173.8386 - mae: 13.1805 - val_loss: 173.2764 - val_mae: 13.1592\n",
            "Epoch 24/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.9147 - mae: 13.1456 - val_loss: 172.3518 - val_mae: 13.1242\n",
            "Epoch 25/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 171.9919 - mae: 13.1106 - val_loss: 171.4292 - val_mae: 13.0892\n",
            "Epoch 26/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 171.0712 - mae: 13.0756 - val_loss: 170.5089 - val_mae: 13.0542\n",
            "Epoch 27/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.1541 - mae: 13.0406 - val_loss: 169.5905 - val_mae: 13.0191\n",
            "Epoch 28/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.2382 - mae: 13.0056 - val_loss: 168.6762 - val_mae: 12.9841\n",
            "Epoch 29/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.3267 - mae: 12.9707 - val_loss: 167.7659 - val_mae: 12.9491\n",
            "Epoch 30/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 167.4172 - mae: 12.9356 - val_loss: 166.8566 - val_mae: 12.9141\n",
            "Epoch 31/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 166.5101 - mae: 12.9007 - val_loss: 165.9499 - val_mae: 12.8791\n",
            "Epoch 32/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 165.6064 - mae: 12.8658 - val_loss: 165.0469 - val_mae: 12.8441\n",
            "Epoch 33/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 164.7039 - mae: 12.8307 - val_loss: 164.1463 - val_mae: 12.8091\n",
            "Epoch 34/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 163.8051 - mae: 12.7958 - val_loss: 163.2468 - val_mae: 12.7741\n",
            "Epoch 35/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 162.9081 - mae: 12.7608 - val_loss: 162.3510 - val_mae: 12.7391\n",
            "Epoch 36/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 162.0146 - mae: 12.7258 - val_loss: 161.4578 - val_mae: 12.7041\n",
            "Epoch 37/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 161.1227 - mae: 12.6908 - val_loss: 160.5666 - val_mae: 12.6690\n",
            "Epoch 38/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 160.2349 - mae: 12.6559 - val_loss: 159.6788 - val_mae: 12.6340\n",
            "Epoch 39/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 159.3475 - mae: 12.6209 - val_loss: 158.7921 - val_mae: 12.5990\n",
            "Epoch 40/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 158.4648 - mae: 12.5859 - val_loss: 157.9097 - val_mae: 12.5640\n",
            "Epoch 41/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 157.5836 - mae: 12.5510 - val_loss: 157.0285 - val_mae: 12.5290\n",
            "Epoch 42/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 156.7038 - mae: 12.5160 - val_loss: 156.1512 - val_mae: 12.4940\n",
            "Epoch 43/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 155.8282 - mae: 12.4810 - val_loss: 155.2753 - val_mae: 12.4590\n",
            "Epoch 44/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 154.9551 - mae: 12.4461 - val_loss: 154.4030 - val_mae: 12.4240\n",
            "Epoch 45/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 154.0832 - mae: 12.4110 - val_loss: 153.5337 - val_mae: 12.3890\n",
            "Epoch 46/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 153.2154 - mae: 12.3760 - val_loss: 152.6658 - val_mae: 12.3540\n",
            "Epoch 47/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 152.3503 - mae: 12.3411 - val_loss: 151.8003 - val_mae: 12.3190\n",
            "Epoch 48/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 151.4862 - mae: 12.3061 - val_loss: 150.9388 - val_mae: 12.2840\n",
            "Epoch 49/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 150.6243 - mae: 12.2711 - val_loss: 150.0789 - val_mae: 12.2490\n",
            "Epoch 50/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 149.7672 - mae: 12.2362 - val_loss: 149.2216 - val_mae: 12.2140\n",
            "Epoch 51/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 148.9110 - mae: 12.2012 - val_loss: 148.3670 - val_mae: 12.1790\n",
            "Epoch 52/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 148.0575 - mae: 12.1662 - val_loss: 147.5140 - val_mae: 12.1440\n",
            "Epoch 53/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 147.2074 - mae: 12.1313 - val_loss: 146.6643 - val_mae: 12.1090\n",
            "Epoch 54/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 146.3584 - mae: 12.0963 - val_loss: 145.8170 - val_mae: 12.0740\n",
            "Epoch 55/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 145.5133 - mae: 12.0613 - val_loss: 144.9720 - val_mae: 12.0390\n",
            "Epoch 56/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 144.6692 - mae: 12.0263 - val_loss: 144.1299 - val_mae: 12.0040\n",
            "Epoch 57/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 143.8295 - mae: 11.9914 - val_loss: 143.2898 - val_mae: 11.9690\n",
            "Epoch 58/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 142.9900 - mae: 11.9564 - val_loss: 142.4527 - val_mae: 11.9340\n",
            "Epoch 59/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 142.1551 - mae: 11.9214 - val_loss: 141.6188 - val_mae: 11.8991\n",
            "Epoch 60/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 141.3213 - mae: 11.8864 - val_loss: 140.7866 - val_mae: 11.8641\n",
            "Epoch 61/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 140.4906 - mae: 11.8514 - val_loss: 139.9574 - val_mae: 11.8291\n",
            "Epoch 62/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 139.6626 - mae: 11.8165 - val_loss: 139.1291 - val_mae: 11.7941\n",
            "Epoch 63/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 138.8366 - mae: 11.7815 - val_loss: 138.3043 - val_mae: 11.7591\n",
            "Epoch 64/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 138.0125 - mae: 11.7465 - val_loss: 137.4834 - val_mae: 11.7242\n",
            "Epoch 65/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 137.1917 - mae: 11.7115 - val_loss: 136.6641 - val_mae: 11.6892\n",
            "Epoch 66/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 136.3731 - mae: 11.6766 - val_loss: 135.8472 - val_mae: 11.6542\n",
            "Epoch 67/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 135.5581 - mae: 11.6416 - val_loss: 135.0323 - val_mae: 11.6192\n",
            "Epoch 68/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 134.7448 - mae: 11.6067 - val_loss: 134.2199 - val_mae: 11.5842\n",
            "Epoch 69/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 133.9333 - mae: 11.5717 - val_loss: 133.4107 - val_mae: 11.5493\n",
            "Epoch 70/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 133.1248 - mae: 11.5367 - val_loss: 132.6023 - val_mae: 11.5142\n",
            "Epoch 71/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 132.3181 - mae: 11.5017 - val_loss: 131.7986 - val_mae: 11.4793\n",
            "Epoch 72/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 131.5161 - mae: 11.4668 - val_loss: 130.9963 - val_mae: 11.4443\n",
            "Epoch 73/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 130.7133 - mae: 11.4317 - val_loss: 130.1970 - val_mae: 11.4094\n",
            "Epoch 74/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 129.9147 - mae: 11.3968 - val_loss: 129.3994 - val_mae: 11.3744\n",
            "Epoch 75/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 129.1187 - mae: 11.3618 - val_loss: 128.6043 - val_mae: 11.3394\n",
            "Epoch 76/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 128.3254 - mae: 11.3269 - val_loss: 127.8113 - val_mae: 11.3044\n",
            "Epoch 77/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 127.5329 - mae: 11.2919 - val_loss: 127.0209 - val_mae: 11.2694\n",
            "Epoch 78/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 126.7453 - mae: 11.2570 - val_loss: 126.2344 - val_mae: 11.2345\n",
            "Epoch 79/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 125.9571 - mae: 11.2219 - val_loss: 125.4492 - val_mae: 11.1995\n",
            "Epoch 80/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 125.1734 - mae: 11.1870 - val_loss: 124.6667 - val_mae: 11.1645\n",
            "Epoch 81/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 124.3938 - mae: 11.1521 - val_loss: 123.8859 - val_mae: 11.1295\n",
            "Epoch 82/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 123.6143 - mae: 11.1171 - val_loss: 123.1084 - val_mae: 11.0945\n",
            "Epoch 83/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 122.8371 - mae: 11.0821 - val_loss: 122.3331 - val_mae: 11.0595\n",
            "Epoch 84/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 122.0626 - mae: 11.0471 - val_loss: 121.5608 - val_mae: 11.0246\n",
            "Epoch 85/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 121.2911 - mae: 11.0121 - val_loss: 120.7902 - val_mae: 10.9896\n",
            "Epoch 86/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 120.5225 - mae: 10.9772 - val_loss: 120.0229 - val_mae: 10.9546\n",
            "Epoch 87/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 119.7550 - mae: 10.9422 - val_loss: 119.2570 - val_mae: 10.9196\n",
            "Epoch 88/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 118.9917 - mae: 10.9072 - val_loss: 118.4942 - val_mae: 10.8846\n",
            "Epoch 89/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 118.2292 - mae: 10.8722 - val_loss: 117.7340 - val_mae: 10.8496\n",
            "Epoch 90/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 117.4699 - mae: 10.8372 - val_loss: 116.9764 - val_mae: 10.8147\n",
            "Epoch 91/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 116.7132 - mae: 10.8023 - val_loss: 116.2207 - val_mae: 10.7797\n",
            "Epoch 92/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 115.9585 - mae: 10.7673 - val_loss: 115.4683 - val_mae: 10.7447\n",
            "Epoch 93/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 115.2068 - mae: 10.7324 - val_loss: 114.7174 - val_mae: 10.7097\n",
            "Epoch 94/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 114.4564 - mae: 10.6973 - val_loss: 113.9701 - val_mae: 10.6748\n",
            "Epoch 95/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 113.7105 - mae: 10.6624 - val_loss: 113.2241 - val_mae: 10.6398\n",
            "Epoch 96/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 112.9649 - mae: 10.6274 - val_loss: 112.4807 - val_mae: 10.6048\n",
            "Epoch 97/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 112.2234 - mae: 10.5925 - val_loss: 111.7402 - val_mae: 10.5699\n",
            "Epoch 98/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 111.4833 - mae: 10.5575 - val_loss: 111.0021 - val_mae: 10.5349\n",
            "Epoch 99/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 110.7470 - mae: 10.5226 - val_loss: 110.2663 - val_mae: 10.4999\n",
            "Epoch 100/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 110.0114 - mae: 10.4876 - val_loss: 109.5323 - val_mae: 10.4649\n",
            "Epoch 101/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 109.2792 - mae: 10.4526 - val_loss: 108.8017 - val_mae: 10.4300\n",
            "Epoch 102/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 108.5493 - mae: 10.4176 - val_loss: 108.0735 - val_mae: 10.3950\n",
            "Epoch 103/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 107.8219 - mae: 10.3827 - val_loss: 107.3475 - val_mae: 10.3600\n",
            "Epoch 104/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 107.0968 - mae: 10.3477 - val_loss: 106.6238 - val_mae: 10.3250\n",
            "Epoch 105/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 106.3740 - mae: 10.3127 - val_loss: 105.9032 - val_mae: 10.2901\n",
            "Epoch 106/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 105.6539 - mae: 10.2777 - val_loss: 105.1850 - val_mae: 10.2551\n",
            "Epoch 107/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 104.9362 - mae: 10.2428 - val_loss: 104.4689 - val_mae: 10.2202\n",
            "Epoch 108/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 104.2212 - mae: 10.2078 - val_loss: 103.7541 - val_mae: 10.1851\n",
            "Epoch 109/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 103.5081 - mae: 10.1728 - val_loss: 103.0428 - val_mae: 10.1502\n",
            "Epoch 110/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 102.7989 - mae: 10.1379 - val_loss: 102.3335 - val_mae: 10.1152\n",
            "Epoch 111/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 102.0897 - mae: 10.1029 - val_loss: 101.6273 - val_mae: 10.0802\n",
            "Epoch 112/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 101.3850 - mae: 10.0679 - val_loss: 100.9238 - val_mae: 10.0453\n",
            "Epoch 113/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 100.6816 - mae: 10.0329 - val_loss: 100.2224 - val_mae: 10.0103\n",
            "Epoch 114/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 99.9804 - mae: 9.9979 - val_loss: 99.5234 - val_mae: 9.9753\n",
            "Epoch 115/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 99.2834 - mae: 9.9630 - val_loss: 98.8266 - val_mae: 9.9403\n",
            "Epoch 116/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 98.5873 - mae: 9.9280 - val_loss: 98.1328 - val_mae: 9.9054\n",
            "Epoch 117/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 97.8948 - mae: 9.8931 - val_loss: 97.4408 - val_mae: 9.8704\n",
            "Epoch 118/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 97.2037 - mae: 9.8581 - val_loss: 96.7519 - val_mae: 9.8354\n",
            "Epoch 119/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 96.5155 - mae: 9.8231 - val_loss: 96.0655 - val_mae: 9.8005\n",
            "Epoch 120/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 95.8300 - mae: 9.7882 - val_loss: 95.3819 - val_mae: 9.7655\n",
            "Epoch 121/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 95.1468 - mae: 9.7532 - val_loss: 94.6998 - val_mae: 9.7305\n",
            "Epoch 122/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 94.4656 - mae: 9.7183 - val_loss: 94.0203 - val_mae: 9.6956\n",
            "Epoch 123/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 93.7864 - mae: 9.6832 - val_loss: 93.3433 - val_mae: 9.6606\n",
            "Epoch 124/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 93.1109 - mae: 9.6483 - val_loss: 92.6686 - val_mae: 9.6256\n",
            "Epoch 125/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 92.4375 - mae: 9.6133 - val_loss: 91.9958 - val_mae: 9.5906\n",
            "Epoch 126/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 91.7664 - mae: 9.5784 - val_loss: 91.3263 - val_mae: 9.5556\n",
            "Epoch 127/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 91.0973 - mae: 9.5434 - val_loss: 90.6592 - val_mae: 9.5207\n",
            "Epoch 128/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 90.4313 - mae: 9.5084 - val_loss: 89.9949 - val_mae: 9.4857\n",
            "Epoch 129/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 89.7674 - mae: 9.4734 - val_loss: 89.3328 - val_mae: 9.4508\n",
            "Epoch 130/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 89.1057 - mae: 9.4385 - val_loss: 88.6725 - val_mae: 9.4158\n",
            "Epoch 131/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 88.4474 - mae: 9.4035 - val_loss: 88.0149 - val_mae: 9.3808\n",
            "Epoch 132/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 87.7913 - mae: 9.3686 - val_loss: 87.3600 - val_mae: 9.3458\n",
            "Epoch 133/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 87.1366 - mae: 9.3336 - val_loss: 86.7075 - val_mae: 9.3108\n",
            "Epoch 134/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 86.4862 - mae: 9.2987 - val_loss: 86.0576 - val_mae: 9.2759\n",
            "Epoch 135/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 85.8362 - mae: 9.2637 - val_loss: 85.4099 - val_mae: 9.2409\n",
            "Epoch 136/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 85.1897 - mae: 9.2287 - val_loss: 84.7648 - val_mae: 9.2059\n",
            "Epoch 137/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 84.5460 - mae: 9.1938 - val_loss: 84.1221 - val_mae: 9.1709\n",
            "Epoch 138/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 83.9036 - mae: 9.1588 - val_loss: 83.4815 - val_mae: 9.1360\n",
            "Epoch 139/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 83.2644 - mae: 9.1238 - val_loss: 82.8439 - val_mae: 9.1010\n",
            "Epoch 140/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 82.6273 - mae: 9.0888 - val_loss: 82.2082 - val_mae: 9.0660\n",
            "Epoch 141/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 81.9930 - mae: 9.0538 - val_loss: 81.5753 - val_mae: 9.0310\n",
            "Epoch 142/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 81.3617 - mae: 9.0189 - val_loss: 80.9451 - val_mae: 8.9961\n",
            "Epoch 143/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 80.7326 - mae: 8.9840 - val_loss: 80.3169 - val_mae: 8.9611\n",
            "Epoch 144/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 80.1050 - mae: 8.9490 - val_loss: 79.6921 - val_mae: 8.9262\n",
            "Epoch 145/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 79.4800 - mae: 8.9140 - val_loss: 79.0691 - val_mae: 8.8912\n",
            "Epoch 146/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 78.8580 - mae: 8.8790 - val_loss: 78.4492 - val_mae: 8.8563\n",
            "Epoch 147/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 78.2382 - mae: 8.8441 - val_loss: 77.8313 - val_mae: 8.8213\n",
            "Epoch 148/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 77.6214 - mae: 8.8091 - val_loss: 77.2156 - val_mae: 8.7864\n",
            "Epoch 149/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 77.0068 - mae: 8.7742 - val_loss: 76.6020 - val_mae: 8.7514\n",
            "Epoch 150/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 76.3940 - mae: 8.7392 - val_loss: 75.9912 - val_mae: 8.7164\n",
            "Epoch 151/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 75.7839 - mae: 8.7042 - val_loss: 75.3827 - val_mae: 8.6814\n",
            "Epoch 152/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 75.1768 - mae: 8.6693 - val_loss: 74.7769 - val_mae: 8.6465\n",
            "Epoch 153/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 74.5718 - mae: 8.6343 - val_loss: 74.1736 - val_mae: 8.6115\n",
            "Epoch 154/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 73.9695 - mae: 8.5993 - val_loss: 73.5727 - val_mae: 8.5765\n",
            "Epoch 155/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 73.3689 - mae: 8.5643 - val_loss: 72.9746 - val_mae: 8.5416\n",
            "Epoch 156/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 72.7722 - mae: 8.5294 - val_loss: 72.3783 - val_mae: 8.5066\n",
            "Epoch 157/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 72.1760 - mae: 8.4944 - val_loss: 71.7840 - val_mae: 8.4716\n",
            "Epoch 158/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 71.5837 - mae: 8.4595 - val_loss: 71.1927 - val_mae: 8.4366\n",
            "Epoch 159/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 70.9932 - mae: 8.4245 - val_loss: 70.6039 - val_mae: 8.4017\n",
            "Epoch 160/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 70.4058 - mae: 8.3896 - val_loss: 70.0177 - val_mae: 8.3667\n",
            "Epoch 161/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 69.8197 - mae: 8.3546 - val_loss: 69.4336 - val_mae: 8.3317\n",
            "Epoch 162/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 69.2374 - mae: 8.3196 - val_loss: 68.8530 - val_mae: 8.2968\n",
            "Epoch 163/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 68.6563 - mae: 8.2847 - val_loss: 68.2740 - val_mae: 8.2619\n",
            "Epoch 164/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 68.0781 - mae: 8.2497 - val_loss: 67.6980 - val_mae: 8.2269\n",
            "Epoch 165/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 67.5030 - mae: 8.2148 - val_loss: 67.1237 - val_mae: 8.1920\n",
            "Epoch 166/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 66.9298 - mae: 8.1798 - val_loss: 66.5523 - val_mae: 8.1570\n",
            "Epoch 167/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 66.3594 - mae: 8.1449 - val_loss: 65.9828 - val_mae: 8.1220\n",
            "Epoch 168/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 65.7911 - mae: 8.1099 - val_loss: 65.4166 - val_mae: 8.0871\n",
            "Epoch 169/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 65.2244 - mae: 8.0749 - val_loss: 64.8524 - val_mae: 8.0521\n",
            "Epoch 170/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 64.6618 - mae: 8.0400 - val_loss: 64.2902 - val_mae: 8.0171\n",
            "Epoch 171/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 64.1010 - mae: 8.0050 - val_loss: 63.7308 - val_mae: 7.9822\n",
            "Epoch 172/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 63.5418 - mae: 7.9700 - val_loss: 63.1741 - val_mae: 7.9472\n",
            "Epoch 173/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 62.9856 - mae: 7.9350 - val_loss: 62.6202 - val_mae: 7.9123\n",
            "Epoch 174/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 62.4322 - mae: 7.9001 - val_loss: 62.0684 - val_mae: 7.8774\n",
            "Epoch 175/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 61.8817 - mae: 7.8652 - val_loss: 61.5186 - val_mae: 7.8424\n",
            "Epoch 176/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 61.3326 - mae: 7.8302 - val_loss: 60.9717 - val_mae: 7.8074\n",
            "Epoch 177/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 60.7863 - mae: 7.7952 - val_loss: 60.4273 - val_mae: 7.7725\n",
            "Epoch 178/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 60.2422 - mae: 7.7603 - val_loss: 59.8853 - val_mae: 7.7376\n",
            "Epoch 179/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 59.7006 - mae: 7.7253 - val_loss: 59.3457 - val_mae: 7.7026\n",
            "Epoch 180/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 59.1630 - mae: 7.6904 - val_loss: 58.8084 - val_mae: 7.6677\n",
            "Epoch 181/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 58.6255 - mae: 7.6554 - val_loss: 58.2734 - val_mae: 7.6327\n",
            "Epoch 182/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 58.0913 - mae: 7.6204 - val_loss: 57.7409 - val_mae: 7.5977\n",
            "Epoch 183/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 57.5596 - mae: 7.5854 - val_loss: 57.2113 - val_mae: 7.5628\n",
            "Epoch 184/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 57.0304 - mae: 7.5505 - val_loss: 56.6842 - val_mae: 7.5279\n",
            "Epoch 185/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 56.5040 - mae: 7.5155 - val_loss: 56.1590 - val_mae: 7.4929\n",
            "Epoch 186/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 55.9799 - mae: 7.4806 - val_loss: 55.6363 - val_mae: 7.4579\n",
            "Epoch 187/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 55.4584 - mae: 7.4457 - val_loss: 55.1154 - val_mae: 7.4229\n",
            "Epoch 188/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 54.9388 - mae: 7.4107 - val_loss: 54.5974 - val_mae: 7.3880\n",
            "Epoch 189/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 54.4220 - mae: 7.3757 - val_loss: 54.0822 - val_mae: 7.3530\n",
            "Epoch 190/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 53.9076 - mae: 7.3408 - val_loss: 53.5693 - val_mae: 7.3181\n",
            "Epoch 191/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 53.3956 - mae: 7.3058 - val_loss: 53.0587 - val_mae: 7.2831\n",
            "Epoch 192/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 52.8850 - mae: 7.2708 - val_loss: 52.5504 - val_mae: 7.2481\n",
            "Epoch 193/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 52.3788 - mae: 7.2359 - val_loss: 52.0446 - val_mae: 7.2131\n",
            "Epoch 194/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 51.8747 - mae: 7.2010 - val_loss: 51.5419 - val_mae: 7.1782\n",
            "Epoch 195/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 51.3709 - mae: 7.1659 - val_loss: 51.0422 - val_mae: 7.1433\n",
            "Epoch 196/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 50.8724 - mae: 7.1310 - val_loss: 50.5438 - val_mae: 7.1083\n",
            "Epoch 197/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 50.3746 - mae: 7.0960 - val_loss: 50.0480 - val_mae: 7.0734\n",
            "Epoch 198/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 49.8798 - mae: 7.0611 - val_loss: 49.5547 - val_mae: 7.0384\n",
            "Epoch 199/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 49.3874 - mae: 7.0262 - val_loss: 49.0638 - val_mae: 7.0035\n",
            "Epoch 200/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 48.8971 - mae: 6.9912 - val_loss: 48.5757 - val_mae: 6.9685\n",
            "Epoch 201/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 48.4100 - mae: 6.9562 - val_loss: 48.0897 - val_mae: 6.9336\n",
            "Epoch 202/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 47.9249 - mae: 6.9213 - val_loss: 47.6062 - val_mae: 6.8986\n",
            "Epoch 203/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 47.4420 - mae: 6.8863 - val_loss: 47.1250 - val_mae: 6.8636\n",
            "Epoch 204/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 46.9617 - mae: 6.8514 - val_loss: 46.6461 - val_mae: 6.8287\n",
            "Epoch 205/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 46.4844 - mae: 6.8164 - val_loss: 46.1702 - val_mae: 6.7937\n",
            "Epoch 206/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 46.0090 - mae: 6.7815 - val_loss: 45.6966 - val_mae: 6.7588\n",
            "Epoch 207/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 45.5360 - mae: 6.7465 - val_loss: 45.2254 - val_mae: 6.7238\n",
            "Epoch 208/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 45.0654 - mae: 6.7115 - val_loss: 44.7567 - val_mae: 6.6889\n",
            "Epoch 209/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 44.5978 - mae: 6.6766 - val_loss: 44.2905 - val_mae: 6.6540\n",
            "Epoch 210/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 44.1326 - mae: 6.6417 - val_loss: 43.8265 - val_mae: 6.6190\n",
            "Epoch 211/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 43.6691 - mae: 6.6067 - val_loss: 43.3646 - val_mae: 6.5840\n",
            "Epoch 212/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 43.2080 - mae: 6.5717 - val_loss: 42.9057 - val_mae: 6.5491\n",
            "Epoch 213/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 42.7507 - mae: 6.5368 - val_loss: 42.4488 - val_mae: 6.5141\n",
            "Epoch 214/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 42.2946 - mae: 6.5018 - val_loss: 41.9949 - val_mae: 6.4792\n",
            "Epoch 215/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 41.8412 - mae: 6.4669 - val_loss: 41.5431 - val_mae: 6.4442\n",
            "Epoch 216/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 41.3902 - mae: 6.4319 - val_loss: 41.0943 - val_mae: 6.4093\n",
            "Epoch 217/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 40.9424 - mae: 6.3970 - val_loss: 40.6468 - val_mae: 6.3743\n",
            "Epoch 218/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 40.4960 - mae: 6.3620 - val_loss: 40.2024 - val_mae: 6.3393\n",
            "Epoch 219/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 40.0525 - mae: 6.3271 - val_loss: 39.7605 - val_mae: 6.3044\n",
            "Epoch 220/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 39.6116 - mae: 6.2921 - val_loss: 39.3210 - val_mae: 6.2694\n",
            "Epoch 221/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 39.1730 - mae: 6.2572 - val_loss: 38.8846 - val_mae: 6.2345\n",
            "Epoch 222/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 38.7370 - mae: 6.2223 - val_loss: 38.4498 - val_mae: 6.1996\n",
            "Epoch 223/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 38.3039 - mae: 6.1874 - val_loss: 38.0178 - val_mae: 6.1646\n",
            "Epoch 224/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 37.8717 - mae: 6.1523 - val_loss: 37.5878 - val_mae: 6.1296\n",
            "Epoch 225/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 37.4424 - mae: 6.1173 - val_loss: 37.1608 - val_mae: 6.0947\n",
            "Epoch 226/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 37.0169 - mae: 6.0825 - val_loss: 36.7361 - val_mae: 6.0598\n",
            "Epoch 227/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 36.5930 - mae: 6.0475 - val_loss: 36.3139 - val_mae: 6.0248\n",
            "Epoch 228/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 36.1719 - mae: 6.0126 - val_loss: 35.8941 - val_mae: 5.9899\n",
            "Epoch 229/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 35.7524 - mae: 5.9776 - val_loss: 35.4769 - val_mae: 5.9550\n",
            "Epoch 230/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 35.3357 - mae: 5.9427 - val_loss: 35.0619 - val_mae: 5.9200\n",
            "Epoch 231/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 34.9218 - mae: 5.9077 - val_loss: 34.6493 - val_mae: 5.8851\n",
            "Epoch 232/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 34.5097 - mae: 5.8727 - val_loss: 34.2391 - val_mae: 5.8501\n",
            "Epoch 233/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 34.1009 - mae: 5.8378 - val_loss: 33.8316 - val_mae: 5.8152\n",
            "Epoch 234/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 33.6939 - mae: 5.8029 - val_loss: 33.4260 - val_mae: 5.7802\n",
            "Epoch 235/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 33.2899 - mae: 5.7680 - val_loss: 33.0228 - val_mae: 5.7452\n",
            "Epoch 236/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 32.8878 - mae: 5.7330 - val_loss: 32.6225 - val_mae: 5.7103\n",
            "Epoch 237/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 32.4881 - mae: 5.6980 - val_loss: 32.2245 - val_mae: 5.6753\n",
            "Epoch 238/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 32.0912 - mae: 5.6631 - val_loss: 31.8290 - val_mae: 5.6404\n",
            "Epoch 239/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 31.6968 - mae: 5.6282 - val_loss: 31.4361 - val_mae: 5.6054\n",
            "Epoch 240/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 31.3042 - mae: 5.5932 - val_loss: 31.0456 - val_mae: 5.5705\n",
            "Epoch 241/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 30.9149 - mae: 5.5583 - val_loss: 30.6577 - val_mae: 5.5356\n",
            "Epoch 242/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 30.5278 - mae: 5.5233 - val_loss: 30.2723 - val_mae: 5.5006\n",
            "Epoch 243/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 30.1431 - mae: 5.4884 - val_loss: 29.8891 - val_mae: 5.4657\n",
            "Epoch 244/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 29.7607 - mae: 5.4534 - val_loss: 29.5084 - val_mae: 5.4308\n",
            "Epoch 245/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 29.3806 - mae: 5.4185 - val_loss: 29.1302 - val_mae: 5.3958\n",
            "Epoch 246/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 29.0030 - mae: 5.3835 - val_loss: 28.7540 - val_mae: 5.3609\n",
            "Epoch 247/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 28.6287 - mae: 5.3486 - val_loss: 28.3806 - val_mae: 5.3259\n",
            "Epoch 248/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 28.2553 - mae: 5.3136 - val_loss: 28.0098 - val_mae: 5.2910\n",
            "Epoch 249/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 27.8859 - mae: 5.2788 - val_loss: 27.6416 - val_mae: 5.2561\n",
            "Epoch 250/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 27.5180 - mae: 5.2438 - val_loss: 27.2756 - val_mae: 5.2211\n",
            "Epoch 251/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 27.1527 - mae: 5.2088 - val_loss: 26.9118 - val_mae: 5.1862\n",
            "Epoch 252/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 26.7902 - mae: 5.1739 - val_loss: 26.5505 - val_mae: 5.1512\n",
            "Epoch 253/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 26.4295 - mae: 5.1390 - val_loss: 26.1920 - val_mae: 5.1163\n",
            "Epoch 254/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 26.0719 - mae: 5.1040 - val_loss: 25.8358 - val_mae: 5.0814\n",
            "Epoch 255/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 25.7160 - mae: 5.0691 - val_loss: 25.4821 - val_mae: 5.0465\n",
            "Epoch 256/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 25.3632 - mae: 5.0341 - val_loss: 25.1310 - val_mae: 5.0116\n",
            "Epoch 257/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 25.0128 - mae: 4.9992 - val_loss: 24.7816 - val_mae: 4.9766\n",
            "Epoch 258/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 24.6651 - mae: 4.9643 - val_loss: 24.4350 - val_mae: 4.9416\n",
            "Epoch 259/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 24.3189 - mae: 4.9293 - val_loss: 24.0915 - val_mae: 4.9068\n",
            "Epoch 260/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 23.9762 - mae: 4.8944 - val_loss: 23.7498 - val_mae: 4.8718\n",
            "Epoch 261/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 23.6350 - mae: 4.8595 - val_loss: 23.4105 - val_mae: 4.8369\n",
            "Epoch 262/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 23.2972 - mae: 4.8246 - val_loss: 23.0736 - val_mae: 4.8019\n",
            "Epoch 263/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 22.9611 - mae: 4.7896 - val_loss: 22.7394 - val_mae: 4.7670\n",
            "Epoch 264/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 22.6277 - mae: 4.7547 - val_loss: 22.4073 - val_mae: 4.7320\n",
            "Epoch 265/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 22.2968 - mae: 4.7198 - val_loss: 22.0781 - val_mae: 4.6971\n",
            "Epoch 266/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 21.9679 - mae: 4.6848 - val_loss: 21.7512 - val_mae: 4.6622\n",
            "Epoch 267/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 21.6424 - mae: 4.6499 - val_loss: 21.4266 - val_mae: 4.6272\n",
            "Epoch 268/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 21.3182 - mae: 4.6149 - val_loss: 21.1047 - val_mae: 4.5923\n",
            "Epoch 269/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 20.9973 - mae: 4.5800 - val_loss: 20.7850 - val_mae: 4.5574\n",
            "Epoch 270/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 20.6787 - mae: 4.5451 - val_loss: 20.4678 - val_mae: 4.5224\n",
            "Epoch 271/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 20.3620 - mae: 4.5101 - val_loss: 20.1530 - val_mae: 4.4875\n",
            "Epoch 272/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 20.0485 - mae: 4.4753 - val_loss: 19.8404 - val_mae: 4.4525\n",
            "Epoch 273/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 19.7369 - mae: 4.4403 - val_loss: 19.5305 - val_mae: 4.4176\n",
            "Epoch 274/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 19.4278 - mae: 4.4054 - val_loss: 19.2233 - val_mae: 4.3827\n",
            "Epoch 275/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 19.1215 - mae: 4.3705 - val_loss: 18.9187 - val_mae: 4.3478\n",
            "Epoch 276/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 18.8172 - mae: 4.3355 - val_loss: 18.6161 - val_mae: 4.3129\n",
            "Epoch 277/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 18.5158 - mae: 4.3006 - val_loss: 18.3161 - val_mae: 4.2780\n",
            "Epoch 278/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 18.2167 - mae: 4.2657 - val_loss: 18.0185 - val_mae: 4.2430\n",
            "Epoch 279/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 17.9194 - mae: 4.2307 - val_loss: 17.7232 - val_mae: 4.2081\n",
            "Epoch 280/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 17.6254 - mae: 4.1958 - val_loss: 17.4305 - val_mae: 4.1732\n",
            "Epoch 281/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 17.3333 - mae: 4.1609 - val_loss: 17.1400 - val_mae: 4.1382\n",
            "Epoch 282/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 17.0440 - mae: 4.1260 - val_loss: 16.8521 - val_mae: 4.1033\n",
            "Epoch 283/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 16.7573 - mae: 4.0911 - val_loss: 16.5669 - val_mae: 4.0684\n",
            "Epoch 284/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 16.4725 - mae: 4.0561 - val_loss: 16.2840 - val_mae: 4.0335\n",
            "Epoch 285/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 16.1907 - mae: 4.0212 - val_loss: 16.0036 - val_mae: 3.9985\n",
            "Epoch 286/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 15.9114 - mae: 3.9863 - val_loss: 15.7256 - val_mae: 3.9636\n",
            "Epoch 287/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 15.6339 - mae: 3.9514 - val_loss: 15.4500 - val_mae: 3.9287\n",
            "Epoch 288/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 15.3590 - mae: 3.9164 - val_loss: 15.1769 - val_mae: 3.8938\n",
            "Epoch 289/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 15.0871 - mae: 3.8816 - val_loss: 14.9061 - val_mae: 3.8589\n",
            "Epoch 290/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 14.8168 - mae: 3.8466 - val_loss: 14.6379 - val_mae: 3.8240\n",
            "Epoch 291/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 14.5495 - mae: 3.8117 - val_loss: 14.3721 - val_mae: 3.7890\n",
            "Epoch 292/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 14.2847 - mae: 3.7768 - val_loss: 14.1087 - val_mae: 3.7541\n",
            "Epoch 293/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 14.0219 - mae: 3.7418 - val_loss: 13.8479 - val_mae: 3.7192\n",
            "Epoch 294/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 13.7620 - mae: 3.7069 - val_loss: 13.5894 - val_mae: 3.6843\n",
            "Epoch 295/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 13.5042 - mae: 3.6720 - val_loss: 13.3335 - val_mae: 3.6494\n",
            "Epoch 296/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 13.2493 - mae: 3.6371 - val_loss: 13.0800 - val_mae: 3.6145\n",
            "Epoch 297/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 12.9962 - mae: 3.6022 - val_loss: 12.8288 - val_mae: 3.5796\n",
            "Epoch 298/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 12.7462 - mae: 3.5673 - val_loss: 12.5801 - val_mae: 3.5447\n",
            "Epoch 299/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 12.4983 - mae: 3.5324 - val_loss: 12.3337 - val_mae: 3.5098\n",
            "Epoch 300/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 12.2525 - mae: 3.4974 - val_loss: 12.0897 - val_mae: 3.4748\n",
            "Epoch 301/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 12.0096 - mae: 3.4625 - val_loss: 11.8482 - val_mae: 3.4399\n",
            "Epoch 302/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 11.7694 - mae: 3.4276 - val_loss: 11.6092 - val_mae: 3.4050\n",
            "Epoch 303/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 11.5311 - mae: 3.3927 - val_loss: 11.3728 - val_mae: 3.3701\n",
            "Epoch 304/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 11.2956 - mae: 3.3578 - val_loss: 11.1386 - val_mae: 3.3352\n",
            "Epoch 305/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 11.0621 - mae: 3.3229 - val_loss: 10.9068 - val_mae: 3.3002\n",
            "Epoch 306/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.8319 - mae: 3.2881 - val_loss: 10.6774 - val_mae: 3.2653\n",
            "Epoch 307/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.6034 - mae: 3.2531 - val_loss: 10.4509 - val_mae: 3.2304\n",
            "Epoch 308/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.3771 - mae: 3.2182 - val_loss: 10.2267 - val_mae: 3.1955\n",
            "Epoch 309/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 10.1540 - mae: 3.1833 - val_loss: 10.0048 - val_mae: 3.1606\n",
            "Epoch 310/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.9327 - mae: 3.1484 - val_loss: 9.7855 - val_mae: 3.1257\n",
            "Epoch 311/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.7144 - mae: 3.1136 - val_loss: 9.5688 - val_mae: 3.0909\n",
            "Epoch 312/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.4982 - mae: 3.0787 - val_loss: 9.3542 - val_mae: 3.0560\n",
            "Epoch 313/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.2847 - mae: 3.0438 - val_loss: 9.1420 - val_mae: 3.0210\n",
            "Epoch 314/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.0736 - mae: 3.0089 - val_loss: 8.9324 - val_mae: 2.9862\n",
            "Epoch 315/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.8645 - mae: 2.9740 - val_loss: 8.7251 - val_mae: 2.9513\n",
            "Epoch 316/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.6583 - mae: 2.9392 - val_loss: 8.5205 - val_mae: 2.9164\n",
            "Epoch 317/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.4546 - mae: 2.9043 - val_loss: 8.3180 - val_mae: 2.8814\n",
            "Epoch 318/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.2530 - mae: 2.8694 - val_loss: 8.1182 - val_mae: 2.8466\n",
            "Epoch 319/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.0541 - mae: 2.8346 - val_loss: 7.9209 - val_mae: 2.8117\n",
            "Epoch 320/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.8576 - mae: 2.7997 - val_loss: 7.7259 - val_mae: 2.7768\n",
            "Epoch 321/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.6634 - mae: 2.7648 - val_loss: 7.5334 - val_mae: 2.7419\n",
            "Epoch 322/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.4719 - mae: 2.7300 - val_loss: 7.3434 - val_mae: 2.7070\n",
            "Epoch 323/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.2825 - mae: 2.6951 - val_loss: 7.1557 - val_mae: 2.6722\n",
            "Epoch 324/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.0958 - mae: 2.6603 - val_loss: 6.9705 - val_mae: 2.6373\n",
            "Epoch 325/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.9114 - mae: 2.6254 - val_loss: 6.7878 - val_mae: 2.6024\n",
            "Epoch 326/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.7297 - mae: 2.5905 - val_loss: 6.6076 - val_mae: 2.5676\n",
            "Epoch 327/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.5500 - mae: 2.5557 - val_loss: 6.4295 - val_mae: 2.5326\n",
            "Epoch 328/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.3730 - mae: 2.5209 - val_loss: 6.2543 - val_mae: 2.4978\n",
            "Epoch 329/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 6.1983 - mae: 2.4860 - val_loss: 6.0812 - val_mae: 2.4629\n",
            "Epoch 330/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.0263 - mae: 2.4512 - val_loss: 5.9106 - val_mae: 2.4280\n",
            "Epoch 331/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.8567 - mae: 2.4164 - val_loss: 5.7423 - val_mae: 2.3931\n",
            "Epoch 332/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.6893 - mae: 2.3815 - val_loss: 5.5765 - val_mae: 2.3582\n",
            "Epoch 333/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.5245 - mae: 2.3467 - val_loss: 5.4133 - val_mae: 2.3234\n",
            "Epoch 334/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.3623 - mae: 2.3119 - val_loss: 5.2524 - val_mae: 2.2885\n",
            "Epoch 335/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.2024 - mae: 2.2771 - val_loss: 5.0939 - val_mae: 2.2536\n",
            "Epoch 336/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.0445 - mae: 2.2422 - val_loss: 4.9382 - val_mae: 2.2188\n",
            "Epoch 337/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.8895 - mae: 2.2074 - val_loss: 4.7847 - val_mae: 2.1839\n",
            "Epoch 338/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.7371 - mae: 2.1726 - val_loss: 4.6336 - val_mae: 2.1490\n",
            "Epoch 339/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 4.5868 - mae: 2.1378 - val_loss: 4.4849 - val_mae: 2.1141\n",
            "Epoch 340/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.4390 - mae: 2.1029 - val_loss: 4.3388 - val_mae: 2.0793\n",
            "Epoch 341/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.2937 - mae: 2.0681 - val_loss: 4.1953 - val_mae: 2.0445\n",
            "Epoch 342/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.1508 - mae: 2.0333 - val_loss: 4.0540 - val_mae: 2.0096\n",
            "Epoch 343/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.0105 - mae: 1.9986 - val_loss: 3.9153 - val_mae: 1.9748\n",
            "Epoch 344/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.8725 - mae: 1.9637 - val_loss: 3.7789 - val_mae: 1.9400\n",
            "Epoch 345/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.7371 - mae: 1.9289 - val_loss: 3.6450 - val_mae: 1.9052\n",
            "Epoch 346/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.6039 - mae: 1.8942 - val_loss: 3.5135 - val_mae: 1.8704\n",
            "Epoch 347/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.4734 - mae: 1.8594 - val_loss: 3.3844 - val_mae: 1.8355\n",
            "Epoch 348/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.3450 - mae: 1.8246 - val_loss: 3.2578 - val_mae: 1.8007\n",
            "Epoch 349/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.2192 - mae: 1.7898 - val_loss: 3.1336 - val_mae: 1.7659\n",
            "Epoch 350/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.0958 - mae: 1.7550 - val_loss: 3.0119 - val_mae: 1.7311\n",
            "Epoch 351/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.9750 - mae: 1.7202 - val_loss: 2.8925 - val_mae: 1.6962\n",
            "Epoch 352/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.8564 - mae: 1.6854 - val_loss: 2.7756 - val_mae: 1.6614\n",
            "Epoch 353/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.7405 - mae: 1.6507 - val_loss: 2.6612 - val_mae: 1.6266\n",
            "Epoch 354/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.6269 - mae: 1.6159 - val_loss: 2.5492 - val_mae: 1.5918\n",
            "Epoch 355/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.5157 - mae: 1.5811 - val_loss: 2.4397 - val_mae: 1.5570\n",
            "Epoch 356/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.4074 - mae: 1.5465 - val_loss: 2.3325 - val_mae: 1.5222\n",
            "Epoch 357/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.3007 - mae: 1.5117 - val_loss: 2.2277 - val_mae: 1.4874\n",
            "Epoch 358/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.1969 - mae: 1.4770 - val_loss: 2.1253 - val_mae: 1.4526\n",
            "Epoch 359/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.0952 - mae: 1.4422 - val_loss: 2.0255 - val_mae: 1.4178\n",
            "Epoch 360/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.9964 - mae: 1.4075 - val_loss: 1.9282 - val_mae: 1.3831\n",
            "Epoch 361/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.8999 - mae: 1.3728 - val_loss: 1.8332 - val_mae: 1.3483\n",
            "Epoch 362/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.8057 - mae: 1.3381 - val_loss: 1.7406 - val_mae: 1.3135\n",
            "Epoch 363/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.7141 - mae: 1.3034 - val_loss: 1.6505 - val_mae: 1.2788\n",
            "Epoch 364/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.6249 - mae: 1.2687 - val_loss: 1.5628 - val_mae: 1.2440\n",
            "Epoch 365/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.5380 - mae: 1.2340 - val_loss: 1.4776 - val_mae: 1.2093\n",
            "Epoch 366/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4537 - mae: 1.1994 - val_loss: 1.3948 - val_mae: 1.1746\n",
            "Epoch 367/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.3716 - mae: 1.1647 - val_loss: 1.3144 - val_mae: 1.1398\n",
            "Epoch 368/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2922 - mae: 1.1300 - val_loss: 1.2364 - val_mae: 1.1051\n",
            "Epoch 369/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2150 - mae: 1.0954 - val_loss: 1.1609 - val_mae: 1.0704\n",
            "Epoch 370/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1405 - mae: 1.0608 - val_loss: 1.0880 - val_mae: 1.0357\n",
            "Epoch 371/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0682 - mae: 1.0262 - val_loss: 1.0172 - val_mae: 1.0010\n",
            "Epoch 372/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9984 - mae: 0.9916 - val_loss: 0.9491 - val_mae: 0.9665\n",
            "Epoch 373/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9311 - mae: 0.9571 - val_loss: 0.8833 - val_mae: 0.9319\n",
            "Epoch 374/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8661 - mae: 0.9226 - val_loss: 0.8200 - val_mae: 0.8973\n",
            "Epoch 375/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8035 - mae: 0.8881 - val_loss: 0.7589 - val_mae: 0.8626\n",
            "Epoch 376/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7434 - mae: 0.8536 - val_loss: 0.7004 - val_mae: 0.8280\n",
            "Epoch 377/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6858 - mae: 0.8191 - val_loss: 0.6442 - val_mae: 0.7934\n",
            "Epoch 378/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6304 - mae: 0.7847 - val_loss: 0.5906 - val_mae: 0.7589\n",
            "Epoch 379/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5777 - mae: 0.7503 - val_loss: 0.5394 - val_mae: 0.7244\n",
            "Epoch 380/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5273 - mae: 0.7160 - val_loss: 0.4905 - val_mae: 0.6898\n",
            "Epoch 381/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4793 - mae: 0.6816 - val_loss: 0.4440 - val_mae: 0.6554\n",
            "Epoch 382/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4337 - mae: 0.6473 - val_loss: 0.4000 - val_mae: 0.6211\n",
            "Epoch 383/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3905 - mae: 0.6131 - val_loss: 0.3584 - val_mae: 0.5868\n",
            "Epoch 384/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3497 - mae: 0.5788 - val_loss: 0.3193 - val_mae: 0.5527\n",
            "Epoch 385/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3114 - mae: 0.5449 - val_loss: 0.2825 - val_mae: 0.5185\n",
            "Epoch 386/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2755 - mae: 0.5109 - val_loss: 0.2482 - val_mae: 0.4846\n",
            "Epoch 387/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2420 - mae: 0.4770 - val_loss: 0.2162 - val_mae: 0.4508\n",
            "Epoch 388/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2109 - mae: 0.4431 - val_loss: 0.1866 - val_mae: 0.4172\n",
            "Epoch 389/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1822 - mae: 0.4096 - val_loss: 0.1595 - val_mae: 0.3838\n",
            "Epoch 390/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1559 - mae: 0.3760 - val_loss: 0.1347 - val_mae: 0.3506\n",
            "Epoch 391/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1319 - mae: 0.3427 - val_loss: 0.1123 - val_mae: 0.3178\n",
            "Epoch 392/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1104 - mae: 0.3096 - val_loss: 0.0923 - val_mae: 0.2855\n",
            "Epoch 393/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0912 - mae: 0.2771 - val_loss: 0.0746 - val_mae: 0.2533\n",
            "Epoch 394/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0744 - mae: 0.2451 - val_loss: 0.0594 - val_mae: 0.2224\n",
            "Epoch 395/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0600 - mae: 0.2142 - val_loss: 0.0465 - val_mae: 0.1929\n",
            "Epoch 396/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0479 - mae: 0.1847 - val_loss: 0.0359 - val_mae: 0.1648\n",
            "Epoch 397/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0381 - mae: 0.1570 - val_loss: 0.0275 - val_mae: 0.1391\n",
            "Epoch 398/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0305 - mae: 0.1322 - val_loss: 0.0214 - val_mae: 0.1174\n",
            "Epoch 399/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0253 - mae: 0.1126 - val_loss: 0.0176 - val_mae: 0.1019\n",
            "Epoch 400/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0221 - mae: 0.0986 - val_loss: 0.0156 - val_mae: 0.0929\n",
            "Epoch 401/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0208 - mae: 0.0914 - val_loss: 0.0153 - val_mae: 0.0904\n",
            "Epoch 402/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0898 - val_loss: 0.0152 - val_mae: 0.0900\n",
            "Epoch 403/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0900 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 404/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0891 - val_loss: 0.0152 - val_mae: 0.0894\n",
            "Epoch 405/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0891\n",
            "Epoch 406/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 407/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0897 - val_loss: 0.0153 - val_mae: 0.0886\n",
            "Epoch 408/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0889 - val_loss: 0.0152 - val_mae: 0.0896\n",
            "Epoch 409/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0205 - mae: 0.0901 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 410/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0888\n",
            "Epoch 411/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0153 - val_mae: 0.0885\n",
            "Epoch 412/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0206 - mae: 0.0892 - val_loss: 0.0153 - val_mae: 0.0888\n",
            "Epoch 413/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0889\n",
            "Epoch 414/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0153 - val_mae: 0.0889\n",
            "Epoch 415/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0897 - val_loss: 0.0153 - val_mae: 0.0885\n",
            "Epoch 416/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0889 - val_loss: 0.0152 - val_mae: 0.0896\n",
            "Epoch 417/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0899 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 418/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0888\n",
            "Epoch 419/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0891 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 420/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 421/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0897 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 422/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0896\n",
            "Epoch 423/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0895\n",
            "Epoch 424/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 425/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 426/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0897 - val_loss: 0.0153 - val_mae: 0.0891\n",
            "Epoch 427/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 428/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0152 - val_mae: 0.0896\n",
            "Epoch 429/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 430/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 431/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0891\n",
            "Epoch 432/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 433/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0892 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 434/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0890 - val_loss: 0.0152 - val_mae: 0.0893\n",
            "Epoch 435/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0153 - val_mae: 0.0895\n",
            "Epoch 436/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0898 - val_loss: 0.0153 - val_mae: 0.0888\n",
            "Epoch 437/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 438/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0890 - val_loss: 0.0153 - val_mae: 0.0897\n",
            "Epoch 439/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0894\n",
            "Epoch 440/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0892 - val_loss: 0.0152 - val_mae: 0.0898\n",
            "Epoch 441/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0899 - val_loss: 0.0152 - val_mae: 0.0892\n",
            "Epoch 442/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0152 - val_mae: 0.0897\n",
            "Epoch 443/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0898 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 444/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0898 - val_loss: 0.0153 - val_mae: 0.0888\n",
            "Epoch 445/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0206 - mae: 0.0889 - val_loss: 0.0153 - val_mae: 0.0894\n",
            "Epoch 446/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 447/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0153 - val_mae: 0.0896\n",
            "Epoch 448/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0899 - val_loss: 0.0153 - val_mae: 0.0891\n",
            "Epoch 449/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0889\n",
            "Epoch 450/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0890 - val_loss: 0.0153 - val_mae: 0.0895\n",
            "Epoch 451/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0897 - val_loss: 0.0152 - val_mae: 0.0893\n",
            "Epoch 452/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0152 - val_mae: 0.0894\n",
            "Epoch 453/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0901\n",
            "Epoch 454/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0898 - val_loss: 0.0153 - val_mae: 0.0895\n",
            "Epoch 455/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 456/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 457/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0892 - val_loss: 0.0153 - val_mae: 0.0895\n",
            "Epoch 458/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0895\n",
            "Epoch 459/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 460/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0900 - val_loss: 0.0153 - val_mae: 0.0889\n",
            "Epoch 461/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0888\n",
            "Epoch 462/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0891 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 463/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0152 - val_mae: 0.0892\n",
            "Epoch 464/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 465/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0898 - val_loss: 0.0153 - val_mae: 0.0891\n",
            "Epoch 466/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0153 - val_mae: 0.0894\n",
            "Epoch 467/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 468/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0892 - val_loss: 0.0153 - val_mae: 0.0899\n",
            "Epoch 469/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0901\n",
            "Epoch 470/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0899 - val_loss: 0.0153 - val_mae: 0.0895\n",
            "Epoch 471/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0153 - val_mae: 0.0896\n",
            "Epoch 472/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0894\n",
            "Epoch 473/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0893 - val_loss: 0.0152 - val_mae: 0.0894\n",
            "Epoch 474/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0152 - val_mae: 0.0895\n",
            "Epoch 475/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0152 - val_mae: 0.0894\n",
            "Epoch 476/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0889\n",
            "Epoch 477/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0888 - val_loss: 0.0153 - val_mae: 0.0898\n",
            "Epoch 478/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0898 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 479/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0900 - val_loss: 0.0153 - val_mae: 0.0886\n",
            "Epoch 480/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0892 - val_loss: 0.0153 - val_mae: 0.0889\n",
            "Epoch 481/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0152 - val_mae: 0.0892\n",
            "Epoch 482/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0897 - val_loss: 0.0153 - val_mae: 0.0888\n",
            "Epoch 483/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 484/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0891 - val_loss: 0.0152 - val_mae: 0.0894\n",
            "Epoch 485/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0892 - val_loss: 0.0153 - val_mae: 0.0906\n",
            "Epoch 486/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0903 - val_loss: 0.0153 - val_mae: 0.0896\n",
            "Epoch 487/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0897\n",
            "Epoch 488/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0897 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 489/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0891\n",
            "Epoch 490/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0152 - val_mae: 0.0892\n",
            "Epoch 491/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0891\n",
            "Epoch 492/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0153 - val_mae: 0.0891\n",
            "Epoch 493/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0894 - val_loss: 0.0152 - val_mae: 0.0893\n",
            "Epoch 494/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0899 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 495/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0892 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 496/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0895 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 497/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0890\n",
            "Epoch 498/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0891 - val_loss: 0.0153 - val_mae: 0.0893\n",
            "Epoch 499/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0896 - val_loss: 0.0153 - val_mae: 0.0892\n",
            "Epoch 500/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0897 - val_loss: 0.0153 - val_mae: 0.0888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltiJYWI6LsJD",
        "colab_type": "code",
        "outputId": "83ba08f4-4665-4c90-dcd3-a8039258513e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "P3 = model3.predict(XVALID)\n",
        "YVALID2 = np.exp(YVALID2)\n",
        "P3=np.exp(P3)\n",
        "\n",
        "#YVALID=np.exp(YVALID)\n",
        "#P3=np.exp(P3)\n",
        "MAE3 = abs(YVALID2 - P3)\n",
        "print(MAE3)\n",
        "M2= MAE3.mean()\n",
        "print(\"M2=\",M2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.43435153e+04 4.06936873e+05 9.06645661e+05 ... 4.45040151e+05\n",
            "  6.80289316e+05 1.01715095e+05]\n",
            " [5.00954578e+05 3.25810000e+02 5.00034598e+05 ... 3.84290880e+04\n",
            "  2.73678253e+05 3.04895967e+05]\n",
            " [8.17619078e+05 3.16338690e+05 1.83370098e+05 ... 2.78235412e+05\n",
            "  4.29862470e+04 6.21560467e+05]\n",
            " ...\n",
            " [4.99027078e+05 2.25331000e+03 5.01962098e+05 ... 4.03565880e+04\n",
            "  2.75605753e+05 3.02968467e+05]\n",
            " [5.38938703e+05 3.76583150e+04 4.62050473e+05 ... 4.44963000e+02\n",
            "  2.35694128e+05 3.42880092e+05]\n",
            " [1.92118265e+05 3.09162123e+05 8.08870911e+05 ... 3.47265401e+05\n",
            "  5.82514566e+05 3.94034510e+03]]\n",
            "M2= 420972.719445511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgad-iiHL1Jg",
        "colab_type": "code",
        "outputId": "ff684825-0bb1-489e-ab5d-09d0828de8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.figure(figsize=(15, 13))\n",
        "plt.plot(h3.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(h3.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "min(h3.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x936 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015223732218146324"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHzkF7y0HHKJ",
        "colab_type": "text"
      },
      "source": [
        "## Neural network with 3 layers (12, 8, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awp6X4fnIci8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(12,input_dim =5, activation='relu'))\n",
        "model2.add(Dense(8, activation='relu'))\n",
        "model2.add(Dense(1, activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt6ZwVgCIi7p",
        "colab_type": "code",
        "outputId": "e993885b-a378-4c40-dd09-25a62fd1efb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2.compile(loss='mse', optimizer = 'rmsprop', metrics=['mae'])\n",
        "history2=model2.fit(XTRAIN, YTRAIN3,validation_data=(XVALID, YVALID3), epochs = 500, batch_size=100, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 178.3523 - mae: 13.3396 - val_loss: 170.5219 - val_mae: 13.0388\n",
            "Epoch 2/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 162.1242 - mae: 12.7038 - val_loss: 153.1887 - val_mae: 12.3383\n",
            "Epoch 3/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 143.2738 - mae: 11.9138 - val_loss: 132.8579 - val_mae: 11.4519\n",
            "Epoch 4/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 121.6273 - mae: 10.9238 - val_loss: 109.9520 - val_mae: 10.3476\n",
            "Epoch 5/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 98.0316 - mae: 9.7127 - val_loss: 85.7952 - val_mae: 9.0195\n",
            "Epoch 6/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 74.0788 - mae: 8.2838 - val_loss: 62.3634 - val_mae: 7.5131\n",
            "Epoch 7/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 51.9460 - mae: 6.7160 - val_loss: 42.0130 - val_mae: 5.9382\n",
            "Epoch 8/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 34.0283 - mae: 5.2245 - val_loss: 26.8777 - val_mae: 4.5229\n",
            "Epoch 9/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 21.8804 - mae: 4.0223 - val_loss: 17.8277 - val_mae: 3.5304\n",
            "Epoch 10/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 15.1283 - mae: 3.2299 - val_loss: 13.3019 - val_mae: 2.9642\n",
            "Epoch 11/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 11.8125 - mae: 2.8111 - val_loss: 10.8871 - val_mae: 2.6756\n",
            "Epoch 12/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 9.8643 - mae: 2.5695 - val_loss: 9.2710 - val_mae: 2.4649\n",
            "Epoch 13/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.4931 - mae: 2.3828 - val_loss: 8.0320 - val_mae: 2.3009\n",
            "Epoch 14/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 7.3479 - mae: 2.2155 - val_loss: 6.9576 - val_mae: 2.1394\n",
            "Epoch 15/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.3545 - mae: 2.0602 - val_loss: 6.0332 - val_mae: 1.9964\n",
            "Epoch 16/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.4865 - mae: 1.9152 - val_loss: 5.2343 - val_mae: 1.8490\n",
            "Epoch 17/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.6881 - mae: 1.7661 - val_loss: 4.4684 - val_mae: 1.7035\n",
            "Epoch 18/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.9341 - mae: 1.6163 - val_loss: 3.7305 - val_mae: 1.5598\n",
            "Epoch 19/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.2638 - mae: 1.4741 - val_loss: 3.1520 - val_mae: 1.4227\n",
            "Epoch 20/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.6730 - mae: 1.3315 - val_loss: 2.5526 - val_mae: 1.2896\n",
            "Epoch 21/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.1560 - mae: 1.1918 - val_loss: 2.0867 - val_mae: 1.1502\n",
            "Epoch 22/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.7245 - mae: 1.0632 - val_loss: 1.6653 - val_mae: 1.0304\n",
            "Epoch 23/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.3514 - mae: 0.9374 - val_loss: 1.2959 - val_mae: 0.8998\n",
            "Epoch 24/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0280 - mae: 0.8110 - val_loss: 0.9985 - val_mae: 0.7999\n",
            "Epoch 25/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7765 - mae: 0.6975 - val_loss: 0.7470 - val_mae: 0.6739\n",
            "Epoch 26/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5857 - mae: 0.5973 - val_loss: 0.5712 - val_mae: 0.5758\n",
            "Epoch 27/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4452 - mae: 0.5114 - val_loss: 0.4395 - val_mae: 0.5015\n",
            "Epoch 28/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3410 - mae: 0.4387 - val_loss: 0.3327 - val_mae: 0.4293\n",
            "Epoch 29/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2672 - mae: 0.3816 - val_loss: 0.2596 - val_mae: 0.3764\n",
            "Epoch 30/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2096 - mae: 0.3357 - val_loss: 0.2114 - val_mae: 0.3193\n",
            "Epoch 31/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1696 - mae: 0.2988 - val_loss: 0.1706 - val_mae: 0.2878\n",
            "Epoch 32/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1391 - mae: 0.2702 - val_loss: 0.1419 - val_mae: 0.2777\n",
            "Epoch 33/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1157 - mae: 0.2450 - val_loss: 0.1157 - val_mae: 0.2395\n",
            "Epoch 34/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0977 - mae: 0.2249 - val_loss: 0.1003 - val_mae: 0.2280\n",
            "Epoch 35/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0845 - mae: 0.2072 - val_loss: 0.0832 - val_mae: 0.2059\n",
            "Epoch 36/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0738 - mae: 0.1945 - val_loss: 0.0732 - val_mae: 0.1925\n",
            "Epoch 37/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0627 - mae: 0.1802 - val_loss: 0.0621 - val_mae: 0.1819\n",
            "Epoch 38/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0552 - mae: 0.1679 - val_loss: 0.0535 - val_mae: 0.1662\n",
            "Epoch 39/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0492 - mae: 0.1569 - val_loss: 0.0461 - val_mae: 0.1557\n",
            "Epoch 40/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - mae: 0.1491 - val_loss: 0.0420 - val_mae: 0.1508\n",
            "Epoch 41/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0395 - mae: 0.1406 - val_loss: 0.0388 - val_mae: 0.1413\n",
            "Epoch 42/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0367 - mae: 0.1347 - val_loss: 0.0347 - val_mae: 0.1369\n",
            "Epoch 43/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0344 - mae: 0.1284 - val_loss: 0.0310 - val_mae: 0.1292\n",
            "Epoch 44/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0312 - mae: 0.1228 - val_loss: 0.0282 - val_mae: 0.1226\n",
            "Epoch 45/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0292 - mae: 0.1176 - val_loss: 0.0253 - val_mae: 0.1175\n",
            "Epoch 46/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.1154 - val_loss: 0.0255 - val_mae: 0.1201\n",
            "Epoch 47/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0268 - mae: 0.1138 - val_loss: 0.0246 - val_mae: 0.1186\n",
            "Epoch 48/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0250 - mae: 0.1077 - val_loss: 0.0201 - val_mae: 0.1022\n",
            "Epoch 49/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0243 - mae: 0.1067 - val_loss: 0.0231 - val_mae: 0.1122\n",
            "Epoch 50/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0229 - mae: 0.1035 - val_loss: 0.0188 - val_mae: 0.1024\n",
            "Epoch 51/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0229 - mae: 0.1035 - val_loss: 0.0188 - val_mae: 0.1025\n",
            "Epoch 52/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - mae: 0.1008 - val_loss: 0.0166 - val_mae: 0.0959\n",
            "Epoch 53/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0219 - mae: 0.0997 - val_loss: 0.0163 - val_mae: 0.0945\n",
            "Epoch 54/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - mae: 0.0973 - val_loss: 0.0162 - val_mae: 0.0933\n",
            "Epoch 55/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0214 - mae: 0.0997 - val_loss: 0.0145 - val_mae: 0.0896\n",
            "Epoch 56/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.0955 - val_loss: 0.0203 - val_mae: 0.1091\n",
            "Epoch 57/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - mae: 0.0969 - val_loss: 0.0161 - val_mae: 0.0979\n",
            "Epoch 58/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.0943 - val_loss: 0.0136 - val_mae: 0.0869\n",
            "Epoch 59/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0193 - mae: 0.0928 - val_loss: 0.0153 - val_mae: 0.0956\n",
            "Epoch 60/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - mae: 0.0930 - val_loss: 0.0154 - val_mae: 0.0923\n",
            "Epoch 61/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.0930 - val_loss: 0.0203 - val_mae: 0.1140\n",
            "Epoch 62/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0189 - mae: 0.0937 - val_loss: 0.0154 - val_mae: 0.0952\n",
            "Epoch 63/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.0927 - val_loss: 0.0134 - val_mae: 0.0879\n",
            "Epoch 64/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.0909 - val_loss: 0.0155 - val_mae: 0.0956\n",
            "Epoch 65/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.0919 - val_loss: 0.0127 - val_mae: 0.0842\n",
            "Epoch 66/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0181 - mae: 0.0903 - val_loss: 0.0158 - val_mae: 0.0949\n",
            "Epoch 67/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0182 - mae: 0.0918 - val_loss: 0.0153 - val_mae: 0.0964\n",
            "Epoch 68/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.0905 - val_loss: 0.0127 - val_mae: 0.0856\n",
            "Epoch 69/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.0917 - val_loss: 0.0118 - val_mae: 0.0818\n",
            "Epoch 70/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0173 - mae: 0.0886 - val_loss: 0.0123 - val_mae: 0.0834\n",
            "Epoch 71/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.0888 - val_loss: 0.0119 - val_mae: 0.0818\n",
            "Epoch 72/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.0895 - val_loss: 0.0165 - val_mae: 0.1036\n",
            "Epoch 73/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0176 - mae: 0.0903 - val_loss: 0.0116 - val_mae: 0.0819\n",
            "Epoch 74/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0168 - mae: 0.0879 - val_loss: 0.0114 - val_mae: 0.0808\n",
            "Epoch 75/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.0889 - val_loss: 0.0128 - val_mae: 0.0879\n",
            "Epoch 76/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0166 - mae: 0.0860 - val_loss: 0.0205 - val_mae: 0.1128\n",
            "Epoch 77/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0172 - mae: 0.0893 - val_loss: 0.0115 - val_mae: 0.0813\n",
            "Epoch 78/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0878 - val_loss: 0.0115 - val_mae: 0.0815\n",
            "Epoch 79/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0867 - val_loss: 0.0114 - val_mae: 0.0821\n",
            "Epoch 80/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.0879 - val_loss: 0.0113 - val_mae: 0.0811\n",
            "Epoch 81/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0845 - val_loss: 0.0111 - val_mae: 0.0802\n",
            "Epoch 82/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0166 - mae: 0.0866 - val_loss: 0.0138 - val_mae: 0.0901\n",
            "Epoch 83/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0875 - val_loss: 0.0127 - val_mae: 0.0869\n",
            "Epoch 84/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0890 - val_loss: 0.0114 - val_mae: 0.0811\n",
            "Epoch 85/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.0864 - val_loss: 0.0122 - val_mae: 0.0855\n",
            "Epoch 86/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - mae: 0.0884 - val_loss: 0.0132 - val_mae: 0.0878\n",
            "Epoch 87/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0882 - val_loss: 0.0112 - val_mae: 0.0810\n",
            "Epoch 88/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - mae: 0.0884 - val_loss: 0.0110 - val_mae: 0.0792\n",
            "Epoch 89/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0847 - val_loss: 0.0110 - val_mae: 0.0784\n",
            "Epoch 90/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0873 - val_loss: 0.0111 - val_mae: 0.0807\n",
            "Epoch 91/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0867 - val_loss: 0.0183 - val_mae: 0.1064\n",
            "Epoch 92/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0882 - val_loss: 0.0130 - val_mae: 0.0874\n",
            "Epoch 93/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0859 - val_loss: 0.0113 - val_mae: 0.0794\n",
            "Epoch 94/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0866 - val_loss: 0.0107 - val_mae: 0.0781\n",
            "Epoch 95/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0858 - val_loss: 0.0118 - val_mae: 0.0828\n",
            "Epoch 96/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0868 - val_loss: 0.0110 - val_mae: 0.0805\n",
            "Epoch 97/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0850 - val_loss: 0.0112 - val_mae: 0.0804\n",
            "Epoch 98/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0871 - val_loss: 0.0142 - val_mae: 0.0921\n",
            "Epoch 99/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0873 - val_loss: 0.0111 - val_mae: 0.0791\n",
            "Epoch 100/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0850 - val_loss: 0.0142 - val_mae: 0.0902\n",
            "Epoch 101/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0879 - val_loss: 0.0114 - val_mae: 0.0814\n",
            "Epoch 102/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - mae: 0.0887 - val_loss: 0.0125 - val_mae: 0.0862\n",
            "Epoch 103/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.0876 - val_loss: 0.0108 - val_mae: 0.0779\n",
            "Epoch 104/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0855 - val_loss: 0.0154 - val_mae: 0.0956\n",
            "Epoch 105/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0880 - val_loss: 0.0120 - val_mae: 0.0822\n",
            "Epoch 106/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0870 - val_loss: 0.0115 - val_mae: 0.0821\n",
            "Epoch 107/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0845 - val_loss: 0.0179 - val_mae: 0.1083\n",
            "Epoch 108/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0869 - val_loss: 0.0110 - val_mae: 0.0792\n",
            "Epoch 109/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0859 - val_loss: 0.0170 - val_mae: 0.1047\n",
            "Epoch 110/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0163 - mae: 0.0867 - val_loss: 0.0106 - val_mae: 0.0773\n",
            "Epoch 111/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0869 - val_loss: 0.0149 - val_mae: 0.0946\n",
            "Epoch 112/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0865 - val_loss: 0.0132 - val_mae: 0.0880\n",
            "Epoch 113/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0861 - val_loss: 0.0163 - val_mae: 0.1036\n",
            "Epoch 114/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0871 - val_loss: 0.0116 - val_mae: 0.0815\n",
            "Epoch 115/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0866 - val_loss: 0.0128 - val_mae: 0.0889\n",
            "Epoch 116/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0166 - mae: 0.0883 - val_loss: 0.0122 - val_mae: 0.0869\n",
            "Epoch 117/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0869 - val_loss: 0.0152 - val_mae: 0.0951\n",
            "Epoch 118/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0855 - val_loss: 0.0111 - val_mae: 0.0806\n",
            "Epoch 119/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0864 - val_loss: 0.0108 - val_mae: 0.0779\n",
            "Epoch 120/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0870 - val_loss: 0.0126 - val_mae: 0.0852\n",
            "Epoch 121/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0857 - val_loss: 0.0124 - val_mae: 0.0860\n",
            "Epoch 122/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0865 - val_loss: 0.0117 - val_mae: 0.0820\n",
            "Epoch 123/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0875 - val_loss: 0.0109 - val_mae: 0.0782\n",
            "Epoch 124/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0866 - val_loss: 0.0121 - val_mae: 0.0832\n",
            "Epoch 125/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0863 - val_loss: 0.0129 - val_mae: 0.0891\n",
            "Epoch 126/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0867 - val_loss: 0.0141 - val_mae: 0.0949\n",
            "Epoch 127/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.0870 - val_loss: 0.0155 - val_mae: 0.0959\n",
            "Epoch 128/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0861 - val_loss: 0.0114 - val_mae: 0.0829\n",
            "Epoch 129/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.0871 - val_loss: 0.0107 - val_mae: 0.0776\n",
            "Epoch 130/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0864 - val_loss: 0.0127 - val_mae: 0.0861\n",
            "Epoch 131/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0855 - val_loss: 0.0117 - val_mae: 0.0817\n",
            "Epoch 132/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0879 - val_loss: 0.0119 - val_mae: 0.0841\n",
            "Epoch 133/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0853 - val_loss: 0.0120 - val_mae: 0.0824\n",
            "Epoch 134/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0160 - mae: 0.0866 - val_loss: 0.0105 - val_mae: 0.0773\n",
            "Epoch 135/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0858 - val_loss: 0.0110 - val_mae: 0.0797\n",
            "Epoch 136/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0877 - val_loss: 0.0116 - val_mae: 0.0830\n",
            "Epoch 137/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0863 - val_loss: 0.0105 - val_mae: 0.0768\n",
            "Epoch 138/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0855 - val_loss: 0.0118 - val_mae: 0.0847\n",
            "Epoch 139/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0164 - mae: 0.0884 - val_loss: 0.0107 - val_mae: 0.0781\n",
            "Epoch 140/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0853 - val_loss: 0.0125 - val_mae: 0.0850\n",
            "Epoch 141/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0859 - val_loss: 0.0112 - val_mae: 0.0814\n",
            "Epoch 142/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0861 - val_loss: 0.0107 - val_mae: 0.0777\n",
            "Epoch 143/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0853 - val_loss: 0.0106 - val_mae: 0.0776\n",
            "Epoch 144/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0894 - val_loss: 0.0125 - val_mae: 0.0869\n",
            "Epoch 145/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0849 - val_loss: 0.0113 - val_mae: 0.0809\n",
            "Epoch 146/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0867 - val_loss: 0.0144 - val_mae: 0.0936\n",
            "Epoch 147/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0860 - val_loss: 0.0106 - val_mae: 0.0775\n",
            "Epoch 148/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0866 - val_loss: 0.0167 - val_mae: 0.1042\n",
            "Epoch 149/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0876 - val_loss: 0.0127 - val_mae: 0.0862\n",
            "Epoch 150/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0854 - val_loss: 0.0107 - val_mae: 0.0778\n",
            "Epoch 151/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0864 - val_loss: 0.0142 - val_mae: 0.0922\n",
            "Epoch 152/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.0890 - val_loss: 0.0107 - val_mae: 0.0781\n",
            "Epoch 153/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0875 - val_loss: 0.0153 - val_mae: 0.0924\n",
            "Epoch 154/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0867 - val_loss: 0.0122 - val_mae: 0.0849\n",
            "Epoch 155/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0882 - val_loss: 0.0156 - val_mae: 0.0946\n",
            "Epoch 156/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0871 - val_loss: 0.0110 - val_mae: 0.0791\n",
            "Epoch 157/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0854 - val_loss: 0.0111 - val_mae: 0.0796\n",
            "Epoch 158/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0863 - val_loss: 0.0146 - val_mae: 0.0956\n",
            "Epoch 159/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0879 - val_loss: 0.0123 - val_mae: 0.0835\n",
            "Epoch 160/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0869 - val_loss: 0.0149 - val_mae: 0.0953\n",
            "Epoch 161/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0864 - val_loss: 0.0110 - val_mae: 0.0790\n",
            "Epoch 162/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0873 - val_loss: 0.0106 - val_mae: 0.0778\n",
            "Epoch 163/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0856 - val_loss: 0.0108 - val_mae: 0.0786\n",
            "Epoch 164/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0854 - val_loss: 0.0114 - val_mae: 0.0797\n",
            "Epoch 165/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0861 - val_loss: 0.0125 - val_mae: 0.0885\n",
            "Epoch 166/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0866 - val_loss: 0.0105 - val_mae: 0.0775\n",
            "Epoch 167/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0876 - val_loss: 0.0114 - val_mae: 0.0817\n",
            "Epoch 168/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0876 - val_loss: 0.0117 - val_mae: 0.0823\n",
            "Epoch 169/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0858 - val_loss: 0.0113 - val_mae: 0.0815\n",
            "Epoch 170/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0853 - val_loss: 0.0119 - val_mae: 0.0832\n",
            "Epoch 171/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0867 - val_loss: 0.0110 - val_mae: 0.0787\n",
            "Epoch 172/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0851 - val_loss: 0.0180 - val_mae: 0.1088\n",
            "Epoch 173/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0868 - val_loss: 0.0107 - val_mae: 0.0778\n",
            "Epoch 174/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0875 - val_loss: 0.0119 - val_mae: 0.0842\n",
            "Epoch 175/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0860 - val_loss: 0.0117 - val_mae: 0.0838\n",
            "Epoch 176/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0869 - val_loss: 0.0105 - val_mae: 0.0768\n",
            "Epoch 177/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0857 - val_loss: 0.0108 - val_mae: 0.0790\n",
            "Epoch 178/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0866 - val_loss: 0.0118 - val_mae: 0.0827\n",
            "Epoch 179/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0867 - val_loss: 0.0130 - val_mae: 0.0871\n",
            "Epoch 180/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0163 - mae: 0.0879 - val_loss: 0.0112 - val_mae: 0.0799\n",
            "Epoch 181/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0840 - val_loss: 0.0187 - val_mae: 0.1125\n",
            "Epoch 182/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0862 - val_loss: 0.0120 - val_mae: 0.0852\n",
            "Epoch 183/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0856 - val_loss: 0.0191 - val_mae: 0.1144\n",
            "Epoch 184/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0878 - val_loss: 0.0136 - val_mae: 0.0914\n",
            "Epoch 185/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0867 - val_loss: 0.0155 - val_mae: 0.1012\n",
            "Epoch 186/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0871 - val_loss: 0.0175 - val_mae: 0.1070\n",
            "Epoch 187/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0865 - val_loss: 0.0150 - val_mae: 0.0981\n",
            "Epoch 188/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0867 - val_loss: 0.0119 - val_mae: 0.0843\n",
            "Epoch 189/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0859 - val_loss: 0.0117 - val_mae: 0.0837\n",
            "Epoch 190/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0863 - val_loss: 0.0120 - val_mae: 0.0850\n",
            "Epoch 191/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0875 - val_loss: 0.0108 - val_mae: 0.0785\n",
            "Epoch 192/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0858 - val_loss: 0.0114 - val_mae: 0.0821\n",
            "Epoch 193/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0862 - val_loss: 0.0132 - val_mae: 0.0901\n",
            "Epoch 194/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0871 - val_loss: 0.0143 - val_mae: 0.0897\n",
            "Epoch 195/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0871 - val_loss: 0.0105 - val_mae: 0.0771\n",
            "Epoch 196/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0870 - val_loss: 0.0132 - val_mae: 0.0882\n",
            "Epoch 197/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0861 - val_loss: 0.0105 - val_mae: 0.0768\n",
            "Epoch 198/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0857 - val_loss: 0.0142 - val_mae: 0.0900\n",
            "Epoch 199/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0869 - val_loss: 0.0195 - val_mae: 0.1073\n",
            "Epoch 200/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0856 - val_loss: 0.0108 - val_mae: 0.0783\n",
            "Epoch 201/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0856 - val_loss: 0.0117 - val_mae: 0.0824\n",
            "Epoch 202/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0882 - val_loss: 0.0142 - val_mae: 0.0922\n",
            "Epoch 203/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0846 - val_loss: 0.0116 - val_mae: 0.0829\n",
            "Epoch 204/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0861 - val_loss: 0.0113 - val_mae: 0.0806\n",
            "Epoch 205/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0848 - val_loss: 0.0121 - val_mae: 0.0854\n",
            "Epoch 206/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0866 - val_loss: 0.0112 - val_mae: 0.0799\n",
            "Epoch 207/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0863 - val_loss: 0.0133 - val_mae: 0.0883\n",
            "Epoch 208/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0849 - val_loss: 0.0122 - val_mae: 0.0865\n",
            "Epoch 209/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0853 - val_loss: 0.0175 - val_mae: 0.1061\n",
            "Epoch 210/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0859 - val_loss: 0.0117 - val_mae: 0.0842\n",
            "Epoch 211/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0869 - val_loss: 0.0124 - val_mae: 0.0830\n",
            "Epoch 212/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0859 - val_loss: 0.0164 - val_mae: 0.1051\n",
            "Epoch 213/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0877 - val_loss: 0.0107 - val_mae: 0.0786\n",
            "Epoch 214/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0857 - val_loss: 0.0114 - val_mae: 0.0822\n",
            "Epoch 215/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0865 - val_loss: 0.0118 - val_mae: 0.0841\n",
            "Epoch 216/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0862 - val_loss: 0.0137 - val_mae: 0.0894\n",
            "Epoch 217/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0870 - val_loss: 0.0136 - val_mae: 0.0879\n",
            "Epoch 218/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0866 - val_loss: 0.0140 - val_mae: 0.0940\n",
            "Epoch 219/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0862 - val_loss: 0.0241 - val_mae: 0.1267\n",
            "Epoch 220/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0877 - val_loss: 0.0106 - val_mae: 0.0777\n",
            "Epoch 221/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0870 - val_loss: 0.0111 - val_mae: 0.0795\n",
            "Epoch 222/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0874 - val_loss: 0.0112 - val_mae: 0.0810\n",
            "Epoch 223/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0868 - val_loss: 0.0106 - val_mae: 0.0769\n",
            "Epoch 224/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0864 - val_loss: 0.0115 - val_mae: 0.0825\n",
            "Epoch 225/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0860 - val_loss: 0.0131 - val_mae: 0.0879\n",
            "Epoch 226/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0864 - val_loss: 0.0153 - val_mae: 0.0988\n",
            "Epoch 227/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0892 - val_loss: 0.0105 - val_mae: 0.0772\n",
            "Epoch 228/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0857 - val_loss: 0.0108 - val_mae: 0.0782\n",
            "Epoch 229/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0889 - val_loss: 0.0106 - val_mae: 0.0776\n",
            "Epoch 230/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0864 - val_loss: 0.0109 - val_mae: 0.0792\n",
            "Epoch 231/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0870 - val_loss: 0.0121 - val_mae: 0.0857\n",
            "Epoch 232/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0864 - val_loss: 0.0106 - val_mae: 0.0778\n",
            "Epoch 233/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0848 - val_loss: 0.0108 - val_mae: 0.0785\n",
            "Epoch 234/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0875 - val_loss: 0.0104 - val_mae: 0.0771\n",
            "Epoch 235/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0862 - val_loss: 0.0106 - val_mae: 0.0774\n",
            "Epoch 236/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0844 - val_loss: 0.0104 - val_mae: 0.0770\n",
            "Epoch 237/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0859 - val_loss: 0.0110 - val_mae: 0.0800\n",
            "Epoch 238/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0862 - val_loss: 0.0113 - val_mae: 0.0806\n",
            "Epoch 239/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0860 - val_loss: 0.0151 - val_mae: 0.0958\n",
            "Epoch 240/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0881 - val_loss: 0.0120 - val_mae: 0.0826\n",
            "Epoch 241/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0854 - val_loss: 0.0122 - val_mae: 0.0847\n",
            "Epoch 242/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0874 - val_loss: 0.0111 - val_mae: 0.0804\n",
            "Epoch 243/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0863 - val_loss: 0.0115 - val_mae: 0.0825\n",
            "Epoch 244/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0861 - val_loss: 0.0123 - val_mae: 0.0835\n",
            "Epoch 245/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0876 - val_loss: 0.0155 - val_mae: 0.0974\n",
            "Epoch 246/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0161 - mae: 0.0887 - val_loss: 0.0136 - val_mae: 0.0920\n",
            "Epoch 247/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0867 - val_loss: 0.0125 - val_mae: 0.0853\n",
            "Epoch 248/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0860 - val_loss: 0.0148 - val_mae: 0.0954\n",
            "Epoch 249/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0876 - val_loss: 0.0105 - val_mae: 0.0779\n",
            "Epoch 250/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0879 - val_loss: 0.0125 - val_mae: 0.0860\n",
            "Epoch 251/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0841 - val_loss: 0.0126 - val_mae: 0.0860\n",
            "Epoch 252/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0852 - val_loss: 0.0107 - val_mae: 0.0784\n",
            "Epoch 253/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0872 - val_loss: 0.0109 - val_mae: 0.0784\n",
            "Epoch 254/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0846 - val_loss: 0.0131 - val_mae: 0.0903\n",
            "Epoch 255/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0880 - val_loss: 0.0114 - val_mae: 0.0801\n",
            "Epoch 256/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0854 - val_loss: 0.0134 - val_mae: 0.0903\n",
            "Epoch 257/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0870 - val_loss: 0.0104 - val_mae: 0.0767\n",
            "Epoch 258/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0852 - val_loss: 0.0158 - val_mae: 0.1012\n",
            "Epoch 259/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0874 - val_loss: 0.0124 - val_mae: 0.0842\n",
            "Epoch 260/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0856 - val_loss: 0.0120 - val_mae: 0.0850\n",
            "Epoch 261/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0879 - val_loss: 0.0108 - val_mae: 0.0786\n",
            "Epoch 262/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0859 - val_loss: 0.0109 - val_mae: 0.0788\n",
            "Epoch 263/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0856 - val_loss: 0.0143 - val_mae: 0.0947\n",
            "Epoch 264/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0842 - val_loss: 0.0150 - val_mae: 0.0925\n",
            "Epoch 265/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0871 - val_loss: 0.0136 - val_mae: 0.0877\n",
            "Epoch 266/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0870 - val_loss: 0.0152 - val_mae: 0.0962\n",
            "Epoch 267/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0857 - val_loss: 0.0140 - val_mae: 0.0912\n",
            "Epoch 268/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0878 - val_loss: 0.0140 - val_mae: 0.0957\n",
            "Epoch 269/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0865 - val_loss: 0.0125 - val_mae: 0.0848\n",
            "Epoch 270/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0869 - val_loss: 0.0121 - val_mae: 0.0843\n",
            "Epoch 271/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0849 - val_loss: 0.0129 - val_mae: 0.0879\n",
            "Epoch 272/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0874 - val_loss: 0.0133 - val_mae: 0.0881\n",
            "Epoch 273/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0880 - val_loss: 0.0123 - val_mae: 0.0866\n",
            "Epoch 274/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0857 - val_loss: 0.0151 - val_mae: 0.0953\n",
            "Epoch 275/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0862 - val_loss: 0.0128 - val_mae: 0.0886\n",
            "Epoch 276/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0872 - val_loss: 0.0123 - val_mae: 0.0866\n",
            "Epoch 277/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0865 - val_loss: 0.0126 - val_mae: 0.0839\n",
            "Epoch 278/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0870 - val_loss: 0.0123 - val_mae: 0.0848\n",
            "Epoch 279/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0855 - val_loss: 0.0149 - val_mae: 0.0918\n",
            "Epoch 280/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0858 - val_loss: 0.0111 - val_mae: 0.0794\n",
            "Epoch 281/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0855 - val_loss: 0.0111 - val_mae: 0.0798\n",
            "Epoch 282/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0864 - val_loss: 0.0119 - val_mae: 0.0823\n",
            "Epoch 283/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0859 - val_loss: 0.0136 - val_mae: 0.0894\n",
            "Epoch 284/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0879 - val_loss: 0.0106 - val_mae: 0.0777\n",
            "Epoch 285/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0852 - val_loss: 0.0134 - val_mae: 0.0885\n",
            "Epoch 286/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0880 - val_loss: 0.0121 - val_mae: 0.0858\n",
            "Epoch 287/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0871 - val_loss: 0.0145 - val_mae: 0.0940\n",
            "Epoch 288/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0853 - val_loss: 0.0109 - val_mae: 0.0790\n",
            "Epoch 289/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0862 - val_loss: 0.0203 - val_mae: 0.1127\n",
            "Epoch 290/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0873 - val_loss: 0.0114 - val_mae: 0.0800\n",
            "Epoch 291/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0850 - val_loss: 0.0132 - val_mae: 0.0891\n",
            "Epoch 292/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0868 - val_loss: 0.0116 - val_mae: 0.0808\n",
            "Epoch 293/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0855 - val_loss: 0.0112 - val_mae: 0.0808\n",
            "Epoch 294/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0856 - val_loss: 0.0111 - val_mae: 0.0795\n",
            "Epoch 295/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0877 - val_loss: 0.0124 - val_mae: 0.0865\n",
            "Epoch 296/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0862 - val_loss: 0.0135 - val_mae: 0.0887\n",
            "Epoch 297/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0863 - val_loss: 0.0110 - val_mae: 0.0782\n",
            "Epoch 298/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0868 - val_loss: 0.0107 - val_mae: 0.0773\n",
            "Epoch 299/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0856 - val_loss: 0.0108 - val_mae: 0.0784\n",
            "Epoch 300/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0861 - val_loss: 0.0118 - val_mae: 0.0816\n",
            "Epoch 301/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0869 - val_loss: 0.0125 - val_mae: 0.0867\n",
            "Epoch 302/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0861 - val_loss: 0.0130 - val_mae: 0.0894\n",
            "Epoch 303/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0858 - val_loss: 0.0117 - val_mae: 0.0825\n",
            "Epoch 304/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0867 - val_loss: 0.0139 - val_mae: 0.0951\n",
            "Epoch 305/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0855 - val_loss: 0.0119 - val_mae: 0.0822\n",
            "Epoch 306/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0852 - val_loss: 0.0181 - val_mae: 0.1114\n",
            "Epoch 307/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0891 - val_loss: 0.0128 - val_mae: 0.0885\n",
            "Epoch 308/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0842 - val_loss: 0.0117 - val_mae: 0.0812\n",
            "Epoch 309/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0866 - val_loss: 0.0126 - val_mae: 0.0882\n",
            "Epoch 310/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0866 - val_loss: 0.0110 - val_mae: 0.0802\n",
            "Epoch 311/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0853 - val_loss: 0.0125 - val_mae: 0.0866\n",
            "Epoch 312/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0860 - val_loss: 0.0132 - val_mae: 0.0880\n",
            "Epoch 313/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0873 - val_loss: 0.0140 - val_mae: 0.0919\n",
            "Epoch 314/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0855 - val_loss: 0.0116 - val_mae: 0.0821\n",
            "Epoch 315/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0878 - val_loss: 0.0133 - val_mae: 0.0916\n",
            "Epoch 316/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0154 - mae: 0.0882 - val_loss: 0.0115 - val_mae: 0.0819\n",
            "Epoch 317/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0850 - val_loss: 0.0109 - val_mae: 0.0788\n",
            "Epoch 318/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0877 - val_loss: 0.0121 - val_mae: 0.0857\n",
            "Epoch 319/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0836 - val_loss: 0.0106 - val_mae: 0.0774\n",
            "Epoch 320/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0872 - val_loss: 0.0106 - val_mae: 0.0767\n",
            "Epoch 321/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0856 - val_loss: 0.0132 - val_mae: 0.0914\n",
            "Epoch 322/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0855 - val_loss: 0.0120 - val_mae: 0.0810\n",
            "Epoch 323/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0857 - val_loss: 0.0112 - val_mae: 0.0805\n",
            "Epoch 324/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0863 - val_loss: 0.0136 - val_mae: 0.0922\n",
            "Epoch 325/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0886 - val_loss: 0.0106 - val_mae: 0.0779\n",
            "Epoch 326/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0854 - val_loss: 0.0107 - val_mae: 0.0776\n",
            "Epoch 327/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0868 - val_loss: 0.0171 - val_mae: 0.1036\n",
            "Epoch 328/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0879 - val_loss: 0.0111 - val_mae: 0.0799\n",
            "Epoch 329/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0868 - val_loss: 0.0133 - val_mae: 0.0858\n",
            "Epoch 330/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0850 - val_loss: 0.0104 - val_mae: 0.0767\n",
            "Epoch 331/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0856 - val_loss: 0.0114 - val_mae: 0.0804\n",
            "Epoch 332/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0847 - val_loss: 0.0228 - val_mae: 0.1252\n",
            "Epoch 333/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0838 - val_loss: 0.0118 - val_mae: 0.0821\n",
            "Epoch 334/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0881 - val_loss: 0.0111 - val_mae: 0.0786\n",
            "Epoch 335/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0868 - val_loss: 0.0107 - val_mae: 0.0781\n",
            "Epoch 336/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0863 - val_loss: 0.0133 - val_mae: 0.0870\n",
            "Epoch 337/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0864 - val_loss: 0.0111 - val_mae: 0.0791\n",
            "Epoch 338/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0856 - val_loss: 0.0105 - val_mae: 0.0771\n",
            "Epoch 339/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0862 - val_loss: 0.0112 - val_mae: 0.0799\n",
            "Epoch 340/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0887 - val_loss: 0.0135 - val_mae: 0.0890\n",
            "Epoch 341/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0867 - val_loss: 0.0112 - val_mae: 0.0794\n",
            "Epoch 342/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0858 - val_loss: 0.0179 - val_mae: 0.1068\n",
            "Epoch 343/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0841 - val_loss: 0.0114 - val_mae: 0.0799\n",
            "Epoch 344/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0853 - val_loss: 0.0115 - val_mae: 0.0793\n",
            "Epoch 345/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0872 - val_loss: 0.0115 - val_mae: 0.0820\n",
            "Epoch 346/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0857 - val_loss: 0.0113 - val_mae: 0.0806\n",
            "Epoch 347/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0858 - val_loss: 0.0123 - val_mae: 0.0852\n",
            "Epoch 348/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0844 - val_loss: 0.0135 - val_mae: 0.0906\n",
            "Epoch 349/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0901 - val_loss: 0.0111 - val_mae: 0.0781\n",
            "Epoch 350/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0847 - val_loss: 0.0119 - val_mae: 0.0836\n",
            "Epoch 351/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0851 - val_loss: 0.0121 - val_mae: 0.0815\n",
            "Epoch 352/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0885 - val_loss: 0.0134 - val_mae: 0.0894\n",
            "Epoch 353/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0853 - val_loss: 0.0108 - val_mae: 0.0781\n",
            "Epoch 354/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0865 - val_loss: 0.0117 - val_mae: 0.0810\n",
            "Epoch 355/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0860 - val_loss: 0.0107 - val_mae: 0.0777\n",
            "Epoch 356/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0857 - val_loss: 0.0130 - val_mae: 0.0851\n",
            "Epoch 357/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0868 - val_loss: 0.0109 - val_mae: 0.0788\n",
            "Epoch 358/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0865 - val_loss: 0.0148 - val_mae: 0.0939\n",
            "Epoch 359/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0856 - val_loss: 0.0129 - val_mae: 0.0866\n",
            "Epoch 360/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0866 - val_loss: 0.0108 - val_mae: 0.0779\n",
            "Epoch 361/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0858 - val_loss: 0.0112 - val_mae: 0.0786\n",
            "Epoch 362/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0862 - val_loss: 0.0119 - val_mae: 0.0819\n",
            "Epoch 363/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0856 - val_loss: 0.0150 - val_mae: 0.0934\n",
            "Epoch 364/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0849 - val_loss: 0.0115 - val_mae: 0.0808\n",
            "Epoch 365/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0856 - val_loss: 0.0158 - val_mae: 0.0976\n",
            "Epoch 366/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0859 - val_loss: 0.0120 - val_mae: 0.0826\n",
            "Epoch 367/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0855 - val_loss: 0.0122 - val_mae: 0.0833\n",
            "Epoch 368/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0855 - val_loss: 0.0177 - val_mae: 0.1032\n",
            "Epoch 369/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0865 - val_loss: 0.0109 - val_mae: 0.0779\n",
            "Epoch 370/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0864 - val_loss: 0.0114 - val_mae: 0.0807\n",
            "Epoch 371/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0867 - val_loss: 0.0134 - val_mae: 0.0915\n",
            "Epoch 372/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0865 - val_loss: 0.0130 - val_mae: 0.0862\n",
            "Epoch 373/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0856 - val_loss: 0.0118 - val_mae: 0.0827\n",
            "Epoch 374/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0874 - val_loss: 0.0113 - val_mae: 0.0785\n",
            "Epoch 375/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0848 - val_loss: 0.0116 - val_mae: 0.0809\n",
            "Epoch 376/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0864 - val_loss: 0.0114 - val_mae: 0.0808\n",
            "Epoch 377/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0854 - val_loss: 0.0121 - val_mae: 0.0814\n",
            "Epoch 378/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0865 - val_loss: 0.0116 - val_mae: 0.0810\n",
            "Epoch 379/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0858 - val_loss: 0.0108 - val_mae: 0.0775\n",
            "Epoch 380/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0864 - val_loss: 0.0108 - val_mae: 0.0776\n",
            "Epoch 381/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0853 - val_loss: 0.0136 - val_mae: 0.0889\n",
            "Epoch 382/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0883 - val_loss: 0.0121 - val_mae: 0.0818\n",
            "Epoch 383/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0858 - val_loss: 0.0126 - val_mae: 0.0876\n",
            "Epoch 384/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0871 - val_loss: 0.0110 - val_mae: 0.0779\n",
            "Epoch 385/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0855 - val_loss: 0.0109 - val_mae: 0.0775\n",
            "Epoch 386/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0842 - val_loss: 0.0110 - val_mae: 0.0783\n",
            "Epoch 387/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0865 - val_loss: 0.0111 - val_mae: 0.0784\n",
            "Epoch 388/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0864 - val_loss: 0.0120 - val_mae: 0.0834\n",
            "Epoch 389/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0155 - mae: 0.0879 - val_loss: 0.0121 - val_mae: 0.0831\n",
            "Epoch 390/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0865 - val_loss: 0.0115 - val_mae: 0.0810\n",
            "Epoch 391/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0856 - val_loss: 0.0123 - val_mae: 0.0832\n",
            "Epoch 392/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0855 - val_loss: 0.0132 - val_mae: 0.0907\n",
            "Epoch 393/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0870 - val_loss: 0.0112 - val_mae: 0.0799\n",
            "Epoch 394/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0859 - val_loss: 0.0124 - val_mae: 0.0866\n",
            "Epoch 395/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0874 - val_loss: 0.0140 - val_mae: 0.0911\n",
            "Epoch 396/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0856 - val_loss: 0.0115 - val_mae: 0.0813\n",
            "Epoch 397/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0870 - val_loss: 0.0112 - val_mae: 0.0792\n",
            "Epoch 398/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0846 - val_loss: 0.0109 - val_mae: 0.0775\n",
            "Epoch 399/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0886 - val_loss: 0.0107 - val_mae: 0.0771\n",
            "Epoch 400/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0866 - val_loss: 0.0118 - val_mae: 0.0825\n",
            "Epoch 401/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0858 - val_loss: 0.0109 - val_mae: 0.0773\n",
            "Epoch 402/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0852 - val_loss: 0.0130 - val_mae: 0.0871\n",
            "Epoch 403/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0850 - val_loss: 0.0119 - val_mae: 0.0823\n",
            "Epoch 404/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0858 - val_loss: 0.0115 - val_mae: 0.0802\n",
            "Epoch 405/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0853 - val_loss: 0.0133 - val_mae: 0.0855\n",
            "Epoch 406/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0855 - val_loss: 0.0154 - val_mae: 0.0927\n",
            "Epoch 407/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0858 - val_loss: 0.0119 - val_mae: 0.0803\n",
            "Epoch 408/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0852 - val_loss: 0.0116 - val_mae: 0.0819\n",
            "Epoch 409/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0859 - val_loss: 0.0165 - val_mae: 0.1008\n",
            "Epoch 410/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0866 - val_loss: 0.0106 - val_mae: 0.0767\n",
            "Epoch 411/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0845 - val_loss: 0.0188 - val_mae: 0.1121\n",
            "Epoch 412/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0857 - val_loss: 0.0131 - val_mae: 0.0863\n",
            "Epoch 413/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0876 - val_loss: 0.0112 - val_mae: 0.0793\n",
            "Epoch 414/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0844 - val_loss: 0.0118 - val_mae: 0.0804\n",
            "Epoch 415/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0858 - val_loss: 0.0122 - val_mae: 0.0847\n",
            "Epoch 416/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0859 - val_loss: 0.0113 - val_mae: 0.0801\n",
            "Epoch 417/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0863 - val_loss: 0.0144 - val_mae: 0.0930\n",
            "Epoch 418/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0876 - val_loss: 0.0118 - val_mae: 0.0818\n",
            "Epoch 419/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0875 - val_loss: 0.0108 - val_mae: 0.0779\n",
            "Epoch 420/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0879 - val_loss: 0.0115 - val_mae: 0.0798\n",
            "Epoch 421/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0847 - val_loss: 0.0112 - val_mae: 0.0782\n",
            "Epoch 422/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0860 - val_loss: 0.0121 - val_mae: 0.0824\n",
            "Epoch 423/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0858 - val_loss: 0.0119 - val_mae: 0.0817\n",
            "Epoch 424/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0859 - val_loss: 0.0110 - val_mae: 0.0779\n",
            "Epoch 425/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0874 - val_loss: 0.0111 - val_mae: 0.0788\n",
            "Epoch 426/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0866 - val_loss: 0.0112 - val_mae: 0.0794\n",
            "Epoch 427/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0854 - val_loss: 0.0209 - val_mae: 0.1151\n",
            "Epoch 428/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0875 - val_loss: 0.0125 - val_mae: 0.0844\n",
            "Epoch 429/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0838 - val_loss: 0.0112 - val_mae: 0.0793\n",
            "Epoch 430/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0878 - val_loss: 0.0164 - val_mae: 0.1042\n",
            "Epoch 431/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0874 - val_loss: 0.0112 - val_mae: 0.0790\n",
            "Epoch 432/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0856 - val_loss: 0.0138 - val_mae: 0.0911\n",
            "Epoch 433/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0871 - val_loss: 0.0120 - val_mae: 0.0820\n",
            "Epoch 434/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0878 - val_loss: 0.0123 - val_mae: 0.0829\n",
            "Epoch 435/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0871 - val_loss: 0.0114 - val_mae: 0.0796\n",
            "Epoch 436/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0865 - val_loss: 0.0123 - val_mae: 0.0833\n",
            "Epoch 437/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0862 - val_loss: 0.0121 - val_mae: 0.0843\n",
            "Epoch 438/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0845 - val_loss: 0.0132 - val_mae: 0.0894\n",
            "Epoch 439/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0852 - val_loss: 0.0113 - val_mae: 0.0793\n",
            "Epoch 440/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0865 - val_loss: 0.0114 - val_mae: 0.0795\n",
            "Epoch 441/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0850 - val_loss: 0.0137 - val_mae: 0.0874\n",
            "Epoch 442/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0860 - val_loss: 0.0115 - val_mae: 0.0794\n",
            "Epoch 443/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0867 - val_loss: 0.0136 - val_mae: 0.0892\n",
            "Epoch 444/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0865 - val_loss: 0.0110 - val_mae: 0.0780\n",
            "Epoch 445/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0849 - val_loss: 0.0174 - val_mae: 0.1044\n",
            "Epoch 446/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0870 - val_loss: 0.0116 - val_mae: 0.0805\n",
            "Epoch 447/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0856 - val_loss: 0.0116 - val_mae: 0.0802\n",
            "Epoch 448/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0845 - val_loss: 0.0151 - val_mae: 0.0965\n",
            "Epoch 449/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0852 - val_loss: 0.0152 - val_mae: 0.0998\n",
            "Epoch 450/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0852 - val_loss: 0.0147 - val_mae: 0.0923\n",
            "Epoch 451/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0863 - val_loss: 0.0118 - val_mae: 0.0802\n",
            "Epoch 452/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0868 - val_loss: 0.0117 - val_mae: 0.0803\n",
            "Epoch 453/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0855 - val_loss: 0.0134 - val_mae: 0.0864\n",
            "Epoch 454/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0842 - val_loss: 0.0154 - val_mae: 0.0985\n",
            "Epoch 455/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0855 - val_loss: 0.0169 - val_mae: 0.1026\n",
            "Epoch 456/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0151 - mae: 0.0873 - val_loss: 0.0154 - val_mae: 0.0928\n",
            "Epoch 457/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0846 - val_loss: 0.0118 - val_mae: 0.0822\n",
            "Epoch 458/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0885 - val_loss: 0.0118 - val_mae: 0.0820\n",
            "Epoch 459/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0859 - val_loss: 0.0115 - val_mae: 0.0806\n",
            "Epoch 460/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0864 - val_loss: 0.0151 - val_mae: 0.0918\n",
            "Epoch 461/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0862 - val_loss: 0.0113 - val_mae: 0.0797\n",
            "Epoch 462/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0875 - val_loss: 0.0166 - val_mae: 0.1038\n",
            "Epoch 463/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0845 - val_loss: 0.0145 - val_mae: 0.0901\n",
            "Epoch 464/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0870 - val_loss: 0.0153 - val_mae: 0.0977\n",
            "Epoch 465/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0869 - val_loss: 0.0147 - val_mae: 0.0921\n",
            "Epoch 466/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0850 - val_loss: 0.0144 - val_mae: 0.0925\n",
            "Epoch 467/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0857 - val_loss: 0.0116 - val_mae: 0.0792\n",
            "Epoch 468/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0859 - val_loss: 0.0124 - val_mae: 0.0847\n",
            "Epoch 469/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0868 - val_loss: 0.0152 - val_mae: 0.0915\n",
            "Epoch 470/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0860 - val_loss: 0.0119 - val_mae: 0.0801\n",
            "Epoch 471/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0880 - val_loss: 0.0112 - val_mae: 0.0790\n",
            "Epoch 472/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0858 - val_loss: 0.0114 - val_mae: 0.0787\n",
            "Epoch 473/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0860 - val_loss: 0.0123 - val_mae: 0.0828\n",
            "Epoch 474/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0847 - val_loss: 0.0112 - val_mae: 0.0790\n",
            "Epoch 475/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0860 - val_loss: 0.0122 - val_mae: 0.0841\n",
            "Epoch 476/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0872 - val_loss: 0.0146 - val_mae: 0.0948\n",
            "Epoch 477/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0876 - val_loss: 0.0130 - val_mae: 0.0851\n",
            "Epoch 478/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0857 - val_loss: 0.0121 - val_mae: 0.0829\n",
            "Epoch 479/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0869 - val_loss: 0.0153 - val_mae: 0.0951\n",
            "Epoch 480/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0859 - val_loss: 0.0120 - val_mae: 0.0834\n",
            "Epoch 481/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0865 - val_loss: 0.0124 - val_mae: 0.0852\n",
            "Epoch 482/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0851 - val_loss: 0.0126 - val_mae: 0.0842\n",
            "Epoch 483/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0867 - val_loss: 0.0158 - val_mae: 0.0966\n",
            "Epoch 484/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0865 - val_loss: 0.0128 - val_mae: 0.0876\n",
            "Epoch 485/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0845 - val_loss: 0.0142 - val_mae: 0.0905\n",
            "Epoch 486/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0152 - mae: 0.0879 - val_loss: 0.0124 - val_mae: 0.0847\n",
            "Epoch 487/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0854 - val_loss: 0.0157 - val_mae: 0.0969\n",
            "Epoch 488/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0877 - val_loss: 0.0142 - val_mae: 0.0886\n",
            "Epoch 489/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0862 - val_loss: 0.0108 - val_mae: 0.0769\n",
            "Epoch 490/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0855 - val_loss: 0.0126 - val_mae: 0.0823\n",
            "Epoch 491/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0857 - val_loss: 0.0158 - val_mae: 0.0987\n",
            "Epoch 492/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0149 - mae: 0.0864 - val_loss: 0.0138 - val_mae: 0.0900\n",
            "Epoch 493/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0858 - val_loss: 0.0115 - val_mae: 0.0799\n",
            "Epoch 494/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0868 - val_loss: 0.0136 - val_mae: 0.0912\n",
            "Epoch 495/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0841 - val_loss: 0.0126 - val_mae: 0.0840\n",
            "Epoch 496/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0156 - mae: 0.0895 - val_loss: 0.0120 - val_mae: 0.0800\n",
            "Epoch 497/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0853 - val_loss: 0.0111 - val_mae: 0.0788\n",
            "Epoch 498/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0867 - val_loss: 0.0136 - val_mae: 0.0877\n",
            "Epoch 499/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0862 - val_loss: 0.0165 - val_mae: 0.1010\n",
            "Epoch 500/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0862 - val_loss: 0.0157 - val_mae: 0.0981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMwH7vTnH_gK",
        "colab_type": "code",
        "outputId": "d1c3d89a-0740-4836-d64f-7c17dc37090c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "P2 = model2.predict(XVALID)\n",
        "YVALID3=np.exp(YVALID3)\n",
        "P2=np.exp(P2)\n",
        "MAE2 = abs(YVALID3 - P2)\n",
        "print(MAE2)\n",
        "M3=MAE2.mean()\n",
        "print(\"M3=\",M3)\n",
        "#M3 = math.exp(temp3)\n",
        "#print(M3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   9601.9847  510882.3725 1010591.1605 ...  548985.6505  784234.8155\n",
            "   205660.5951]\n",
            " [ 518602.9528   17322.565   482386.223  ...   20780.713   256029.878\n",
            "   322544.3424]\n",
            " [ 728405.8278  227125.44    272583.348  ...  189022.162    46227.003\n",
            "   532347.2174]\n",
            " ...\n",
            " [ 469499.4528   31780.935   531489.723  ...   69884.213   305133.378\n",
            "   273440.8424]\n",
            " [ 513937.8278   12657.44    487051.348  ...   25445.838   260695.003\n",
            "   317879.2174]\n",
            " [ 126160.3278  375120.06    874828.848  ...  413223.338   648472.503\n",
            "    69898.2826]]\n",
            "M3= 397426.1049016334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWt0-s5vGI4Y",
        "colab_type": "code",
        "outputId": "56995f8c-60de-4abb-f908-21c01493f7ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "plt.scatter(YVALID3,P2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6cae057710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn-xdsBInlMS",
        "colab_type": "code",
        "outputId": "23a2566a-843a-472e-ef82-6f4a30a780b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "import matplotlib.pyplot as plt \n",
        "plt.figure(figsize=(15, 13))\n",
        "plt.plot(history2.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history2.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "min(history2.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x936 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.010386980138719082"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWxM4Ts4qicG",
        "colab_type": "text"
      },
      "source": [
        "# Neural network using sigmoid in last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrWoMK1rqmci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model5 = Sequential()\n",
        "model5.add(Dense(12,input_dim =5, activation='relu'))\n",
        "model5.add(Dense(8, activation='relu'))\n",
        "model5.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m4OaDLdq069",
        "colab_type": "code",
        "outputId": "683a6699-ef88-4dd0-9c16-2b5c63ca363f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model5.compile(loss='mse', optimizer = 'rmsprop', metrics=['mae'])\n",
        "history5=model5.fit(XTRAIN, YTRAIN4,validation_data=(XVALID, YVALID4), epochs = 500, batch_size=100, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 178.4574 - mae: 13.3527 - val_loss: 177.1440 - val_mae: 13.3029\n",
            "Epoch 2/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 176.1530 - mae: 13.2656 - val_loss: 175.0505 - val_mae: 13.2238\n",
            "Epoch 3/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 174.1079 - mae: 13.1884 - val_loss: 173.1101 - val_mae: 13.1505\n",
            "Epoch 4/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 172.2616 - mae: 13.1187 - val_loss: 171.4277 - val_mae: 13.0870\n",
            "Epoch 5/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.7699 - mae: 13.0623 - val_loss: 170.1456 - val_mae: 13.0386\n",
            "Epoch 6/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.7101 - mae: 13.0223 - val_loss: 169.2941 - val_mae: 13.0065\n",
            "Epoch 7/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 169.0707 - mae: 12.9980 - val_loss: 168.8251 - val_mae: 12.9887\n",
            "Epoch 8/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.7368 - mae: 12.9854 - val_loss: 168.5975 - val_mae: 12.9801\n",
            "Epoch 9/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.5843 - mae: 12.9796 - val_loss: 168.5014 - val_mae: 12.9764\n",
            "Epoch 10/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.5218 - mae: 12.9772 - val_loss: 168.4640 - val_mae: 12.9750\n",
            "Epoch 11/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4987 - mae: 12.9763 - val_loss: 168.4510 - val_mae: 12.9745\n",
            "Epoch 12/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4908 - mae: 12.9760 - val_loss: 168.4467 - val_mae: 12.9743\n",
            "Epoch 13/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4882 - mae: 12.9759 - val_loss: 168.4453 - val_mae: 12.9743\n",
            "Epoch 14/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4874 - mae: 12.9759 - val_loss: 168.4449 - val_mae: 12.9743\n",
            "Epoch 15/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4448 - val_mae: 12.9743\n",
            "Epoch 16/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 17/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 18/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 19/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 20/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 21/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 22/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 23/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 24/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 25/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 26/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 27/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 28/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 29/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 30/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 31/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 32/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 33/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 34/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 35/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 36/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 37/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 38/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 39/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 40/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 41/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 42/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 43/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 44/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 45/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 46/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 47/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 48/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 49/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 50/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 51/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 52/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 53/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 54/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 55/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 56/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 57/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 58/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 59/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 60/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 61/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 62/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 63/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 64/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 65/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 66/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 67/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 68/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 69/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 70/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 71/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 72/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 73/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 74/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 75/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 76/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 77/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 78/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 79/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 80/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 81/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 82/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 83/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 84/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 85/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 86/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 87/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 88/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 89/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 90/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 91/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 92/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 93/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 94/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 95/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 96/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 97/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 98/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 99/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 100/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 101/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 102/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 103/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 104/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 105/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 106/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 107/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 108/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 109/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 110/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 111/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 112/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 113/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 114/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 115/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 116/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 117/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 118/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 119/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 120/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 121/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 122/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 123/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 124/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 125/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 126/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 127/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 128/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 129/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 130/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 131/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 132/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 133/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 134/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 135/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 136/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 137/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 138/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 139/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 140/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 141/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 142/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 143/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 144/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 145/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 146/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 147/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 148/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 149/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 150/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 151/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 152/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 153/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 154/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 155/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 156/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 157/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 158/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 159/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 160/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 161/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 162/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 163/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 164/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 165/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 166/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 167/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 168/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 169/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 170/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 171/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 172/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 173/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 174/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 175/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 176/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 177/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 178/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 179/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 180/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 181/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 182/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 183/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 184/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 185/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 186/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 187/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 188/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 189/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 190/500\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 191/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 192/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 193/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 194/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 195/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 196/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 197/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 198/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 199/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 200/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 201/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 202/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 203/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 204/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 205/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 206/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 207/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 208/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 209/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 210/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 211/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 212/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 213/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 214/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 215/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 216/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 217/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 218/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 219/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 220/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 221/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 222/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 223/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 224/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 225/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 226/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 227/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 228/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 229/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 230/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 231/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 232/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 233/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 234/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 235/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 236/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 237/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 238/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 239/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 240/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 241/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 242/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 243/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 244/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 245/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 246/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 247/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 248/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 249/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 250/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 251/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 252/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 253/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 254/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 255/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 256/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 257/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 258/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 259/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 260/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 261/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 262/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 263/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 264/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 265/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 266/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 267/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 268/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 269/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 270/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 271/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 272/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 273/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 274/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 275/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 276/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 277/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 278/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 279/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 280/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 281/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 282/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 283/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 284/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 285/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 286/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 287/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 288/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 289/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 290/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 291/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 292/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 293/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 294/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 295/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 296/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 297/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 298/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 299/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 300/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 301/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 302/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 303/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 304/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 305/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 306/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 307/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 308/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 309/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 310/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 311/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 312/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 313/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 314/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 315/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 316/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 317/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 318/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 319/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 320/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 321/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 322/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 323/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 324/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 325/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 326/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 327/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 328/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 329/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 330/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 331/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 332/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 333/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 334/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 335/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 336/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 337/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 338/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 339/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 340/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 341/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 342/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 343/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 344/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 345/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 346/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 347/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 348/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 349/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 350/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 351/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 352/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 353/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 354/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 355/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 356/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 357/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 358/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 359/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 360/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 361/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 362/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 363/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 364/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 365/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 366/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 367/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 368/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 369/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 370/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 371/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 372/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 373/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 374/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 375/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 376/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 377/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 378/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 379/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 380/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 381/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 382/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 383/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 384/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 385/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 386/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 387/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 388/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 389/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 390/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 391/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 392/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 393/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 394/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 395/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 396/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 397/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 398/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 399/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 400/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 401/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 402/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 403/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 404/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 405/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 406/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 407/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 408/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 409/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 410/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 411/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 412/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 413/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 414/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 415/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 416/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 417/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 418/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 419/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 420/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 421/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 422/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 423/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 424/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 425/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 426/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 427/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 428/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 429/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 430/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 431/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 432/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 433/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 434/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 435/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 436/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 437/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 438/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 439/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 440/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 441/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 442/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 443/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 444/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 445/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 446/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 447/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 448/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 449/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 450/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 451/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 452/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 453/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 454/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 455/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 456/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 457/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 458/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 459/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 460/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 461/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 462/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 463/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 464/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 465/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 466/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 467/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 468/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 469/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 470/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 471/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 472/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 473/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 474/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 475/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 476/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 477/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 478/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 479/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 480/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 481/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 482/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 483/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 484/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 485/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 486/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 487/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 488/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 489/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 490/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 491/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 492/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 493/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 494/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 495/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 496/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 168.4872 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 497/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 498/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 499/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n",
            "Epoch 500/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 168.4871 - mae: 12.9759 - val_loss: 168.4447 - val_mae: 12.9743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4KgvrQ8q8T0",
        "colab_type": "code",
        "outputId": "80e6e154-899e-4d3b-99e0-f21619c43030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "P5 = model5.predict(XVALID)\n",
        "YVALID4=np.exp(YVALID4)\n",
        "P2=np.exp(P2)\n",
        "MAE5 = abs(YVALID4 - P5)\n",
        "print(MAE5)\n",
        "M4=MAE5.mean()\n",
        "print(\"M4=\",M4)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 590198.1722 1091478.56   1591187.348  ... 1129581.838  1364831.003\n",
            "   786256.7826]\n",
            " [ 590198.1722 1091478.56   1591187.348  ... 1129581.838  1364831.003\n",
            "   786256.7826]\n",
            " [ 590198.1722 1091478.56   1591187.348  ... 1129581.838  1364831.003\n",
            "   786256.7826]\n",
            " ...\n",
            " [ 590198.1722 1091478.56   1591187.348  ... 1129581.838  1364831.003\n",
            "   786256.7826]\n",
            " [ 590198.1722 1091478.56   1591187.348  ... 1129581.838  1364831.003\n",
            "   786256.7826]\n",
            " [ 590198.1722 1091478.56   1591187.348  ... 1129581.838  1364831.003\n",
            "   786256.7826]]\n",
            "M4= 1232767.9800132667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sriAsKGq_wd",
        "colab_type": "code",
        "outputId": "30998b0b-169a-44af-af0d-7bbfd479ab0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "import matplotlib.pyplot as plt \n",
        "plt.figure(figsize=(15, 13))\n",
        "plt.plot(history5.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history5.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "min(history5.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x936 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168.44471740722656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X27ZZYKyr4LX",
        "colab_type": "text"
      },
      "source": [
        "# Comparing mean MAE and minimum val_loss for all the models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M4CjISmBF5-",
        "colab_type": "text"
      },
      "source": [
        "Model | Mean MAE | minimum val_loss\n",
        "--- | --- | ---\n",
        "Logistic regression | 1232766.2617 | 168.44471740722656\n",
        "   Linear regression |           420972.7194 | 0.015223732218146324\n",
        "   Neural network with 3 layers (12,8,1) and last layer having linear activation|     397426.1049 | 0.010386980138719082\n",
        "   Neural network with last layer having  sigmoid activation |   1232767.9800 |168.44471740722656\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcmMWn8Sr-MY",
        "colab_type": "code",
        "outputId": "dd2c8501-c829-4faa-d53e-d83f0d4bfeec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(M1, M2, M3, M4)\n",
        "min(M1,M2,M3,M4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1232766.2617315208 420972.719445511 397426.1049016334 1232767.9800132667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "397426.1049016334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJJhd_EICtQU",
        "colab_type": "text"
      },
      "source": [
        "As we can see from the above we get the best mean MAE when we use neural network with 3 layers that have 12, 8 and 1 neurons respectively. Linear regression gives us the second best mean MAE and logistic regression and using sigmoid in the last layer for activation gives us very bad mean MAE, this is expected because our target is a continuous variable and sigmoid is meant to be used for binary target data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci7DMLSkIkw7",
        "colab_type": "text"
      },
      "source": [
        "# How big the architecture needs to be to overfit the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKqi0hRH3a58",
        "colab_type": "text"
      },
      "source": [
        "We are trying to find the architecture that we need to overfit our data. We do this my increasing the number of layers, increasing the number of neurons in each layer and increasing the number of epochs. We train the model on our training set and then try to predit our training set and compare which architecture gives us the highest mean MAE value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbSgU3loXC4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "YVALID5=np.log(YVALID)\n",
        "YTRAIN5=np.log(YTRAIN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nId1qQ-1IpGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model6 = Sequential()\n",
        "model6.add(Dense(256,input_dim =5, activation='relu'))\n",
        "model6.add(Dense(256, activation='relu'))\n",
        "model6.add(Dense(256, activation='relu'))\n",
        "model6.add(Dense(256, activation='relu'))\n",
        "model6.add(Dense(1, activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khekfbOiI3aS",
        "colab_type": "code",
        "outputId": "0a618ed5-923d-47ff-f02e-8662dd133454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model6.compile(loss='mse', optimizer = 'rmsprop', metrics=['mae'])\n",
        "history6=model6.fit(XTRAIN, YTRAIN5,validation_data=(XVALID, YVALID5), epochs = 1000, batch_size=100, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 27.8294 - mae: 4.0248 - val_loss: 12.2148 - val_mae: 2.7396\n",
            "Epoch 2/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 9.6629 - mae: 2.5085 - val_loss: 10.3300 - val_mae: 2.7694\n",
            "Epoch 3/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 7.4389 - mae: 2.2413 - val_loss: 4.8599 - val_mae: 1.7398\n",
            "Epoch 4/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 4.9457 - mae: 1.8794 - val_loss: 4.3584 - val_mae: 1.8804\n",
            "Epoch 5/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 3.6919 - mae: 1.6675 - val_loss: 2.4520 - val_mae: 1.2483\n",
            "Epoch 6/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 3.0983 - mae: 1.5843 - val_loss: 3.2330 - val_mae: 1.7256\n",
            "Epoch 7/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 2.7226 - mae: 1.5310 - val_loss: 1.8859 - val_mae: 1.2417\n",
            "Epoch 8/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 2.2774 - mae: 1.4188 - val_loss: 1.2204 - val_mae: 1.0378\n",
            "Epoch 9/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 2.1333 - mae: 1.3677 - val_loss: 1.5359 - val_mae: 1.1426\n",
            "Epoch 10/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 1.9071 - mae: 1.3099 - val_loss: 1.8113 - val_mae: 1.3103\n",
            "Epoch 11/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 1.8035 - mae: 1.2811 - val_loss: 1.4633 - val_mae: 1.1368\n",
            "Epoch 12/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 1.5886 - mae: 1.1952 - val_loss: 2.2649 - val_mae: 1.4726\n",
            "Epoch 13/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 1.4739 - mae: 1.1567 - val_loss: 1.2131 - val_mae: 1.0228\n",
            "Epoch 14/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 1.4245 - mae: 1.1405 - val_loss: 1.4065 - val_mae: 1.1483\n",
            "Epoch 15/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 1.2940 - mae: 1.0862 - val_loss: 1.0978 - val_mae: 0.9698\n",
            "Epoch 16/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 1.1883 - mae: 1.0387 - val_loss: 1.5323 - val_mae: 1.2053\n",
            "Epoch 17/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 1.1593 - mae: 1.0247 - val_loss: 0.6338 - val_mae: 0.7224\n",
            "Epoch 18/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 1.0860 - mae: 0.9909 - val_loss: 1.4014 - val_mae: 1.1461\n",
            "Epoch 19/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 1.0297 - mae: 0.9702 - val_loss: 0.9401 - val_mae: 0.9312\n",
            "Epoch 20/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.9753 - mae: 0.9464 - val_loss: 0.9963 - val_mae: 0.9711\n",
            "Epoch 21/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.9307 - mae: 0.9201 - val_loss: 0.7088 - val_mae: 0.7679\n",
            "Epoch 22/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.8736 - mae: 0.8904 - val_loss: 0.8446 - val_mae: 0.9021\n",
            "Epoch 23/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.8836 - mae: 0.9024 - val_loss: 0.6765 - val_mae: 0.7609\n",
            "Epoch 24/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.7908 - mae: 0.8467 - val_loss: 1.4291 - val_mae: 1.1783\n",
            "Epoch 25/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.8170 - mae: 0.8607 - val_loss: 0.6813 - val_mae: 0.7785\n",
            "Epoch 26/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.7428 - mae: 0.8250 - val_loss: 0.8094 - val_mae: 0.8810\n",
            "Epoch 27/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.7239 - mae: 0.8136 - val_loss: 0.8636 - val_mae: 0.8858\n",
            "Epoch 28/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.6941 - mae: 0.7982 - val_loss: 0.8080 - val_mae: 0.8821\n",
            "Epoch 29/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.6759 - mae: 0.7869 - val_loss: 0.5647 - val_mae: 0.7205\n",
            "Epoch 30/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.6588 - mae: 0.7775 - val_loss: 0.5857 - val_mae: 0.7392\n",
            "Epoch 31/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.6067 - mae: 0.7486 - val_loss: 0.6472 - val_mae: 0.7608\n",
            "Epoch 32/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.5870 - mae: 0.7334 - val_loss: 0.5098 - val_mae: 0.6936\n",
            "Epoch 33/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.5926 - mae: 0.7350 - val_loss: 0.6015 - val_mae: 0.7419\n",
            "Epoch 34/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.5671 - mae: 0.7228 - val_loss: 0.8160 - val_mae: 0.8825\n",
            "Epoch 35/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.5541 - mae: 0.7148 - val_loss: 0.3555 - val_mae: 0.5516\n",
            "Epoch 36/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.5225 - mae: 0.6925 - val_loss: 0.6526 - val_mae: 0.7790\n",
            "Epoch 37/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.5042 - mae: 0.6804 - val_loss: 0.5696 - val_mae: 0.7275\n",
            "Epoch 38/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.4783 - mae: 0.6605 - val_loss: 0.3885 - val_mae: 0.6030\n",
            "Epoch 39/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.4925 - mae: 0.6729 - val_loss: 0.3312 - val_mae: 0.5394\n",
            "Epoch 40/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.4509 - mae: 0.6413 - val_loss: 0.5137 - val_mae: 0.6969\n",
            "Epoch 41/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.4402 - mae: 0.6321 - val_loss: 0.3483 - val_mae: 0.5582\n",
            "Epoch 42/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.4367 - mae: 0.6338 - val_loss: 0.4779 - val_mae: 0.6711\n",
            "Epoch 43/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.4113 - mae: 0.6118 - val_loss: 0.4147 - val_mae: 0.6141\n",
            "Epoch 44/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.4134 - mae: 0.6160 - val_loss: 0.4249 - val_mae: 0.6313\n",
            "Epoch 45/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3908 - mae: 0.5955 - val_loss: 0.2708 - val_mae: 0.4843\n",
            "Epoch 46/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3746 - mae: 0.5806 - val_loss: 0.3808 - val_mae: 0.5873\n",
            "Epoch 47/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3891 - mae: 0.5941 - val_loss: 0.2964 - val_mae: 0.5205\n",
            "Epoch 48/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3731 - mae: 0.5874 - val_loss: 0.4622 - val_mae: 0.6530\n",
            "Epoch 49/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3548 - mae: 0.5692 - val_loss: 0.3895 - val_mae: 0.5950\n",
            "Epoch 50/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3530 - mae: 0.5673 - val_loss: 0.4542 - val_mae: 0.6538\n",
            "Epoch 51/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3530 - mae: 0.5686 - val_loss: 0.3423 - val_mae: 0.5576\n",
            "Epoch 52/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3486 - mae: 0.5557 - val_loss: 0.5391 - val_mae: 0.7127\n",
            "Epoch 53/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3239 - mae: 0.5404 - val_loss: 0.3075 - val_mae: 0.5306\n",
            "Epoch 54/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3258 - mae: 0.5447 - val_loss: 0.2671 - val_mae: 0.4944\n",
            "Epoch 55/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.3205 - mae: 0.5416 - val_loss: 0.2609 - val_mae: 0.4853\n",
            "Epoch 56/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3062 - mae: 0.5287 - val_loss: 0.3246 - val_mae: 0.5326\n",
            "Epoch 57/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.3100 - mae: 0.5316 - val_loss: 0.3341 - val_mae: 0.5546\n",
            "Epoch 58/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2862 - mae: 0.5076 - val_loss: 0.3161 - val_mae: 0.5338\n",
            "Epoch 59/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2973 - mae: 0.5189 - val_loss: 0.2001 - val_mae: 0.4193\n",
            "Epoch 60/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2755 - mae: 0.4978 - val_loss: 0.4748 - val_mae: 0.6708\n",
            "Epoch 61/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2914 - mae: 0.5158 - val_loss: 0.2602 - val_mae: 0.4829\n",
            "Epoch 62/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2713 - mae: 0.4975 - val_loss: 0.2688 - val_mae: 0.4966\n",
            "Epoch 63/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2629 - mae: 0.4882 - val_loss: 0.2641 - val_mae: 0.4848\n",
            "Epoch 64/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2671 - mae: 0.4942 - val_loss: 0.2417 - val_mae: 0.4598\n",
            "Epoch 65/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2610 - mae: 0.4850 - val_loss: 0.3019 - val_mae: 0.5190\n",
            "Epoch 66/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2585 - mae: 0.4847 - val_loss: 0.2198 - val_mae: 0.4435\n",
            "Epoch 67/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2326 - mae: 0.4585 - val_loss: 0.2277 - val_mae: 0.4554\n",
            "Epoch 68/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2508 - mae: 0.4778 - val_loss: 0.1967 - val_mae: 0.4272\n",
            "Epoch 69/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2344 - mae: 0.4626 - val_loss: 0.3262 - val_mae: 0.5373\n",
            "Epoch 70/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2277 - mae: 0.4484 - val_loss: 0.2208 - val_mae: 0.4453\n",
            "Epoch 71/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2313 - mae: 0.4577 - val_loss: 0.1768 - val_mae: 0.3976\n",
            "Epoch 72/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.2228 - mae: 0.4484 - val_loss: 0.2678 - val_mae: 0.4999\n",
            "Epoch 73/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2071 - mae: 0.4329 - val_loss: 0.2023 - val_mae: 0.4277\n",
            "Epoch 74/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2092 - mae: 0.4316 - val_loss: 0.1845 - val_mae: 0.3976\n",
            "Epoch 75/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.2191 - mae: 0.4457 - val_loss: 0.1705 - val_mae: 0.3767\n",
            "Epoch 76/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1928 - mae: 0.4148 - val_loss: 0.2582 - val_mae: 0.4888\n",
            "Epoch 77/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1978 - mae: 0.4232 - val_loss: 0.2005 - val_mae: 0.4285\n",
            "Epoch 78/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1839 - mae: 0.4055 - val_loss: 0.1835 - val_mae: 0.3973\n",
            "Epoch 79/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1903 - mae: 0.4125 - val_loss: 0.1281 - val_mae: 0.3297\n",
            "Epoch 80/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1763 - mae: 0.3997 - val_loss: 0.1583 - val_mae: 0.3736\n",
            "Epoch 81/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1672 - mae: 0.3862 - val_loss: 0.2129 - val_mae: 0.4379\n",
            "Epoch 82/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1693 - mae: 0.3878 - val_loss: 0.2025 - val_mae: 0.4328\n",
            "Epoch 83/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1807 - mae: 0.4012 - val_loss: 0.1456 - val_mae: 0.3636\n",
            "Epoch 84/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1508 - mae: 0.3656 - val_loss: 0.2166 - val_mae: 0.4485\n",
            "Epoch 85/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1595 - mae: 0.3775 - val_loss: 0.1344 - val_mae: 0.3412\n",
            "Epoch 86/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1518 - mae: 0.3637 - val_loss: 0.1446 - val_mae: 0.3556\n",
            "Epoch 87/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1569 - mae: 0.3710 - val_loss: 0.1329 - val_mae: 0.3362\n",
            "Epoch 88/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1415 - mae: 0.3561 - val_loss: 0.1624 - val_mae: 0.3798\n",
            "Epoch 89/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1408 - mae: 0.3522 - val_loss: 0.0995 - val_mae: 0.2834\n",
            "Epoch 90/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1373 - mae: 0.3441 - val_loss: 0.1529 - val_mae: 0.3698\n",
            "Epoch 91/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1290 - mae: 0.3369 - val_loss: 0.1633 - val_mae: 0.3876\n",
            "Epoch 92/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1323 - mae: 0.3393 - val_loss: 0.1639 - val_mae: 0.3833\n",
            "Epoch 93/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1289 - mae: 0.3385 - val_loss: 0.1260 - val_mae: 0.3272\n",
            "Epoch 94/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1197 - mae: 0.3256 - val_loss: 0.1118 - val_mae: 0.3130\n",
            "Epoch 95/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1198 - mae: 0.3271 - val_loss: 0.1257 - val_mae: 0.3251\n",
            "Epoch 96/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1154 - mae: 0.3196 - val_loss: 0.1286 - val_mae: 0.3345\n",
            "Epoch 97/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1138 - mae: 0.3171 - val_loss: 0.1405 - val_mae: 0.3502\n",
            "Epoch 98/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1150 - mae: 0.3160 - val_loss: 0.0763 - val_mae: 0.2388\n",
            "Epoch 99/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1043 - mae: 0.3023 - val_loss: 0.1102 - val_mae: 0.3077\n",
            "Epoch 100/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.1065 - mae: 0.3043 - val_loss: 0.1168 - val_mae: 0.3179\n",
            "Epoch 101/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1071 - mae: 0.3054 - val_loss: 0.1026 - val_mae: 0.2915\n",
            "Epoch 102/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.1025 - mae: 0.2997 - val_loss: 0.0869 - val_mae: 0.2694\n",
            "Epoch 103/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0978 - mae: 0.2905 - val_loss: 0.0687 - val_mae: 0.2335\n",
            "Epoch 104/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0949 - mae: 0.2838 - val_loss: 0.1431 - val_mae: 0.3508\n",
            "Epoch 105/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0951 - mae: 0.2864 - val_loss: 0.0613 - val_mae: 0.2223\n",
            "Epoch 106/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0884 - mae: 0.2790 - val_loss: 0.1249 - val_mae: 0.3319\n",
            "Epoch 107/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0958 - mae: 0.2854 - val_loss: 0.0922 - val_mae: 0.2811\n",
            "Epoch 108/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0853 - mae: 0.2716 - val_loss: 0.0721 - val_mae: 0.2484\n",
            "Epoch 109/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0886 - mae: 0.2749 - val_loss: 0.1010 - val_mae: 0.2772\n",
            "Epoch 110/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0869 - mae: 0.2749 - val_loss: 0.1282 - val_mae: 0.3167\n",
            "Epoch 111/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0841 - mae: 0.2692 - val_loss: 0.0701 - val_mae: 0.2334\n",
            "Epoch 112/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0765 - mae: 0.2488 - val_loss: 0.1651 - val_mae: 0.3767\n",
            "Epoch 113/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0870 - mae: 0.2726 - val_loss: 0.0764 - val_mae: 0.2554\n",
            "Epoch 114/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0758 - mae: 0.2501 - val_loss: 0.0588 - val_mae: 0.2166\n",
            "Epoch 115/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0795 - mae: 0.2595 - val_loss: 0.0764 - val_mae: 0.2528\n",
            "Epoch 116/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0780 - mae: 0.2586 - val_loss: 0.0811 - val_mae: 0.2563\n",
            "Epoch 117/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0745 - mae: 0.2518 - val_loss: 0.0969 - val_mae: 0.2901\n",
            "Epoch 118/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0700 - mae: 0.2412 - val_loss: 0.1144 - val_mae: 0.3131\n",
            "Epoch 119/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0733 - mae: 0.2500 - val_loss: 0.0727 - val_mae: 0.2261\n",
            "Epoch 120/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0662 - mae: 0.2340 - val_loss: 0.0841 - val_mae: 0.2676\n",
            "Epoch 121/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0764 - mae: 0.2506 - val_loss: 0.0707 - val_mae: 0.2314\n",
            "Epoch 122/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0678 - mae: 0.2381 - val_loss: 0.0538 - val_mae: 0.2081\n",
            "Epoch 123/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0681 - mae: 0.2387 - val_loss: 0.0776 - val_mae: 0.2492\n",
            "Epoch 124/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0689 - mae: 0.2353 - val_loss: 0.1663 - val_mae: 0.3807\n",
            "Epoch 125/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0644 - mae: 0.2293 - val_loss: 0.0539 - val_mae: 0.1978\n",
            "Epoch 126/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0712 - mae: 0.2389 - val_loss: 0.0808 - val_mae: 0.2605\n",
            "Epoch 127/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0655 - mae: 0.2343 - val_loss: 0.0707 - val_mae: 0.2394\n",
            "Epoch 128/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0667 - mae: 0.2387 - val_loss: 0.1248 - val_mae: 0.2984\n",
            "Epoch 129/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0663 - mae: 0.2371 - val_loss: 0.0762 - val_mae: 0.2484\n",
            "Epoch 130/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0701 - mae: 0.2435 - val_loss: 0.0696 - val_mae: 0.2406\n",
            "Epoch 131/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0598 - mae: 0.2192 - val_loss: 0.0257 - val_mae: 0.1246\n",
            "Epoch 132/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0700 - mae: 0.2331 - val_loss: 0.0885 - val_mae: 0.2801\n",
            "Epoch 133/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0651 - mae: 0.2325 - val_loss: 0.0524 - val_mae: 0.2046\n",
            "Epoch 134/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0631 - mae: 0.2306 - val_loss: 0.0630 - val_mae: 0.2309\n",
            "Epoch 135/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0633 - mae: 0.2309 - val_loss: 0.0798 - val_mae: 0.2611\n",
            "Epoch 136/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0677 - mae: 0.2395 - val_loss: 0.0721 - val_mae: 0.2472\n",
            "Epoch 137/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0624 - mae: 0.2295 - val_loss: 0.0778 - val_mae: 0.2552\n",
            "Epoch 138/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0606 - mae: 0.2230 - val_loss: 0.1031 - val_mae: 0.3013\n",
            "Epoch 139/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0645 - mae: 0.2328 - val_loss: 0.0380 - val_mae: 0.1611\n",
            "Epoch 140/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0652 - mae: 0.2324 - val_loss: 0.0696 - val_mae: 0.2375\n",
            "Epoch 141/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0652 - mae: 0.2322 - val_loss: 0.0569 - val_mae: 0.1970\n",
            "Epoch 142/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0611 - mae: 0.2181 - val_loss: 0.0892 - val_mae: 0.2777\n",
            "Epoch 143/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0647 - mae: 0.2333 - val_loss: 0.0631 - val_mae: 0.2275\n",
            "Epoch 144/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0596 - mae: 0.2193 - val_loss: 0.1088 - val_mae: 0.3135\n",
            "Epoch 145/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0637 - mae: 0.2300 - val_loss: 0.0853 - val_mae: 0.2723\n",
            "Epoch 146/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0606 - mae: 0.2225 - val_loss: 0.0519 - val_mae: 0.2078\n",
            "Epoch 147/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0615 - mae: 0.2257 - val_loss: 0.0758 - val_mae: 0.2463\n",
            "Epoch 148/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0619 - mae: 0.2285 - val_loss: 0.0589 - val_mae: 0.2242\n",
            "Epoch 149/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0616 - mae: 0.2269 - val_loss: 0.0369 - val_mae: 0.1656\n",
            "Epoch 150/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0596 - mae: 0.2222 - val_loss: 0.0519 - val_mae: 0.2079\n",
            "Epoch 151/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0580 - mae: 0.2149 - val_loss: 0.0412 - val_mae: 0.1773\n",
            "Epoch 152/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0628 - mae: 0.2301 - val_loss: 0.1049 - val_mae: 0.2929\n",
            "Epoch 153/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0590 - mae: 0.2122 - val_loss: 0.0389 - val_mae: 0.1615\n",
            "Epoch 154/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0579 - mae: 0.2080 - val_loss: 0.1395 - val_mae: 0.3544\n",
            "Epoch 155/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0589 - mae: 0.2158 - val_loss: 0.0733 - val_mae: 0.2466\n",
            "Epoch 156/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0593 - mae: 0.2234 - val_loss: 0.0609 - val_mae: 0.2266\n",
            "Epoch 157/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0585 - mae: 0.2206 - val_loss: 0.0631 - val_mae: 0.2307\n",
            "Epoch 158/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0616 - mae: 0.2274 - val_loss: 0.0677 - val_mae: 0.2399\n",
            "Epoch 159/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0601 - mae: 0.2258 - val_loss: 0.0272 - val_mae: 0.1319\n",
            "Epoch 160/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0574 - mae: 0.2139 - val_loss: 0.0931 - val_mae: 0.2843\n",
            "Epoch 161/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0586 - mae: 0.2199 - val_loss: 0.0750 - val_mae: 0.2497\n",
            "Epoch 162/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0606 - mae: 0.2210 - val_loss: 0.0367 - val_mae: 0.1632\n",
            "Epoch 163/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0535 - mae: 0.2026 - val_loss: 0.0821 - val_mae: 0.2666\n",
            "Epoch 164/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0599 - mae: 0.2225 - val_loss: 0.0644 - val_mae: 0.2258\n",
            "Epoch 165/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0586 - mae: 0.2201 - val_loss: 0.0311 - val_mae: 0.1498\n",
            "Epoch 166/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0582 - mae: 0.2207 - val_loss: 0.0506 - val_mae: 0.1793\n",
            "Epoch 167/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0570 - mae: 0.2108 - val_loss: 0.0928 - val_mae: 0.2867\n",
            "Epoch 168/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0581 - mae: 0.2177 - val_loss: 0.0424 - val_mae: 0.1741\n",
            "Epoch 169/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0575 - mae: 0.2167 - val_loss: 0.0770 - val_mae: 0.2552\n",
            "Epoch 170/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0550 - mae: 0.2120 - val_loss: 0.1099 - val_mae: 0.3003\n",
            "Epoch 171/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0609 - mae: 0.2237 - val_loss: 0.0455 - val_mae: 0.1871\n",
            "Epoch 172/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0553 - mae: 0.2122 - val_loss: 0.0297 - val_mae: 0.1420\n",
            "Epoch 173/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0578 - mae: 0.2177 - val_loss: 0.0539 - val_mae: 0.2067\n",
            "Epoch 174/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0558 - mae: 0.2134 - val_loss: 0.1059 - val_mae: 0.3061\n",
            "Epoch 175/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0550 - mae: 0.2116 - val_loss: 0.0666 - val_mae: 0.2359\n",
            "Epoch 176/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0620 - mae: 0.2143 - val_loss: 0.0453 - val_mae: 0.1850\n",
            "Epoch 177/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0542 - mae: 0.2095 - val_loss: 0.0763 - val_mae: 0.2522\n",
            "Epoch 178/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0553 - mae: 0.2122 - val_loss: 0.0483 - val_mae: 0.1872\n",
            "Epoch 179/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0559 - mae: 0.1961 - val_loss: 0.1475 - val_mae: 0.3684\n",
            "Epoch 180/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0531 - mae: 0.2053 - val_loss: 0.0408 - val_mae: 0.1770\n",
            "Epoch 181/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0591 - mae: 0.2175 - val_loss: 0.0532 - val_mae: 0.1971\n",
            "Epoch 182/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0584 - mae: 0.2202 - val_loss: 0.0494 - val_mae: 0.2017\n",
            "Epoch 183/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0528 - mae: 0.2006 - val_loss: 0.0256 - val_mae: 0.1299\n",
            "Epoch 184/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0564 - mae: 0.2113 - val_loss: 0.0358 - val_mae: 0.1582\n",
            "Epoch 185/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0547 - mae: 0.2135 - val_loss: 0.0583 - val_mae: 0.2186\n",
            "Epoch 186/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0565 - mae: 0.2159 - val_loss: 0.0665 - val_mae: 0.2375\n",
            "Epoch 187/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0560 - mae: 0.2134 - val_loss: 0.0643 - val_mae: 0.2321\n",
            "Epoch 188/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0520 - mae: 0.2030 - val_loss: 0.0461 - val_mae: 0.1908\n",
            "Epoch 189/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0617 - mae: 0.2190 - val_loss: 0.0458 - val_mae: 0.1886\n",
            "Epoch 190/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0507 - mae: 0.1998 - val_loss: 0.0671 - val_mae: 0.2270\n",
            "Epoch 191/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0579 - mae: 0.2156 - val_loss: 0.0377 - val_mae: 0.1570\n",
            "Epoch 192/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0513 - mae: 0.2036 - val_loss: 0.0538 - val_mae: 0.2024\n",
            "Epoch 193/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0558 - mae: 0.2129 - val_loss: 0.0255 - val_mae: 0.1279\n",
            "Epoch 194/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0504 - mae: 0.1923 - val_loss: 0.0797 - val_mae: 0.2613\n",
            "Epoch 195/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0579 - mae: 0.2193 - val_loss: 0.0607 - val_mae: 0.2203\n",
            "Epoch 196/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0544 - mae: 0.2106 - val_loss: 0.0554 - val_mae: 0.2081\n",
            "Epoch 197/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0539 - mae: 0.2113 - val_loss: 0.0514 - val_mae: 0.2010\n",
            "Epoch 198/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0518 - mae: 0.2043 - val_loss: 0.0422 - val_mae: 0.1823\n",
            "Epoch 199/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0558 - mae: 0.2130 - val_loss: 0.0607 - val_mae: 0.2239\n",
            "Epoch 200/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0535 - mae: 0.2062 - val_loss: 0.0271 - val_mae: 0.1399\n",
            "Epoch 201/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0527 - mae: 0.2003 - val_loss: 0.0782 - val_mae: 0.2543\n",
            "Epoch 202/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0511 - mae: 0.1998 - val_loss: 0.0765 - val_mae: 0.2527\n",
            "Epoch 203/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0554 - mae: 0.2134 - val_loss: 0.0676 - val_mae: 0.2288\n",
            "Epoch 204/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0560 - mae: 0.2154 - val_loss: 0.0608 - val_mae: 0.2170\n",
            "Epoch 205/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0497 - mae: 0.1989 - val_loss: 0.0937 - val_mae: 0.2877\n",
            "Epoch 206/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0562 - mae: 0.2102 - val_loss: 0.0376 - val_mae: 0.1662\n",
            "Epoch 207/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0545 - mae: 0.2081 - val_loss: 0.0450 - val_mae: 0.1850\n",
            "Epoch 208/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0523 - mae: 0.2089 - val_loss: 0.0508 - val_mae: 0.2002\n",
            "Epoch 209/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0510 - mae: 0.2044 - val_loss: 0.0394 - val_mae: 0.1726\n",
            "Epoch 210/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0584 - mae: 0.2140 - val_loss: 0.0530 - val_mae: 0.1893\n",
            "Epoch 211/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0470 - mae: 0.1826 - val_loss: 0.0330 - val_mae: 0.1486\n",
            "Epoch 212/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0550 - mae: 0.2053 - val_loss: 0.0922 - val_mae: 0.2759\n",
            "Epoch 213/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0505 - mae: 0.2013 - val_loss: 0.0465 - val_mae: 0.1882\n",
            "Epoch 214/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0528 - mae: 0.2089 - val_loss: 0.0627 - val_mae: 0.2227\n",
            "Epoch 215/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0530 - mae: 0.2070 - val_loss: 0.0317 - val_mae: 0.1505\n",
            "Epoch 216/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0525 - mae: 0.2060 - val_loss: 0.0446 - val_mae: 0.1795\n",
            "Epoch 217/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0527 - mae: 0.2081 - val_loss: 0.0615 - val_mae: 0.2243\n",
            "Epoch 218/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0508 - mae: 0.2046 - val_loss: 0.0729 - val_mae: 0.2375\n",
            "Epoch 219/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0531 - mae: 0.2109 - val_loss: 0.0517 - val_mae: 0.2050\n",
            "Epoch 220/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0500 - mae: 0.2009 - val_loss: 0.0389 - val_mae: 0.1637\n",
            "Epoch 221/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0505 - mae: 0.2025 - val_loss: 0.0653 - val_mae: 0.2345\n",
            "Epoch 222/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0548 - mae: 0.2114 - val_loss: 0.0531 - val_mae: 0.2094\n",
            "Epoch 223/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0524 - mae: 0.2042 - val_loss: 0.0216 - val_mae: 0.1118\n",
            "Epoch 224/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0524 - mae: 0.2068 - val_loss: 0.0582 - val_mae: 0.2154\n",
            "Epoch 225/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0548 - mae: 0.2128 - val_loss: 0.0497 - val_mae: 0.1918\n",
            "Epoch 226/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0501 - mae: 0.1977 - val_loss: 0.0536 - val_mae: 0.1901\n",
            "Epoch 227/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0529 - mae: 0.2087 - val_loss: 0.0698 - val_mae: 0.2377\n",
            "Epoch 228/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0492 - mae: 0.1989 - val_loss: 0.0700 - val_mae: 0.2317\n",
            "Epoch 229/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0529 - mae: 0.2069 - val_loss: 0.0435 - val_mae: 0.1749\n",
            "Epoch 230/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0505 - mae: 0.2031 - val_loss: 0.0433 - val_mae: 0.1696\n",
            "Epoch 231/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0509 - mae: 0.2035 - val_loss: 0.0795 - val_mae: 0.2604\n",
            "Epoch 232/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0503 - mae: 0.2033 - val_loss: 0.0628 - val_mae: 0.2198\n",
            "Epoch 233/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0520 - mae: 0.2071 - val_loss: 0.0646 - val_mae: 0.2305\n",
            "Epoch 234/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0487 - mae: 0.1978 - val_loss: 0.0525 - val_mae: 0.1983\n",
            "Epoch 235/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0528 - mae: 0.2086 - val_loss: 0.0470 - val_mae: 0.1809\n",
            "Epoch 236/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0498 - mae: 0.2003 - val_loss: 0.0685 - val_mae: 0.2377\n",
            "Epoch 237/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0504 - mae: 0.2029 - val_loss: 0.0355 - val_mae: 0.1544\n",
            "Epoch 238/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0524 - mae: 0.2074 - val_loss: 0.0728 - val_mae: 0.2413\n",
            "Epoch 239/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0485 - mae: 0.1936 - val_loss: 0.0279 - val_mae: 0.1369\n",
            "Epoch 240/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0510 - mae: 0.1995 - val_loss: 0.1139 - val_mae: 0.2956\n",
            "Epoch 241/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0483 - mae: 0.1999 - val_loss: 0.0609 - val_mae: 0.1983\n",
            "Epoch 242/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0511 - mae: 0.2055 - val_loss: 0.0418 - val_mae: 0.1686\n",
            "Epoch 243/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0505 - mae: 0.2021 - val_loss: 0.0351 - val_mae: 0.1534\n",
            "Epoch 244/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0502 - mae: 0.2019 - val_loss: 0.0668 - val_mae: 0.2112\n",
            "Epoch 245/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0506 - mae: 0.2038 - val_loss: 0.0603 - val_mae: 0.2182\n",
            "Epoch 246/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0492 - mae: 0.2001 - val_loss: 0.0417 - val_mae: 0.1753\n",
            "Epoch 247/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0509 - mae: 0.1963 - val_loss: 0.0402 - val_mae: 0.1659\n",
            "Epoch 248/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0453 - mae: 0.1682 - val_loss: 0.0380 - val_mae: 0.1371\n",
            "Epoch 249/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0459 - mae: 0.1874 - val_loss: 0.0537 - val_mae: 0.2016\n",
            "Epoch 250/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0496 - mae: 0.2016 - val_loss: 0.0569 - val_mae: 0.2096\n",
            "Epoch 251/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0522 - mae: 0.2082 - val_loss: 0.0540 - val_mae: 0.1972\n",
            "Epoch 252/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0492 - mae: 0.1999 - val_loss: 0.0722 - val_mae: 0.2091\n",
            "Epoch 253/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0519 - mae: 0.2062 - val_loss: 0.0526 - val_mae: 0.1907\n",
            "Epoch 254/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0487 - mae: 0.1963 - val_loss: 0.0409 - val_mae: 0.1566\n",
            "Epoch 255/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0517 - mae: 0.2050 - val_loss: 0.0618 - val_mae: 0.2100\n",
            "Epoch 256/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0462 - mae: 0.1912 - val_loss: 0.0724 - val_mae: 0.2241\n",
            "Epoch 257/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0518 - mae: 0.2002 - val_loss: 0.0276 - val_mae: 0.1234\n",
            "Epoch 258/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0465 - mae: 0.1849 - val_loss: 0.1154 - val_mae: 0.2899\n",
            "Epoch 259/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0496 - mae: 0.2009 - val_loss: 0.0530 - val_mae: 0.2015\n",
            "Epoch 260/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0475 - mae: 0.1972 - val_loss: 0.0504 - val_mae: 0.1735\n",
            "Epoch 261/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0487 - mae: 0.1983 - val_loss: 0.0574 - val_mae: 0.2069\n",
            "Epoch 262/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0492 - mae: 0.1987 - val_loss: 0.0502 - val_mae: 0.1915\n",
            "Epoch 263/1000\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0510 - mae: 0.2031 - val_loss: 0.0517 - val_mae: 0.1927\n",
            "Epoch 264/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0465 - mae: 0.1925 - val_loss: 0.0465 - val_mae: 0.1619\n",
            "Epoch 265/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0496 - mae: 0.2012 - val_loss: 0.0494 - val_mae: 0.1778\n",
            "Epoch 266/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0479 - mae: 0.1964 - val_loss: 0.0705 - val_mae: 0.2198\n",
            "Epoch 267/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0483 - mae: 0.1986 - val_loss: 0.0346 - val_mae: 0.1486\n",
            "Epoch 268/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0465 - mae: 0.1933 - val_loss: 0.0691 - val_mae: 0.2211\n",
            "Epoch 269/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0486 - mae: 0.1985 - val_loss: 0.0408 - val_mae: 0.1698\n",
            "Epoch 270/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0493 - mae: 0.1977 - val_loss: 0.0855 - val_mae: 0.2529\n",
            "Epoch 271/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0481 - mae: 0.1938 - val_loss: 0.0489 - val_mae: 0.1851\n",
            "Epoch 272/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0457 - mae: 0.1897 - val_loss: 0.0829 - val_mae: 0.2568\n",
            "Epoch 273/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0500 - mae: 0.2014 - val_loss: 0.0521 - val_mae: 0.1982\n",
            "Epoch 274/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0491 - mae: 0.2001 - val_loss: 0.0672 - val_mae: 0.1908\n",
            "Epoch 275/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0494 - mae: 0.2021 - val_loss: 0.0474 - val_mae: 0.1680\n",
            "Epoch 276/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0460 - mae: 0.1904 - val_loss: 0.0798 - val_mae: 0.2602\n",
            "Epoch 277/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0467 - mae: 0.1905 - val_loss: 0.0293 - val_mae: 0.1261\n",
            "Epoch 278/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0459 - mae: 0.1904 - val_loss: 0.0804 - val_mae: 0.2576\n",
            "Epoch 279/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0504 - mae: 0.1988 - val_loss: 0.0499 - val_mae: 0.1807\n",
            "Epoch 280/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0453 - mae: 0.1872 - val_loss: 0.0446 - val_mae: 0.1639\n",
            "Epoch 281/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0489 - mae: 0.1981 - val_loss: 0.0631 - val_mae: 0.2214\n",
            "Epoch 282/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0463 - mae: 0.1901 - val_loss: 0.0377 - val_mae: 0.1663\n",
            "Epoch 283/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0466 - mae: 0.1934 - val_loss: 0.0835 - val_mae: 0.2601\n",
            "Epoch 284/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0466 - mae: 0.1947 - val_loss: 0.0691 - val_mae: 0.2310\n",
            "Epoch 285/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0448 - mae: 0.1898 - val_loss: 0.0581 - val_mae: 0.2073\n",
            "Epoch 286/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0479 - mae: 0.1989 - val_loss: 0.0494 - val_mae: 0.1882\n",
            "Epoch 287/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0467 - mae: 0.1956 - val_loss: 0.0335 - val_mae: 0.1489\n",
            "Epoch 288/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0463 - mae: 0.1874 - val_loss: 0.0635 - val_mae: 0.2223\n",
            "Epoch 289/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0458 - mae: 0.1941 - val_loss: 0.0718 - val_mae: 0.1974\n",
            "Epoch 290/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0474 - mae: 0.1967 - val_loss: 0.0612 - val_mae: 0.2056\n",
            "Epoch 291/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0472 - mae: 0.1959 - val_loss: 0.0515 - val_mae: 0.2005\n",
            "Epoch 292/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0479 - mae: 0.1952 - val_loss: 0.0757 - val_mae: 0.2270\n",
            "Epoch 293/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0452 - mae: 0.1927 - val_loss: 0.0650 - val_mae: 0.2207\n",
            "Epoch 294/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0477 - mae: 0.1959 - val_loss: 0.0570 - val_mae: 0.2072\n",
            "Epoch 295/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0457 - mae: 0.1896 - val_loss: 0.0554 - val_mae: 0.2024\n",
            "Epoch 296/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0462 - mae: 0.1926 - val_loss: 0.0441 - val_mae: 0.1741\n",
            "Epoch 297/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0462 - mae: 0.1936 - val_loss: 0.0871 - val_mae: 0.2631\n",
            "Epoch 298/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0456 - mae: 0.1929 - val_loss: 0.0833 - val_mae: 0.2529\n",
            "Epoch 299/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0460 - mae: 0.1897 - val_loss: 0.0502 - val_mae: 0.1829\n",
            "Epoch 300/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0449 - mae: 0.1897 - val_loss: 0.0685 - val_mae: 0.2341\n",
            "Epoch 301/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0485 - mae: 0.1979 - val_loss: 0.0609 - val_mae: 0.2171\n",
            "Epoch 302/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0467 - mae: 0.1948 - val_loss: 0.0551 - val_mae: 0.1818\n",
            "Epoch 303/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0438 - mae: 0.1857 - val_loss: 0.0490 - val_mae: 0.1899\n",
            "Epoch 304/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0476 - mae: 0.1948 - val_loss: 0.0456 - val_mae: 0.1800\n",
            "Epoch 305/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0468 - mae: 0.1970 - val_loss: 0.0340 - val_mae: 0.1499\n",
            "Epoch 306/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0434 - mae: 0.1807 - val_loss: 0.0769 - val_mae: 0.2357\n",
            "Epoch 307/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0463 - mae: 0.1930 - val_loss: 0.0293 - val_mae: 0.1331\n",
            "Epoch 308/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0440 - mae: 0.1851 - val_loss: 0.0450 - val_mae: 0.1705\n",
            "Epoch 309/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0440 - mae: 0.1880 - val_loss: 0.0448 - val_mae: 0.1772\n",
            "Epoch 310/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0479 - mae: 0.1973 - val_loss: 0.0603 - val_mae: 0.2162\n",
            "Epoch 311/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0456 - mae: 0.1930 - val_loss: 0.0443 - val_mae: 0.1766\n",
            "Epoch 312/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0458 - mae: 0.1911 - val_loss: 0.0525 - val_mae: 0.1972\n",
            "Epoch 313/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0436 - mae: 0.1864 - val_loss: 0.0810 - val_mae: 0.2570\n",
            "Epoch 314/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0467 - mae: 0.1928 - val_loss: 0.0664 - val_mae: 0.2240\n",
            "Epoch 315/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0456 - mae: 0.1912 - val_loss: 0.0490 - val_mae: 0.1790\n",
            "Epoch 316/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0452 - mae: 0.1923 - val_loss: 0.0403 - val_mae: 0.1539\n",
            "Epoch 317/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0450 - mae: 0.1894 - val_loss: 0.0484 - val_mae: 0.1670\n",
            "Epoch 318/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0439 - mae: 0.1888 - val_loss: 0.0603 - val_mae: 0.2163\n",
            "Epoch 319/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0475 - mae: 0.1949 - val_loss: 0.0589 - val_mae: 0.1698\n",
            "Epoch 320/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0450 - mae: 0.1870 - val_loss: 0.0843 - val_mae: 0.2550\n",
            "Epoch 321/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0444 - mae: 0.1830 - val_loss: 0.0523 - val_mae: 0.1896\n",
            "Epoch 322/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0466 - mae: 0.1959 - val_loss: 0.0764 - val_mae: 0.2410\n",
            "Epoch 323/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0446 - mae: 0.1832 - val_loss: 0.0635 - val_mae: 0.2147\n",
            "Epoch 324/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0415 - mae: 0.1835 - val_loss: 0.0558 - val_mae: 0.1973\n",
            "Epoch 325/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0470 - mae: 0.1964 - val_loss: 0.0454 - val_mae: 0.1729\n",
            "Epoch 326/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0447 - mae: 0.1897 - val_loss: 0.0626 - val_mae: 0.2057\n",
            "Epoch 327/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0424 - mae: 0.1809 - val_loss: 0.0617 - val_mae: 0.2144\n",
            "Epoch 328/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0436 - mae: 0.1868 - val_loss: 0.0999 - val_mae: 0.2767\n",
            "Epoch 329/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0470 - mae: 0.1946 - val_loss: 0.0377 - val_mae: 0.1604\n",
            "Epoch 330/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0434 - mae: 0.1811 - val_loss: 0.0937 - val_mae: 0.2490\n",
            "Epoch 331/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0430 - mae: 0.1874 - val_loss: 0.0506 - val_mae: 0.1895\n",
            "Epoch 332/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0445 - mae: 0.1903 - val_loss: 0.0584 - val_mae: 0.1894\n",
            "Epoch 333/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0439 - mae: 0.1890 - val_loss: 0.0550 - val_mae: 0.1724\n",
            "Epoch 334/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0405 - mae: 0.1774 - val_loss: 0.0414 - val_mae: 0.1613\n",
            "Epoch 335/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0480 - mae: 0.1959 - val_loss: 0.0516 - val_mae: 0.1851\n",
            "Epoch 336/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0454 - mae: 0.1847 - val_loss: 0.0544 - val_mae: 0.1742\n",
            "Epoch 337/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0386 - mae: 0.1601 - val_loss: 0.0399 - val_mae: 0.1466\n",
            "Epoch 338/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0455 - mae: 0.1906 - val_loss: 0.0580 - val_mae: 0.2096\n",
            "Epoch 339/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0450 - mae: 0.1908 - val_loss: 0.0455 - val_mae: 0.1717\n",
            "Epoch 340/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0426 - mae: 0.1848 - val_loss: 0.0675 - val_mae: 0.2154\n",
            "Epoch 341/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0437 - mae: 0.1891 - val_loss: 0.0544 - val_mae: 0.1686\n",
            "Epoch 342/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0432 - mae: 0.1862 - val_loss: 0.0555 - val_mae: 0.2003\n",
            "Epoch 343/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0435 - mae: 0.1877 - val_loss: 0.0448 - val_mae: 0.1631\n",
            "Epoch 344/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0409 - mae: 0.1791 - val_loss: 0.0833 - val_mae: 0.2612\n",
            "Epoch 345/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0480 - mae: 0.1973 - val_loss: 0.0457 - val_mae: 0.1722\n",
            "Epoch 346/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0438 - mae: 0.1880 - val_loss: 0.0495 - val_mae: 0.1861\n",
            "Epoch 347/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0425 - mae: 0.1852 - val_loss: 0.0529 - val_mae: 0.1958\n",
            "Epoch 348/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0419 - mae: 0.1852 - val_loss: 0.0580 - val_mae: 0.2105\n",
            "Epoch 349/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0438 - mae: 0.1878 - val_loss: 0.0752 - val_mae: 0.2432\n",
            "Epoch 350/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0447 - mae: 0.1883 - val_loss: 0.0319 - val_mae: 0.1461\n",
            "Epoch 351/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0428 - mae: 0.1841 - val_loss: 0.0673 - val_mae: 0.2127\n",
            "Epoch 352/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0426 - mae: 0.1853 - val_loss: 0.0600 - val_mae: 0.2054\n",
            "Epoch 353/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0426 - mae: 0.1836 - val_loss: 0.0314 - val_mae: 0.1389\n",
            "Epoch 354/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0439 - mae: 0.1884 - val_loss: 0.0629 - val_mae: 0.2163\n",
            "Epoch 355/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0416 - mae: 0.1829 - val_loss: 0.0338 - val_mae: 0.1253\n",
            "Epoch 356/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0422 - mae: 0.1639 - val_loss: 0.0306 - val_mae: 0.1143\n",
            "Epoch 357/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0436 - mae: 0.1805 - val_loss: 0.0488 - val_mae: 0.1925\n",
            "Epoch 358/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0432 - mae: 0.1846 - val_loss: 0.0425 - val_mae: 0.1526\n",
            "Epoch 359/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0402 - mae: 0.1741 - val_loss: 0.1104 - val_mae: 0.3054\n",
            "Epoch 360/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0436 - mae: 0.1873 - val_loss: 0.0435 - val_mae: 0.1776\n",
            "Epoch 361/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0433 - mae: 0.1871 - val_loss: 0.0509 - val_mae: 0.1842\n",
            "Epoch 362/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0414 - mae: 0.1795 - val_loss: 0.0466 - val_mae: 0.1683\n",
            "Epoch 363/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0432 - mae: 0.1876 - val_loss: 0.0441 - val_mae: 0.1564\n",
            "Epoch 364/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0421 - mae: 0.1842 - val_loss: 0.0531 - val_mae: 0.1754\n",
            "Epoch 365/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1854 - val_loss: 0.0692 - val_mae: 0.2231\n",
            "Epoch 366/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0442 - mae: 0.1849 - val_loss: 0.0451 - val_mae: 0.1734\n",
            "Epoch 367/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0368 - mae: 0.1614 - val_loss: 0.0205 - val_mae: 0.0839\n",
            "Epoch 368/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0446 - mae: 0.1777 - val_loss: 0.0800 - val_mae: 0.2505\n",
            "Epoch 369/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0430 - mae: 0.1822 - val_loss: 0.0553 - val_mae: 0.1785\n",
            "Epoch 370/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0425 - mae: 0.1865 - val_loss: 0.0511 - val_mae: 0.1930\n",
            "Epoch 371/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0420 - mae: 0.1834 - val_loss: 0.0691 - val_mae: 0.2184\n",
            "Epoch 372/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0398 - mae: 0.1762 - val_loss: 0.0701 - val_mae: 0.2154\n",
            "Epoch 373/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0451 - mae: 0.1894 - val_loss: 0.0457 - val_mae: 0.1692\n",
            "Epoch 374/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0402 - mae: 0.1763 - val_loss: 0.0594 - val_mae: 0.1922\n",
            "Epoch 375/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0426 - mae: 0.1856 - val_loss: 0.0561 - val_mae: 0.1932\n",
            "Epoch 376/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0429 - mae: 0.1859 - val_loss: 0.0572 - val_mae: 0.1947\n",
            "Epoch 377/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0404 - mae: 0.1778 - val_loss: 0.0897 - val_mae: 0.2598\n",
            "Epoch 378/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0428 - mae: 0.1847 - val_loss: 0.0442 - val_mae: 0.1703\n",
            "Epoch 379/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0428 - mae: 0.1865 - val_loss: 0.0688 - val_mae: 0.2250\n",
            "Epoch 380/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0417 - mae: 0.1833 - val_loss: 0.0440 - val_mae: 0.1703\n",
            "Epoch 381/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0383 - mae: 0.1704 - val_loss: 0.1092 - val_mae: 0.3018\n",
            "Epoch 382/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0426 - mae: 0.1821 - val_loss: 0.0535 - val_mae: 0.1838\n",
            "Epoch 383/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0423 - mae: 0.1814 - val_loss: 0.0808 - val_mae: 0.2136\n",
            "Epoch 384/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0417 - mae: 0.1830 - val_loss: 0.0347 - val_mae: 0.1435\n",
            "Epoch 385/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0425 - mae: 0.1828 - val_loss: 0.1005 - val_mae: 0.2727\n",
            "Epoch 386/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0427 - mae: 0.1845 - val_loss: 0.0348 - val_mae: 0.1470\n",
            "Epoch 387/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0402 - mae: 0.1781 - val_loss: 0.0424 - val_mae: 0.1600\n",
            "Epoch 388/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0416 - mae: 0.1844 - val_loss: 0.0517 - val_mae: 0.1913\n",
            "Epoch 389/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0426 - mae: 0.1866 - val_loss: 0.0745 - val_mae: 0.2221\n",
            "Epoch 390/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0404 - mae: 0.1774 - val_loss: 0.0340 - val_mae: 0.1328\n",
            "Epoch 391/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0414 - mae: 0.1776 - val_loss: 0.0380 - val_mae: 0.1434\n",
            "Epoch 392/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0406 - mae: 0.1809 - val_loss: 0.0498 - val_mae: 0.1845\n",
            "Epoch 393/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0407 - mae: 0.1814 - val_loss: 0.1033 - val_mae: 0.2784\n",
            "Epoch 394/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0427 - mae: 0.1764 - val_loss: 0.0473 - val_mae: 0.1814\n",
            "Epoch 395/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0386 - mae: 0.1724 - val_loss: 0.0587 - val_mae: 0.1842\n",
            "Epoch 396/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0409 - mae: 0.1802 - val_loss: 0.0545 - val_mae: 0.1920\n",
            "Epoch 397/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0438 - mae: 0.1827 - val_loss: 0.0246 - val_mae: 0.1001\n",
            "Epoch 398/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0367 - mae: 0.1615 - val_loss: 0.0891 - val_mae: 0.2664\n",
            "Epoch 399/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0435 - mae: 0.1861 - val_loss: 0.0635 - val_mae: 0.1973\n",
            "Epoch 400/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0409 - mae: 0.1805 - val_loss: 0.0353 - val_mae: 0.1413\n",
            "Epoch 401/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0403 - mae: 0.1750 - val_loss: 0.0950 - val_mae: 0.2638\n",
            "Epoch 402/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0411 - mae: 0.1793 - val_loss: 0.0776 - val_mae: 0.2384\n",
            "Epoch 403/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0397 - mae: 0.1752 - val_loss: 0.0362 - val_mae: 0.1330\n",
            "Epoch 404/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0411 - mae: 0.1801 - val_loss: 0.0424 - val_mae: 0.1621\n",
            "Epoch 405/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0417 - mae: 0.1846 - val_loss: 0.0401 - val_mae: 0.1157\n",
            "Epoch 406/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0386 - mae: 0.1705 - val_loss: 0.0382 - val_mae: 0.1533\n",
            "Epoch 407/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0413 - mae: 0.1802 - val_loss: 0.0885 - val_mae: 0.2515\n",
            "Epoch 408/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0417 - mae: 0.1806 - val_loss: 0.0442 - val_mae: 0.1611\n",
            "Epoch 409/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0396 - mae: 0.1770 - val_loss: 0.0854 - val_mae: 0.2537\n",
            "Epoch 410/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0395 - mae: 0.1786 - val_loss: 0.0491 - val_mae: 0.1876\n",
            "Epoch 411/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0444 - mae: 0.1866 - val_loss: 0.0360 - val_mae: 0.1450\n",
            "Epoch 412/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0393 - mae: 0.1760 - val_loss: 0.0439 - val_mae: 0.1716\n",
            "Epoch 413/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0405 - mae: 0.1765 - val_loss: 0.0320 - val_mae: 0.1301\n",
            "Epoch 414/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0402 - mae: 0.1771 - val_loss: 0.0511 - val_mae: 0.1787\n",
            "Epoch 415/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0432 - mae: 0.1865 - val_loss: 0.0336 - val_mae: 0.1355\n",
            "Epoch 416/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0389 - mae: 0.1753 - val_loss: 0.0695 - val_mae: 0.2275\n",
            "Epoch 417/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0393 - mae: 0.1759 - val_loss: 0.0504 - val_mae: 0.1800\n",
            "Epoch 418/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0412 - mae: 0.1815 - val_loss: 0.0657 - val_mae: 0.2195\n",
            "Epoch 419/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0393 - mae: 0.1748 - val_loss: 0.0415 - val_mae: 0.1445\n",
            "Epoch 420/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0406 - mae: 0.1772 - val_loss: 0.0476 - val_mae: 0.1728\n",
            "Epoch 421/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0381 - mae: 0.1747 - val_loss: 0.0566 - val_mae: 0.2080\n",
            "Epoch 422/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0412 - mae: 0.1818 - val_loss: 0.0516 - val_mae: 0.1867\n",
            "Epoch 423/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0409 - mae: 0.1801 - val_loss: 0.0255 - val_mae: 0.1133\n",
            "Epoch 424/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0402 - mae: 0.1777 - val_loss: 0.0501 - val_mae: 0.1841\n",
            "Epoch 425/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0379 - mae: 0.1704 - val_loss: 0.0415 - val_mae: 0.1428\n",
            "Epoch 426/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0413 - mae: 0.1779 - val_loss: 0.0329 - val_mae: 0.1362\n",
            "Epoch 427/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0388 - mae: 0.1740 - val_loss: 0.0411 - val_mae: 0.1661\n",
            "Epoch 428/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0382 - mae: 0.1742 - val_loss: 0.0462 - val_mae: 0.1841\n",
            "Epoch 429/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0414 - mae: 0.1825 - val_loss: 0.0497 - val_mae: 0.1819\n",
            "Epoch 430/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0383 - mae: 0.1750 - val_loss: 0.0271 - val_mae: 0.1252\n",
            "Epoch 431/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0396 - mae: 0.1759 - val_loss: 0.0528 - val_mae: 0.1924\n",
            "Epoch 432/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0406 - mae: 0.1772 - val_loss: 0.0878 - val_mae: 0.2723\n",
            "Epoch 433/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0394 - mae: 0.1719 - val_loss: 0.0428 - val_mae: 0.1528\n",
            "Epoch 434/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0413 - mae: 0.1824 - val_loss: 0.0349 - val_mae: 0.1531\n",
            "Epoch 435/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0376 - mae: 0.1721 - val_loss: 0.0435 - val_mae: 0.1706\n",
            "Epoch 436/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0400 - mae: 0.1774 - val_loss: 0.0567 - val_mae: 0.2074\n",
            "Epoch 437/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0418 - mae: 0.1839 - val_loss: 0.0528 - val_mae: 0.1866\n",
            "Epoch 438/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0362 - mae: 0.1611 - val_loss: 0.0347 - val_mae: 0.1453\n",
            "Epoch 439/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0419 - mae: 0.1774 - val_loss: 0.0766 - val_mae: 0.2373\n",
            "Epoch 440/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0395 - mae: 0.1781 - val_loss: 0.0302 - val_mae: 0.1178\n",
            "Epoch 441/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0390 - mae: 0.1733 - val_loss: 0.0467 - val_mae: 0.1678\n",
            "Epoch 442/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0389 - mae: 0.1741 - val_loss: 0.0555 - val_mae: 0.1982\n",
            "Epoch 443/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0389 - mae: 0.1752 - val_loss: 0.0572 - val_mae: 0.2121\n",
            "Epoch 444/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0412 - mae: 0.1825 - val_loss: 0.0429 - val_mae: 0.1710\n",
            "Epoch 445/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0393 - mae: 0.1766 - val_loss: 0.0375 - val_mae: 0.1586\n",
            "Epoch 446/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0399 - mae: 0.1792 - val_loss: 0.0400 - val_mae: 0.1526\n",
            "Epoch 447/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0417 - mae: 0.1832 - val_loss: 0.0363 - val_mae: 0.1538\n",
            "Epoch 448/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0346 - mae: 0.1458 - val_loss: 0.0293 - val_mae: 0.1275\n",
            "Epoch 449/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0404 - mae: 0.1776 - val_loss: 0.0492 - val_mae: 0.1783\n",
            "Epoch 450/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0386 - mae: 0.1769 - val_loss: 0.0421 - val_mae: 0.1669\n",
            "Epoch 451/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0411 - mae: 0.1812 - val_loss: 0.0431 - val_mae: 0.1766\n",
            "Epoch 452/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0393 - mae: 0.1775 - val_loss: 0.0442 - val_mae: 0.1725\n",
            "Epoch 453/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0377 - mae: 0.1743 - val_loss: 0.0882 - val_mae: 0.2696\n",
            "Epoch 454/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0390 - mae: 0.1678 - val_loss: 0.0366 - val_mae: 0.1484\n",
            "Epoch 455/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0380 - mae: 0.1744 - val_loss: 0.0193 - val_mae: 0.1025\n",
            "Epoch 456/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0373 - mae: 0.1682 - val_loss: 0.0758 - val_mae: 0.2430\n",
            "Epoch 457/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0409 - mae: 0.1806 - val_loss: 0.0441 - val_mae: 0.1535\n",
            "Epoch 458/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0400 - mae: 0.1763 - val_loss: 0.0595 - val_mae: 0.2061\n",
            "Epoch 459/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0383 - mae: 0.1718 - val_loss: 0.0442 - val_mae: 0.1744\n",
            "Epoch 460/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0362 - mae: 0.1679 - val_loss: 0.0457 - val_mae: 0.1809\n",
            "Epoch 461/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0405 - mae: 0.1815 - val_loss: 0.0472 - val_mae: 0.1672\n",
            "Epoch 462/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0394 - mae: 0.1759 - val_loss: 0.0445 - val_mae: 0.1644\n",
            "Epoch 463/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0386 - mae: 0.1708 - val_loss: 0.0921 - val_mae: 0.2709\n",
            "Epoch 464/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0401 - mae: 0.1784 - val_loss: 0.0377 - val_mae: 0.1641\n",
            "Epoch 465/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0383 - mae: 0.1745 - val_loss: 0.0703 - val_mae: 0.2215\n",
            "Epoch 466/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0405 - mae: 0.1780 - val_loss: 0.0365 - val_mae: 0.1546\n",
            "Epoch 467/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0380 - mae: 0.1708 - val_loss: 0.0531 - val_mae: 0.1793\n",
            "Epoch 468/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0388 - mae: 0.1754 - val_loss: 0.0341 - val_mae: 0.1397\n",
            "Epoch 469/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0387 - mae: 0.1745 - val_loss: 0.0473 - val_mae: 0.1713\n",
            "Epoch 470/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0381 - mae: 0.1734 - val_loss: 0.0419 - val_mae: 0.1685\n",
            "Epoch 471/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0412 - mae: 0.1780 - val_loss: 0.0476 - val_mae: 0.1571\n",
            "Epoch 472/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0248 - mae: 0.1119 - val_loss: 0.1328 - val_mae: 0.3261\n",
            "Epoch 473/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0455 - mae: 0.1754 - val_loss: 0.0436 - val_mae: 0.1691\n",
            "Epoch 474/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0363 - mae: 0.1672 - val_loss: 0.0410 - val_mae: 0.1516\n",
            "Epoch 475/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0379 - mae: 0.1719 - val_loss: 0.0449 - val_mae: 0.1783\n",
            "Epoch 476/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0391 - mae: 0.1776 - val_loss: 0.0458 - val_mae: 0.1696\n",
            "Epoch 477/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0373 - mae: 0.1707 - val_loss: 0.0635 - val_mae: 0.2256\n",
            "Epoch 478/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0401 - mae: 0.1796 - val_loss: 0.0540 - val_mae: 0.1976\n",
            "Epoch 479/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0392 - mae: 0.1781 - val_loss: 0.0485 - val_mae: 0.1821\n",
            "Epoch 480/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0377 - mae: 0.1710 - val_loss: 0.0712 - val_mae: 0.2296\n",
            "Epoch 481/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0380 - mae: 0.1726 - val_loss: 0.0522 - val_mae: 0.1862\n",
            "Epoch 482/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0406 - mae: 0.1804 - val_loss: 0.0502 - val_mae: 0.1794\n",
            "Epoch 483/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0364 - mae: 0.1691 - val_loss: 0.0464 - val_mae: 0.1816\n",
            "Epoch 484/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0404 - mae: 0.1809 - val_loss: 0.0510 - val_mae: 0.1744\n",
            "Epoch 485/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0381 - mae: 0.1732 - val_loss: 0.0292 - val_mae: 0.1302\n",
            "Epoch 486/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.1670 - val_loss: 0.0485 - val_mae: 0.1589\n",
            "Epoch 487/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0370 - mae: 0.1676 - val_loss: 0.0926 - val_mae: 0.2823\n",
            "Epoch 488/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0404 - mae: 0.1691 - val_loss: 0.0477 - val_mae: 0.1621\n",
            "Epoch 489/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0340 - mae: 0.1572 - val_loss: 0.0349 - val_mae: 0.1466\n",
            "Epoch 490/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0386 - mae: 0.1712 - val_loss: 0.0789 - val_mae: 0.2504\n",
            "Epoch 491/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0389 - mae: 0.1744 - val_loss: 0.0789 - val_mae: 0.2515\n",
            "Epoch 492/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0378 - mae: 0.1706 - val_loss: 0.0549 - val_mae: 0.2001\n",
            "Epoch 493/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0391 - mae: 0.1772 - val_loss: 0.0403 - val_mae: 0.1633\n",
            "Epoch 494/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0368 - mae: 0.1698 - val_loss: 0.0513 - val_mae: 0.1819\n",
            "Epoch 495/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0364 - mae: 0.1685 - val_loss: 0.0746 - val_mae: 0.2367\n",
            "Epoch 496/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0394 - mae: 0.1747 - val_loss: 0.0744 - val_mae: 0.2433\n",
            "Epoch 497/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0378 - mae: 0.1740 - val_loss: 0.0574 - val_mae: 0.1933\n",
            "Epoch 498/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0383 - mae: 0.1753 - val_loss: 0.0473 - val_mae: 0.1730\n",
            "Epoch 499/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0320 - mae: 0.1534 - val_loss: 0.0962 - val_mae: 0.2794\n",
            "Epoch 500/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0422 - mae: 0.1690 - val_loss: 0.1006 - val_mae: 0.2894\n",
            "Epoch 501/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0367 - mae: 0.1668 - val_loss: 0.0704 - val_mae: 0.1911\n",
            "Epoch 502/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0370 - mae: 0.1719 - val_loss: 0.0504 - val_mae: 0.1874\n",
            "Epoch 503/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0391 - mae: 0.1783 - val_loss: 0.0482 - val_mae: 0.1859\n",
            "Epoch 504/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0358 - mae: 0.1665 - val_loss: 0.0389 - val_mae: 0.1348\n",
            "Epoch 505/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0399 - mae: 0.1752 - val_loss: 0.0708 - val_mae: 0.2163\n",
            "Epoch 506/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0385 - mae: 0.1711 - val_loss: 0.0200 - val_mae: 0.1033\n",
            "Epoch 507/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0354 - mae: 0.1548 - val_loss: 0.0598 - val_mae: 0.2046\n",
            "Epoch 508/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0384 - mae: 0.1747 - val_loss: 0.0381 - val_mae: 0.1509\n",
            "Epoch 509/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0391 - mae: 0.1758 - val_loss: 0.0424 - val_mae: 0.1476\n",
            "Epoch 510/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.1685 - val_loss: 0.0583 - val_mae: 0.2061\n",
            "Epoch 511/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0375 - mae: 0.1732 - val_loss: 0.0609 - val_mae: 0.1856\n",
            "Epoch 512/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0379 - mae: 0.1718 - val_loss: 0.0380 - val_mae: 0.1441\n",
            "Epoch 513/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0349 - mae: 0.1616 - val_loss: 0.0723 - val_mae: 0.2327\n",
            "Epoch 514/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0391 - mae: 0.1737 - val_loss: 0.0361 - val_mae: 0.1361\n",
            "Epoch 515/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0356 - mae: 0.1659 - val_loss: 0.0832 - val_mae: 0.2499\n",
            "Epoch 516/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0390 - mae: 0.1689 - val_loss: 0.0295 - val_mae: 0.1251\n",
            "Epoch 517/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0349 - mae: 0.1616 - val_loss: 0.0606 - val_mae: 0.2141\n",
            "Epoch 518/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0380 - mae: 0.1738 - val_loss: 0.0475 - val_mae: 0.1658\n",
            "Epoch 519/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0362 - mae: 0.1686 - val_loss: 0.0454 - val_mae: 0.1568\n",
            "Epoch 520/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0365 - mae: 0.1691 - val_loss: 0.0334 - val_mae: 0.1394\n",
            "Epoch 521/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0367 - mae: 0.1702 - val_loss: 0.0732 - val_mae: 0.2376\n",
            "Epoch 522/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0372 - mae: 0.1703 - val_loss: 0.0421 - val_mae: 0.1629\n",
            "Epoch 523/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0375 - mae: 0.1727 - val_loss: 0.0464 - val_mae: 0.1772\n",
            "Epoch 524/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0374 - mae: 0.1725 - val_loss: 0.0481 - val_mae: 0.1765\n",
            "Epoch 525/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0362 - mae: 0.1678 - val_loss: 0.0808 - val_mae: 0.2582\n",
            "Epoch 526/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0363 - mae: 0.1694 - val_loss: 0.0555 - val_mae: 0.1975\n",
            "Epoch 527/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0385 - mae: 0.1746 - val_loss: 0.0779 - val_mae: 0.2289\n",
            "Epoch 528/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.1680 - val_loss: 0.0502 - val_mae: 0.1903\n",
            "Epoch 529/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0382 - mae: 0.1723 - val_loss: 0.0411 - val_mae: 0.1419\n",
            "Epoch 530/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0374 - mae: 0.1733 - val_loss: 0.0432 - val_mae: 0.1693\n",
            "Epoch 531/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0372 - mae: 0.1723 - val_loss: 0.0347 - val_mae: 0.1324\n",
            "Epoch 532/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0332 - mae: 0.1455 - val_loss: 0.0312 - val_mae: 0.1314\n",
            "Epoch 533/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0384 - mae: 0.1750 - val_loss: 0.0416 - val_mae: 0.1500\n",
            "Epoch 534/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0383 - mae: 0.1753 - val_loss: 0.0292 - val_mae: 0.1238\n",
            "Epoch 535/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0336 - mae: 0.1624 - val_loss: 0.0736 - val_mae: 0.2416\n",
            "Epoch 536/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0386 - mae: 0.1710 - val_loss: 0.0338 - val_mae: 0.1233\n",
            "Epoch 537/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0359 - mae: 0.1659 - val_loss: 0.0556 - val_mae: 0.1741\n",
            "Epoch 538/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0368 - mae: 0.1714 - val_loss: 0.0404 - val_mae: 0.1301\n",
            "Epoch 539/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0374 - mae: 0.1713 - val_loss: 0.0515 - val_mae: 0.1771\n",
            "Epoch 540/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0378 - mae: 0.1742 - val_loss: 0.0506 - val_mae: 0.1935\n",
            "Epoch 541/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0353 - mae: 0.1650 - val_loss: 0.0453 - val_mae: 0.1661\n",
            "Epoch 542/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.1698 - val_loss: 0.0386 - val_mae: 0.1615\n",
            "Epoch 543/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0354 - mae: 0.1642 - val_loss: 0.0478 - val_mae: 0.1588\n",
            "Epoch 544/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0357 - mae: 0.1672 - val_loss: 0.0645 - val_mae: 0.2211\n",
            "Epoch 545/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0369 - mae: 0.1711 - val_loss: 0.0735 - val_mae: 0.2400\n",
            "Epoch 546/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.1675 - val_loss: 0.0421 - val_mae: 0.1639\n",
            "Epoch 547/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0339 - mae: 0.1597 - val_loss: 0.0864 - val_mae: 0.2522\n",
            "Epoch 548/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0374 - mae: 0.1703 - val_loss: 0.0331 - val_mae: 0.1261\n",
            "Epoch 549/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0363 - mae: 0.1615 - val_loss: 0.0662 - val_mae: 0.2086\n",
            "Epoch 550/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0354 - mae: 0.1636 - val_loss: 0.0425 - val_mae: 0.1692\n",
            "Epoch 551/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0347 - mae: 0.1641 - val_loss: 0.0600 - val_mae: 0.1975\n",
            "Epoch 552/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.1657 - val_loss: 0.0943 - val_mae: 0.2822\n",
            "Epoch 553/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0370 - mae: 0.1723 - val_loss: 0.0471 - val_mae: 0.1557\n",
            "Epoch 554/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0340 - mae: 0.1608 - val_loss: 0.0194 - val_mae: 0.0839\n",
            "Epoch 555/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0335 - mae: 0.1429 - val_loss: 0.0294 - val_mae: 0.1110\n",
            "Epoch 556/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0386 - mae: 0.1706 - val_loss: 0.0404 - val_mae: 0.1527\n",
            "Epoch 557/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0347 - mae: 0.1649 - val_loss: 0.0694 - val_mae: 0.2091\n",
            "Epoch 558/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0331 - mae: 0.1553 - val_loss: 0.0741 - val_mae: 0.2348\n",
            "Epoch 559/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0393 - mae: 0.1751 - val_loss: 0.0558 - val_mae: 0.1839\n",
            "Epoch 560/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.1700 - val_loss: 0.0336 - val_mae: 0.1440\n",
            "Epoch 561/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0349 - mae: 0.1652 - val_loss: 0.0421 - val_mae: 0.1608\n",
            "Epoch 562/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0358 - mae: 0.1670 - val_loss: 0.0416 - val_mae: 0.1638\n",
            "Epoch 563/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0368 - mae: 0.1701 - val_loss: 0.1080 - val_mae: 0.2899\n",
            "Epoch 564/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0358 - mae: 0.1661 - val_loss: 0.0487 - val_mae: 0.1544\n",
            "Epoch 565/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0362 - mae: 0.1683 - val_loss: 0.0547 - val_mae: 0.1884\n",
            "Epoch 566/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0360 - mae: 0.1667 - val_loss: 0.0344 - val_mae: 0.1282\n",
            "Epoch 567/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0355 - mae: 0.1662 - val_loss: 0.0499 - val_mae: 0.1896\n",
            "Epoch 568/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0352 - mae: 0.1653 - val_loss: 0.0566 - val_mae: 0.1661\n",
            "Epoch 569/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0315 - mae: 0.1444 - val_loss: 0.0213 - val_mae: 0.0913\n",
            "Epoch 570/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0381 - mae: 0.1678 - val_loss: 0.0490 - val_mae: 0.1642\n",
            "Epoch 571/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0358 - mae: 0.1673 - val_loss: 0.0420 - val_mae: 0.1621\n",
            "Epoch 572/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0368 - mae: 0.1712 - val_loss: 0.0594 - val_mae: 0.1964\n",
            "Epoch 573/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0322 - mae: 0.1546 - val_loss: 0.0883 - val_mae: 0.2643\n",
            "Epoch 574/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0369 - mae: 0.1693 - val_loss: 0.0642 - val_mae: 0.2179\n",
            "Epoch 575/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0340 - mae: 0.1635 - val_loss: 0.0518 - val_mae: 0.1931\n",
            "Epoch 576/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0347 - mae: 0.1643 - val_loss: 0.0435 - val_mae: 0.1719\n",
            "Epoch 577/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0360 - mae: 0.1688 - val_loss: 0.0518 - val_mae: 0.1785\n",
            "Epoch 578/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0350 - mae: 0.1649 - val_loss: 0.0400 - val_mae: 0.1613\n",
            "Epoch 579/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0343 - mae: 0.1622 - val_loss: 0.0463 - val_mae: 0.1702\n",
            "Epoch 580/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0361 - mae: 0.1669 - val_loss: 0.0294 - val_mae: 0.1329\n",
            "Epoch 581/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0334 - mae: 0.1590 - val_loss: 0.0316 - val_mae: 0.1395\n",
            "Epoch 582/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0374 - mae: 0.1726 - val_loss: 0.0329 - val_mae: 0.1223\n",
            "Epoch 583/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0350 - mae: 0.1660 - val_loss: 0.0463 - val_mae: 0.1633\n",
            "Epoch 584/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0331 - mae: 0.1569 - val_loss: 0.0561 - val_mae: 0.1849\n",
            "Epoch 585/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0387 - mae: 0.1734 - val_loss: 0.0464 - val_mae: 0.1767\n",
            "Epoch 586/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0330 - mae: 0.1566 - val_loss: 0.0618 - val_mae: 0.2019\n",
            "Epoch 587/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0353 - mae: 0.1683 - val_loss: 0.0325 - val_mae: 0.1270\n",
            "Epoch 588/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0352 - mae: 0.1641 - val_loss: 0.0525 - val_mae: 0.1783\n",
            "Epoch 589/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0347 - mae: 0.1647 - val_loss: 0.0352 - val_mae: 0.1317\n",
            "Epoch 590/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0338 - mae: 0.1618 - val_loss: 0.0689 - val_mae: 0.2286\n",
            "Epoch 591/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0369 - mae: 0.1692 - val_loss: 0.0476 - val_mae: 0.1801\n",
            "Epoch 592/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0324 - mae: 0.1536 - val_loss: 0.0359 - val_mae: 0.1174\n",
            "Epoch 593/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0348 - mae: 0.1649 - val_loss: 0.0357 - val_mae: 0.1488\n",
            "Epoch 594/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0352 - mae: 0.1641 - val_loss: 0.0874 - val_mae: 0.2638\n",
            "Epoch 595/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0351 - mae: 0.1655 - val_loss: 0.0436 - val_mae: 0.1705\n",
            "Epoch 596/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0341 - mae: 0.1641 - val_loss: 0.0677 - val_mae: 0.2213\n",
            "Epoch 597/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0348 - mae: 0.1675 - val_loss: 0.0415 - val_mae: 0.1642\n",
            "Epoch 598/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0350 - mae: 0.1657 - val_loss: 0.0667 - val_mae: 0.2146\n",
            "Epoch 599/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0347 - mae: 0.1649 - val_loss: 0.0343 - val_mae: 0.1473\n",
            "Epoch 600/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0352 - mae: 0.1648 - val_loss: 0.0401 - val_mae: 0.1441\n",
            "Epoch 601/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0352 - mae: 0.1676 - val_loss: 0.0509 - val_mae: 0.1951\n",
            "Epoch 602/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0354 - mae: 0.1632 - val_loss: 0.0444 - val_mae: 0.1698\n",
            "Epoch 603/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0306 - mae: 0.1466 - val_loss: 0.0435 - val_mae: 0.1683\n",
            "Epoch 604/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0362 - mae: 0.1689 - val_loss: 0.0586 - val_mae: 0.1984\n",
            "Epoch 605/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0349 - mae: 0.1662 - val_loss: 0.0497 - val_mae: 0.1847\n",
            "Epoch 606/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0332 - mae: 0.1593 - val_loss: 0.0438 - val_mae: 0.1613\n",
            "Epoch 607/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0353 - mae: 0.1634 - val_loss: 0.0549 - val_mae: 0.1990\n",
            "Epoch 608/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0325 - mae: 0.1556 - val_loss: 0.0626 - val_mae: 0.2039\n",
            "Epoch 609/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0352 - mae: 0.1673 - val_loss: 0.0392 - val_mae: 0.1513\n",
            "Epoch 610/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0327 - mae: 0.1545 - val_loss: 0.0851 - val_mae: 0.2616\n",
            "Epoch 611/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0343 - mae: 0.1646 - val_loss: 0.0507 - val_mae: 0.1876\n",
            "Epoch 612/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0371 - mae: 0.1722 - val_loss: 0.0346 - val_mae: 0.1346\n",
            "Epoch 613/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0339 - mae: 0.1624 - val_loss: 0.0457 - val_mae: 0.1798\n",
            "Epoch 614/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0355 - mae: 0.1658 - val_loss: 0.0431 - val_mae: 0.1693\n",
            "Epoch 615/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0318 - mae: 0.1511 - val_loss: 0.0595 - val_mae: 0.2121\n",
            "Epoch 616/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0363 - mae: 0.1690 - val_loss: 0.0504 - val_mae: 0.1705\n",
            "Epoch 617/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0345 - mae: 0.1641 - val_loss: 0.0552 - val_mae: 0.1956\n",
            "Epoch 618/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0324 - mae: 0.1594 - val_loss: 0.0274 - val_mae: 0.1173\n",
            "Epoch 619/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0353 - mae: 0.1608 - val_loss: 0.0378 - val_mae: 0.1383\n",
            "Epoch 620/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0324 - mae: 0.1573 - val_loss: 0.0480 - val_mae: 0.1798\n",
            "Epoch 621/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0354 - mae: 0.1679 - val_loss: 0.0451 - val_mae: 0.1672\n",
            "Epoch 622/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0350 - mae: 0.1659 - val_loss: 0.0463 - val_mae: 0.1598\n",
            "Epoch 623/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0313 - mae: 0.1519 - val_loss: 0.0428 - val_mae: 0.1731\n",
            "Epoch 624/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0347 - mae: 0.1597 - val_loss: 0.0321 - val_mae: 0.1340\n",
            "Epoch 625/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0340 - mae: 0.1612 - val_loss: 0.0337 - val_mae: 0.1345\n",
            "Epoch 626/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0333 - mae: 0.1597 - val_loss: 0.0436 - val_mae: 0.1673\n",
            "Epoch 627/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0330 - mae: 0.1595 - val_loss: 0.0350 - val_mae: 0.1405\n",
            "Epoch 628/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0357 - mae: 0.1646 - val_loss: 0.0764 - val_mae: 0.2435\n",
            "Epoch 629/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0335 - mae: 0.1622 - val_loss: 0.0360 - val_mae: 0.1345\n",
            "Epoch 630/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0332 - mae: 0.1599 - val_loss: 0.0398 - val_mae: 0.1266\n",
            "Epoch 631/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0337 - mae: 0.1569 - val_loss: 0.0685 - val_mae: 0.2279\n",
            "Epoch 632/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0335 - mae: 0.1619 - val_loss: 0.0410 - val_mae: 0.1450\n",
            "Epoch 633/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0358 - mae: 0.1667 - val_loss: 0.0445 - val_mae: 0.1649\n",
            "Epoch 634/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0321 - mae: 0.1591 - val_loss: 0.0627 - val_mae: 0.1921\n",
            "Epoch 635/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0342 - mae: 0.1628 - val_loss: 0.0384 - val_mae: 0.1562\n",
            "Epoch 636/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0330 - mae: 0.1618 - val_loss: 0.0351 - val_mae: 0.1513\n",
            "Epoch 637/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0330 - mae: 0.1619 - val_loss: 0.0399 - val_mae: 0.1653\n",
            "Epoch 638/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0342 - mae: 0.1598 - val_loss: 0.0614 - val_mae: 0.2072\n",
            "Epoch 639/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0349 - mae: 0.1649 - val_loss: 0.0331 - val_mae: 0.1408\n",
            "Epoch 640/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0322 - mae: 0.1565 - val_loss: 0.0534 - val_mae: 0.1870\n",
            "Epoch 641/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0342 - mae: 0.1624 - val_loss: 0.0346 - val_mae: 0.1349\n",
            "Epoch 642/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0326 - mae: 0.1529 - val_loss: 0.0584 - val_mae: 0.1755\n",
            "Epoch 643/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0340 - mae: 0.1636 - val_loss: 0.0429 - val_mae: 0.1682\n",
            "Epoch 644/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0322 - mae: 0.1558 - val_loss: 0.0622 - val_mae: 0.2130\n",
            "Epoch 645/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0350 - mae: 0.1651 - val_loss: 0.0343 - val_mae: 0.1481\n",
            "Epoch 646/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0329 - mae: 0.1602 - val_loss: 0.0675 - val_mae: 0.2154\n",
            "Epoch 647/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0345 - mae: 0.1650 - val_loss: 0.0486 - val_mae: 0.1828\n",
            "Epoch 648/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0322 - mae: 0.1590 - val_loss: 0.0443 - val_mae: 0.1507\n",
            "Epoch 649/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0356 - mae: 0.1652 - val_loss: 0.0355 - val_mae: 0.1404\n",
            "Epoch 650/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0327 - mae: 0.1585 - val_loss: 0.0394 - val_mae: 0.1435\n",
            "Epoch 651/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0339 - mae: 0.1636 - val_loss: 0.0570 - val_mae: 0.1969\n",
            "Epoch 652/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0319 - mae: 0.1560 - val_loss: 0.0442 - val_mae: 0.1707\n",
            "Epoch 653/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0343 - mae: 0.1610 - val_loss: 0.0408 - val_mae: 0.1575\n",
            "Epoch 654/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1393 - val_loss: 0.0673 - val_mae: 0.2201\n",
            "Epoch 655/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0365 - mae: 0.1643 - val_loss: 0.0667 - val_mae: 0.2143\n",
            "Epoch 656/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0308 - mae: 0.1548 - val_loss: 0.0522 - val_mae: 0.1890\n",
            "Epoch 657/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0336 - mae: 0.1620 - val_loss: 0.0512 - val_mae: 0.1900\n",
            "Epoch 658/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0350 - mae: 0.1652 - val_loss: 0.0439 - val_mae: 0.1469\n",
            "Epoch 659/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0328 - mae: 0.1609 - val_loss: 0.0488 - val_mae: 0.1774\n",
            "Epoch 660/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0322 - mae: 0.1563 - val_loss: 0.0373 - val_mae: 0.1538\n",
            "Epoch 661/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0338 - mae: 0.1621 - val_loss: 0.0370 - val_mae: 0.1550\n",
            "Epoch 662/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0305 - mae: 0.1475 - val_loss: 0.0478 - val_mae: 0.1563\n",
            "Epoch 663/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0344 - mae: 0.1638 - val_loss: 0.0647 - val_mae: 0.2097\n",
            "Epoch 664/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0319 - mae: 0.1522 - val_loss: 0.0294 - val_mae: 0.1320\n",
            "Epoch 665/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0313 - mae: 0.1490 - val_loss: 0.0447 - val_mae: 0.1660\n",
            "Epoch 666/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0338 - mae: 0.1628 - val_loss: 0.0370 - val_mae: 0.1254\n",
            "Epoch 667/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0338 - mae: 0.1611 - val_loss: 0.0399 - val_mae: 0.1621\n",
            "Epoch 668/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0319 - mae: 0.1561 - val_loss: 0.0320 - val_mae: 0.1244\n",
            "Epoch 669/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0336 - mae: 0.1630 - val_loss: 0.0508 - val_mae: 0.1815\n",
            "Epoch 670/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0337 - mae: 0.1618 - val_loss: 0.0632 - val_mae: 0.1861\n",
            "Epoch 671/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0312 - mae: 0.1532 - val_loss: 0.0413 - val_mae: 0.1604\n",
            "Epoch 672/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0354 - mae: 0.1655 - val_loss: 0.0628 - val_mae: 0.2131\n",
            "Epoch 673/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0318 - mae: 0.1541 - val_loss: 0.0304 - val_mae: 0.1329\n",
            "Epoch 674/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0312 - mae: 0.1554 - val_loss: 0.0406 - val_mae: 0.1478\n",
            "Epoch 675/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0337 - mae: 0.1577 - val_loss: 0.0608 - val_mae: 0.1960\n",
            "Epoch 676/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0307 - mae: 0.1541 - val_loss: 0.0543 - val_mae: 0.2007\n",
            "Epoch 677/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0341 - mae: 0.1624 - val_loss: 0.0511 - val_mae: 0.1858\n",
            "Epoch 678/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0327 - mae: 0.1587 - val_loss: 0.0330 - val_mae: 0.1214\n",
            "Epoch 679/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0313 - mae: 0.1397 - val_loss: 0.0348 - val_mae: 0.1130\n",
            "Epoch 680/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0343 - mae: 0.1597 - val_loss: 0.0414 - val_mae: 0.1605\n",
            "Epoch 681/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0316 - mae: 0.1560 - val_loss: 0.0302 - val_mae: 0.1358\n",
            "Epoch 682/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0306 - mae: 0.1533 - val_loss: 0.0552 - val_mae: 0.1965\n",
            "Epoch 683/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0358 - mae: 0.1678 - val_loss: 0.0449 - val_mae: 0.1635\n",
            "Epoch 684/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0311 - mae: 0.1539 - val_loss: 0.0405 - val_mae: 0.1500\n",
            "Epoch 685/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0334 - mae: 0.1610 - val_loss: 0.0548 - val_mae: 0.1871\n",
            "Epoch 686/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0318 - mae: 0.1576 - val_loss: 0.0327 - val_mae: 0.1317\n",
            "Epoch 687/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0327 - mae: 0.1574 - val_loss: 0.0707 - val_mae: 0.2245\n",
            "Epoch 688/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0327 - mae: 0.1539 - val_loss: 0.0430 - val_mae: 0.1656\n",
            "Epoch 689/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0319 - mae: 0.1572 - val_loss: 0.0504 - val_mae: 0.1745\n",
            "Epoch 690/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0325 - mae: 0.1588 - val_loss: 0.0471 - val_mae: 0.1720\n",
            "Epoch 691/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0323 - mae: 0.1602 - val_loss: 0.0560 - val_mae: 0.1914\n",
            "Epoch 692/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0331 - mae: 0.1610 - val_loss: 0.0483 - val_mae: 0.1733\n",
            "Epoch 693/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0310 - mae: 0.1546 - val_loss: 0.0410 - val_mae: 0.1517\n",
            "Epoch 694/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0315 - mae: 0.1565 - val_loss: 0.0449 - val_mae: 0.1702\n",
            "Epoch 695/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0334 - mae: 0.1614 - val_loss: 0.0675 - val_mae: 0.2170\n",
            "Epoch 696/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0317 - mae: 0.1573 - val_loss: 0.0499 - val_mae: 0.1789\n",
            "Epoch 697/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0343 - mae: 0.1637 - val_loss: 0.0676 - val_mae: 0.2158\n",
            "Epoch 698/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0311 - mae: 0.1530 - val_loss: 0.0409 - val_mae: 0.1605\n",
            "Epoch 699/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0318 - mae: 0.1573 - val_loss: 0.0532 - val_mae: 0.1875\n",
            "Epoch 700/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0320 - mae: 0.1531 - val_loss: 0.0603 - val_mae: 0.2108\n",
            "Epoch 701/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0331 - mae: 0.1610 - val_loss: 0.0459 - val_mae: 0.1767\n",
            "Epoch 702/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0305 - mae: 0.1536 - val_loss: 0.0297 - val_mae: 0.1275\n",
            "Epoch 703/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0316 - mae: 0.1573 - val_loss: 0.0396 - val_mae: 0.1559\n",
            "Epoch 704/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0320 - mae: 0.1575 - val_loss: 0.0399 - val_mae: 0.1630\n",
            "Epoch 705/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0346 - mae: 0.1652 - val_loss: 0.0509 - val_mae: 0.1736\n",
            "Epoch 706/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0305 - mae: 0.1493 - val_loss: 0.0255 - val_mae: 0.1127\n",
            "Epoch 707/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0307 - mae: 0.1480 - val_loss: 0.0824 - val_mae: 0.2564\n",
            "Epoch 708/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0322 - mae: 0.1579 - val_loss: 0.0314 - val_mae: 0.1328\n",
            "Epoch 709/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0322 - mae: 0.1566 - val_loss: 0.0514 - val_mae: 0.1814\n",
            "Epoch 710/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0330 - mae: 0.1592 - val_loss: 0.0354 - val_mae: 0.1387\n",
            "Epoch 711/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0307 - mae: 0.1550 - val_loss: 0.0521 - val_mae: 0.1721\n",
            "Epoch 712/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1449 - val_loss: 0.0246 - val_mae: 0.1010\n",
            "Epoch 713/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0332 - mae: 0.1594 - val_loss: 0.0342 - val_mae: 0.1372\n",
            "Epoch 714/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0322 - mae: 0.1579 - val_loss: 0.0441 - val_mae: 0.1625\n",
            "Epoch 715/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0320 - mae: 0.1588 - val_loss: 0.0575 - val_mae: 0.1926\n",
            "Epoch 716/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0310 - mae: 0.1551 - val_loss: 0.0344 - val_mae: 0.1470\n",
            "Epoch 717/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0323 - mae: 0.1585 - val_loss: 0.0536 - val_mae: 0.1651\n",
            "Epoch 718/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0305 - mae: 0.1533 - val_loss: 0.0526 - val_mae: 0.1951\n",
            "Epoch 719/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0326 - mae: 0.1602 - val_loss: 0.0398 - val_mae: 0.1538\n",
            "Epoch 720/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0293 - mae: 0.1335 - val_loss: 0.0270 - val_mae: 0.1106\n",
            "Epoch 721/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0308 - mae: 0.1494 - val_loss: 0.0359 - val_mae: 0.1504\n",
            "Epoch 722/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0317 - mae: 0.1534 - val_loss: 0.0409 - val_mae: 0.1540\n",
            "Epoch 723/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0302 - mae: 0.1497 - val_loss: 0.0217 - val_mae: 0.0872\n",
            "Epoch 724/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0292 - mae: 0.1305 - val_loss: 0.0233 - val_mae: 0.0920\n",
            "Epoch 725/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0311 - mae: 0.1474 - val_loss: 0.0921 - val_mae: 0.2698\n",
            "Epoch 726/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0324 - mae: 0.1513 - val_loss: 0.0503 - val_mae: 0.1927\n",
            "Epoch 727/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0313 - mae: 0.1567 - val_loss: 0.0414 - val_mae: 0.1541\n",
            "Epoch 728/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0330 - mae: 0.1603 - val_loss: 0.0545 - val_mae: 0.1928\n",
            "Epoch 729/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.1521 - val_loss: 0.0308 - val_mae: 0.1194\n",
            "Epoch 730/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.1510 - val_loss: 0.0364 - val_mae: 0.1445\n",
            "Epoch 731/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0331 - mae: 0.1609 - val_loss: 0.0407 - val_mae: 0.1618\n",
            "Epoch 732/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1519 - val_loss: 0.0443 - val_mae: 0.1592\n",
            "Epoch 733/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0337 - mae: 0.1575 - val_loss: 0.0525 - val_mae: 0.1733\n",
            "Epoch 734/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0306 - mae: 0.1505 - val_loss: 0.0462 - val_mae: 0.1824\n",
            "Epoch 735/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0290 - mae: 0.1448 - val_loss: 0.0514 - val_mae: 0.1733\n",
            "Epoch 736/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0351 - mae: 0.1618 - val_loss: 0.0354 - val_mae: 0.1456\n",
            "Epoch 737/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0318 - mae: 0.1575 - val_loss: 0.0491 - val_mae: 0.1808\n",
            "Epoch 738/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0299 - mae: 0.1510 - val_loss: 0.0491 - val_mae: 0.1695\n",
            "Epoch 739/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0298 - mae: 0.1470 - val_loss: 0.0733 - val_mae: 0.2179\n",
            "Epoch 740/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0324 - mae: 0.1583 - val_loss: 0.0391 - val_mae: 0.1506\n",
            "Epoch 741/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0312 - mae: 0.1548 - val_loss: 0.0547 - val_mae: 0.1780\n",
            "Epoch 742/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0311 - mae: 0.1534 - val_loss: 0.0296 - val_mae: 0.1154\n",
            "Epoch 743/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0312 - mae: 0.1561 - val_loss: 0.0757 - val_mae: 0.2390\n",
            "Epoch 744/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0299 - mae: 0.1467 - val_loss: 0.0344 - val_mae: 0.1356\n",
            "Epoch 745/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0319 - mae: 0.1563 - val_loss: 0.0433 - val_mae: 0.1650\n",
            "Epoch 746/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0320 - mae: 0.1589 - val_loss: 0.0483 - val_mae: 0.1672\n",
            "Epoch 747/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1507 - val_loss: 0.0662 - val_mae: 0.2162\n",
            "Epoch 748/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0324 - mae: 0.1581 - val_loss: 0.0262 - val_mae: 0.1108\n",
            "Epoch 749/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0296 - mae: 0.1501 - val_loss: 0.0819 - val_mae: 0.2270\n",
            "Epoch 750/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0317 - mae: 0.1553 - val_loss: 0.0486 - val_mae: 0.1840\n",
            "Epoch 751/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0337 - mae: 0.1590 - val_loss: 0.0290 - val_mae: 0.1177\n",
            "Epoch 752/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0292 - mae: 0.1480 - val_loss: 0.0595 - val_mae: 0.1889\n",
            "Epoch 753/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0312 - mae: 0.1540 - val_loss: 0.0425 - val_mae: 0.1592\n",
            "Epoch 754/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0330 - mae: 0.1605 - val_loss: 0.0468 - val_mae: 0.1746\n",
            "Epoch 755/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0302 - mae: 0.1540 - val_loss: 0.0463 - val_mae: 0.1673\n",
            "Epoch 756/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0318 - mae: 0.1586 - val_loss: 0.0445 - val_mae: 0.1651\n",
            "Epoch 757/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0312 - mae: 0.1572 - val_loss: 0.0509 - val_mae: 0.1794\n",
            "Epoch 758/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0306 - mae: 0.1543 - val_loss: 0.0527 - val_mae: 0.1930\n",
            "Epoch 759/1000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0312 - mae: 0.1545 - val_loss: 0.0423 - val_mae: 0.1486\n",
            "Epoch 760/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0319 - mae: 0.1582 - val_loss: 0.0528 - val_mae: 0.1877\n",
            "Epoch 761/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1504 - val_loss: 0.0341 - val_mae: 0.1283\n",
            "Epoch 762/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0311 - mae: 0.1543 - val_loss: 0.0375 - val_mae: 0.1534\n",
            "Epoch 763/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0314 - mae: 0.1559 - val_loss: 0.0621 - val_mae: 0.1932\n",
            "Epoch 764/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0301 - mae: 0.1509 - val_loss: 0.0281 - val_mae: 0.1091\n",
            "Epoch 765/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0321 - mae: 0.1556 - val_loss: 0.0365 - val_mae: 0.1443\n",
            "Epoch 766/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0295 - mae: 0.1470 - val_loss: 0.0407 - val_mae: 0.1669\n",
            "Epoch 767/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0312 - mae: 0.1567 - val_loss: 0.0452 - val_mae: 0.1651\n",
            "Epoch 768/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0296 - mae: 0.1479 - val_loss: 0.0349 - val_mae: 0.1414\n",
            "Epoch 769/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0314 - mae: 0.1565 - val_loss: 0.0398 - val_mae: 0.1556\n",
            "Epoch 770/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0327 - mae: 0.1592 - val_loss: 0.0352 - val_mae: 0.1352\n",
            "Epoch 771/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0293 - mae: 0.1480 - val_loss: 0.0601 - val_mae: 0.2027\n",
            "Epoch 772/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0315 - mae: 0.1580 - val_loss: 0.0426 - val_mae: 0.1596\n",
            "Epoch 773/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0308 - mae: 0.1543 - val_loss: 0.0249 - val_mae: 0.1018\n",
            "Epoch 774/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0285 - mae: 0.1427 - val_loss: 0.0380 - val_mae: 0.1490\n",
            "Epoch 775/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0326 - mae: 0.1576 - val_loss: 0.0622 - val_mae: 0.2189\n",
            "Epoch 776/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1524 - val_loss: 0.0412 - val_mae: 0.1620\n",
            "Epoch 777/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0326 - mae: 0.1604 - val_loss: 0.0505 - val_mae: 0.1888\n",
            "Epoch 778/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0304 - mae: 0.1522 - val_loss: 0.0449 - val_mae: 0.1720\n",
            "Epoch 779/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0312 - mae: 0.1556 - val_loss: 0.0505 - val_mae: 0.1903\n",
            "Epoch 780/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1515 - val_loss: 0.0295 - val_mae: 0.1319\n",
            "Epoch 781/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0322 - mae: 0.1573 - val_loss: 0.0403 - val_mae: 0.1436\n",
            "Epoch 782/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0286 - mae: 0.1451 - val_loss: 0.0583 - val_mae: 0.2007\n",
            "Epoch 783/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0298 - mae: 0.1517 - val_loss: 0.0490 - val_mae: 0.1877\n",
            "Epoch 784/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0322 - mae: 0.1589 - val_loss: 0.0417 - val_mae: 0.1484\n",
            "Epoch 785/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0308 - mae: 0.1551 - val_loss: 0.0402 - val_mae: 0.1500\n",
            "Epoch 786/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0298 - mae: 0.1515 - val_loss: 0.0518 - val_mae: 0.1844\n",
            "Epoch 787/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0318 - mae: 0.1546 - val_loss: 0.0312 - val_mae: 0.1246\n",
            "Epoch 788/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0298 - mae: 0.1527 - val_loss: 0.0627 - val_mae: 0.2097\n",
            "Epoch 789/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0309 - mae: 0.1558 - val_loss: 0.0728 - val_mae: 0.2289\n",
            "Epoch 790/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0293 - mae: 0.1489 - val_loss: 0.0478 - val_mae: 0.1815\n",
            "Epoch 791/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0325 - mae: 0.1600 - val_loss: 0.0431 - val_mae: 0.1657\n",
            "Epoch 792/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0295 - mae: 0.1468 - val_loss: 0.0321 - val_mae: 0.1251\n",
            "Epoch 793/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0315 - mae: 0.1574 - val_loss: 0.0458 - val_mae: 0.1626\n",
            "Epoch 794/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0304 - mae: 0.1527 - val_loss: 0.0389 - val_mae: 0.1621\n",
            "Epoch 795/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0305 - mae: 0.1546 - val_loss: 0.0513 - val_mae: 0.1863\n",
            "Epoch 796/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.1535 - val_loss: 0.0402 - val_mae: 0.1552\n",
            "Epoch 797/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0313 - mae: 0.1568 - val_loss: 0.0426 - val_mae: 0.1588\n",
            "Epoch 798/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0313 - mae: 0.1564 - val_loss: 0.0342 - val_mae: 0.1434\n",
            "Epoch 799/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0312 - mae: 0.1504 - val_loss: 0.0471 - val_mae: 0.1786\n",
            "Epoch 800/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0290 - mae: 0.1491 - val_loss: 0.0331 - val_mae: 0.1418\n",
            "Epoch 801/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0309 - mae: 0.1553 - val_loss: 0.0519 - val_mae: 0.1712\n",
            "Epoch 802/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0303 - mae: 0.1536 - val_loss: 0.0461 - val_mae: 0.1679\n",
            "Epoch 803/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1506 - val_loss: 0.0630 - val_mae: 0.2071\n",
            "Epoch 804/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1531 - val_loss: 0.0524 - val_mae: 0.1956\n",
            "Epoch 805/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0316 - mae: 0.1452 - val_loss: 0.0555 - val_mae: 0.2006\n",
            "Epoch 806/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0283 - mae: 0.1459 - val_loss: 0.0622 - val_mae: 0.2156\n",
            "Epoch 807/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0306 - mae: 0.1542 - val_loss: 0.0467 - val_mae: 0.1714\n",
            "Epoch 808/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1539 - val_loss: 0.0485 - val_mae: 0.1763\n",
            "Epoch 809/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0308 - mae: 0.1505 - val_loss: 0.0495 - val_mae: 0.1797\n",
            "Epoch 810/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0290 - mae: 0.1495 - val_loss: 0.0309 - val_mae: 0.1230\n",
            "Epoch 811/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0321 - mae: 0.1571 - val_loss: 0.0414 - val_mae: 0.1686\n",
            "Epoch 812/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0308 - mae: 0.1553 - val_loss: 0.0394 - val_mae: 0.1510\n",
            "Epoch 813/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0297 - mae: 0.1491 - val_loss: 0.0648 - val_mae: 0.2058\n",
            "Epoch 814/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.1536 - val_loss: 0.0299 - val_mae: 0.1151\n",
            "Epoch 815/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0312 - mae: 0.1566 - val_loss: 0.0706 - val_mae: 0.2025\n",
            "Epoch 816/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0311 - mae: 0.1548 - val_loss: 0.0429 - val_mae: 0.1732\n",
            "Epoch 817/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0299 - mae: 0.1522 - val_loss: 0.0448 - val_mae: 0.1539\n",
            "Epoch 818/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0311 - mae: 0.1559 - val_loss: 0.0335 - val_mae: 0.1447\n",
            "Epoch 819/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0299 - mae: 0.1528 - val_loss: 0.0653 - val_mae: 0.2039\n",
            "Epoch 820/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0283 - mae: 0.1451 - val_loss: 0.0451 - val_mae: 0.1753\n",
            "Epoch 821/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0327 - mae: 0.1607 - val_loss: 0.0472 - val_mae: 0.1788\n",
            "Epoch 822/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0301 - mae: 0.1538 - val_loss: 0.0434 - val_mae: 0.1664\n",
            "Epoch 823/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0290 - mae: 0.1468 - val_loss: 0.0346 - val_mae: 0.1357\n",
            "Epoch 824/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0301 - mae: 0.1512 - val_loss: 0.0373 - val_mae: 0.1414\n",
            "Epoch 825/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0295 - mae: 0.1520 - val_loss: 0.0482 - val_mae: 0.1839\n",
            "Epoch 826/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0306 - mae: 0.1499 - val_loss: 0.0282 - val_mae: 0.1260\n",
            "Epoch 827/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0276 - mae: 0.1435 - val_loss: 0.0348 - val_mae: 0.1479\n",
            "Epoch 828/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0325 - mae: 0.1587 - val_loss: 0.0407 - val_mae: 0.1553\n",
            "Epoch 829/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0281 - mae: 0.1450 - val_loss: 0.0480 - val_mae: 0.1658\n",
            "Epoch 830/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0303 - mae: 0.1519 - val_loss: 0.0515 - val_mae: 0.1891\n",
            "Epoch 831/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0307 - mae: 0.1534 - val_loss: 0.0342 - val_mae: 0.1264\n",
            "Epoch 832/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0300 - mae: 0.1536 - val_loss: 0.0523 - val_mae: 0.1895\n",
            "Epoch 833/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0276 - mae: 0.1460 - val_loss: 0.0591 - val_mae: 0.2083\n",
            "Epoch 834/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0313 - mae: 0.1554 - val_loss: 0.0302 - val_mae: 0.1180\n",
            "Epoch 835/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0311 - mae: 0.1558 - val_loss: 0.0539 - val_mae: 0.1818\n",
            "Epoch 836/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0274 - mae: 0.1395 - val_loss: 0.0418 - val_mae: 0.1521\n",
            "Epoch 837/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0319 - mae: 0.1577 - val_loss: 0.0448 - val_mae: 0.1624\n",
            "Epoch 838/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0303 - mae: 0.1526 - val_loss: 0.0573 - val_mae: 0.1965\n",
            "Epoch 839/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0289 - mae: 0.1482 - val_loss: 0.0511 - val_mae: 0.1747\n",
            "Epoch 840/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0309 - mae: 0.1517 - val_loss: 0.0442 - val_mae: 0.1730\n",
            "Epoch 841/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0298 - mae: 0.1509 - val_loss: 0.0441 - val_mae: 0.1445\n",
            "Epoch 842/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0295 - mae: 0.1512 - val_loss: 0.0627 - val_mae: 0.2146\n",
            "Epoch 843/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0305 - mae: 0.1518 - val_loss: 0.0594 - val_mae: 0.1923\n",
            "Epoch 844/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0293 - mae: 0.1504 - val_loss: 0.0455 - val_mae: 0.1783\n",
            "Epoch 845/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0288 - mae: 0.1500 - val_loss: 0.0435 - val_mae: 0.1552\n",
            "Epoch 846/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1517 - val_loss: 0.0422 - val_mae: 0.1677\n",
            "Epoch 847/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0313 - mae: 0.1566 - val_loss: 0.0496 - val_mae: 0.1768\n",
            "Epoch 848/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0302 - mae: 0.1526 - val_loss: 0.0329 - val_mae: 0.1317\n",
            "Epoch 849/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0282 - mae: 0.1462 - val_loss: 0.0442 - val_mae: 0.1608\n",
            "Epoch 850/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1510 - val_loss: 0.0453 - val_mae: 0.1728\n",
            "Epoch 851/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0284 - mae: 0.1458 - val_loss: 0.0483 - val_mae: 0.1765\n",
            "Epoch 852/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.1501 - val_loss: 0.0694 - val_mae: 0.2297\n",
            "Epoch 853/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0279 - mae: 0.1436 - val_loss: 0.0720 - val_mae: 0.2155\n",
            "Epoch 854/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0296 - mae: 0.1497 - val_loss: 0.0360 - val_mae: 0.1464\n",
            "Epoch 855/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0311 - mae: 0.1545 - val_loss: 0.0514 - val_mae: 0.1671\n",
            "Epoch 856/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0306 - mae: 0.1551 - val_loss: 0.0389 - val_mae: 0.1532\n",
            "Epoch 857/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0296 - mae: 0.1500 - val_loss: 0.0462 - val_mae: 0.1631\n",
            "Epoch 858/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0276 - mae: 0.1455 - val_loss: 0.0422 - val_mae: 0.1654\n",
            "Epoch 859/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0330 - mae: 0.1554 - val_loss: 0.0374 - val_mae: 0.1418\n",
            "Epoch 860/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0273 - mae: 0.1426 - val_loss: 0.0353 - val_mae: 0.1423\n",
            "Epoch 861/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0280 - mae: 0.1444 - val_loss: 0.0400 - val_mae: 0.1405\n",
            "Epoch 862/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0306 - mae: 0.1537 - val_loss: 0.0692 - val_mae: 0.2270\n",
            "Epoch 863/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0296 - mae: 0.1471 - val_loss: 0.0308 - val_mae: 0.1212\n",
            "Epoch 864/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0292 - mae: 0.1477 - val_loss: 0.0364 - val_mae: 0.1512\n",
            "Epoch 865/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1519 - val_loss: 0.0501 - val_mae: 0.1851\n",
            "Epoch 866/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0294 - mae: 0.1509 - val_loss: 0.0360 - val_mae: 0.1396\n",
            "Epoch 867/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0297 - mae: 0.1516 - val_loss: 0.0433 - val_mae: 0.1558\n",
            "Epoch 868/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0281 - mae: 0.1476 - val_loss: 0.0434 - val_mae: 0.1684\n",
            "Epoch 869/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0301 - mae: 0.1525 - val_loss: 0.0484 - val_mae: 0.1634\n",
            "Epoch 870/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0285 - mae: 0.1472 - val_loss: 0.0481 - val_mae: 0.1751\n",
            "Epoch 871/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0273 - mae: 0.1419 - val_loss: 0.0436 - val_mae: 0.1629\n",
            "Epoch 872/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0316 - mae: 0.1559 - val_loss: 0.0416 - val_mae: 0.1613\n",
            "Epoch 873/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0284 - mae: 0.1483 - val_loss: 0.0398 - val_mae: 0.1467\n",
            "Epoch 874/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0290 - mae: 0.1499 - val_loss: 0.0295 - val_mae: 0.1174\n",
            "Epoch 875/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0274 - mae: 0.1436 - val_loss: 0.0346 - val_mae: 0.1353\n",
            "Epoch 876/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0321 - mae: 0.1510 - val_loss: 0.0310 - val_mae: 0.1344\n",
            "Epoch 877/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0269 - mae: 0.1418 - val_loss: 0.0655 - val_mae: 0.2182\n",
            "Epoch 878/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0284 - mae: 0.1469 - val_loss: 0.0382 - val_mae: 0.1536\n",
            "Epoch 879/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.1545 - val_loss: 0.0300 - val_mae: 0.1267\n",
            "Epoch 880/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0271 - mae: 0.1342 - val_loss: 0.0416 - val_mae: 0.1693\n",
            "Epoch 881/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0306 - mae: 0.1546 - val_loss: 0.0547 - val_mae: 0.1712\n",
            "Epoch 882/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0289 - mae: 0.1495 - val_loss: 0.0364 - val_mae: 0.1518\n",
            "Epoch 883/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0294 - mae: 0.1512 - val_loss: 0.0339 - val_mae: 0.1380\n",
            "Epoch 884/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0299 - mae: 0.1493 - val_loss: 0.0302 - val_mae: 0.1275\n",
            "Epoch 885/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0285 - mae: 0.1474 - val_loss: 0.0347 - val_mae: 0.1388\n",
            "Epoch 886/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0293 - mae: 0.1493 - val_loss: 0.0362 - val_mae: 0.1335\n",
            "Epoch 887/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0291 - mae: 0.1504 - val_loss: 0.0473 - val_mae: 0.1730\n",
            "Epoch 888/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0286 - mae: 0.1474 - val_loss: 0.0287 - val_mae: 0.1224\n",
            "Epoch 889/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0269 - mae: 0.1389 - val_loss: 0.0707 - val_mae: 0.2233\n",
            "Epoch 890/1000\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0306 - mae: 0.1530 - val_loss: 0.0280 - val_mae: 0.1202\n",
            "Epoch 891/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0287 - mae: 0.1482 - val_loss: 0.0439 - val_mae: 0.1613\n",
            "Epoch 892/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0294 - mae: 0.1502 - val_loss: 0.0233 - val_mae: 0.0997\n",
            "Epoch 893/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0276 - mae: 0.1356 - val_loss: 0.0357 - val_mae: 0.1352\n",
            "Epoch 894/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0288 - mae: 0.1467 - val_loss: 0.0488 - val_mae: 0.1838\n",
            "Epoch 895/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0293 - mae: 0.1474 - val_loss: 0.0242 - val_mae: 0.1092\n",
            "Epoch 896/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0287 - mae: 0.1472 - val_loss: 0.0354 - val_mae: 0.1490\n",
            "Epoch 897/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0285 - mae: 0.1483 - val_loss: 0.0446 - val_mae: 0.1562\n",
            "Epoch 898/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0275 - mae: 0.1434 - val_loss: 0.0399 - val_mae: 0.1518\n",
            "Epoch 899/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0311 - mae: 0.1565 - val_loss: 0.0442 - val_mae: 0.1595\n",
            "Epoch 900/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0278 - mae: 0.1441 - val_loss: 0.0292 - val_mae: 0.1054\n",
            "Epoch 901/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0276 - mae: 0.1448 - val_loss: 0.0346 - val_mae: 0.1398\n",
            "Epoch 902/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0303 - mae: 0.1533 - val_loss: 0.0345 - val_mae: 0.1361\n",
            "Epoch 903/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0291 - mae: 0.1482 - val_loss: 0.0376 - val_mae: 0.1415\n",
            "Epoch 904/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0266 - mae: 0.1421 - val_loss: 0.0497 - val_mae: 0.1805\n",
            "Epoch 905/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0301 - mae: 0.1540 - val_loss: 0.0477 - val_mae: 0.1808\n",
            "Epoch 906/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0270 - mae: 0.1405 - val_loss: 0.0281 - val_mae: 0.1167\n",
            "Epoch 907/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0305 - mae: 0.1498 - val_loss: 0.0506 - val_mae: 0.1860\n",
            "Epoch 908/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0282 - mae: 0.1464 - val_loss: 0.0535 - val_mae: 0.1937\n",
            "Epoch 909/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0287 - mae: 0.1493 - val_loss: 0.0352 - val_mae: 0.1411\n",
            "Epoch 910/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0283 - mae: 0.1458 - val_loss: 0.0391 - val_mae: 0.1515\n",
            "Epoch 911/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0291 - mae: 0.1495 - val_loss: 0.0347 - val_mae: 0.1189\n",
            "Epoch 912/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0291 - mae: 0.1499 - val_loss: 0.0305 - val_mae: 0.1249\n",
            "Epoch 913/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0259 - mae: 0.1373 - val_loss: 0.0766 - val_mae: 0.2429\n",
            "Epoch 914/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0313 - mae: 0.1547 - val_loss: 0.0324 - val_mae: 0.1337\n",
            "Epoch 915/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0289 - mae: 0.1487 - val_loss: 0.0401 - val_mae: 0.1439\n",
            "Epoch 916/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0273 - mae: 0.1417 - val_loss: 0.0424 - val_mae: 0.1585\n",
            "Epoch 917/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0288 - mae: 0.1494 - val_loss: 0.0689 - val_mae: 0.2127\n",
            "Epoch 918/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0284 - mae: 0.1464 - val_loss: 0.0400 - val_mae: 0.1583\n",
            "Epoch 919/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0277 - mae: 0.1457 - val_loss: 0.0358 - val_mae: 0.1376\n",
            "Epoch 920/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0271 - mae: 0.1434 - val_loss: 0.0257 - val_mae: 0.1098\n",
            "Epoch 921/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0281 - mae: 0.1400 - val_loss: 0.0588 - val_mae: 0.2070\n",
            "Epoch 922/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0292 - mae: 0.1481 - val_loss: 0.0270 - val_mae: 0.1102\n",
            "Epoch 923/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0270 - mae: 0.1425 - val_loss: 0.0492 - val_mae: 0.1850\n",
            "Epoch 924/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0295 - mae: 0.1496 - val_loss: 0.0468 - val_mae: 0.1801\n",
            "Epoch 925/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0283 - mae: 0.1403 - val_loss: 0.0265 - val_mae: 0.1121\n",
            "Epoch 926/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0284 - mae: 0.1458 - val_loss: 0.0563 - val_mae: 0.1874\n",
            "Epoch 927/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0276 - mae: 0.1457 - val_loss: 0.0572 - val_mae: 0.1959\n",
            "Epoch 928/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0280 - mae: 0.1477 - val_loss: 0.0382 - val_mae: 0.1549\n",
            "Epoch 929/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1527 - val_loss: 0.0460 - val_mae: 0.1756\n",
            "Epoch 930/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0281 - mae: 0.1471 - val_loss: 0.0365 - val_mae: 0.1418\n",
            "Epoch 931/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0274 - mae: 0.1442 - val_loss: 0.0360 - val_mae: 0.1484\n",
            "Epoch 932/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0284 - mae: 0.1478 - val_loss: 0.0358 - val_mae: 0.1445\n",
            "Epoch 933/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0290 - mae: 0.1493 - val_loss: 0.0543 - val_mae: 0.2006\n",
            "Epoch 934/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0260 - mae: 0.1400 - val_loss: 0.0387 - val_mae: 0.1509\n",
            "Epoch 935/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0293 - mae: 0.1508 - val_loss: 0.0354 - val_mae: 0.1323\n",
            "Epoch 936/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0271 - mae: 0.1444 - val_loss: 0.0314 - val_mae: 0.1162\n",
            "Epoch 937/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.1528 - val_loss: 0.0366 - val_mae: 0.1477\n",
            "Epoch 938/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0266 - mae: 0.1401 - val_loss: 0.0438 - val_mae: 0.1696\n",
            "Epoch 939/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0282 - mae: 0.1475 - val_loss: 0.0672 - val_mae: 0.2175\n",
            "Epoch 940/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0270 - mae: 0.1387 - val_loss: 0.0268 - val_mae: 0.1151\n",
            "Epoch 941/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0270 - mae: 0.1408 - val_loss: 0.0524 - val_mae: 0.1831\n",
            "Epoch 942/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0293 - mae: 0.1494 - val_loss: 0.0328 - val_mae: 0.1235\n",
            "Epoch 943/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0280 - mae: 0.1473 - val_loss: 0.0541 - val_mae: 0.1921\n",
            "Epoch 944/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0279 - mae: 0.1452 - val_loss: 0.0417 - val_mae: 0.1602\n",
            "Epoch 945/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0294 - mae: 0.1485 - val_loss: 0.0492 - val_mae: 0.1698\n",
            "Epoch 946/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0273 - mae: 0.1413 - val_loss: 0.0414 - val_mae: 0.1497\n",
            "Epoch 947/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0274 - mae: 0.1433 - val_loss: 0.0498 - val_mae: 0.1812\n",
            "Epoch 948/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0281 - mae: 0.1427 - val_loss: 0.0358 - val_mae: 0.1510\n",
            "Epoch 949/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0251 - mae: 0.1352 - val_loss: 0.0462 - val_mae: 0.1711\n",
            "Epoch 950/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1523 - val_loss: 0.0334 - val_mae: 0.1423\n",
            "Epoch 951/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0286 - mae: 0.1473 - val_loss: 0.0337 - val_mae: 0.1366\n",
            "Epoch 952/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0270 - mae: 0.1430 - val_loss: 0.0430 - val_mae: 0.1643\n",
            "Epoch 953/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0262 - mae: 0.1336 - val_loss: 0.0265 - val_mae: 0.1069\n",
            "Epoch 954/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0269 - mae: 0.1396 - val_loss: 0.0260 - val_mae: 0.0994\n",
            "Epoch 955/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0271 - mae: 0.1346 - val_loss: 0.0294 - val_mae: 0.1227\n",
            "Epoch 956/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0290 - mae: 0.1499 - val_loss: 0.0401 - val_mae: 0.1607\n",
            "Epoch 957/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0272 - mae: 0.1450 - val_loss: 0.0543 - val_mae: 0.1840\n",
            "Epoch 958/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0285 - mae: 0.1449 - val_loss: 0.0446 - val_mae: 0.1695\n",
            "Epoch 959/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0276 - mae: 0.1430 - val_loss: 0.0281 - val_mae: 0.1258\n",
            "Epoch 960/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0270 - mae: 0.1429 - val_loss: 0.0330 - val_mae: 0.1357\n",
            "Epoch 961/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0274 - mae: 0.1459 - val_loss: 0.0444 - val_mae: 0.1774\n",
            "Epoch 962/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0285 - mae: 0.1473 - val_loss: 0.0541 - val_mae: 0.1993\n",
            "Epoch 963/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0263 - mae: 0.1423 - val_loss: 0.0480 - val_mae: 0.1659\n",
            "Epoch 964/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0284 - mae: 0.1484 - val_loss: 0.0320 - val_mae: 0.1320\n",
            "Epoch 965/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0260 - mae: 0.1368 - val_loss: 0.0183 - val_mae: 0.0849\n",
            "Epoch 966/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0295 - mae: 0.1458 - val_loss: 0.0439 - val_mae: 0.1756\n",
            "Epoch 967/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0268 - mae: 0.1431 - val_loss: 0.0585 - val_mae: 0.2068\n",
            "Epoch 968/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0278 - mae: 0.1445 - val_loss: 0.0443 - val_mae: 0.1468\n",
            "Epoch 969/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0270 - mae: 0.1428 - val_loss: 0.0535 - val_mae: 0.1898\n",
            "Epoch 970/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0273 - mae: 0.1447 - val_loss: 0.0421 - val_mae: 0.1591\n",
            "Epoch 971/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0275 - mae: 0.1450 - val_loss: 0.0461 - val_mae: 0.1722\n",
            "Epoch 972/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0280 - mae: 0.1464 - val_loss: 0.0362 - val_mae: 0.1555\n",
            "Epoch 973/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0250 - mae: 0.1325 - val_loss: 0.0268 - val_mae: 0.0910\n",
            "Epoch 974/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0287 - mae: 0.1439 - val_loss: 0.0407 - val_mae: 0.1593\n",
            "Epoch 975/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0282 - mae: 0.1480 - val_loss: 0.0288 - val_mae: 0.1283\n",
            "Epoch 976/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0248 - mae: 0.1343 - val_loss: 0.0336 - val_mae: 0.1383\n",
            "Epoch 977/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0294 - mae: 0.1455 - val_loss: 0.0548 - val_mae: 0.1976\n",
            "Epoch 978/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0252 - mae: 0.1314 - val_loss: 0.0227 - val_mae: 0.0984\n",
            "Epoch 979/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0243 - mae: 0.1300 - val_loss: 0.0531 - val_mae: 0.1927\n",
            "Epoch 980/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0299 - mae: 0.1495 - val_loss: 0.0389 - val_mae: 0.1592\n",
            "Epoch 981/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0259 - mae: 0.1406 - val_loss: 0.0376 - val_mae: 0.1464\n",
            "Epoch 982/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0283 - mae: 0.1445 - val_loss: 0.0510 - val_mae: 0.1897\n",
            "Epoch 983/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0266 - mae: 0.1393 - val_loss: 0.0314 - val_mae: 0.1132\n",
            "Epoch 984/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0273 - mae: 0.1441 - val_loss: 0.0298 - val_mae: 0.1308\n",
            "Epoch 985/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0267 - mae: 0.1421 - val_loss: 0.0554 - val_mae: 0.1890\n",
            "Epoch 986/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0289 - mae: 0.1451 - val_loss: 0.0378 - val_mae: 0.1448\n",
            "Epoch 987/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0254 - mae: 0.1370 - val_loss: 0.0448 - val_mae: 0.1796\n",
            "Epoch 988/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0271 - mae: 0.1443 - val_loss: 0.0391 - val_mae: 0.1525\n",
            "Epoch 989/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0274 - mae: 0.1460 - val_loss: 0.0355 - val_mae: 0.1370\n",
            "Epoch 990/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0268 - mae: 0.1417 - val_loss: 0.0358 - val_mae: 0.1493\n",
            "Epoch 991/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0266 - mae: 0.1435 - val_loss: 0.0329 - val_mae: 0.1392\n",
            "Epoch 992/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0259 - mae: 0.1378 - val_loss: 0.0477 - val_mae: 0.1847\n",
            "Epoch 993/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0278 - mae: 0.1443 - val_loss: 0.0486 - val_mae: 0.1808\n",
            "Epoch 994/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0247 - mae: 0.1341 - val_loss: 0.0534 - val_mae: 0.1915\n",
            "Epoch 995/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0275 - mae: 0.1443 - val_loss: 0.0363 - val_mae: 0.1405\n",
            "Epoch 996/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0276 - mae: 0.1444 - val_loss: 0.0408 - val_mae: 0.1575\n",
            "Epoch 997/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0271 - mae: 0.1439 - val_loss: 0.0476 - val_mae: 0.1810\n",
            "Epoch 998/1000\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0270 - mae: 0.1440 - val_loss: 0.0456 - val_mae: 0.1684\n",
            "Epoch 999/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0264 - mae: 0.1424 - val_loss: 0.0406 - val_mae: 0.1663\n",
            "Epoch 1000/1000\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 0.0260 - mae: 0.1398 - val_loss: 0.0263 - val_mae: 0.1139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlwI3i4dJY1K",
        "colab_type": "code",
        "outputId": "6e893daa-1ba9-4977-8798-daaf7386cf59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "P6 = model6.predict(XTRAIN)\n",
        "YTRAIN5=np.exp(YTRAIN5)\n",
        "P6=np.exp(P6)\n",
        "MAE6 = abs(YTRAIN5 - P6)\n",
        "print(MAE6)\n",
        "M5=MAE6.mean()\n",
        "print(\"M5=\",M5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 157176.07    398206.452   835365.6624 ...  904924.31   1049976.2278\n",
            "   638857.219 ]\n",
            " [ 178704.805    62325.577   499484.7874 ...  569043.435   714095.3528\n",
            "   302976.344 ]\n",
            " [ 444065.18    203034.798   234124.4124 ...  303683.06    448734.9778\n",
            "    37615.969 ]\n",
            " ...\n",
            " [ 693668.7425  452638.3605   15479.1501 ...   54079.4975  199131.4153\n",
            "   211987.5935]\n",
            " [ 755663.9925  514633.6105   77474.4001 ...    7915.7525  137136.1653\n",
            "   273982.8435]\n",
            " [ 421468.43    180438.048   256721.1624 ...  326279.81    471331.7278\n",
            "    60212.719 ]]\n",
            "M5= 419710.4214536134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhkSgxqWV13t",
        "colab_type": "code",
        "outputId": "0d222f53-e3a3-4fb2-c72f-752f3f641239",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.figure(figsize=(15, 13))\n",
        "plt.plot(history6.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history6.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "min(history6.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x936 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0183052197098732"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZlBj9S9XaL8",
        "colab_type": "text"
      },
      "source": [
        "Number of layers |Number of neurons | Epochs | Mean MAE\n",
        "--- | --- | --- | ---\n",
        "5 | 256,256,256,256,1 | 1000 | 419710.421\n",
        "6 | 256,250,150,100,50,1| 700 | 407455.452\n",
        "6 | 256,250,150,100,50,1| 1000 | 383967.0292\n",
        "6 | 256,250,150,100,50,1| 2000 | 415189.291\n",
        "6 | 256,250,250,200,100,1 | 2000 | 379906.062\n",
        "6 | 256,256,256,256,256,1 | 2000 | 385185.843\n",
        "7 | 256,256,256,256,256,256,1 | 3000 | 385761.5310\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHmzPnttJN_z",
        "colab_type": "code",
        "outputId": "c957e0ad-74fa-4225-c8b4-ab1a588a328c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "min(419710.421,407455.452,383967.0292, 415189.291, 379906.062, 385185.843,385761.5310)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "379906.062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjWDAKnI3EiK",
        "colab_type": "text"
      },
      "source": [
        "As seen above a variety of different combinations of number of layers, number of neurons and epochs were tried to find the model with the lowest mean MAE. The architecture with 6 layers containing 256 neurons in the first five layers and 1 neuron in the last layer gave us the best mean MAE. Further increasing or decreasing the number of neurons or the epochs did not improve our mean MAE. As such when we have a lot of data (number of rows) as I do in my dataset it can be hard to overfit the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1uGILMm4h1z",
        "colab_type": "text"
      },
      "source": [
        "# Overfit architecture when we have output as an input variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T8Mxbb5W_Uw",
        "colab_type": "text"
      },
      "source": [
        "We split our dataset again but this time we add our price column as an input column as well. Our model will have 6 inputs instead of 5 now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwcXSZAX4nED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "dataset2 = np.genfromtxt('USA_Housing_project.csv', delimiter=\",\", skip_header = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXjVXBna5gFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "np.random.shuffle(dataset2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFwzMOiJ5jft",
        "colab_type": "code",
        "outputId": "033f8368-9fb8-4177-9610-a007cbb35ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Index for 30%\n",
        "index_30percent = int(0.3 * len(dataset[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation\n",
        "XVALID_d2 = dataset[:index_30percent, [0,1,2,3,4,5]]\n",
        "YVALID_d2 = dataset[:index_30percent, 5]\n",
        "XTRAIN_d2 = dataset[index_30percent:, [0,1,2,3,4,5]]\n",
        "YTRAIN_d2 = dataset[index_30percent:, 5]\n",
        "#print(XVALID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THRY-b465v6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Applying mean and std from xtrain to xvalid\n",
        "mean = XTRAIN_d2.mean(axis = 0)\n",
        "XTRAIN_d2 -= mean\n",
        "std = XTRAIN_d2.std(axis = 0)\n",
        "XTRAIN_d2 /= std\n",
        "\n",
        "XVALID_d2 -= mean\n",
        "XVALID_d2 /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE28SYYV55rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "YTRAIN_d2_1 = np.log(YTRAIN_d2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crUF3KKu6FCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "YVALID_d2_1 = np.log(YVALID_d2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwsHxHW66PKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model7 = Sequential()\n",
        "model7.add(Dense(256,input_dim =6, activation='relu'))\n",
        "model7.add(Dense(256, activation='relu'))\n",
        "model7.add(Dense(256, activation='relu'))\n",
        "model7.add(Dense(256, activation='relu'))\n",
        "model7.add(Dense(256, activation='relu'))\n",
        "model7.add(Dense(1, activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmatBz_r6do0",
        "colab_type": "code",
        "outputId": "bcfe2569-99ed-4575-bcd1-d79e31e108c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model7.compile(loss='mse', optimizer = 'rmsprop', metrics=['mae'])\n",
        "history7=model7.fit(XTRAIN_d2, YTRAIN_d2_1,validation_data=(XVALID_d2, YVALID_d2_1), epochs = 2000, batch_size=100, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 32.1285 - mae: 4.3271 - val_loss: 16.8121 - val_mae: 3.5171\n",
            "Epoch 2/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 12.5632 - mae: 2.9244 - val_loss: 10.8169 - val_mae: 2.6189\n",
            "Epoch 3/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 9.0519 - mae: 2.4871 - val_loss: 17.7148 - val_mae: 3.9865\n",
            "Epoch 4/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 6.9664 - mae: 2.2176 - val_loss: 4.3819 - val_mae: 1.6592\n",
            "Epoch 5/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 5.1662 - mae: 1.9689 - val_loss: 4.9977 - val_mae: 2.0955\n",
            "Epoch 6/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 4.0253 - mae: 1.8058 - val_loss: 2.6146 - val_mae: 1.3843\n",
            "Epoch 7/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 3.2725 - mae: 1.6723 - val_loss: 3.8838 - val_mae: 1.9045\n",
            "Epoch 8/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 3.0015 - mae: 1.6246 - val_loss: 2.5153 - val_mae: 1.4594\n",
            "Epoch 9/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 2.4947 - mae: 1.4769 - val_loss: 2.5739 - val_mae: 1.5538\n",
            "Epoch 10/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 2.2323 - mae: 1.4171 - val_loss: 1.9527 - val_mae: 1.2966\n",
            "Epoch 11/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 2.0571 - mae: 1.3613 - val_loss: 1.9300 - val_mae: 1.3516\n",
            "Epoch 12/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 1.8068 - mae: 1.2866 - val_loss: 1.4798 - val_mae: 1.1558\n",
            "Epoch 13/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 1.5780 - mae: 1.1998 - val_loss: 1.8891 - val_mae: 1.3429\n",
            "Epoch 14/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 1.4171 - mae: 1.1334 - val_loss: 1.3642 - val_mae: 1.1219\n",
            "Epoch 15/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 1.3081 - mae: 1.0981 - val_loss: 1.2377 - val_mae: 1.0892\n",
            "Epoch 16/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 1.1757 - mae: 1.0514 - val_loss: 0.8160 - val_mae: 0.8736\n",
            "Epoch 17/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 1.0148 - mae: 0.9757 - val_loss: 1.0362 - val_mae: 1.0022\n",
            "Epoch 18/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.9287 - mae: 0.9349 - val_loss: 0.7628 - val_mae: 0.8444\n",
            "Epoch 19/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.8179 - mae: 0.8752 - val_loss: 1.0277 - val_mae: 1.0027\n",
            "Epoch 20/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.6977 - mae: 0.8133 - val_loss: 0.5775 - val_mae: 0.7411\n",
            "Epoch 21/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.6002 - mae: 0.7601 - val_loss: 0.6151 - val_mae: 0.7769\n",
            "Epoch 22/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.5184 - mae: 0.7088 - val_loss: 0.5232 - val_mae: 0.7133\n",
            "Epoch 23/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.4591 - mae: 0.6671 - val_loss: 0.5071 - val_mae: 0.7081\n",
            "Epoch 24/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.4110 - mae: 0.6337 - val_loss: 0.3781 - val_mae: 0.6110\n",
            "Epoch 25/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3705 - mae: 0.6018 - val_loss: 0.4259 - val_mae: 0.6483\n",
            "Epoch 26/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3638 - mae: 0.5969 - val_loss: 0.2927 - val_mae: 0.5340\n",
            "Epoch 27/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3398 - mae: 0.5731 - val_loss: 0.3689 - val_mae: 0.6006\n",
            "Epoch 28/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3466 - mae: 0.5798 - val_loss: 0.3291 - val_mae: 0.5677\n",
            "Epoch 29/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3303 - mae: 0.5671 - val_loss: 0.4101 - val_mae: 0.6339\n",
            "Epoch 30/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3305 - mae: 0.5645 - val_loss: 0.3478 - val_mae: 0.5847\n",
            "Epoch 31/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3239 - mae: 0.5613 - val_loss: 0.3660 - val_mae: 0.5964\n",
            "Epoch 32/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3165 - mae: 0.5536 - val_loss: 0.3144 - val_mae: 0.5547\n",
            "Epoch 33/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3162 - mae: 0.5533 - val_loss: 0.2961 - val_mae: 0.5382\n",
            "Epoch 34/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3006 - mae: 0.5382 - val_loss: 0.2545 - val_mae: 0.4990\n",
            "Epoch 35/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.3074 - mae: 0.5460 - val_loss: 0.3032 - val_mae: 0.5438\n",
            "Epoch 36/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2999 - mae: 0.5408 - val_loss: 0.2699 - val_mae: 0.5114\n",
            "Epoch 37/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2930 - mae: 0.5323 - val_loss: 0.4615 - val_mae: 0.6740\n",
            "Epoch 38/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2991 - mae: 0.5372 - val_loss: 0.2701 - val_mae: 0.5141\n",
            "Epoch 39/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2938 - mae: 0.5307 - val_loss: 0.2702 - val_mae: 0.5121\n",
            "Epoch 40/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2811 - mae: 0.5235 - val_loss: 0.2479 - val_mae: 0.4925\n",
            "Epoch 41/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2815 - mae: 0.5229 - val_loss: 0.2838 - val_mae: 0.5256\n",
            "Epoch 42/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2731 - mae: 0.5145 - val_loss: 0.2569 - val_mae: 0.5001\n",
            "Epoch 43/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2814 - mae: 0.5223 - val_loss: 0.2917 - val_mae: 0.5358\n",
            "Epoch 44/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2727 - mae: 0.5167 - val_loss: 0.2446 - val_mae: 0.4910\n",
            "Epoch 45/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2635 - mae: 0.5068 - val_loss: 0.2622 - val_mae: 0.5070\n",
            "Epoch 46/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2705 - mae: 0.5136 - val_loss: 0.2422 - val_mae: 0.4879\n",
            "Epoch 47/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2586 - mae: 0.5016 - val_loss: 0.3190 - val_mae: 0.5563\n",
            "Epoch 48/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2633 - mae: 0.5063 - val_loss: 0.1827 - val_mae: 0.4212\n",
            "Epoch 49/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2547 - mae: 0.4985 - val_loss: 0.2875 - val_mae: 0.5287\n",
            "Epoch 50/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2548 - mae: 0.4998 - val_loss: 0.2131 - val_mae: 0.4572\n",
            "Epoch 51/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2605 - mae: 0.5030 - val_loss: 0.2070 - val_mae: 0.4505\n",
            "Epoch 52/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2512 - mae: 0.4949 - val_loss: 0.2376 - val_mae: 0.4821\n",
            "Epoch 53/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2471 - mae: 0.4915 - val_loss: 0.2925 - val_mae: 0.5361\n",
            "Epoch 54/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2504 - mae: 0.4955 - val_loss: 0.2160 - val_mae: 0.4603\n",
            "Epoch 55/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2426 - mae: 0.4861 - val_loss: 0.2728 - val_mae: 0.5164\n",
            "Epoch 56/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2397 - mae: 0.4832 - val_loss: 0.2351 - val_mae: 0.4807\n",
            "Epoch 57/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2471 - mae: 0.4911 - val_loss: 0.2058 - val_mae: 0.4468\n",
            "Epoch 58/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2384 - mae: 0.4822 - val_loss: 0.1915 - val_mae: 0.4330\n",
            "Epoch 59/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2337 - mae: 0.4768 - val_loss: 0.2410 - val_mae: 0.4874\n",
            "Epoch 60/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2374 - mae: 0.4825 - val_loss: 0.2201 - val_mae: 0.4658\n",
            "Epoch 61/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2369 - mae: 0.4808 - val_loss: 0.1908 - val_mae: 0.4318\n",
            "Epoch 62/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2318 - mae: 0.4757 - val_loss: 0.2542 - val_mae: 0.5018\n",
            "Epoch 63/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2287 - mae: 0.4734 - val_loss: 0.2802 - val_mae: 0.5250\n",
            "Epoch 64/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2331 - mae: 0.4768 - val_loss: 0.2063 - val_mae: 0.4514\n",
            "Epoch 65/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2286 - mae: 0.4744 - val_loss: 0.2397 - val_mae: 0.4851\n",
            "Epoch 66/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2298 - mae: 0.4747 - val_loss: 0.2122 - val_mae: 0.4569\n",
            "Epoch 67/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2236 - mae: 0.4681 - val_loss: 0.2050 - val_mae: 0.4482\n",
            "Epoch 68/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2180 - mae: 0.4615 - val_loss: 0.1935 - val_mae: 0.4358\n",
            "Epoch 69/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2185 - mae: 0.4625 - val_loss: 0.2425 - val_mae: 0.4810\n",
            "Epoch 70/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2209 - mae: 0.4638 - val_loss: 0.2161 - val_mae: 0.4607\n",
            "Epoch 71/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2222 - mae: 0.4661 - val_loss: 0.2312 - val_mae: 0.4765\n",
            "Epoch 72/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2193 - mae: 0.4634 - val_loss: 0.2082 - val_mae: 0.4512\n",
            "Epoch 73/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2171 - mae: 0.4612 - val_loss: 0.2113 - val_mae: 0.4548\n",
            "Epoch 74/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2129 - mae: 0.4555 - val_loss: 0.2319 - val_mae: 0.4772\n",
            "Epoch 75/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2066 - mae: 0.4496 - val_loss: 0.1948 - val_mae: 0.4361\n",
            "Epoch 76/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2196 - mae: 0.4628 - val_loss: 0.2522 - val_mae: 0.4995\n",
            "Epoch 77/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2062 - mae: 0.4500 - val_loss: 0.1833 - val_mae: 0.4204\n",
            "Epoch 78/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2086 - mae: 0.4512 - val_loss: 0.2087 - val_mae: 0.4528\n",
            "Epoch 79/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2084 - mae: 0.4500 - val_loss: 0.2665 - val_mae: 0.5119\n",
            "Epoch 80/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2060 - mae: 0.4493 - val_loss: 0.1622 - val_mae: 0.3993\n",
            "Epoch 81/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2028 - mae: 0.4452 - val_loss: 0.2672 - val_mae: 0.5054\n",
            "Epoch 82/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2051 - mae: 0.4469 - val_loss: 0.1643 - val_mae: 0.4022\n",
            "Epoch 83/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1964 - mae: 0.4387 - val_loss: 0.2113 - val_mae: 0.4538\n",
            "Epoch 84/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1977 - mae: 0.4406 - val_loss: 0.2265 - val_mae: 0.4715\n",
            "Epoch 85/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.2011 - mae: 0.4422 - val_loss: 0.1411 - val_mae: 0.3667\n",
            "Epoch 86/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1959 - mae: 0.4377 - val_loss: 0.1816 - val_mae: 0.4235\n",
            "Epoch 87/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1950 - mae: 0.4372 - val_loss: 0.2061 - val_mae: 0.4478\n",
            "Epoch 88/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1901 - mae: 0.4327 - val_loss: 0.1644 - val_mae: 0.4025\n",
            "Epoch 89/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1925 - mae: 0.4338 - val_loss: 0.2364 - val_mae: 0.4843\n",
            "Epoch 90/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1893 - mae: 0.4312 - val_loss: 0.2114 - val_mae: 0.4574\n",
            "Epoch 91/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1867 - mae: 0.4270 - val_loss: 0.1592 - val_mae: 0.3874\n",
            "Epoch 92/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1896 - mae: 0.4297 - val_loss: 0.1613 - val_mae: 0.3964\n",
            "Epoch 93/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1854 - mae: 0.4271 - val_loss: 0.2057 - val_mae: 0.4494\n",
            "Epoch 94/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1857 - mae: 0.4278 - val_loss: 0.1714 - val_mae: 0.4111\n",
            "Epoch 95/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1853 - mae: 0.4263 - val_loss: 0.1991 - val_mae: 0.4405\n",
            "Epoch 96/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1822 - mae: 0.4231 - val_loss: 0.1796 - val_mae: 0.4183\n",
            "Epoch 97/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1786 - mae: 0.4184 - val_loss: 0.1646 - val_mae: 0.3983\n",
            "Epoch 98/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1799 - mae: 0.4198 - val_loss: 0.1666 - val_mae: 0.4041\n",
            "Epoch 99/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1788 - mae: 0.4191 - val_loss: 0.2080 - val_mae: 0.4374\n",
            "Epoch 100/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1783 - mae: 0.4179 - val_loss: 0.1900 - val_mae: 0.4319\n",
            "Epoch 101/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1782 - mae: 0.4177 - val_loss: 0.1988 - val_mae: 0.4427\n",
            "Epoch 102/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1703 - mae: 0.4075 - val_loss: 0.2089 - val_mae: 0.4532\n",
            "Epoch 103/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1717 - mae: 0.4094 - val_loss: 0.2022 - val_mae: 0.4419\n",
            "Epoch 104/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1723 - mae: 0.4110 - val_loss: 0.1831 - val_mae: 0.4241\n",
            "Epoch 105/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1715 - mae: 0.4102 - val_loss: 0.1958 - val_mae: 0.4216\n",
            "Epoch 106/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1688 - mae: 0.4063 - val_loss: 0.1490 - val_mae: 0.3831\n",
            "Epoch 107/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1688 - mae: 0.4078 - val_loss: 0.1668 - val_mae: 0.4022\n",
            "Epoch 108/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1668 - mae: 0.4051 - val_loss: 0.1723 - val_mae: 0.4123\n",
            "Epoch 109/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1639 - mae: 0.4020 - val_loss: 0.2129 - val_mae: 0.4566\n",
            "Epoch 110/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1648 - mae: 0.4032 - val_loss: 0.1608 - val_mae: 0.3978\n",
            "Epoch 111/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1617 - mae: 0.3990 - val_loss: 0.1685 - val_mae: 0.4038\n",
            "Epoch 112/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1591 - mae: 0.3962 - val_loss: 0.1599 - val_mae: 0.3972\n",
            "Epoch 113/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1640 - mae: 0.4014 - val_loss: 0.1589 - val_mae: 0.3951\n",
            "Epoch 114/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1559 - mae: 0.3909 - val_loss: 0.1572 - val_mae: 0.3898\n",
            "Epoch 115/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1597 - mae: 0.3964 - val_loss: 0.1954 - val_mae: 0.4300\n",
            "Epoch 116/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1551 - mae: 0.3906 - val_loss: 0.1648 - val_mae: 0.4018\n",
            "Epoch 117/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1595 - mae: 0.3962 - val_loss: 0.1875 - val_mae: 0.4287\n",
            "Epoch 118/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1542 - mae: 0.3890 - val_loss: 0.1593 - val_mae: 0.3955\n",
            "Epoch 119/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1539 - mae: 0.3893 - val_loss: 0.1493 - val_mae: 0.3827\n",
            "Epoch 120/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1527 - mae: 0.3877 - val_loss: 0.1545 - val_mae: 0.3888\n",
            "Epoch 121/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1533 - mae: 0.3889 - val_loss: 0.1502 - val_mae: 0.3791\n",
            "Epoch 122/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1533 - mae: 0.3891 - val_loss: 0.1298 - val_mae: 0.3573\n",
            "Epoch 123/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1479 - mae: 0.3819 - val_loss: 0.1558 - val_mae: 0.3846\n",
            "Epoch 124/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1511 - mae: 0.3856 - val_loss: 0.1591 - val_mae: 0.3940\n",
            "Epoch 125/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1468 - mae: 0.3802 - val_loss: 0.1486 - val_mae: 0.3804\n",
            "Epoch 126/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1467 - mae: 0.3802 - val_loss: 0.1681 - val_mae: 0.4021\n",
            "Epoch 127/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1514 - mae: 0.3851 - val_loss: 0.1381 - val_mae: 0.3639\n",
            "Epoch 128/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1454 - mae: 0.3758 - val_loss: 0.1565 - val_mae: 0.3920\n",
            "Epoch 129/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1469 - mae: 0.3805 - val_loss: 0.1311 - val_mae: 0.3588\n",
            "Epoch 130/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1420 - mae: 0.3739 - val_loss: 0.1781 - val_mae: 0.4198\n",
            "Epoch 131/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1460 - mae: 0.3783 - val_loss: 0.1325 - val_mae: 0.3532\n",
            "Epoch 132/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1437 - mae: 0.3757 - val_loss: 0.1362 - val_mae: 0.3674\n",
            "Epoch 133/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1425 - mae: 0.3750 - val_loss: 0.1326 - val_mae: 0.3585\n",
            "Epoch 134/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1421 - mae: 0.3742 - val_loss: 0.1317 - val_mae: 0.3592\n",
            "Epoch 135/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1427 - mae: 0.3746 - val_loss: 0.1402 - val_mae: 0.3686\n",
            "Epoch 136/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1388 - mae: 0.3695 - val_loss: 0.1108 - val_mae: 0.3303\n",
            "Epoch 137/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1354 - mae: 0.3652 - val_loss: 0.1538 - val_mae: 0.3901\n",
            "Epoch 138/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1388 - mae: 0.3699 - val_loss: 0.1328 - val_mae: 0.3625\n",
            "Epoch 139/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1369 - mae: 0.3668 - val_loss: 0.1569 - val_mae: 0.3840\n",
            "Epoch 140/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1340 - mae: 0.3635 - val_loss: 0.1187 - val_mae: 0.3422\n",
            "Epoch 141/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1346 - mae: 0.3639 - val_loss: 0.1365 - val_mae: 0.3656\n",
            "Epoch 142/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1353 - mae: 0.3648 - val_loss: 0.1173 - val_mae: 0.3400\n",
            "Epoch 143/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1337 - mae: 0.3610 - val_loss: 0.1140 - val_mae: 0.3357\n",
            "Epoch 144/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1345 - mae: 0.3635 - val_loss: 0.1351 - val_mae: 0.3656\n",
            "Epoch 145/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1311 - mae: 0.3589 - val_loss: 0.1693 - val_mae: 0.4095\n",
            "Epoch 146/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1322 - mae: 0.3613 - val_loss: 0.1199 - val_mae: 0.3440\n",
            "Epoch 147/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1286 - mae: 0.3564 - val_loss: 0.1512 - val_mae: 0.3827\n",
            "Epoch 148/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1308 - mae: 0.3578 - val_loss: 0.1034 - val_mae: 0.3200\n",
            "Epoch 149/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1277 - mae: 0.3538 - val_loss: 0.1337 - val_mae: 0.3637\n",
            "Epoch 150/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1287 - mae: 0.3558 - val_loss: 0.1340 - val_mae: 0.3642\n",
            "Epoch 151/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1260 - mae: 0.3521 - val_loss: 0.1445 - val_mae: 0.3781\n",
            "Epoch 152/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1274 - mae: 0.3541 - val_loss: 0.1374 - val_mae: 0.3686\n",
            "Epoch 153/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1245 - mae: 0.3500 - val_loss: 0.1512 - val_mae: 0.3863\n",
            "Epoch 154/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1260 - mae: 0.3527 - val_loss: 0.1028 - val_mae: 0.3187\n",
            "Epoch 155/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1213 - mae: 0.3450 - val_loss: 0.1508 - val_mae: 0.3862\n",
            "Epoch 156/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1248 - mae: 0.3502 - val_loss: 0.1373 - val_mae: 0.3686\n",
            "Epoch 157/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1209 - mae: 0.3449 - val_loss: 0.1198 - val_mae: 0.3434\n",
            "Epoch 158/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1234 - mae: 0.3478 - val_loss: 0.1365 - val_mae: 0.3676\n",
            "Epoch 159/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1192 - mae: 0.3405 - val_loss: 0.1130 - val_mae: 0.3337\n",
            "Epoch 160/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1196 - mae: 0.3417 - val_loss: 0.1323 - val_mae: 0.3615\n",
            "Epoch 161/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1204 - mae: 0.3443 - val_loss: 0.1380 - val_mae: 0.3695\n",
            "Epoch 162/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1215 - mae: 0.3454 - val_loss: 0.1233 - val_mae: 0.3480\n",
            "Epoch 163/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1153 - mae: 0.3368 - val_loss: 0.1118 - val_mae: 0.3322\n",
            "Epoch 164/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1190 - mae: 0.3415 - val_loss: 0.1270 - val_mae: 0.3543\n",
            "Epoch 165/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1174 - mae: 0.3387 - val_loss: 0.1419 - val_mae: 0.3746\n",
            "Epoch 166/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1152 - mae: 0.3359 - val_loss: 0.0822 - val_mae: 0.2835\n",
            "Epoch 167/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1179 - mae: 0.3392 - val_loss: 0.1211 - val_mae: 0.3462\n",
            "Epoch 168/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1144 - mae: 0.3354 - val_loss: 0.1024 - val_mae: 0.3180\n",
            "Epoch 169/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1164 - mae: 0.3385 - val_loss: 0.1198 - val_mae: 0.3442\n",
            "Epoch 170/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1112 - mae: 0.3293 - val_loss: 0.0986 - val_mae: 0.3121\n",
            "Epoch 171/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1151 - mae: 0.3365 - val_loss: 0.1173 - val_mae: 0.3395\n",
            "Epoch 172/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1110 - mae: 0.3294 - val_loss: 0.1387 - val_mae: 0.3708\n",
            "Epoch 173/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1135 - mae: 0.3343 - val_loss: 0.1460 - val_mae: 0.3708\n",
            "Epoch 174/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1105 - mae: 0.3301 - val_loss: 0.1034 - val_mae: 0.3197\n",
            "Epoch 175/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1098 - mae: 0.3280 - val_loss: 0.1016 - val_mae: 0.3162\n",
            "Epoch 176/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1090 - mae: 0.3268 - val_loss: 0.1258 - val_mae: 0.3519\n",
            "Epoch 177/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1098 - mae: 0.3288 - val_loss: 0.1037 - val_mae: 0.3204\n",
            "Epoch 178/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1070 - mae: 0.3250 - val_loss: 0.1091 - val_mae: 0.3288\n",
            "Epoch 179/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1066 - mae: 0.3223 - val_loss: 0.1344 - val_mae: 0.3632\n",
            "Epoch 180/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1095 - mae: 0.3280 - val_loss: 0.0922 - val_mae: 0.3016\n",
            "Epoch 181/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1083 - mae: 0.3247 - val_loss: 0.1112 - val_mae: 0.3314\n",
            "Epoch 182/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1041 - mae: 0.3206 - val_loss: 0.1002 - val_mae: 0.3149\n",
            "Epoch 183/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1055 - mae: 0.3219 - val_loss: 0.0963 - val_mae: 0.3089\n",
            "Epoch 184/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1049 - mae: 0.3211 - val_loss: 0.0917 - val_mae: 0.3007\n",
            "Epoch 185/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1051 - mae: 0.3208 - val_loss: 0.1173 - val_mae: 0.3389\n",
            "Epoch 186/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1006 - mae: 0.3131 - val_loss: 0.0817 - val_mae: 0.2844\n",
            "Epoch 187/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1042 - mae: 0.3198 - val_loss: 0.1037 - val_mae: 0.3200\n",
            "Epoch 188/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1013 - mae: 0.3151 - val_loss: 0.1043 - val_mae: 0.3204\n",
            "Epoch 189/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1008 - mae: 0.3148 - val_loss: 0.1201 - val_mae: 0.3422\n",
            "Epoch 190/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1012 - mae: 0.3157 - val_loss: 0.0867 - val_mae: 0.2930\n",
            "Epoch 191/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.1003 - mae: 0.3139 - val_loss: 0.0959 - val_mae: 0.3065\n",
            "Epoch 192/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1003 - mae: 0.3127 - val_loss: 0.0758 - val_mae: 0.2738\n",
            "Epoch 193/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1015 - mae: 0.3157 - val_loss: 0.0887 - val_mae: 0.2945\n",
            "Epoch 194/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0968 - mae: 0.3085 - val_loss: 0.0908 - val_mae: 0.3001\n",
            "Epoch 195/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0981 - mae: 0.3112 - val_loss: 0.0922 - val_mae: 0.3004\n",
            "Epoch 196/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0977 - mae: 0.3110 - val_loss: 0.0969 - val_mae: 0.3092\n",
            "Epoch 197/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0974 - mae: 0.3088 - val_loss: 0.1163 - val_mae: 0.3379\n",
            "Epoch 198/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0974 - mae: 0.3095 - val_loss: 0.0878 - val_mae: 0.2940\n",
            "Epoch 199/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0962 - mae: 0.3071 - val_loss: 0.1038 - val_mae: 0.3198\n",
            "Epoch 200/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0944 - mae: 0.3053 - val_loss: 0.1077 - val_mae: 0.3260\n",
            "Epoch 201/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0977 - mae: 0.3094 - val_loss: 0.0730 - val_mae: 0.2664\n",
            "Epoch 202/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0939 - mae: 0.3033 - val_loss: 0.1132 - val_mae: 0.3356\n",
            "Epoch 203/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0952 - mae: 0.3054 - val_loss: 0.0875 - val_mae: 0.2910\n",
            "Epoch 204/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0945 - mae: 0.3047 - val_loss: 0.0889 - val_mae: 0.2965\n",
            "Epoch 205/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0943 - mae: 0.3042 - val_loss: 0.0969 - val_mae: 0.3094\n",
            "Epoch 206/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0934 - mae: 0.3034 - val_loss: 0.0984 - val_mae: 0.3116\n",
            "Epoch 207/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0916 - mae: 0.3007 - val_loss: 0.0786 - val_mae: 0.2759\n",
            "Epoch 208/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0953 - mae: 0.3059 - val_loss: 0.0744 - val_mae: 0.2704\n",
            "Epoch 209/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0901 - mae: 0.2972 - val_loss: 0.1080 - val_mae: 0.3249\n",
            "Epoch 210/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0915 - mae: 0.2997 - val_loss: 0.0801 - val_mae: 0.2804\n",
            "Epoch 211/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0932 - mae: 0.3011 - val_loss: 0.1085 - val_mae: 0.3258\n",
            "Epoch 212/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0899 - mae: 0.2969 - val_loss: 0.0821 - val_mae: 0.2849\n",
            "Epoch 213/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0913 - mae: 0.2987 - val_loss: 0.0997 - val_mae: 0.3085\n",
            "Epoch 214/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0874 - mae: 0.2933 - val_loss: 0.0759 - val_mae: 0.2735\n",
            "Epoch 215/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0927 - mae: 0.2993 - val_loss: 0.1216 - val_mae: 0.3440\n",
            "Epoch 216/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0884 - mae: 0.2947 - val_loss: 0.0821 - val_mae: 0.2843\n",
            "Epoch 217/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0880 - mae: 0.2944 - val_loss: 0.1029 - val_mae: 0.3186\n",
            "Epoch 218/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0886 - mae: 0.2945 - val_loss: 0.0877 - val_mae: 0.2945\n",
            "Epoch 219/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0883 - mae: 0.2952 - val_loss: 0.0914 - val_mae: 0.3004\n",
            "Epoch 220/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0870 - mae: 0.2923 - val_loss: 0.0912 - val_mae: 0.3004\n",
            "Epoch 221/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0865 - mae: 0.2923 - val_loss: 0.0784 - val_mae: 0.2777\n",
            "Epoch 222/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0878 - mae: 0.2931 - val_loss: 0.1100 - val_mae: 0.3304\n",
            "Epoch 223/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0850 - mae: 0.2888 - val_loss: 0.0851 - val_mae: 0.2891\n",
            "Epoch 224/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0864 - mae: 0.2919 - val_loss: 0.0899 - val_mae: 0.2976\n",
            "Epoch 225/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0864 - mae: 0.2910 - val_loss: 0.0959 - val_mae: 0.3074\n",
            "Epoch 226/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0864 - mae: 0.2917 - val_loss: 0.0758 - val_mae: 0.2731\n",
            "Epoch 227/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0826 - mae: 0.2853 - val_loss: 0.0992 - val_mae: 0.3111\n",
            "Epoch 228/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0854 - mae: 0.2890 - val_loss: 0.0949 - val_mae: 0.3063\n",
            "Epoch 229/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0848 - mae: 0.2878 - val_loss: 0.1080 - val_mae: 0.3266\n",
            "Epoch 230/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0838 - mae: 0.2864 - val_loss: 0.0712 - val_mae: 0.2652\n",
            "Epoch 231/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0850 - mae: 0.2891 - val_loss: 0.0789 - val_mae: 0.2736\n",
            "Epoch 232/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0822 - mae: 0.2845 - val_loss: 0.0938 - val_mae: 0.3052\n",
            "Epoch 233/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0831 - mae: 0.2864 - val_loss: 0.0933 - val_mae: 0.3037\n",
            "Epoch 234/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0815 - mae: 0.2817 - val_loss: 0.0813 - val_mae: 0.2825\n",
            "Epoch 235/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0847 - mae: 0.2868 - val_loss: 0.0734 - val_mae: 0.2687\n",
            "Epoch 236/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0792 - mae: 0.2788 - val_loss: 0.0748 - val_mae: 0.2716\n",
            "Epoch 237/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0821 - mae: 0.2842 - val_loss: 0.0902 - val_mae: 0.2984\n",
            "Epoch 238/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0821 - mae: 0.2849 - val_loss: 0.0814 - val_mae: 0.2839\n",
            "Epoch 239/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0811 - mae: 0.2827 - val_loss: 0.0873 - val_mae: 0.2880\n",
            "Epoch 240/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0811 - mae: 0.2829 - val_loss: 0.0853 - val_mae: 0.2907\n",
            "Epoch 241/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0793 - mae: 0.2794 - val_loss: 0.0812 - val_mae: 0.2834\n",
            "Epoch 242/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0792 - mae: 0.2779 - val_loss: 0.0841 - val_mae: 0.2888\n",
            "Epoch 243/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0817 - mae: 0.2802 - val_loss: 0.0839 - val_mae: 0.2856\n",
            "Epoch 244/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0772 - mae: 0.2755 - val_loss: 0.0627 - val_mae: 0.2484\n",
            "Epoch 245/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0792 - mae: 0.2790 - val_loss: 0.0897 - val_mae: 0.2983\n",
            "Epoch 246/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0767 - mae: 0.2751 - val_loss: 0.0910 - val_mae: 0.3002\n",
            "Epoch 247/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0786 - mae: 0.2783 - val_loss: 0.0920 - val_mae: 0.2992\n",
            "Epoch 248/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0785 - mae: 0.2776 - val_loss: 0.0718 - val_mae: 0.2667\n",
            "Epoch 249/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0764 - mae: 0.2736 - val_loss: 0.0791 - val_mae: 0.2787\n",
            "Epoch 250/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0762 - mae: 0.2738 - val_loss: 0.0736 - val_mae: 0.2702\n",
            "Epoch 251/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0779 - mae: 0.2767 - val_loss: 0.0627 - val_mae: 0.2476\n",
            "Epoch 252/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0759 - mae: 0.2731 - val_loss: 0.0888 - val_mae: 0.2964\n",
            "Epoch 253/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0761 - mae: 0.2735 - val_loss: 0.0755 - val_mae: 0.2726\n",
            "Epoch 254/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0757 - mae: 0.2736 - val_loss: 0.0769 - val_mae: 0.2748\n",
            "Epoch 255/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0757 - mae: 0.2714 - val_loss: 0.0563 - val_mae: 0.2341\n",
            "Epoch 256/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0750 - mae: 0.2711 - val_loss: 0.0692 - val_mae: 0.2603\n",
            "Epoch 257/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0750 - mae: 0.2722 - val_loss: 0.0723 - val_mae: 0.2672\n",
            "Epoch 258/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0757 - mae: 0.2716 - val_loss: 0.0835 - val_mae: 0.2874\n",
            "Epoch 259/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0743 - mae: 0.2694 - val_loss: 0.0952 - val_mae: 0.3061\n",
            "Epoch 260/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0737 - mae: 0.2692 - val_loss: 0.0621 - val_mae: 0.2463\n",
            "Epoch 261/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0751 - mae: 0.2723 - val_loss: 0.0846 - val_mae: 0.2897\n",
            "Epoch 262/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0721 - mae: 0.2665 - val_loss: 0.0589 - val_mae: 0.2412\n",
            "Epoch 263/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0746 - mae: 0.2707 - val_loss: 0.0690 - val_mae: 0.2611\n",
            "Epoch 264/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0728 - mae: 0.2671 - val_loss: 0.0835 - val_mae: 0.2879\n",
            "Epoch 265/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0722 - mae: 0.2673 - val_loss: 0.0797 - val_mae: 0.2806\n",
            "Epoch 266/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0735 - mae: 0.2691 - val_loss: 0.0734 - val_mae: 0.2695\n",
            "Epoch 267/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0725 - mae: 0.2670 - val_loss: 0.0814 - val_mae: 0.2756\n",
            "Epoch 268/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0710 - mae: 0.2638 - val_loss: 0.0660 - val_mae: 0.2560\n",
            "Epoch 269/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0717 - mae: 0.2657 - val_loss: 0.0622 - val_mae: 0.2483\n",
            "Epoch 270/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0711 - mae: 0.2643 - val_loss: 0.0697 - val_mae: 0.2621\n",
            "Epoch 271/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0708 - mae: 0.2636 - val_loss: 0.0723 - val_mae: 0.2673\n",
            "Epoch 272/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0717 - mae: 0.2658 - val_loss: 0.0575 - val_mae: 0.2384\n",
            "Epoch 273/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0697 - mae: 0.2618 - val_loss: 0.0823 - val_mae: 0.2831\n",
            "Epoch 274/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0699 - mae: 0.2620 - val_loss: 0.0634 - val_mae: 0.2500\n",
            "Epoch 275/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0693 - mae: 0.2603 - val_loss: 0.0988 - val_mae: 0.3091\n",
            "Epoch 276/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0695 - mae: 0.2614 - val_loss: 0.0754 - val_mae: 0.2734\n",
            "Epoch 277/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0699 - mae: 0.2615 - val_loss: 0.0669 - val_mae: 0.2553\n",
            "Epoch 278/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0664 - mae: 0.2562 - val_loss: 0.0781 - val_mae: 0.2779\n",
            "Epoch 279/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0688 - mae: 0.2601 - val_loss: 0.0687 - val_mae: 0.2604\n",
            "Epoch 280/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0669 - mae: 0.2555 - val_loss: 0.0572 - val_mae: 0.2372\n",
            "Epoch 281/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0686 - mae: 0.2596 - val_loss: 0.0603 - val_mae: 0.2401\n",
            "Epoch 282/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0676 - mae: 0.2578 - val_loss: 0.0489 - val_mae: 0.2193\n",
            "Epoch 283/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0675 - mae: 0.2573 - val_loss: 0.0650 - val_mae: 0.2532\n",
            "Epoch 284/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0661 - mae: 0.2544 - val_loss: 0.0632 - val_mae: 0.2498\n",
            "Epoch 285/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0663 - mae: 0.2553 - val_loss: 0.0702 - val_mae: 0.2581\n",
            "Epoch 286/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0664 - mae: 0.2556 - val_loss: 0.0604 - val_mae: 0.2446\n",
            "Epoch 287/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0655 - mae: 0.2536 - val_loss: 0.0620 - val_mae: 0.2476\n",
            "Epoch 288/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0651 - mae: 0.2524 - val_loss: 0.0633 - val_mae: 0.2507\n",
            "Epoch 289/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0658 - mae: 0.2543 - val_loss: 0.0769 - val_mae: 0.2754\n",
            "Epoch 290/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0652 - mae: 0.2538 - val_loss: 0.0624 - val_mae: 0.2486\n",
            "Epoch 291/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0644 - mae: 0.2515 - val_loss: 0.0671 - val_mae: 0.2579\n",
            "Epoch 292/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0644 - mae: 0.2518 - val_loss: 0.0755 - val_mae: 0.2728\n",
            "Epoch 293/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0645 - mae: 0.2526 - val_loss: 0.0679 - val_mae: 0.2587\n",
            "Epoch 294/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0636 - mae: 0.2511 - val_loss: 0.0601 - val_mae: 0.2437\n",
            "Epoch 295/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0633 - mae: 0.2500 - val_loss: 0.0529 - val_mae: 0.2260\n",
            "Epoch 296/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0636 - mae: 0.2502 - val_loss: 0.0677 - val_mae: 0.2587\n",
            "Epoch 297/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0622 - mae: 0.2470 - val_loss: 0.0753 - val_mae: 0.2722\n",
            "Epoch 298/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0640 - mae: 0.2508 - val_loss: 0.0514 - val_mae: 0.2258\n",
            "Epoch 299/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0620 - mae: 0.2459 - val_loss: 0.0660 - val_mae: 0.2536\n",
            "Epoch 300/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0618 - mae: 0.2466 - val_loss: 0.0582 - val_mae: 0.2387\n",
            "Epoch 301/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0620 - mae: 0.2459 - val_loss: 0.0786 - val_mae: 0.2755\n",
            "Epoch 302/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0611 - mae: 0.2456 - val_loss: 0.0452 - val_mae: 0.2099\n",
            "Epoch 303/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0610 - mae: 0.2449 - val_loss: 0.0701 - val_mae: 0.2608\n",
            "Epoch 304/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0595 - mae: 0.2415 - val_loss: 0.0614 - val_mae: 0.2466\n",
            "Epoch 305/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0628 - mae: 0.2476 - val_loss: 0.0503 - val_mae: 0.2200\n",
            "Epoch 306/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0599 - mae: 0.2433 - val_loss: 0.0503 - val_mae: 0.2231\n",
            "Epoch 307/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0594 - mae: 0.2425 - val_loss: 0.0662 - val_mae: 0.2532\n",
            "Epoch 308/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0589 - mae: 0.2408 - val_loss: 0.0620 - val_mae: 0.2474\n",
            "Epoch 309/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0598 - mae: 0.2431 - val_loss: 0.0499 - val_mae: 0.2211\n",
            "Epoch 310/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0591 - mae: 0.2405 - val_loss: 0.0578 - val_mae: 0.2392\n",
            "Epoch 311/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0579 - mae: 0.2385 - val_loss: 0.0569 - val_mae: 0.2353\n",
            "Epoch 312/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0593 - mae: 0.2421 - val_loss: 0.0642 - val_mae: 0.2513\n",
            "Epoch 313/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0593 - mae: 0.2404 - val_loss: 0.0733 - val_mae: 0.2685\n",
            "Epoch 314/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0573 - mae: 0.2374 - val_loss: 0.0562 - val_mae: 0.2360\n",
            "Epoch 315/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0574 - mae: 0.2370 - val_loss: 0.0591 - val_mae: 0.2416\n",
            "Epoch 316/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0573 - mae: 0.2368 - val_loss: 0.0697 - val_mae: 0.2631\n",
            "Epoch 317/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0569 - mae: 0.2365 - val_loss: 0.0607 - val_mae: 0.2372\n",
            "Epoch 318/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0572 - mae: 0.2353 - val_loss: 0.0546 - val_mae: 0.2324\n",
            "Epoch 319/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0567 - mae: 0.2362 - val_loss: 0.0595 - val_mae: 0.2386\n",
            "Epoch 320/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0552 - mae: 0.2332 - val_loss: 0.0481 - val_mae: 0.2183\n",
            "Epoch 321/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0557 - mae: 0.2342 - val_loss: 0.0466 - val_mae: 0.2124\n",
            "Epoch 322/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0550 - mae: 0.2330 - val_loss: 0.0559 - val_mae: 0.2353\n",
            "Epoch 323/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0557 - mae: 0.2328 - val_loss: 0.0742 - val_mae: 0.2702\n",
            "Epoch 324/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0552 - mae: 0.2329 - val_loss: 0.0527 - val_mae: 0.2283\n",
            "Epoch 325/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0549 - mae: 0.2326 - val_loss: 0.0551 - val_mae: 0.2329\n",
            "Epoch 326/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0534 - mae: 0.2291 - val_loss: 0.0500 - val_mae: 0.2187\n",
            "Epoch 327/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0521 - mae: 0.2271 - val_loss: 0.0508 - val_mae: 0.2241\n",
            "Epoch 328/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0542 - mae: 0.2311 - val_loss: 0.0553 - val_mae: 0.2346\n",
            "Epoch 329/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0526 - mae: 0.2270 - val_loss: 0.0602 - val_mae: 0.2440\n",
            "Epoch 330/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0532 - mae: 0.2289 - val_loss: 0.0446 - val_mae: 0.2103\n",
            "Epoch 331/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0525 - mae: 0.2266 - val_loss: 0.0436 - val_mae: 0.2051\n",
            "Epoch 332/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0520 - mae: 0.2258 - val_loss: 0.0605 - val_mae: 0.2451\n",
            "Epoch 333/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0510 - mae: 0.2236 - val_loss: 0.0588 - val_mae: 0.2398\n",
            "Epoch 334/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0524 - mae: 0.2267 - val_loss: 0.0569 - val_mae: 0.2378\n",
            "Epoch 335/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0510 - mae: 0.2241 - val_loss: 0.0428 - val_mae: 0.2016\n",
            "Epoch 336/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0501 - mae: 0.2218 - val_loss: 0.0516 - val_mae: 0.2262\n",
            "Epoch 337/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0519 - mae: 0.2221 - val_loss: 0.0375 - val_mae: 0.1909\n",
            "Epoch 338/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0505 - mae: 0.2219 - val_loss: 0.0398 - val_mae: 0.1985\n",
            "Epoch 339/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0499 - mae: 0.2209 - val_loss: 0.0598 - val_mae: 0.2414\n",
            "Epoch 340/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0491 - mae: 0.2184 - val_loss: 0.0508 - val_mae: 0.2242\n",
            "Epoch 341/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0513 - mae: 0.2241 - val_loss: 0.0671 - val_mae: 0.2534\n",
            "Epoch 342/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0491 - mae: 0.2181 - val_loss: 0.0380 - val_mae: 0.1940\n",
            "Epoch 343/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0484 - mae: 0.2176 - val_loss: 0.0619 - val_mae: 0.2452\n",
            "Epoch 344/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0496 - mae: 0.2207 - val_loss: 0.0442 - val_mae: 0.2092\n",
            "Epoch 345/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0479 - mae: 0.2170 - val_loss: 0.0598 - val_mae: 0.2428\n",
            "Epoch 346/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0481 - mae: 0.2172 - val_loss: 0.0372 - val_mae: 0.1909\n",
            "Epoch 347/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0480 - mae: 0.2176 - val_loss: 0.0526 - val_mae: 0.2278\n",
            "Epoch 348/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0483 - mae: 0.2157 - val_loss: 0.0556 - val_mae: 0.2350\n",
            "Epoch 349/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0482 - mae: 0.2175 - val_loss: 0.0539 - val_mae: 0.2259\n",
            "Epoch 350/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0477 - mae: 0.2161 - val_loss: 0.0405 - val_mae: 0.2003\n",
            "Epoch 351/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0464 - mae: 0.2130 - val_loss: 0.0560 - val_mae: 0.2349\n",
            "Epoch 352/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0471 - mae: 0.2157 - val_loss: 0.0441 - val_mae: 0.2090\n",
            "Epoch 353/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0471 - mae: 0.2150 - val_loss: 0.0380 - val_mae: 0.1912\n",
            "Epoch 354/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0453 - mae: 0.2110 - val_loss: 0.0376 - val_mae: 0.1893\n",
            "Epoch 355/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0454 - mae: 0.2112 - val_loss: 0.0530 - val_mae: 0.2270\n",
            "Epoch 356/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0466 - mae: 0.2131 - val_loss: 0.0359 - val_mae: 0.1881\n",
            "Epoch 357/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0451 - mae: 0.2102 - val_loss: 0.0536 - val_mae: 0.2300\n",
            "Epoch 358/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0456 - mae: 0.2121 - val_loss: 0.0439 - val_mae: 0.2083\n",
            "Epoch 359/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0438 - mae: 0.2066 - val_loss: 0.0563 - val_mae: 0.2329\n",
            "Epoch 360/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0463 - mae: 0.2124 - val_loss: 0.0643 - val_mae: 0.2515\n",
            "Epoch 361/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0443 - mae: 0.2080 - val_loss: 0.0523 - val_mae: 0.2256\n",
            "Epoch 362/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0442 - mae: 0.2087 - val_loss: 0.0520 - val_mae: 0.2268\n",
            "Epoch 363/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0439 - mae: 0.2071 - val_loss: 0.0571 - val_mae: 0.2287\n",
            "Epoch 364/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0435 - mae: 0.2064 - val_loss: 0.0542 - val_mae: 0.2321\n",
            "Epoch 365/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0441 - mae: 0.2083 - val_loss: 0.0524 - val_mae: 0.2265\n",
            "Epoch 366/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0422 - mae: 0.2032 - val_loss: 0.0465 - val_mae: 0.2142\n",
            "Epoch 367/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0430 - mae: 0.2052 - val_loss: 0.0479 - val_mae: 0.2169\n",
            "Epoch 368/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0425 - mae: 0.2049 - val_loss: 0.0412 - val_mae: 0.2018\n",
            "Epoch 369/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0434 - mae: 0.2052 - val_loss: 0.0524 - val_mae: 0.2234\n",
            "Epoch 370/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0423 - mae: 0.2033 - val_loss: 0.0404 - val_mae: 0.1955\n",
            "Epoch 371/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0423 - mae: 0.2043 - val_loss: 0.0446 - val_mae: 0.2097\n",
            "Epoch 372/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0414 - mae: 0.2009 - val_loss: 0.0323 - val_mae: 0.1778\n",
            "Epoch 373/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0419 - mae: 0.2032 - val_loss: 0.0467 - val_mae: 0.2138\n",
            "Epoch 374/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0413 - mae: 0.2010 - val_loss: 0.0391 - val_mae: 0.1968\n",
            "Epoch 375/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0408 - mae: 0.2009 - val_loss: 0.0434 - val_mae: 0.2068\n",
            "Epoch 376/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0401 - mae: 0.1984 - val_loss: 0.0446 - val_mae: 0.2102\n",
            "Epoch 377/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0411 - mae: 0.2006 - val_loss: 0.0503 - val_mae: 0.2218\n",
            "Epoch 378/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0412 - mae: 0.2016 - val_loss: 0.0478 - val_mae: 0.2163\n",
            "Epoch 379/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0403 - mae: 0.1989 - val_loss: 0.0363 - val_mae: 0.1865\n",
            "Epoch 380/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0403 - mae: 0.1979 - val_loss: 0.0581 - val_mae: 0.2398\n",
            "Epoch 381/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0409 - mae: 0.1997 - val_loss: 0.0450 - val_mae: 0.2067\n",
            "Epoch 382/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0391 - mae: 0.1957 - val_loss: 0.0456 - val_mae: 0.2121\n",
            "Epoch 383/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0400 - mae: 0.1974 - val_loss: 0.0372 - val_mae: 0.1906\n",
            "Epoch 384/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0399 - mae: 0.1981 - val_loss: 0.0339 - val_mae: 0.1813\n",
            "Epoch 385/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0389 - mae: 0.1950 - val_loss: 0.0419 - val_mae: 0.2032\n",
            "Epoch 386/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0399 - mae: 0.1968 - val_loss: 0.0310 - val_mae: 0.1747\n",
            "Epoch 387/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0396 - mae: 0.1966 - val_loss: 0.0553 - val_mae: 0.2282\n",
            "Epoch 388/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0382 - mae: 0.1930 - val_loss: 0.0316 - val_mae: 0.1764\n",
            "Epoch 389/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0386 - mae: 0.1945 - val_loss: 0.0388 - val_mae: 0.1948\n",
            "Epoch 390/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0383 - mae: 0.1940 - val_loss: 0.0373 - val_mae: 0.1897\n",
            "Epoch 391/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0382 - mae: 0.1940 - val_loss: 0.0364 - val_mae: 0.1807\n",
            "Epoch 392/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0380 - mae: 0.1918 - val_loss: 0.0244 - val_mae: 0.1543\n",
            "Epoch 393/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0377 - mae: 0.1918 - val_loss: 0.0462 - val_mae: 0.2098\n",
            "Epoch 394/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0379 - mae: 0.1935 - val_loss: 0.0307 - val_mae: 0.1715\n",
            "Epoch 395/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0376 - mae: 0.1914 - val_loss: 0.0404 - val_mae: 0.1979\n",
            "Epoch 396/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0357 - mae: 0.1872 - val_loss: 0.0409 - val_mae: 0.2012\n",
            "Epoch 397/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0384 - mae: 0.1934 - val_loss: 0.0373 - val_mae: 0.1909\n",
            "Epoch 398/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0364 - mae: 0.1893 - val_loss: 0.0316 - val_mae: 0.1763\n",
            "Epoch 399/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0363 - mae: 0.1884 - val_loss: 0.0434 - val_mae: 0.2046\n",
            "Epoch 400/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0360 - mae: 0.1881 - val_loss: 0.0370 - val_mae: 0.1904\n",
            "Epoch 401/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0364 - mae: 0.1893 - val_loss: 0.0356 - val_mae: 0.1852\n",
            "Epoch 402/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0354 - mae: 0.1869 - val_loss: 0.0364 - val_mae: 0.1889\n",
            "Epoch 403/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0363 - mae: 0.1869 - val_loss: 0.0498 - val_mae: 0.2161\n",
            "Epoch 404/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0355 - mae: 0.1866 - val_loss: 0.0314 - val_mae: 0.1715\n",
            "Epoch 405/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0359 - mae: 0.1878 - val_loss: 0.0464 - val_mae: 0.2106\n",
            "Epoch 406/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0350 - mae: 0.1844 - val_loss: 0.0339 - val_mae: 0.1795\n",
            "Epoch 407/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0353 - mae: 0.1849 - val_loss: 0.0422 - val_mae: 0.2033\n",
            "Epoch 408/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0353 - mae: 0.1861 - val_loss: 0.0444 - val_mae: 0.2092\n",
            "Epoch 409/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0346 - mae: 0.1836 - val_loss: 0.0315 - val_mae: 0.1748\n",
            "Epoch 410/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0349 - mae: 0.1853 - val_loss: 0.0348 - val_mae: 0.1857\n",
            "Epoch 411/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0348 - mae: 0.1848 - val_loss: 0.0288 - val_mae: 0.1674\n",
            "Epoch 412/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0342 - mae: 0.1827 - val_loss: 0.0425 - val_mae: 0.2029\n",
            "Epoch 413/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0342 - mae: 0.1833 - val_loss: 0.0314 - val_mae: 0.1742\n",
            "Epoch 414/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0341 - mae: 0.1828 - val_loss: 0.0290 - val_mae: 0.1665\n",
            "Epoch 415/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0335 - mae: 0.1819 - val_loss: 0.0290 - val_mae: 0.1679\n",
            "Epoch 416/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0328 - mae: 0.1791 - val_loss: 0.0386 - val_mae: 0.1942\n",
            "Epoch 417/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0341 - mae: 0.1821 - val_loss: 0.0335 - val_mae: 0.1793\n",
            "Epoch 418/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0339 - mae: 0.1823 - val_loss: 0.0274 - val_mae: 0.1642\n",
            "Epoch 419/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0331 - mae: 0.1801 - val_loss: 0.0308 - val_mae: 0.1675\n",
            "Epoch 420/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0325 - mae: 0.1786 - val_loss: 0.0267 - val_mae: 0.1610\n",
            "Epoch 421/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0337 - mae: 0.1811 - val_loss: 0.0300 - val_mae: 0.1661\n",
            "Epoch 422/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0321 - mae: 0.1774 - val_loss: 0.0402 - val_mae: 0.1982\n",
            "Epoch 423/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0318 - mae: 0.1746 - val_loss: 0.0313 - val_mae: 0.1731\n",
            "Epoch 424/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0336 - mae: 0.1802 - val_loss: 0.0238 - val_mae: 0.1522\n",
            "Epoch 425/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0313 - mae: 0.1745 - val_loss: 0.0369 - val_mae: 0.1902\n",
            "Epoch 426/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0320 - mae: 0.1776 - val_loss: 0.0318 - val_mae: 0.1768\n",
            "Epoch 427/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0323 - mae: 0.1777 - val_loss: 0.0314 - val_mae: 0.1754\n",
            "Epoch 428/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0317 - mae: 0.1772 - val_loss: 0.0310 - val_mae: 0.1752\n",
            "Epoch 429/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0314 - mae: 0.1750 - val_loss: 0.0377 - val_mae: 0.1877\n",
            "Epoch 430/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0316 - mae: 0.1767 - val_loss: 0.0285 - val_mae: 0.1674\n",
            "Epoch 431/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0307 - mae: 0.1741 - val_loss: 0.0303 - val_mae: 0.1725\n",
            "Epoch 432/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0310 - mae: 0.1747 - val_loss: 0.0345 - val_mae: 0.1835\n",
            "Epoch 433/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0312 - mae: 0.1744 - val_loss: 0.0360 - val_mae: 0.1870\n",
            "Epoch 434/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0304 - mae: 0.1723 - val_loss: 0.0323 - val_mae: 0.1780\n",
            "Epoch 435/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0306 - mae: 0.1739 - val_loss: 0.0297 - val_mae: 0.1695\n",
            "Epoch 436/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0302 - mae: 0.1713 - val_loss: 0.0256 - val_mae: 0.1584\n",
            "Epoch 437/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0309 - mae: 0.1725 - val_loss: 0.0411 - val_mae: 0.1914\n",
            "Epoch 438/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0295 - mae: 0.1690 - val_loss: 0.0399 - val_mae: 0.1981\n",
            "Epoch 439/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0304 - mae: 0.1716 - val_loss: 0.0273 - val_mae: 0.1548\n",
            "Epoch 440/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0298 - mae: 0.1708 - val_loss: 0.0248 - val_mae: 0.1546\n",
            "Epoch 441/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0292 - mae: 0.1662 - val_loss: 0.0359 - val_mae: 0.1866\n",
            "Epoch 442/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0296 - mae: 0.1707 - val_loss: 0.0273 - val_mae: 0.1609\n",
            "Epoch 443/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0291 - mae: 0.1685 - val_loss: 0.0284 - val_mae: 0.1598\n",
            "Epoch 444/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0294 - mae: 0.1693 - val_loss: 0.0282 - val_mae: 0.1661\n",
            "Epoch 445/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0294 - mae: 0.1698 - val_loss: 0.0273 - val_mae: 0.1594\n",
            "Epoch 446/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0284 - mae: 0.1659 - val_loss: 0.0257 - val_mae: 0.1558\n",
            "Epoch 447/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0282 - mae: 0.1658 - val_loss: 0.0272 - val_mae: 0.1613\n",
            "Epoch 448/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0283 - mae: 0.1667 - val_loss: 0.0247 - val_mae: 0.1563\n",
            "Epoch 449/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0275 - mae: 0.1643 - val_loss: 0.0310 - val_mae: 0.1725\n",
            "Epoch 450/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0282 - mae: 0.1658 - val_loss: 0.0228 - val_mae: 0.1495\n",
            "Epoch 451/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0277 - mae: 0.1632 - val_loss: 0.0368 - val_mae: 0.1895\n",
            "Epoch 452/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0280 - mae: 0.1661 - val_loss: 0.0241 - val_mae: 0.1525\n",
            "Epoch 453/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0269 - mae: 0.1627 - val_loss: 0.0287 - val_mae: 0.1669\n",
            "Epoch 454/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0281 - mae: 0.1653 - val_loss: 0.0291 - val_mae: 0.1673\n",
            "Epoch 455/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0267 - mae: 0.1622 - val_loss: 0.0282 - val_mae: 0.1602\n",
            "Epoch 456/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0272 - mae: 0.1634 - val_loss: 0.0265 - val_mae: 0.1618\n",
            "Epoch 457/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0274 - mae: 0.1639 - val_loss: 0.0233 - val_mae: 0.1499\n",
            "Epoch 458/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0268 - mae: 0.1617 - val_loss: 0.0192 - val_mae: 0.1373\n",
            "Epoch 459/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0276 - mae: 0.1623 - val_loss: 0.0253 - val_mae: 0.1574\n",
            "Epoch 460/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0262 - mae: 0.1606 - val_loss: 0.0262 - val_mae: 0.1599\n",
            "Epoch 461/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0267 - mae: 0.1622 - val_loss: 0.0249 - val_mae: 0.1564\n",
            "Epoch 462/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0258 - mae: 0.1596 - val_loss: 0.0338 - val_mae: 0.1820\n",
            "Epoch 463/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0271 - mae: 0.1630 - val_loss: 0.0222 - val_mae: 0.1460\n",
            "Epoch 464/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0268 - mae: 0.1615 - val_loss: 0.0308 - val_mae: 0.1722\n",
            "Epoch 465/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0257 - mae: 0.1585 - val_loss: 0.0330 - val_mae: 0.1799\n",
            "Epoch 466/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0262 - mae: 0.1607 - val_loss: 0.0232 - val_mae: 0.1505\n",
            "Epoch 467/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0266 - mae: 0.1609 - val_loss: 0.0362 - val_mae: 0.1818\n",
            "Epoch 468/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0257 - mae: 0.1585 - val_loss: 0.0265 - val_mae: 0.1610\n",
            "Epoch 469/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0256 - mae: 0.1591 - val_loss: 0.0293 - val_mae: 0.1690\n",
            "Epoch 470/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0257 - mae: 0.1584 - val_loss: 0.0238 - val_mae: 0.1526\n",
            "Epoch 471/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0258 - mae: 0.1589 - val_loss: 0.0239 - val_mae: 0.1507\n",
            "Epoch 472/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0258 - mae: 0.1572 - val_loss: 0.0193 - val_mae: 0.1366\n",
            "Epoch 473/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0252 - mae: 0.1567 - val_loss: 0.0279 - val_mae: 0.1645\n",
            "Epoch 474/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0256 - mae: 0.1573 - val_loss: 0.0236 - val_mae: 0.1499\n",
            "Epoch 475/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0253 - mae: 0.1575 - val_loss: 0.0283 - val_mae: 0.1617\n",
            "Epoch 476/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0251 - mae: 0.1572 - val_loss: 0.0270 - val_mae: 0.1590\n",
            "Epoch 477/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0252 - mae: 0.1567 - val_loss: 0.0255 - val_mae: 0.1521\n",
            "Epoch 478/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0252 - mae: 0.1567 - val_loss: 0.0337 - val_mae: 0.1822\n",
            "Epoch 479/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0241 - mae: 0.1537 - val_loss: 0.0235 - val_mae: 0.1490\n",
            "Epoch 480/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0248 - mae: 0.1551 - val_loss: 0.0361 - val_mae: 0.1882\n",
            "Epoch 481/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0249 - mae: 0.1558 - val_loss: 0.0233 - val_mae: 0.1501\n",
            "Epoch 482/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0245 - mae: 0.1549 - val_loss: 0.0290 - val_mae: 0.1688\n",
            "Epoch 483/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0245 - mae: 0.1554 - val_loss: 0.0300 - val_mae: 0.1700\n",
            "Epoch 484/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0246 - mae: 0.1550 - val_loss: 0.0261 - val_mae: 0.1589\n",
            "Epoch 485/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0242 - mae: 0.1548 - val_loss: 0.0302 - val_mae: 0.1650\n",
            "Epoch 486/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0238 - mae: 0.1526 - val_loss: 0.0277 - val_mae: 0.1633\n",
            "Epoch 487/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0255 - mae: 0.1566 - val_loss: 0.0261 - val_mae: 0.1580\n",
            "Epoch 488/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0244 - mae: 0.1542 - val_loss: 0.0216 - val_mae: 0.1450\n",
            "Epoch 489/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0235 - mae: 0.1512 - val_loss: 0.0279 - val_mae: 0.1641\n",
            "Epoch 490/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0249 - mae: 0.1558 - val_loss: 0.0206 - val_mae: 0.1425\n",
            "Epoch 491/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0243 - mae: 0.1542 - val_loss: 0.0206 - val_mae: 0.1373\n",
            "Epoch 492/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0232 - mae: 0.1510 - val_loss: 0.0223 - val_mae: 0.1460\n",
            "Epoch 493/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0243 - mae: 0.1542 - val_loss: 0.0270 - val_mae: 0.1579\n",
            "Epoch 494/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0243 - mae: 0.1537 - val_loss: 0.0216 - val_mae: 0.1462\n",
            "Epoch 495/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0241 - mae: 0.1532 - val_loss: 0.0245 - val_mae: 0.1551\n",
            "Epoch 496/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0241 - mae: 0.1532 - val_loss: 0.0198 - val_mae: 0.1398\n",
            "Epoch 497/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0229 - mae: 0.1495 - val_loss: 0.0249 - val_mae: 0.1557\n",
            "Epoch 498/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0243 - mae: 0.1529 - val_loss: 0.0279 - val_mae: 0.1661\n",
            "Epoch 499/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0238 - mae: 0.1530 - val_loss: 0.0241 - val_mae: 0.1534\n",
            "Epoch 500/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0233 - mae: 0.1506 - val_loss: 0.0156 - val_mae: 0.1211\n",
            "Epoch 501/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0236 - mae: 0.1513 - val_loss: 0.0334 - val_mae: 0.1779\n",
            "Epoch 502/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0233 - mae: 0.1506 - val_loss: 0.0289 - val_mae: 0.1641\n",
            "Epoch 503/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0235 - mae: 0.1512 - val_loss: 0.0237 - val_mae: 0.1519\n",
            "Epoch 504/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0231 - mae: 0.1508 - val_loss: 0.0265 - val_mae: 0.1619\n",
            "Epoch 505/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0228 - mae: 0.1497 - val_loss: 0.0240 - val_mae: 0.1505\n",
            "Epoch 506/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0234 - mae: 0.1507 - val_loss: 0.0228 - val_mae: 0.1490\n",
            "Epoch 507/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0234 - mae: 0.1518 - val_loss: 0.0280 - val_mae: 0.1562\n",
            "Epoch 508/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0235 - mae: 0.1513 - val_loss: 0.0283 - val_mae: 0.1656\n",
            "Epoch 509/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0231 - mae: 0.1497 - val_loss: 0.0161 - val_mae: 0.1250\n",
            "Epoch 510/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0231 - mae: 0.1496 - val_loss: 0.0277 - val_mae: 0.1651\n",
            "Epoch 511/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0229 - mae: 0.1498 - val_loss: 0.0259 - val_mae: 0.1564\n",
            "Epoch 512/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0220 - mae: 0.1471 - val_loss: 0.0244 - val_mae: 0.1540\n",
            "Epoch 513/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0238 - mae: 0.1513 - val_loss: 0.0247 - val_mae: 0.1538\n",
            "Epoch 514/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0219 - mae: 0.1442 - val_loss: 0.0243 - val_mae: 0.1538\n",
            "Epoch 515/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0238 - mae: 0.1510 - val_loss: 0.0171 - val_mae: 0.1280\n",
            "Epoch 516/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0224 - mae: 0.1474 - val_loss: 0.0298 - val_mae: 0.1707\n",
            "Epoch 517/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0222 - mae: 0.1476 - val_loss: 0.0254 - val_mae: 0.1511\n",
            "Epoch 518/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0230 - mae: 0.1487 - val_loss: 0.0206 - val_mae: 0.1422\n",
            "Epoch 519/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0227 - mae: 0.1493 - val_loss: 0.0273 - val_mae: 0.1599\n",
            "Epoch 520/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0221 - mae: 0.1463 - val_loss: 0.0176 - val_mae: 0.1259\n",
            "Epoch 521/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0229 - mae: 0.1492 - val_loss: 0.0298 - val_mae: 0.1589\n",
            "Epoch 522/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0219 - mae: 0.1469 - val_loss: 0.0221 - val_mae: 0.1480\n",
            "Epoch 523/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0223 - mae: 0.1468 - val_loss: 0.0137 - val_mae: 0.1153\n",
            "Epoch 524/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0219 - mae: 0.1462 - val_loss: 0.0286 - val_mae: 0.1671\n",
            "Epoch 525/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0225 - mae: 0.1481 - val_loss: 0.0181 - val_mae: 0.1322\n",
            "Epoch 526/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0220 - mae: 0.1464 - val_loss: 0.0206 - val_mae: 0.1427\n",
            "Epoch 527/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0224 - mae: 0.1452 - val_loss: 0.0210 - val_mae: 0.1438\n",
            "Epoch 528/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0228 - mae: 0.1481 - val_loss: 0.0279 - val_mae: 0.1639\n",
            "Epoch 529/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0217 - mae: 0.1457 - val_loss: 0.0247 - val_mae: 0.1530\n",
            "Epoch 530/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0222 - mae: 0.1478 - val_loss: 0.0258 - val_mae: 0.1597\n",
            "Epoch 531/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0214 - mae: 0.1447 - val_loss: 0.0255 - val_mae: 0.1588\n",
            "Epoch 532/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0221 - mae: 0.1462 - val_loss: 0.0187 - val_mae: 0.1358\n",
            "Epoch 533/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0217 - mae: 0.1446 - val_loss: 0.0264 - val_mae: 0.1601\n",
            "Epoch 534/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0215 - mae: 0.1450 - val_loss: 0.0291 - val_mae: 0.1691\n",
            "Epoch 535/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0223 - mae: 0.1474 - val_loss: 0.0206 - val_mae: 0.1405\n",
            "Epoch 536/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0215 - mae: 0.1437 - val_loss: 0.0265 - val_mae: 0.1605\n",
            "Epoch 537/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0213 - mae: 0.1443 - val_loss: 0.0236 - val_mae: 0.1480\n",
            "Epoch 538/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0223 - mae: 0.1471 - val_loss: 0.0196 - val_mae: 0.1391\n",
            "Epoch 539/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0211 - mae: 0.1438 - val_loss: 0.0235 - val_mae: 0.1430\n",
            "Epoch 540/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0220 - mae: 0.1458 - val_loss: 0.0195 - val_mae: 0.1390\n",
            "Epoch 541/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0213 - mae: 0.1444 - val_loss: 0.0207 - val_mae: 0.1418\n",
            "Epoch 542/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0209 - mae: 0.1434 - val_loss: 0.0186 - val_mae: 0.1357\n",
            "Epoch 543/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0209 - mae: 0.1427 - val_loss: 0.0258 - val_mae: 0.1561\n",
            "Epoch 544/2000\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0218 - mae: 0.1447 - val_loss: 0.0234 - val_mae: 0.1518\n",
            "Epoch 545/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0215 - mae: 0.1456 - val_loss: 0.0185 - val_mae: 0.1322\n",
            "Epoch 546/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0213 - mae: 0.1446 - val_loss: 0.0183 - val_mae: 0.1316\n",
            "Epoch 547/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0203 - mae: 0.1413 - val_loss: 0.0224 - val_mae: 0.1475\n",
            "Epoch 548/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0213 - mae: 0.1444 - val_loss: 0.0203 - val_mae: 0.1390\n",
            "Epoch 549/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0211 - mae: 0.1432 - val_loss: 0.0159 - val_mae: 0.1240\n",
            "Epoch 550/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0209 - mae: 0.1436 - val_loss: 0.0200 - val_mae: 0.1406\n",
            "Epoch 551/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0204 - mae: 0.1417 - val_loss: 0.0296 - val_mae: 0.1629\n",
            "Epoch 552/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0209 - mae: 0.1426 - val_loss: 0.0268 - val_mae: 0.1571\n",
            "Epoch 553/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0206 - mae: 0.1420 - val_loss: 0.0209 - val_mae: 0.1401\n",
            "Epoch 554/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0202 - mae: 0.1395 - val_loss: 0.0221 - val_mae: 0.1476\n",
            "Epoch 555/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0205 - mae: 0.1421 - val_loss: 0.0170 - val_mae: 0.1291\n",
            "Epoch 556/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0209 - mae: 0.1432 - val_loss: 0.0249 - val_mae: 0.1571\n",
            "Epoch 557/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0203 - mae: 0.1399 - val_loss: 0.0251 - val_mae: 0.1564\n",
            "Epoch 558/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0211 - mae: 0.1436 - val_loss: 0.0165 - val_mae: 0.1275\n",
            "Epoch 559/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0202 - mae: 0.1399 - val_loss: 0.0196 - val_mae: 0.1347\n",
            "Epoch 560/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0208 - mae: 0.1417 - val_loss: 0.0261 - val_mae: 0.1605\n",
            "Epoch 561/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0201 - mae: 0.1401 - val_loss: 0.0187 - val_mae: 0.1350\n",
            "Epoch 562/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0212 - mae: 0.1433 - val_loss: 0.0186 - val_mae: 0.1355\n",
            "Epoch 563/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0195 - mae: 0.1382 - val_loss: 0.0168 - val_mae: 0.1277\n",
            "Epoch 564/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0205 - mae: 0.1408 - val_loss: 0.0151 - val_mae: 0.1177\n",
            "Epoch 565/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0204 - mae: 0.1410 - val_loss: 0.0204 - val_mae: 0.1403\n",
            "Epoch 566/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0201 - mae: 0.1398 - val_loss: 0.0219 - val_mae: 0.1474\n",
            "Epoch 567/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0199 - mae: 0.1393 - val_loss: 0.0217 - val_mae: 0.1457\n",
            "Epoch 568/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0199 - mae: 0.1395 - val_loss: 0.0220 - val_mae: 0.1434\n",
            "Epoch 569/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0202 - mae: 0.1405 - val_loss: 0.0224 - val_mae: 0.1413\n",
            "Epoch 570/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0196 - mae: 0.1380 - val_loss: 0.0195 - val_mae: 0.1387\n",
            "Epoch 571/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0200 - mae: 0.1405 - val_loss: 0.0208 - val_mae: 0.1417\n",
            "Epoch 572/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0201 - mae: 0.1390 - val_loss: 0.0132 - val_mae: 0.1120\n",
            "Epoch 573/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0197 - mae: 0.1388 - val_loss: 0.0238 - val_mae: 0.1519\n",
            "Epoch 574/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0203 - mae: 0.1395 - val_loss: 0.0148 - val_mae: 0.1203\n",
            "Epoch 575/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0201 - mae: 0.1386 - val_loss: 0.0319 - val_mae: 0.1759\n",
            "Epoch 576/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0196 - mae: 0.1364 - val_loss: 0.0144 - val_mae: 0.1180\n",
            "Epoch 577/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0197 - mae: 0.1390 - val_loss: 0.0269 - val_mae: 0.1583\n",
            "Epoch 578/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0201 - mae: 0.1394 - val_loss: 0.0164 - val_mae: 0.1269\n",
            "Epoch 579/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0192 - mae: 0.1367 - val_loss: 0.0226 - val_mae: 0.1458\n",
            "Epoch 580/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0192 - mae: 0.1350 - val_loss: 0.0158 - val_mae: 0.1239\n",
            "Epoch 581/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0203 - mae: 0.1406 - val_loss: 0.0192 - val_mae: 0.1363\n",
            "Epoch 582/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0198 - mae: 0.1393 - val_loss: 0.0178 - val_mae: 0.1313\n",
            "Epoch 583/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0192 - mae: 0.1376 - val_loss: 0.0171 - val_mae: 0.1291\n",
            "Epoch 584/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0190 - mae: 0.1359 - val_loss: 0.0183 - val_mae: 0.1311\n",
            "Epoch 585/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0200 - mae: 0.1388 - val_loss: 0.0213 - val_mae: 0.1405\n",
            "Epoch 586/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0197 - mae: 0.1382 - val_loss: 0.0221 - val_mae: 0.1471\n",
            "Epoch 587/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0189 - mae: 0.1360 - val_loss: 0.0215 - val_mae: 0.1445\n",
            "Epoch 588/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0197 - mae: 0.1371 - val_loss: 0.0091 - val_mae: 0.0918\n",
            "Epoch 589/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0192 - mae: 0.1364 - val_loss: 0.0238 - val_mae: 0.1525\n",
            "Epoch 590/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0193 - mae: 0.1376 - val_loss: 0.0179 - val_mae: 0.1329\n",
            "Epoch 591/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0196 - mae: 0.1377 - val_loss: 0.0168 - val_mae: 0.1280\n",
            "Epoch 592/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0189 - mae: 0.1365 - val_loss: 0.0189 - val_mae: 0.1364\n",
            "Epoch 593/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0196 - mae: 0.1373 - val_loss: 0.0158 - val_mae: 0.1236\n",
            "Epoch 594/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0187 - mae: 0.1344 - val_loss: 0.0171 - val_mae: 0.1280\n",
            "Epoch 595/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0195 - mae: 0.1381 - val_loss: 0.0214 - val_mae: 0.1422\n",
            "Epoch 596/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0193 - mae: 0.1369 - val_loss: 0.0213 - val_mae: 0.1376\n",
            "Epoch 597/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0191 - mae: 0.1358 - val_loss: 0.0202 - val_mae: 0.1408\n",
            "Epoch 598/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0180 - mae: 0.1320 - val_loss: 0.0226 - val_mae: 0.1489\n",
            "Epoch 599/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0196 - mae: 0.1385 - val_loss: 0.0170 - val_mae: 0.1238\n",
            "Epoch 600/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0186 - mae: 0.1343 - val_loss: 0.0176 - val_mae: 0.1297\n",
            "Epoch 601/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0189 - mae: 0.1362 - val_loss: 0.0176 - val_mae: 0.1314\n",
            "Epoch 602/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0191 - mae: 0.1366 - val_loss: 0.0165 - val_mae: 0.1270\n",
            "Epoch 603/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0187 - mae: 0.1358 - val_loss: 0.0204 - val_mae: 0.1404\n",
            "Epoch 604/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0185 - mae: 0.1345 - val_loss: 0.0165 - val_mae: 0.1259\n",
            "Epoch 605/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0193 - mae: 0.1373 - val_loss: 0.0159 - val_mae: 0.1236\n",
            "Epoch 606/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0187 - mae: 0.1345 - val_loss: 0.0191 - val_mae: 0.1315\n",
            "Epoch 607/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0180 - mae: 0.1326 - val_loss: 0.0201 - val_mae: 0.1395\n",
            "Epoch 608/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0183 - mae: 0.1346 - val_loss: 0.0201 - val_mae: 0.1341\n",
            "Epoch 609/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0188 - mae: 0.1354 - val_loss: 0.0195 - val_mae: 0.1362\n",
            "Epoch 610/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0191 - mae: 0.1364 - val_loss: 0.0184 - val_mae: 0.1336\n",
            "Epoch 611/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0173 - mae: 0.1299 - val_loss: 0.0242 - val_mae: 0.1532\n",
            "Epoch 612/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0188 - mae: 0.1351 - val_loss: 0.0126 - val_mae: 0.1094\n",
            "Epoch 613/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0187 - mae: 0.1339 - val_loss: 0.0181 - val_mae: 0.1251\n",
            "Epoch 614/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0184 - mae: 0.1342 - val_loss: 0.0179 - val_mae: 0.1315\n",
            "Epoch 615/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0185 - mae: 0.1352 - val_loss: 0.0183 - val_mae: 0.1314\n",
            "Epoch 616/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0188 - mae: 0.1344 - val_loss: 0.0155 - val_mae: 0.1232\n",
            "Epoch 617/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0179 - mae: 0.1312 - val_loss: 0.0212 - val_mae: 0.1435\n",
            "Epoch 618/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0186 - mae: 0.1345 - val_loss: 0.0235 - val_mae: 0.1516\n",
            "Epoch 619/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0184 - mae: 0.1334 - val_loss: 0.0204 - val_mae: 0.1406\n",
            "Epoch 620/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0179 - mae: 0.1323 - val_loss: 0.0225 - val_mae: 0.1486\n",
            "Epoch 621/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0182 - mae: 0.1339 - val_loss: 0.0187 - val_mae: 0.1351\n",
            "Epoch 622/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0184 - mae: 0.1335 - val_loss: 0.0202 - val_mae: 0.1400\n",
            "Epoch 623/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0181 - mae: 0.1330 - val_loss: 0.0242 - val_mae: 0.1520\n",
            "Epoch 624/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0176 - mae: 0.1305 - val_loss: 0.0169 - val_mae: 0.1290\n",
            "Epoch 625/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0183 - mae: 0.1333 - val_loss: 0.0095 - val_mae: 0.0943\n",
            "Epoch 626/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0182 - mae: 0.1322 - val_loss: 0.0203 - val_mae: 0.1386\n",
            "Epoch 627/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0182 - mae: 0.1339 - val_loss: 0.0212 - val_mae: 0.1384\n",
            "Epoch 628/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0179 - mae: 0.1315 - val_loss: 0.0177 - val_mae: 0.1314\n",
            "Epoch 629/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0184 - mae: 0.1341 - val_loss: 0.0237 - val_mae: 0.1433\n",
            "Epoch 630/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0177 - mae: 0.1318 - val_loss: 0.0154 - val_mae: 0.1227\n",
            "Epoch 631/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0181 - mae: 0.1322 - val_loss: 0.0179 - val_mae: 0.1317\n",
            "Epoch 632/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0183 - mae: 0.1331 - val_loss: 0.0195 - val_mae: 0.1355\n",
            "Epoch 633/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0178 - mae: 0.1326 - val_loss: 0.0187 - val_mae: 0.1326\n",
            "Epoch 634/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0181 - mae: 0.1328 - val_loss: 0.0183 - val_mae: 0.1329\n",
            "Epoch 635/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0177 - mae: 0.1320 - val_loss: 0.0271 - val_mae: 0.1522\n",
            "Epoch 636/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0181 - mae: 0.1333 - val_loss: 0.0130 - val_mae: 0.1120\n",
            "Epoch 637/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0171 - mae: 0.1284 - val_loss: 0.0226 - val_mae: 0.1464\n",
            "Epoch 638/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0179 - mae: 0.1326 - val_loss: 0.0192 - val_mae: 0.1378\n",
            "Epoch 639/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0175 - mae: 0.1307 - val_loss: 0.0203 - val_mae: 0.1388\n",
            "Epoch 640/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0181 - mae: 0.1327 - val_loss: 0.0222 - val_mae: 0.1483\n",
            "Epoch 641/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0177 - mae: 0.1312 - val_loss: 0.0272 - val_mae: 0.1459\n",
            "Epoch 642/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0181 - mae: 0.1318 - val_loss: 0.0165 - val_mae: 0.1275\n",
            "Epoch 643/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0174 - mae: 0.1302 - val_loss: 0.0220 - val_mae: 0.1464\n",
            "Epoch 644/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0181 - mae: 0.1316 - val_loss: 0.0212 - val_mae: 0.1439\n",
            "Epoch 645/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0169 - mae: 0.1280 - val_loss: 0.0201 - val_mae: 0.1396\n",
            "Epoch 646/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0180 - mae: 0.1328 - val_loss: 0.0195 - val_mae: 0.1361\n",
            "Epoch 647/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0173 - mae: 0.1302 - val_loss: 0.0197 - val_mae: 0.1357\n",
            "Epoch 648/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0176 - mae: 0.1304 - val_loss: 0.0200 - val_mae: 0.1397\n",
            "Epoch 649/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0181 - mae: 0.1319 - val_loss: 0.0130 - val_mae: 0.1095\n",
            "Epoch 650/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0168 - mae: 0.1275 - val_loss: 0.0225 - val_mae: 0.1484\n",
            "Epoch 651/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0178 - mae: 0.1311 - val_loss: 0.0123 - val_mae: 0.1071\n",
            "Epoch 652/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0175 - mae: 0.1302 - val_loss: 0.0232 - val_mae: 0.1500\n",
            "Epoch 653/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0175 - mae: 0.1311 - val_loss: 0.0221 - val_mae: 0.1305\n",
            "Epoch 654/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0170 - mae: 0.1286 - val_loss: 0.0145 - val_mae: 0.1161\n",
            "Epoch 655/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0178 - mae: 0.1305 - val_loss: 0.0196 - val_mae: 0.1312\n",
            "Epoch 656/2000\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0172 - mae: 0.1300 - val_loss: 0.0159 - val_mae: 0.1240\n",
            "Epoch 657/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0172 - mae: 0.1299 - val_loss: 0.0178 - val_mae: 0.1283\n",
            "Epoch 658/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0175 - mae: 0.1305 - val_loss: 0.0153 - val_mae: 0.1203\n",
            "Epoch 659/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0173 - mae: 0.1301 - val_loss: 0.0189 - val_mae: 0.1308\n",
            "Epoch 660/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0167 - mae: 0.1279 - val_loss: 0.0165 - val_mae: 0.1250\n",
            "Epoch 661/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0176 - mae: 0.1311 - val_loss: 0.0156 - val_mae: 0.1203\n",
            "Epoch 662/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0166 - mae: 0.1279 - val_loss: 0.0185 - val_mae: 0.1349\n",
            "Epoch 663/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0174 - mae: 0.1294 - val_loss: 0.0217 - val_mae: 0.1456\n",
            "Epoch 664/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0169 - mae: 0.1284 - val_loss: 0.0154 - val_mae: 0.1220\n",
            "Epoch 665/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0173 - mae: 0.1305 - val_loss: 0.0227 - val_mae: 0.1443\n",
            "Epoch 666/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0170 - mae: 0.1289 - val_loss: 0.0169 - val_mae: 0.1293\n",
            "Epoch 667/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0172 - mae: 0.1291 - val_loss: 0.0182 - val_mae: 0.1320\n",
            "Epoch 668/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0171 - mae: 0.1296 - val_loss: 0.0153 - val_mae: 0.1201\n",
            "Epoch 669/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0170 - mae: 0.1279 - val_loss: 0.0143 - val_mae: 0.1158\n",
            "Epoch 670/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0173 - mae: 0.1302 - val_loss: 0.0170 - val_mae: 0.1291\n",
            "Epoch 671/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0165 - mae: 0.1270 - val_loss: 0.0253 - val_mae: 0.1559\n",
            "Epoch 672/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0171 - mae: 0.1283 - val_loss: 0.0124 - val_mae: 0.1078\n",
            "Epoch 673/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0167 - mae: 0.1281 - val_loss: 0.0221 - val_mae: 0.1441\n",
            "Epoch 674/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0170 - mae: 0.1293 - val_loss: 0.0208 - val_mae: 0.1425\n",
            "Epoch 675/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0170 - mae: 0.1273 - val_loss: 0.0197 - val_mae: 0.1358\n",
            "Epoch 676/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0172 - mae: 0.1300 - val_loss: 0.0167 - val_mae: 0.1280\n",
            "Epoch 677/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0166 - mae: 0.1281 - val_loss: 0.0179 - val_mae: 0.1323\n",
            "Epoch 678/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0166 - mae: 0.1277 - val_loss: 0.0138 - val_mae: 0.1154\n",
            "Epoch 679/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0165 - mae: 0.1268 - val_loss: 0.0279 - val_mae: 0.1573\n",
            "Epoch 680/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0171 - mae: 0.1288 - val_loss: 0.0149 - val_mae: 0.1205\n",
            "Epoch 681/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0165 - mae: 0.1275 - val_loss: 0.0144 - val_mae: 0.1141\n",
            "Epoch 682/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0165 - mae: 0.1264 - val_loss: 0.0181 - val_mae: 0.1328\n",
            "Epoch 683/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0172 - mae: 0.1295 - val_loss: 0.0166 - val_mae: 0.1265\n",
            "Epoch 684/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0162 - mae: 0.1256 - val_loss: 0.0173 - val_mae: 0.1305\n",
            "Epoch 685/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0169 - mae: 0.1286 - val_loss: 0.0146 - val_mae: 0.1119\n",
            "Epoch 686/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0167 - mae: 0.1278 - val_loss: 0.0151 - val_mae: 0.1211\n",
            "Epoch 687/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.1238 - val_loss: 0.0198 - val_mae: 0.1327\n",
            "Epoch 688/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0175 - mae: 0.1286 - val_loss: 0.0148 - val_mae: 0.1199\n",
            "Epoch 689/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0164 - mae: 0.1266 - val_loss: 0.0158 - val_mae: 0.1231\n",
            "Epoch 690/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0161 - mae: 0.1250 - val_loss: 0.0199 - val_mae: 0.1341\n",
            "Epoch 691/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0169 - mae: 0.1281 - val_loss: 0.0237 - val_mae: 0.1393\n",
            "Epoch 692/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0164 - mae: 0.1274 - val_loss: 0.0149 - val_mae: 0.1187\n",
            "Epoch 693/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0166 - mae: 0.1273 - val_loss: 0.0168 - val_mae: 0.1270\n",
            "Epoch 694/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0164 - mae: 0.1255 - val_loss: 0.0170 - val_mae: 0.1286\n",
            "Epoch 695/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0164 - mae: 0.1269 - val_loss: 0.0186 - val_mae: 0.1309\n",
            "Epoch 696/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0164 - mae: 0.1263 - val_loss: 0.0172 - val_mae: 0.1277\n",
            "Epoch 697/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0164 - mae: 0.1259 - val_loss: 0.0149 - val_mae: 0.1180\n",
            "Epoch 698/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0171 - mae: 0.1285 - val_loss: 0.0155 - val_mae: 0.1222\n",
            "Epoch 699/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0163 - mae: 0.1255 - val_loss: 0.0171 - val_mae: 0.1225\n",
            "Epoch 700/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0160 - mae: 0.1259 - val_loss: 0.0159 - val_mae: 0.1196\n",
            "Epoch 701/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.1249 - val_loss: 0.0211 - val_mae: 0.1432\n",
            "Epoch 702/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0161 - mae: 0.1253 - val_loss: 0.0168 - val_mae: 0.1267\n",
            "Epoch 703/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0167 - mae: 0.1280 - val_loss: 0.0152 - val_mae: 0.1217\n",
            "Epoch 704/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0165 - mae: 0.1266 - val_loss: 0.0167 - val_mae: 0.1229\n",
            "Epoch 705/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0158 - mae: 0.1244 - val_loss: 0.0206 - val_mae: 0.1415\n",
            "Epoch 706/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0167 - mae: 0.1267 - val_loss: 0.0139 - val_mae: 0.1160\n",
            "Epoch 707/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.1249 - val_loss: 0.0112 - val_mae: 0.1034\n",
            "Epoch 708/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0164 - mae: 0.1267 - val_loss: 0.0146 - val_mae: 0.1198\n",
            "Epoch 709/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0161 - mae: 0.1260 - val_loss: 0.0151 - val_mae: 0.1210\n",
            "Epoch 710/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0161 - mae: 0.1254 - val_loss: 0.0198 - val_mae: 0.1352\n",
            "Epoch 711/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1244 - val_loss: 0.0157 - val_mae: 0.1228\n",
            "Epoch 712/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0160 - mae: 0.1258 - val_loss: 0.0131 - val_mae: 0.1135\n",
            "Epoch 713/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0162 - mae: 0.1256 - val_loss: 0.0165 - val_mae: 0.1225\n",
            "Epoch 714/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0160 - mae: 0.1253 - val_loss: 0.0206 - val_mae: 0.1412\n",
            "Epoch 715/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0162 - mae: 0.1252 - val_loss: 0.0123 - val_mae: 0.1086\n",
            "Epoch 716/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0161 - mae: 0.1256 - val_loss: 0.0153 - val_mae: 0.1214\n",
            "Epoch 717/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1235 - val_loss: 0.0164 - val_mae: 0.1243\n",
            "Epoch 718/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.1249 - val_loss: 0.0149 - val_mae: 0.1204\n",
            "Epoch 719/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0165 - mae: 0.1262 - val_loss: 0.0159 - val_mae: 0.1238\n",
            "Epoch 720/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0158 - mae: 0.1247 - val_loss: 0.0164 - val_mae: 0.1256\n",
            "Epoch 721/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0155 - mae: 0.1236 - val_loss: 0.0160 - val_mae: 0.1246\n",
            "Epoch 722/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0161 - mae: 0.1251 - val_loss: 0.0128 - val_mae: 0.1117\n",
            "Epoch 723/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1240 - val_loss: 0.0234 - val_mae: 0.1497\n",
            "Epoch 724/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0161 - mae: 0.1236 - val_loss: 0.0132 - val_mae: 0.1106\n",
            "Epoch 725/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0164 - mae: 0.1261 - val_loss: 0.0180 - val_mae: 0.1315\n",
            "Epoch 726/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1251 - val_loss: 0.0165 - val_mae: 0.1224\n",
            "Epoch 727/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0153 - mae: 0.1224 - val_loss: 0.0229 - val_mae: 0.1392\n",
            "Epoch 728/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0165 - mae: 0.1267 - val_loss: 0.0136 - val_mae: 0.1143\n",
            "Epoch 729/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0157 - mae: 0.1230 - val_loss: 0.0172 - val_mae: 0.1285\n",
            "Epoch 730/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0157 - mae: 0.1247 - val_loss: 0.0135 - val_mae: 0.1149\n",
            "Epoch 731/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1250 - val_loss: 0.0171 - val_mae: 0.1251\n",
            "Epoch 732/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0158 - mae: 0.1234 - val_loss: 0.0187 - val_mae: 0.1353\n",
            "Epoch 733/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1229 - val_loss: 0.0116 - val_mae: 0.1043\n",
            "Epoch 734/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0165 - mae: 0.1258 - val_loss: 0.0157 - val_mae: 0.1171\n",
            "Epoch 735/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0149 - mae: 0.1196 - val_loss: 0.0204 - val_mae: 0.1391\n",
            "Epoch 736/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1251 - val_loss: 0.0139 - val_mae: 0.1152\n",
            "Epoch 737/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1254 - val_loss: 0.0157 - val_mae: 0.1214\n",
            "Epoch 738/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0157 - mae: 0.1240 - val_loss: 0.0140 - val_mae: 0.1164\n",
            "Epoch 739/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0158 - mae: 0.1237 - val_loss: 0.0123 - val_mae: 0.1085\n",
            "Epoch 740/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0157 - mae: 0.1242 - val_loss: 0.0163 - val_mae: 0.1257\n",
            "Epoch 741/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1245 - val_loss: 0.0157 - val_mae: 0.1190\n",
            "Epoch 742/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.1245 - val_loss: 0.0129 - val_mae: 0.1113\n",
            "Epoch 743/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1225 - val_loss: 0.0226 - val_mae: 0.1432\n",
            "Epoch 744/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0156 - mae: 0.1233 - val_loss: 0.0130 - val_mae: 0.1113\n",
            "Epoch 745/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.1250 - val_loss: 0.0191 - val_mae: 0.1310\n",
            "Epoch 746/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0162 - mae: 0.1251 - val_loss: 0.0217 - val_mae: 0.1467\n",
            "Epoch 747/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1204 - val_loss: 0.0221 - val_mae: 0.1443\n",
            "Epoch 748/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0163 - mae: 0.1255 - val_loss: 0.0156 - val_mae: 0.1225\n",
            "Epoch 749/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0153 - mae: 0.1222 - val_loss: 0.0152 - val_mae: 0.1206\n",
            "Epoch 750/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0161 - mae: 0.1242 - val_loss: 0.0145 - val_mae: 0.1190\n",
            "Epoch 751/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0158 - mae: 0.1232 - val_loss: 0.0160 - val_mae: 0.1232\n",
            "Epoch 752/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1219 - val_loss: 0.0181 - val_mae: 0.1323\n",
            "Epoch 753/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1236 - val_loss: 0.0175 - val_mae: 0.1252\n",
            "Epoch 754/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.1251 - val_loss: 0.0153 - val_mae: 0.1220\n",
            "Epoch 755/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0153 - mae: 0.1221 - val_loss: 0.0143 - val_mae: 0.1139\n",
            "Epoch 756/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0160 - mae: 0.1252 - val_loss: 0.0169 - val_mae: 0.1278\n",
            "Epoch 757/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1211 - val_loss: 0.0173 - val_mae: 0.1269\n",
            "Epoch 758/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1245 - val_loss: 0.0185 - val_mae: 0.1345\n",
            "Epoch 759/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0157 - mae: 0.1224 - val_loss: 0.0154 - val_mae: 0.1137\n",
            "Epoch 760/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0157 - mae: 0.1229 - val_loss: 0.0102 - val_mae: 0.0977\n",
            "Epoch 761/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1223 - val_loss: 0.0200 - val_mae: 0.1383\n",
            "Epoch 762/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1224 - val_loss: 0.0135 - val_mae: 0.1136\n",
            "Epoch 763/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1245 - val_loss: 0.0179 - val_mae: 0.1277\n",
            "Epoch 764/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1224 - val_loss: 0.0147 - val_mae: 0.1174\n",
            "Epoch 765/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1217 - val_loss: 0.0199 - val_mae: 0.1302\n",
            "Epoch 766/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0161 - mae: 0.1246 - val_loss: 0.0108 - val_mae: 0.0983\n",
            "Epoch 767/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0153 - mae: 0.1213 - val_loss: 0.0201 - val_mae: 0.1349\n",
            "Epoch 768/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0157 - mae: 0.1234 - val_loss: 0.0168 - val_mae: 0.1275\n",
            "Epoch 769/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0153 - mae: 0.1227 - val_loss: 0.0150 - val_mae: 0.1214\n",
            "Epoch 770/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1228 - val_loss: 0.0152 - val_mae: 0.1207\n",
            "Epoch 771/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.1248 - val_loss: 0.0124 - val_mae: 0.1057\n",
            "Epoch 772/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1212 - val_loss: 0.0126 - val_mae: 0.1111\n",
            "Epoch 773/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0160 - mae: 0.1246 - val_loss: 0.0180 - val_mae: 0.1217\n",
            "Epoch 774/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0154 - mae: 0.1219 - val_loss: 0.0148 - val_mae: 0.1196\n",
            "Epoch 775/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1214 - val_loss: 0.0191 - val_mae: 0.1328\n",
            "Epoch 776/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0158 - mae: 0.1242 - val_loss: 0.0161 - val_mae: 0.1208\n",
            "Epoch 777/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1220 - val_loss: 0.0217 - val_mae: 0.1328\n",
            "Epoch 778/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0154 - mae: 0.1223 - val_loss: 0.0147 - val_mae: 0.1139\n",
            "Epoch 779/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0158 - mae: 0.1231 - val_loss: 0.0203 - val_mae: 0.1346\n",
            "Epoch 780/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1214 - val_loss: 0.0158 - val_mae: 0.1232\n",
            "Epoch 781/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1229 - val_loss: 0.0162 - val_mae: 0.1247\n",
            "Epoch 782/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0153 - mae: 0.1228 - val_loss: 0.0153 - val_mae: 0.1217\n",
            "Epoch 783/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1228 - val_loss: 0.0153 - val_mae: 0.1190\n",
            "Epoch 784/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0149 - mae: 0.1202 - val_loss: 0.0187 - val_mae: 0.1297\n",
            "Epoch 785/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1230 - val_loss: 0.0204 - val_mae: 0.1382\n",
            "Epoch 786/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0157 - mae: 0.1240 - val_loss: 0.0157 - val_mae: 0.1231\n",
            "Epoch 787/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1217 - val_loss: 0.0136 - val_mae: 0.1058\n",
            "Epoch 788/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0156 - mae: 0.1233 - val_loss: 0.0142 - val_mae: 0.1155\n",
            "Epoch 789/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0149 - mae: 0.1208 - val_loss: 0.0164 - val_mae: 0.1192\n",
            "Epoch 790/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1222 - val_loss: 0.0168 - val_mae: 0.1256\n",
            "Epoch 791/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0156 - mae: 0.1232 - val_loss: 0.0239 - val_mae: 0.1527\n",
            "Epoch 792/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1218 - val_loss: 0.0141 - val_mae: 0.1158\n",
            "Epoch 793/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1211 - val_loss: 0.0150 - val_mae: 0.1203\n",
            "Epoch 794/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1205 - val_loss: 0.0120 - val_mae: 0.1065\n",
            "Epoch 795/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0154 - mae: 0.1227 - val_loss: 0.0200 - val_mae: 0.1353\n",
            "Epoch 796/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.1202 - val_loss: 0.0171 - val_mae: 0.1283\n",
            "Epoch 797/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0157 - mae: 0.1234 - val_loss: 0.0172 - val_mae: 0.1231\n",
            "Epoch 798/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1218 - val_loss: 0.0166 - val_mae: 0.1276\n",
            "Epoch 799/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1225 - val_loss: 0.0137 - val_mae: 0.1147\n",
            "Epoch 800/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0148 - mae: 0.1196 - val_loss: 0.0173 - val_mae: 0.1287\n",
            "Epoch 801/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0156 - mae: 0.1217 - val_loss: 0.0192 - val_mae: 0.1341\n",
            "Epoch 802/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0154 - mae: 0.1227 - val_loss: 0.0152 - val_mae: 0.1212\n",
            "Epoch 803/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1213 - val_loss: 0.0276 - val_mae: 0.1492\n",
            "Epoch 804/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0154 - mae: 0.1216 - val_loss: 0.0127 - val_mae: 0.1094\n",
            "Epoch 805/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1213 - val_loss: 0.0207 - val_mae: 0.1365\n",
            "Epoch 806/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0149 - mae: 0.1213 - val_loss: 0.0179 - val_mae: 0.1243\n",
            "Epoch 807/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0152 - mae: 0.1218 - val_loss: 0.0205 - val_mae: 0.1357\n",
            "Epoch 808/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0153 - mae: 0.1225 - val_loss: 0.0152 - val_mae: 0.1220\n",
            "Epoch 809/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1214 - val_loss: 0.0184 - val_mae: 0.1300\n",
            "Epoch 810/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0154 - mae: 0.1229 - val_loss: 0.0146 - val_mae: 0.1172\n",
            "Epoch 811/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1193 - val_loss: 0.0194 - val_mae: 0.1335\n",
            "Epoch 812/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0151 - mae: 0.1219 - val_loss: 0.0201 - val_mae: 0.1348\n",
            "Epoch 813/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0153 - mae: 0.1222 - val_loss: 0.0150 - val_mae: 0.1194\n",
            "Epoch 814/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1203 - val_loss: 0.0205 - val_mae: 0.1379\n",
            "Epoch 815/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0146 - mae: 0.1201 - val_loss: 0.0198 - val_mae: 0.1360\n",
            "Epoch 816/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0154 - mae: 0.1224 - val_loss: 0.0142 - val_mae: 0.1117\n",
            "Epoch 817/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0152 - mae: 0.1218 - val_loss: 0.0184 - val_mae: 0.1260\n",
            "Epoch 818/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1207 - val_loss: 0.0148 - val_mae: 0.1206\n",
            "Epoch 819/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1216 - val_loss: 0.0154 - val_mae: 0.1224\n",
            "Epoch 820/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0156 - mae: 0.1227 - val_loss: 0.0131 - val_mae: 0.1062\n",
            "Epoch 821/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0144 - mae: 0.1194 - val_loss: 0.0209 - val_mae: 0.1344\n",
            "Epoch 822/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0149 - mae: 0.1202 - val_loss: 0.0122 - val_mae: 0.1050\n",
            "Epoch 823/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0153 - mae: 0.1221 - val_loss: 0.0163 - val_mae: 0.1223\n",
            "Epoch 824/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0150 - mae: 0.1211 - val_loss: 0.0150 - val_mae: 0.1134\n",
            "Epoch 825/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0148 - mae: 0.1209 - val_loss: 0.0153 - val_mae: 0.1189\n",
            "Epoch 826/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0151 - mae: 0.1209 - val_loss: 0.0174 - val_mae: 0.1288\n",
            "Epoch 827/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0147 - mae: 0.1205 - val_loss: 0.0148 - val_mae: 0.1188\n",
            "Epoch 828/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0150 - mae: 0.1207 - val_loss: 0.0158 - val_mae: 0.1213\n",
            "Epoch 829/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0149 - mae: 0.1207 - val_loss: 0.0232 - val_mae: 0.1467\n",
            "Epoch 830/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0154 - mae: 0.1226 - val_loss: 0.0120 - val_mae: 0.1031\n",
            "Epoch 831/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.1180 - val_loss: 0.0208 - val_mae: 0.1354\n",
            "Epoch 832/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1208 - val_loss: 0.0153 - val_mae: 0.1208\n",
            "Epoch 833/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0150 - mae: 0.1215 - val_loss: 0.0177 - val_mae: 0.1277\n",
            "Epoch 834/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1198 - val_loss: 0.0159 - val_mae: 0.1153\n",
            "Epoch 835/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0154 - mae: 0.1204 - val_loss: 0.0161 - val_mae: 0.1164\n",
            "Epoch 836/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0149 - mae: 0.1197 - val_loss: 0.0127 - val_mae: 0.1106\n",
            "Epoch 837/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0154 - mae: 0.1219 - val_loss: 0.0162 - val_mae: 0.1217\n",
            "Epoch 838/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0148 - mae: 0.1204 - val_loss: 0.0151 - val_mae: 0.1210\n",
            "Epoch 839/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1186 - val_loss: 0.0205 - val_mae: 0.1380\n",
            "Epoch 840/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1219 - val_loss: 0.0118 - val_mae: 0.1015\n",
            "Epoch 841/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1198 - val_loss: 0.0171 - val_mae: 0.1233\n",
            "Epoch 842/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0150 - mae: 0.1216 - val_loss: 0.0132 - val_mae: 0.1136\n",
            "Epoch 843/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1197 - val_loss: 0.0189 - val_mae: 0.1236\n",
            "Epoch 844/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.1198 - val_loss: 0.0115 - val_mae: 0.1062\n",
            "Epoch 845/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0148 - mae: 0.1191 - val_loss: 0.0168 - val_mae: 0.1271\n",
            "Epoch 846/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0149 - mae: 0.1204 - val_loss: 0.0172 - val_mae: 0.1293\n",
            "Epoch 847/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.1189 - val_loss: 0.0172 - val_mae: 0.1269\n",
            "Epoch 848/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0155 - mae: 0.1226 - val_loss: 0.0122 - val_mae: 0.1079\n",
            "Epoch 849/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1166 - val_loss: 0.0183 - val_mae: 0.1298\n",
            "Epoch 850/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0148 - mae: 0.1202 - val_loss: 0.0122 - val_mae: 0.1025\n",
            "Epoch 851/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0148 - mae: 0.1196 - val_loss: 0.0247 - val_mae: 0.1418\n",
            "Epoch 852/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1194 - val_loss: 0.0145 - val_mae: 0.1187\n",
            "Epoch 853/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.1196 - val_loss: 0.0177 - val_mae: 0.1232\n",
            "Epoch 854/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0151 - mae: 0.1201 - val_loss: 0.0126 - val_mae: 0.1075\n",
            "Epoch 855/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1188 - val_loss: 0.0160 - val_mae: 0.1201\n",
            "Epoch 856/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1188 - val_loss: 0.0188 - val_mae: 0.1360\n",
            "Epoch 857/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.1197 - val_loss: 0.0185 - val_mae: 0.1290\n",
            "Epoch 858/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0149 - mae: 0.1201 - val_loss: 0.0155 - val_mae: 0.1204\n",
            "Epoch 859/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0148 - mae: 0.1204 - val_loss: 0.0155 - val_mae: 0.1226\n",
            "Epoch 860/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1187 - val_loss: 0.0132 - val_mae: 0.1129\n",
            "Epoch 861/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0148 - mae: 0.1200 - val_loss: 0.0176 - val_mae: 0.1255\n",
            "Epoch 862/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.1212 - val_loss: 0.0131 - val_mae: 0.1128\n",
            "Epoch 863/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1162 - val_loss: 0.0163 - val_mae: 0.1242\n",
            "Epoch 864/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.1205 - val_loss: 0.0152 - val_mae: 0.1183\n",
            "Epoch 865/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1194 - val_loss: 0.0167 - val_mae: 0.1077\n",
            "Epoch 866/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1185 - val_loss: 0.0143 - val_mae: 0.1178\n",
            "Epoch 867/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0151 - mae: 0.1215 - val_loss: 0.0147 - val_mae: 0.1161\n",
            "Epoch 868/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0147 - mae: 0.1195 - val_loss: 0.0123 - val_mae: 0.1047\n",
            "Epoch 869/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0142 - mae: 0.1174 - val_loss: 0.0158 - val_mae: 0.1212\n",
            "Epoch 870/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0146 - mae: 0.1201 - val_loss: 0.0147 - val_mae: 0.1161\n",
            "Epoch 871/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0150 - mae: 0.1212 - val_loss: 0.0215 - val_mae: 0.1291\n",
            "Epoch 872/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1170 - val_loss: 0.0140 - val_mae: 0.1153\n",
            "Epoch 873/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.1202 - val_loss: 0.0145 - val_mae: 0.1114\n",
            "Epoch 874/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1186 - val_loss: 0.0158 - val_mae: 0.1244\n",
            "Epoch 875/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0145 - mae: 0.1196 - val_loss: 0.0186 - val_mae: 0.1329\n",
            "Epoch 876/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1193 - val_loss: 0.0170 - val_mae: 0.1278\n",
            "Epoch 877/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1191 - val_loss: 0.0150 - val_mae: 0.1162\n",
            "Epoch 878/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1197 - val_loss: 0.0151 - val_mae: 0.1218\n",
            "Epoch 879/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0148 - mae: 0.1201 - val_loss: 0.0136 - val_mae: 0.1134\n",
            "Epoch 880/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.1168 - val_loss: 0.0154 - val_mae: 0.1207\n",
            "Epoch 881/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.1200 - val_loss: 0.0156 - val_mae: 0.1186\n",
            "Epoch 882/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1201 - val_loss: 0.0134 - val_mae: 0.1061\n",
            "Epoch 883/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.1181 - val_loss: 0.0195 - val_mae: 0.1281\n",
            "Epoch 884/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1192 - val_loss: 0.0132 - val_mae: 0.1138\n",
            "Epoch 885/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.1185 - val_loss: 0.0154 - val_mae: 0.1179\n",
            "Epoch 886/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0143 - mae: 0.1187 - val_loss: 0.0145 - val_mae: 0.1154\n",
            "Epoch 887/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0151 - mae: 0.1206 - val_loss: 0.0147 - val_mae: 0.1063\n",
            "Epoch 888/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0141 - mae: 0.1178 - val_loss: 0.0128 - val_mae: 0.1116\n",
            "Epoch 889/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1187 - val_loss: 0.0144 - val_mae: 0.1142\n",
            "Epoch 890/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1193 - val_loss: 0.0154 - val_mae: 0.1231\n",
            "Epoch 891/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1188 - val_loss: 0.0163 - val_mae: 0.1190\n",
            "Epoch 892/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1192 - val_loss: 0.0205 - val_mae: 0.1410\n",
            "Epoch 893/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1190 - val_loss: 0.0142 - val_mae: 0.1169\n",
            "Epoch 894/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0145 - mae: 0.1194 - val_loss: 0.0159 - val_mae: 0.1217\n",
            "Epoch 895/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1192 - val_loss: 0.0207 - val_mae: 0.1298\n",
            "Epoch 896/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1185 - val_loss: 0.0130 - val_mae: 0.1092\n",
            "Epoch 897/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1193 - val_loss: 0.0121 - val_mae: 0.1045\n",
            "Epoch 898/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0146 - mae: 0.1190 - val_loss: 0.0206 - val_mae: 0.1347\n",
            "Epoch 899/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0141 - mae: 0.1169 - val_loss: 0.0191 - val_mae: 0.1288\n",
            "Epoch 900/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0148 - mae: 0.1201 - val_loss: 0.0152 - val_mae: 0.1194\n",
            "Epoch 901/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1175 - val_loss: 0.0171 - val_mae: 0.1254\n",
            "Epoch 902/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1200 - val_loss: 0.0119 - val_mae: 0.1071\n",
            "Epoch 903/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1174 - val_loss: 0.0186 - val_mae: 0.1333\n",
            "Epoch 904/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1191 - val_loss: 0.0146 - val_mae: 0.1195\n",
            "Epoch 905/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0145 - mae: 0.1193 - val_loss: 0.0198 - val_mae: 0.1226\n",
            "Epoch 906/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1188 - val_loss: 0.0132 - val_mae: 0.1124\n",
            "Epoch 907/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1177 - val_loss: 0.0133 - val_mae: 0.1133\n",
            "Epoch 908/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1178 - val_loss: 0.0164 - val_mae: 0.1221\n",
            "Epoch 909/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.1198 - val_loss: 0.0161 - val_mae: 0.1244\n",
            "Epoch 910/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1187 - val_loss: 0.0150 - val_mae: 0.1206\n",
            "Epoch 911/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0140 - mae: 0.1168 - val_loss: 0.0146 - val_mae: 0.1164\n",
            "Epoch 912/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0144 - mae: 0.1192 - val_loss: 0.0154 - val_mae: 0.1205\n",
            "Epoch 913/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1188 - val_loss: 0.0144 - val_mae: 0.1142\n",
            "Epoch 914/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.1181 - val_loss: 0.0177 - val_mae: 0.1305\n",
            "Epoch 915/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1185 - val_loss: 0.0131 - val_mae: 0.1137\n",
            "Epoch 916/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.1175 - val_loss: 0.0174 - val_mae: 0.1294\n",
            "Epoch 917/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1198 - val_loss: 0.0235 - val_mae: 0.1367\n",
            "Epoch 918/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1167 - val_loss: 0.0148 - val_mae: 0.1152\n",
            "Epoch 919/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0148 - mae: 0.1196 - val_loss: 0.0203 - val_mae: 0.1286\n",
            "Epoch 920/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1158 - val_loss: 0.0147 - val_mae: 0.1180\n",
            "Epoch 921/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.1183 - val_loss: 0.0145 - val_mae: 0.1136\n",
            "Epoch 922/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.1175 - val_loss: 0.0181 - val_mae: 0.1270\n",
            "Epoch 923/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0144 - mae: 0.1194 - val_loss: 0.0145 - val_mae: 0.1173\n",
            "Epoch 924/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1185 - val_loss: 0.0150 - val_mae: 0.1198\n",
            "Epoch 925/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1162 - val_loss: 0.0161 - val_mae: 0.1143\n",
            "Epoch 926/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0145 - mae: 0.1190 - val_loss: 0.0156 - val_mae: 0.1214\n",
            "Epoch 927/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1179 - val_loss: 0.0180 - val_mae: 0.1209\n",
            "Epoch 928/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.1176 - val_loss: 0.0175 - val_mae: 0.1281\n",
            "Epoch 929/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.1180 - val_loss: 0.0158 - val_mae: 0.1191\n",
            "Epoch 930/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0143 - mae: 0.1175 - val_loss: 0.0149 - val_mae: 0.1183\n",
            "Epoch 931/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0144 - mae: 0.1190 - val_loss: 0.0114 - val_mae: 0.1002\n",
            "Epoch 932/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1166 - val_loss: 0.0173 - val_mae: 0.1235\n",
            "Epoch 933/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1172 - val_loss: 0.0155 - val_mae: 0.1147\n",
            "Epoch 934/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1170 - val_loss: 0.0168 - val_mae: 0.1271\n",
            "Epoch 935/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1185 - val_loss: 0.0140 - val_mae: 0.1128\n",
            "Epoch 936/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1187 - val_loss: 0.0138 - val_mae: 0.1130\n",
            "Epoch 937/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1165 - val_loss: 0.0148 - val_mae: 0.1146\n",
            "Epoch 938/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1176 - val_loss: 0.0170 - val_mae: 0.1283\n",
            "Epoch 939/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.1181 - val_loss: 0.0181 - val_mae: 0.1293\n",
            "Epoch 940/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.1179 - val_loss: 0.0097 - val_mae: 0.0956\n",
            "Epoch 941/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1158 - val_loss: 0.0198 - val_mae: 0.1331\n",
            "Epoch 942/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0142 - mae: 0.1183 - val_loss: 0.0155 - val_mae: 0.1222\n",
            "Epoch 943/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1177 - val_loss: 0.0127 - val_mae: 0.0992\n",
            "Epoch 944/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1162 - val_loss: 0.0155 - val_mae: 0.1210\n",
            "Epoch 945/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1184 - val_loss: 0.0177 - val_mae: 0.1283\n",
            "Epoch 946/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0141 - mae: 0.1176 - val_loss: 0.0140 - val_mae: 0.1153\n",
            "Epoch 947/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1156 - val_loss: 0.0181 - val_mae: 0.1243\n",
            "Epoch 948/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0142 - mae: 0.1175 - val_loss: 0.0156 - val_mae: 0.1237\n",
            "Epoch 949/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0143 - mae: 0.1179 - val_loss: 0.0116 - val_mae: 0.0993\n",
            "Epoch 950/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0142 - mae: 0.1177 - val_loss: 0.0204 - val_mae: 0.1388\n",
            "Epoch 951/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1167 - val_loss: 0.0127 - val_mae: 0.1078\n",
            "Epoch 952/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1151 - val_loss: 0.0152 - val_mae: 0.1189\n",
            "Epoch 953/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0146 - mae: 0.1195 - val_loss: 0.0181 - val_mae: 0.1295\n",
            "Epoch 954/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0135 - mae: 0.1150 - val_loss: 0.0141 - val_mae: 0.1141\n",
            "Epoch 955/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1172 - val_loss: 0.0189 - val_mae: 0.1323\n",
            "Epoch 956/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0138 - mae: 0.1164 - val_loss: 0.0171 - val_mae: 0.1244\n",
            "Epoch 957/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0145 - mae: 0.1188 - val_loss: 0.0221 - val_mae: 0.1320\n",
            "Epoch 958/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1167 - val_loss: 0.0146 - val_mae: 0.1176\n",
            "Epoch 959/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0141 - mae: 0.1180 - val_loss: 0.0078 - val_mae: 0.0826\n",
            "Epoch 960/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1150 - val_loss: 0.0163 - val_mae: 0.1246\n",
            "Epoch 961/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1178 - val_loss: 0.0160 - val_mae: 0.1154\n",
            "Epoch 962/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.1171 - val_loss: 0.0149 - val_mae: 0.1179\n",
            "Epoch 963/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1171 - val_loss: 0.0124 - val_mae: 0.1041\n",
            "Epoch 964/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1156 - val_loss: 0.0156 - val_mae: 0.1219\n",
            "Epoch 965/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.1147 - val_loss: 0.0185 - val_mae: 0.1310\n",
            "Epoch 966/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1163 - val_loss: 0.0106 - val_mae: 0.0979\n",
            "Epoch 967/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0142 - mae: 0.1175 - val_loss: 0.0174 - val_mae: 0.1282\n",
            "Epoch 968/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0137 - mae: 0.1145 - val_loss: 0.0134 - val_mae: 0.1123\n",
            "Epoch 969/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0138 - mae: 0.1171 - val_loss: 0.0172 - val_mae: 0.1209\n",
            "Epoch 970/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1179 - val_loss: 0.0145 - val_mae: 0.1159\n",
            "Epoch 971/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0136 - mae: 0.1159 - val_loss: 0.0174 - val_mae: 0.1220\n",
            "Epoch 972/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0139 - mae: 0.1170 - val_loss: 0.0126 - val_mae: 0.1092\n",
            "Epoch 973/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1150 - val_loss: 0.0216 - val_mae: 0.1421\n",
            "Epoch 974/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.1178 - val_loss: 0.0115 - val_mae: 0.1039\n",
            "Epoch 975/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1155 - val_loss: 0.0139 - val_mae: 0.1147\n",
            "Epoch 976/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1163 - val_loss: 0.0118 - val_mae: 0.1057\n",
            "Epoch 977/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0141 - mae: 0.1179 - val_loss: 0.0151 - val_mae: 0.1159\n",
            "Epoch 978/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0134 - mae: 0.1146 - val_loss: 0.0140 - val_mae: 0.1137\n",
            "Epoch 979/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1153 - val_loss: 0.0172 - val_mae: 0.1258\n",
            "Epoch 980/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0144 - mae: 0.1178 - val_loss: 0.0131 - val_mae: 0.1105\n",
            "Epoch 981/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1152 - val_loss: 0.0182 - val_mae: 0.1227\n",
            "Epoch 982/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1154 - val_loss: 0.0125 - val_mae: 0.1089\n",
            "Epoch 983/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0135 - mae: 0.1151 - val_loss: 0.0166 - val_mae: 0.1189\n",
            "Epoch 984/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0142 - mae: 0.1177 - val_loss: 0.0148 - val_mae: 0.1183\n",
            "Epoch 985/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1163 - val_loss: 0.0106 - val_mae: 0.0973\n",
            "Epoch 986/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1142 - val_loss: 0.0133 - val_mae: 0.1115\n",
            "Epoch 987/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1165 - val_loss: 0.0176 - val_mae: 0.1255\n",
            "Epoch 988/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1160 - val_loss: 0.0178 - val_mae: 0.1286\n",
            "Epoch 989/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1171 - val_loss: 0.0133 - val_mae: 0.1054\n",
            "Epoch 990/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1162 - val_loss: 0.0161 - val_mae: 0.1220\n",
            "Epoch 991/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1161 - val_loss: 0.0134 - val_mae: 0.1066\n",
            "Epoch 992/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1166 - val_loss: 0.0165 - val_mae: 0.1250\n",
            "Epoch 993/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1147 - val_loss: 0.0170 - val_mae: 0.1169\n",
            "Epoch 994/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1158 - val_loss: 0.0151 - val_mae: 0.1143\n",
            "Epoch 995/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1166 - val_loss: 0.0162 - val_mae: 0.1229\n",
            "Epoch 996/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1155 - val_loss: 0.0152 - val_mae: 0.1161\n",
            "Epoch 997/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1166 - val_loss: 0.0101 - val_mae: 0.0967\n",
            "Epoch 998/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0140 - mae: 0.1155 - val_loss: 0.0175 - val_mae: 0.1311\n",
            "Epoch 999/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1146 - val_loss: 0.0157 - val_mae: 0.1213\n",
            "Epoch 1000/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1167 - val_loss: 0.0172 - val_mae: 0.1211\n",
            "Epoch 1001/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1154 - val_loss: 0.0145 - val_mae: 0.1102\n",
            "Epoch 1002/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1163 - val_loss: 0.0136 - val_mae: 0.1139\n",
            "Epoch 1003/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0136 - mae: 0.1154 - val_loss: 0.0121 - val_mae: 0.1060\n",
            "Epoch 1004/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1167 - val_loss: 0.0163 - val_mae: 0.1162\n",
            "Epoch 1005/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1149 - val_loss: 0.0123 - val_mae: 0.1028\n",
            "Epoch 1006/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.1182 - val_loss: 0.0136 - val_mae: 0.1133\n",
            "Epoch 1007/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1130 - val_loss: 0.0143 - val_mae: 0.1174\n",
            "Epoch 1008/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1156 - val_loss: 0.0167 - val_mae: 0.1238\n",
            "Epoch 1009/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1152 - val_loss: 0.0154 - val_mae: 0.1195\n",
            "Epoch 1010/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1155 - val_loss: 0.0137 - val_mae: 0.1087\n",
            "Epoch 1011/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1160 - val_loss: 0.0169 - val_mae: 0.1231\n",
            "Epoch 1012/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1163 - val_loss: 0.0130 - val_mae: 0.1119\n",
            "Epoch 1013/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1160 - val_loss: 0.0210 - val_mae: 0.1334\n",
            "Epoch 1014/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1163 - val_loss: 0.0140 - val_mae: 0.1111\n",
            "Epoch 1015/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1138 - val_loss: 0.0184 - val_mae: 0.1278\n",
            "Epoch 1016/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1152 - val_loss: 0.0133 - val_mae: 0.1108\n",
            "Epoch 1017/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1166 - val_loss: 0.0120 - val_mae: 0.1047\n",
            "Epoch 1018/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1129 - val_loss: 0.0171 - val_mae: 0.1291\n",
            "Epoch 1019/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.1170 - val_loss: 0.0144 - val_mae: 0.1134\n",
            "Epoch 1020/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.0990\n",
            "Epoch 1021/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1159 - val_loss: 0.0172 - val_mae: 0.1242\n",
            "Epoch 1022/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1154 - val_loss: 0.0120 - val_mae: 0.1046\n",
            "Epoch 1023/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1155 - val_loss: 0.0140 - val_mae: 0.1145\n",
            "Epoch 1024/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1149 - val_loss: 0.0104 - val_mae: 0.0989\n",
            "Epoch 1025/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0139 - mae: 0.1155 - val_loss: 0.0116 - val_mae: 0.1005\n",
            "Epoch 1026/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0134 - mae: 0.1146 - val_loss: 0.0105 - val_mae: 0.1001\n",
            "Epoch 1027/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1145 - val_loss: 0.0125 - val_mae: 0.1044\n",
            "Epoch 1028/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1153 - val_loss: 0.0155 - val_mae: 0.1232\n",
            "Epoch 1029/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1150 - val_loss: 0.0129 - val_mae: 0.1075\n",
            "Epoch 1030/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1160 - val_loss: 0.0125 - val_mae: 0.1091\n",
            "Epoch 1031/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1144 - val_loss: 0.0122 - val_mae: 0.1016\n",
            "Epoch 1032/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1148 - val_loss: 0.0139 - val_mae: 0.1118\n",
            "Epoch 1033/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1147 - val_loss: 0.0182 - val_mae: 0.1260\n",
            "Epoch 1034/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1155 - val_loss: 0.0155 - val_mae: 0.1197\n",
            "Epoch 1035/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1144 - val_loss: 0.0159 - val_mae: 0.1220\n",
            "Epoch 1036/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1158 - val_loss: 0.0123 - val_mae: 0.1094\n",
            "Epoch 1037/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1147 - val_loss: 0.0148 - val_mae: 0.1162\n",
            "Epoch 1038/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1152 - val_loss: 0.0139 - val_mae: 0.1171\n",
            "Epoch 1039/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1150 - val_loss: 0.0181 - val_mae: 0.1305\n",
            "Epoch 1040/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1150 - val_loss: 0.0151 - val_mae: 0.1176\n",
            "Epoch 1041/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1134 - val_loss: 0.0161 - val_mae: 0.1239\n",
            "Epoch 1042/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1156 - val_loss: 0.0148 - val_mae: 0.1191\n",
            "Epoch 1043/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0132 - mae: 0.1142 - val_loss: 0.0169 - val_mae: 0.1264\n",
            "Epoch 1044/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1154 - val_loss: 0.0160 - val_mae: 0.1213\n",
            "Epoch 1045/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0133 - mae: 0.1145 - val_loss: 0.0192 - val_mae: 0.1282\n",
            "Epoch 1046/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0135 - mae: 0.1146 - val_loss: 0.0131 - val_mae: 0.1117\n",
            "Epoch 1047/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1152 - val_loss: 0.0145 - val_mae: 0.1162\n",
            "Epoch 1048/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1149 - val_loss: 0.0090 - val_mae: 0.0828\n",
            "Epoch 1049/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1130 - val_loss: 0.0135 - val_mae: 0.1144\n",
            "Epoch 1050/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1150 - val_loss: 0.0146 - val_mae: 0.1163\n",
            "Epoch 1051/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0137 - mae: 0.1153 - val_loss: 0.0185 - val_mae: 0.1248\n",
            "Epoch 1052/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1140 - val_loss: 0.0161 - val_mae: 0.1176\n",
            "Epoch 1053/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1130 - val_loss: 0.0121 - val_mae: 0.1072\n",
            "Epoch 1054/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.1162 - val_loss: 0.0125 - val_mae: 0.1090\n",
            "Epoch 1055/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1143 - val_loss: 0.0158 - val_mae: 0.1190\n",
            "Epoch 1056/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1140 - val_loss: 0.0135 - val_mae: 0.1131\n",
            "Epoch 1057/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1147 - val_loss: 0.0109 - val_mae: 0.1005\n",
            "Epoch 1058/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1146 - val_loss: 0.0133 - val_mae: 0.1094\n",
            "Epoch 1059/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1155 - val_loss: 0.0157 - val_mae: 0.1179\n",
            "Epoch 1060/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1141 - val_loss: 0.0115 - val_mae: 0.1040\n",
            "Epoch 1061/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1148 - val_loss: 0.0116 - val_mae: 0.1060\n",
            "Epoch 1062/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1142 - val_loss: 0.0179 - val_mae: 0.1315\n",
            "Epoch 1063/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1145 - val_loss: 0.0144 - val_mae: 0.1179\n",
            "Epoch 1064/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0136 - mae: 0.1151 - val_loss: 0.0153 - val_mae: 0.1224\n",
            "Epoch 1065/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1128 - val_loss: 0.0135 - val_mae: 0.1120\n",
            "Epoch 1066/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1150 - val_loss: 0.0132 - val_mae: 0.1125\n",
            "Epoch 1067/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0134 - mae: 0.1140 - val_loss: 0.0138 - val_mae: 0.1103\n",
            "Epoch 1068/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0132 - mae: 0.1138 - val_loss: 0.0125 - val_mae: 0.1054\n",
            "Epoch 1069/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1153 - val_loss: 0.0135 - val_mae: 0.1086\n",
            "Epoch 1070/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1144 - val_loss: 0.0163 - val_mae: 0.1260\n",
            "Epoch 1071/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1129 - val_loss: 0.0120 - val_mae: 0.1063\n",
            "Epoch 1072/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0133 - mae: 0.1143 - val_loss: 0.0134 - val_mae: 0.1140\n",
            "Epoch 1073/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1153 - val_loss: 0.0112 - val_mae: 0.1034\n",
            "Epoch 1074/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1136 - val_loss: 0.0162 - val_mae: 0.1231\n",
            "Epoch 1075/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0135 - mae: 0.1147 - val_loss: 0.0133 - val_mae: 0.1079\n",
            "Epoch 1076/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0132 - mae: 0.1139 - val_loss: 0.0092 - val_mae: 0.0891\n",
            "Epoch 1077/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0131 - mae: 0.1130 - val_loss: 0.0160 - val_mae: 0.1193\n",
            "Epoch 1078/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0134 - mae: 0.1152 - val_loss: 0.0142 - val_mae: 0.1165\n",
            "Epoch 1079/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1148 - val_loss: 0.0157 - val_mae: 0.1134\n",
            "Epoch 1080/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0132 - mae: 0.1142 - val_loss: 0.0150 - val_mae: 0.1157\n",
            "Epoch 1081/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1125 - val_loss: 0.0171 - val_mae: 0.1274\n",
            "Epoch 1082/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0136 - mae: 0.1155 - val_loss: 0.0105 - val_mae: 0.0977\n",
            "Epoch 1083/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0135 - mae: 0.1138 - val_loss: 0.0142 - val_mae: 0.1119\n",
            "Epoch 1084/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1129 - val_loss: 0.0157 - val_mae: 0.1232\n",
            "Epoch 1085/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0138 - mae: 0.1157 - val_loss: 0.0130 - val_mae: 0.1060\n",
            "Epoch 1086/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1123 - val_loss: 0.0126 - val_mae: 0.1108\n",
            "Epoch 1087/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1148 - val_loss: 0.0126 - val_mae: 0.1104\n",
            "Epoch 1088/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1142 - val_loss: 0.0125 - val_mae: 0.1048\n",
            "Epoch 1089/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1127 - val_loss: 0.0147 - val_mae: 0.1160\n",
            "Epoch 1090/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1143 - val_loss: 0.0176 - val_mae: 0.1263\n",
            "Epoch 1091/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1140 - val_loss: 0.0172 - val_mae: 0.1165\n",
            "Epoch 1092/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1143 - val_loss: 0.0132 - val_mae: 0.1137\n",
            "Epoch 1093/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1144 - val_loss: 0.0130 - val_mae: 0.1074\n",
            "Epoch 1094/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1138 - val_loss: 0.0138 - val_mae: 0.1164\n",
            "Epoch 1095/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1137 - val_loss: 0.0145 - val_mae: 0.1173\n",
            "Epoch 1096/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1129 - val_loss: 0.0118 - val_mae: 0.1011\n",
            "Epoch 1097/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1143 - val_loss: 0.0157 - val_mae: 0.1172\n",
            "Epoch 1098/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1145 - val_loss: 0.0136 - val_mae: 0.1104\n",
            "Epoch 1099/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1126 - val_loss: 0.0137 - val_mae: 0.1149\n",
            "Epoch 1100/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0135 - mae: 0.1147 - val_loss: 0.0192 - val_mae: 0.1345\n",
            "Epoch 1101/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1121 - val_loss: 0.0126 - val_mae: 0.1087\n",
            "Epoch 1102/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0133 - mae: 0.1136 - val_loss: 0.0155 - val_mae: 0.1211\n",
            "Epoch 1103/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.1153 - val_loss: 0.0125 - val_mae: 0.1070\n",
            "Epoch 1104/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1129 - val_loss: 0.0129 - val_mae: 0.1110\n",
            "Epoch 1105/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0133 - mae: 0.1140 - val_loss: 0.0135 - val_mae: 0.1115\n",
            "Epoch 1106/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1137 - val_loss: 0.0098 - val_mae: 0.0943\n",
            "Epoch 1107/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1135 - val_loss: 0.0159 - val_mae: 0.1221\n",
            "Epoch 1108/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1140 - val_loss: 0.0100 - val_mae: 0.0947\n",
            "Epoch 1109/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1133 - val_loss: 0.0169 - val_mae: 0.1198\n",
            "Epoch 1110/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1122 - val_loss: 0.0125 - val_mae: 0.1056\n",
            "Epoch 1111/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1140 - val_loss: 0.0166 - val_mae: 0.1163\n",
            "Epoch 1112/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1135 - val_loss: 0.0158 - val_mae: 0.1225\n",
            "Epoch 1113/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1141 - val_loss: 0.0115 - val_mae: 0.0986\n",
            "Epoch 1114/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1132 - val_loss: 0.0186 - val_mae: 0.1320\n",
            "Epoch 1115/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1123 - val_loss: 0.0151 - val_mae: 0.1164\n",
            "Epoch 1116/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0133 - mae: 0.1143 - val_loss: 0.0149 - val_mae: 0.1193\n",
            "Epoch 1117/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1140 - val_loss: 0.0138 - val_mae: 0.1148\n",
            "Epoch 1118/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1137 - val_loss: 0.0135 - val_mae: 0.1097\n",
            "Epoch 1119/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1148 - val_loss: 0.0169 - val_mae: 0.1168\n",
            "Epoch 1120/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0129 - mae: 0.1128 - val_loss: 0.0130 - val_mae: 0.1102\n",
            "Epoch 1121/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1130 - val_loss: 0.0168 - val_mae: 0.1185\n",
            "Epoch 1122/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1140 - val_loss: 0.0118 - val_mae: 0.1054\n",
            "Epoch 1123/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1144 - val_loss: 0.0144 - val_mae: 0.1153\n",
            "Epoch 1124/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1114 - val_loss: 0.0137 - val_mae: 0.1104\n",
            "Epoch 1125/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0134 - mae: 0.1146 - val_loss: 0.0173 - val_mae: 0.1267\n",
            "Epoch 1126/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1120 - val_loss: 0.0140 - val_mae: 0.1174\n",
            "Epoch 1127/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0138 - mae: 0.1155 - val_loss: 0.0162 - val_mae: 0.1235\n",
            "Epoch 1128/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1114 - val_loss: 0.0119 - val_mae: 0.0992\n",
            "Epoch 1129/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0133 - mae: 0.1140 - val_loss: 0.0170 - val_mae: 0.1220\n",
            "Epoch 1130/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1122 - val_loss: 0.0128 - val_mae: 0.1107\n",
            "Epoch 1131/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1137 - val_loss: 0.0145 - val_mae: 0.1179\n",
            "Epoch 1132/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0129 - mae: 0.1131 - val_loss: 0.0133 - val_mae: 0.1087\n",
            "Epoch 1133/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1135 - val_loss: 0.0170 - val_mae: 0.1215\n",
            "Epoch 1134/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1126 - val_loss: 0.0137 - val_mae: 0.1111\n",
            "Epoch 1135/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1135 - val_loss: 0.0205 - val_mae: 0.1350\n",
            "Epoch 1136/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1133 - val_loss: 0.0125 - val_mae: 0.1100\n",
            "Epoch 1137/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1122 - val_loss: 0.0167 - val_mae: 0.1179\n",
            "Epoch 1138/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1134 - val_loss: 0.0167 - val_mae: 0.1283\n",
            "Epoch 1139/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0131 - mae: 0.1126 - val_loss: 0.0110 - val_mae: 0.0972\n",
            "Epoch 1140/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1124 - val_loss: 0.0181 - val_mae: 0.1321\n",
            "Epoch 1141/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1119 - val_loss: 0.0165 - val_mae: 0.1177\n",
            "Epoch 1142/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1135 - val_loss: 0.0114 - val_mae: 0.1030\n",
            "Epoch 1143/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1126 - val_loss: 0.0167 - val_mae: 0.1201\n",
            "Epoch 1144/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1137 - val_loss: 0.0169 - val_mae: 0.1191\n",
            "Epoch 1145/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1111 - val_loss: 0.0221 - val_mae: 0.1403\n",
            "Epoch 1146/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1131 - val_loss: 0.0135 - val_mae: 0.1139\n",
            "Epoch 1147/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1129 - val_loss: 0.0147 - val_mae: 0.1173\n",
            "Epoch 1148/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1136 - val_loss: 0.0126 - val_mae: 0.1090\n",
            "Epoch 1149/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1119 - val_loss: 0.0133 - val_mae: 0.1099\n",
            "Epoch 1150/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0130 - mae: 0.1131 - val_loss: 0.0131 - val_mae: 0.1099\n",
            "Epoch 1151/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1117 - val_loss: 0.0191 - val_mae: 0.1294\n",
            "Epoch 1152/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1132 - val_loss: 0.0131 - val_mae: 0.1066\n",
            "Epoch 1153/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1115 - val_loss: 0.0219 - val_mae: 0.1419\n",
            "Epoch 1154/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1127 - val_loss: 0.0144 - val_mae: 0.1155\n",
            "Epoch 1155/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0131 - mae: 0.1140 - val_loss: 0.0130 - val_mae: 0.1096\n",
            "Epoch 1156/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1136 - val_loss: 0.0143 - val_mae: 0.1152\n",
            "Epoch 1157/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1114 - val_loss: 0.0195 - val_mae: 0.1284\n",
            "Epoch 1158/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0132 - mae: 0.1134 - val_loss: 0.0120 - val_mae: 0.1077\n",
            "Epoch 1159/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1135 - val_loss: 0.0153 - val_mae: 0.1184\n",
            "Epoch 1160/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0126 - mae: 0.1103 - val_loss: 0.0089 - val_mae: 0.0897\n",
            "Epoch 1161/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1138 - val_loss: 0.0147 - val_mae: 0.1150\n",
            "Epoch 1162/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1127 - val_loss: 0.0148 - val_mae: 0.1155\n",
            "Epoch 1163/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1115 - val_loss: 0.0149 - val_mae: 0.1191\n",
            "Epoch 1164/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0128 - mae: 0.1118 - val_loss: 0.0128 - val_mae: 0.1093\n",
            "Epoch 1165/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1133 - val_loss: 0.0105 - val_mae: 0.0947\n",
            "Epoch 1166/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1112 - val_loss: 0.0142 - val_mae: 0.1152\n",
            "Epoch 1167/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1121 - val_loss: 0.0160 - val_mae: 0.1219\n",
            "Epoch 1168/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1120 - val_loss: 0.0104 - val_mae: 0.0988\n",
            "Epoch 1169/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1123 - val_loss: 0.0154 - val_mae: 0.1194\n",
            "Epoch 1170/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1130 - val_loss: 0.0170 - val_mae: 0.1238\n",
            "Epoch 1171/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0129 - mae: 0.1127 - val_loss: 0.0168 - val_mae: 0.1248\n",
            "Epoch 1172/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1109 - val_loss: 0.0148 - val_mae: 0.1186\n",
            "Epoch 1173/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1134 - val_loss: 0.0133 - val_mae: 0.1122\n",
            "Epoch 1174/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1125 - val_loss: 0.0128 - val_mae: 0.1101\n",
            "Epoch 1175/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.1141 - val_loss: 0.0101 - val_mae: 0.0952\n",
            "Epoch 1176/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1102 - val_loss: 0.0169 - val_mae: 0.1275\n",
            "Epoch 1177/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1130 - val_loss: 0.0175 - val_mae: 0.1272\n",
            "Epoch 1178/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1133 - val_loss: 0.0117 - val_mae: 0.1067\n",
            "Epoch 1179/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.1108 - val_loss: 0.0146 - val_mae: 0.1141\n",
            "Epoch 1180/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1132 - val_loss: 0.0115 - val_mae: 0.1009\n",
            "Epoch 1181/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1122 - val_loss: 0.0168 - val_mae: 0.1194\n",
            "Epoch 1182/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1119 - val_loss: 0.0127 - val_mae: 0.1021\n",
            "Epoch 1183/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0131 - mae: 0.1129 - val_loss: 0.0138 - val_mae: 0.1130\n",
            "Epoch 1184/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1131 - val_loss: 0.0101 - val_mae: 0.0961\n",
            "Epoch 1185/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1090 - val_loss: 0.0162 - val_mae: 0.1204\n",
            "Epoch 1186/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1138 - val_loss: 0.0110 - val_mae: 0.1027\n",
            "Epoch 1187/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1112 - val_loss: 0.0180 - val_mae: 0.1240\n",
            "Epoch 1188/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1121 - val_loss: 0.0154 - val_mae: 0.1171\n",
            "Epoch 1189/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1126 - val_loss: 0.0142 - val_mae: 0.1136\n",
            "Epoch 1190/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1122 - val_loss: 0.0138 - val_mae: 0.1136\n",
            "Epoch 1191/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1126 - val_loss: 0.0136 - val_mae: 0.1094\n",
            "Epoch 1192/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1118 - val_loss: 0.0130 - val_mae: 0.1114\n",
            "Epoch 1193/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1131 - val_loss: 0.0141 - val_mae: 0.1078\n",
            "Epoch 1194/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1113 - val_loss: 0.0123 - val_mae: 0.1056\n",
            "Epoch 1195/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0129 - mae: 0.1122 - val_loss: 0.0142 - val_mae: 0.1130\n",
            "Epoch 1196/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1123 - val_loss: 0.0123 - val_mae: 0.1072\n",
            "Epoch 1197/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1128 - val_loss: 0.0179 - val_mae: 0.1226\n",
            "Epoch 1198/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1114 - val_loss: 0.0139 - val_mae: 0.1168\n",
            "Epoch 1199/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1118 - val_loss: 0.0138 - val_mae: 0.1118\n",
            "Epoch 1200/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1119 - val_loss: 0.0180 - val_mae: 0.1330\n",
            "Epoch 1201/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1126 - val_loss: 0.0128 - val_mae: 0.1080\n",
            "Epoch 1202/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0126 - mae: 0.1111 - val_loss: 0.0129 - val_mae: 0.1119\n",
            "Epoch 1203/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0128 - mae: 0.1123 - val_loss: 0.0137 - val_mae: 0.1109\n",
            "Epoch 1204/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0131 - mae: 0.1131 - val_loss: 0.0154 - val_mae: 0.1225\n",
            "Epoch 1205/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1112 - val_loss: 0.0132 - val_mae: 0.1091\n",
            "Epoch 1206/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1123 - val_loss: 0.0127 - val_mae: 0.1057\n",
            "Epoch 1207/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1112 - val_loss: 0.0148 - val_mae: 0.1181\n",
            "Epoch 1208/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1110 - val_loss: 0.0143 - val_mae: 0.1159\n",
            "Epoch 1209/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1124 - val_loss: 0.0106 - val_mae: 0.0986\n",
            "Epoch 1210/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1122 - val_loss: 0.0110 - val_mae: 0.1017\n",
            "Epoch 1211/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0129 - mae: 0.1122 - val_loss: 0.0174 - val_mae: 0.1196\n",
            "Epoch 1212/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1118 - val_loss: 0.0133 - val_mae: 0.1133\n",
            "Epoch 1213/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1107 - val_loss: 0.0160 - val_mae: 0.1178\n",
            "Epoch 1214/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1123 - val_loss: 0.0127 - val_mae: 0.1074\n",
            "Epoch 1215/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1117 - val_loss: 0.0151 - val_mae: 0.1158\n",
            "Epoch 1216/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1116 - val_loss: 0.0143 - val_mae: 0.1162\n",
            "Epoch 1217/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1126 - val_loss: 0.0117 - val_mae: 0.1001\n",
            "Epoch 1218/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1113 - val_loss: 0.0176 - val_mae: 0.1301\n",
            "Epoch 1219/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1127 - val_loss: 0.0125 - val_mae: 0.1072\n",
            "Epoch 1220/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1108 - val_loss: 0.0128 - val_mae: 0.1094\n",
            "Epoch 1221/2000\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0127 - mae: 0.1114 - val_loss: 0.0118 - val_mae: 0.1037\n",
            "Epoch 1222/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0126 - mae: 0.1111 - val_loss: 0.0181 - val_mae: 0.1320\n",
            "Epoch 1223/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0128 - mae: 0.1124 - val_loss: 0.0132 - val_mae: 0.1111\n",
            "Epoch 1224/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1116 - val_loss: 0.0116 - val_mae: 0.1028\n",
            "Epoch 1225/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0128 - mae: 0.1123 - val_loss: 0.0156 - val_mae: 0.1210\n",
            "Epoch 1226/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0124 - mae: 0.1103 - val_loss: 0.0123 - val_mae: 0.1073\n",
            "Epoch 1227/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1107 - val_loss: 0.0174 - val_mae: 0.1270\n",
            "Epoch 1228/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1120 - val_loss: 0.0130 - val_mae: 0.1126\n",
            "Epoch 1229/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1120 - val_loss: 0.0120 - val_mae: 0.1050\n",
            "Epoch 1230/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1113 - val_loss: 0.0117 - val_mae: 0.1044\n",
            "Epoch 1231/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1106 - val_loss: 0.0159 - val_mae: 0.1189\n",
            "Epoch 1232/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1118 - val_loss: 0.0181 - val_mae: 0.1299\n",
            "Epoch 1233/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1111 - val_loss: 0.0167 - val_mae: 0.1231\n",
            "Epoch 1234/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1128 - val_loss: 0.0119 - val_mae: 0.1063\n",
            "Epoch 1235/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0124 - mae: 0.1104 - val_loss: 0.0171 - val_mae: 0.1225\n",
            "Epoch 1236/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1113 - val_loss: 0.0145 - val_mae: 0.1161\n",
            "Epoch 1237/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1114 - val_loss: 0.0147 - val_mae: 0.1119\n",
            "Epoch 1238/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.1126 - val_loss: 0.0179 - val_mae: 0.1315\n",
            "Epoch 1239/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.1103 - val_loss: 0.0171 - val_mae: 0.1200\n",
            "Epoch 1240/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1116 - val_loss: 0.0133 - val_mae: 0.1132\n",
            "Epoch 1241/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1120 - val_loss: 0.0138 - val_mae: 0.1141\n",
            "Epoch 1242/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1109 - val_loss: 0.0122 - val_mae: 0.1083\n",
            "Epoch 1243/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1123 - val_loss: 0.0150 - val_mae: 0.1096\n",
            "Epoch 1244/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1102 - val_loss: 0.0136 - val_mae: 0.1148\n",
            "Epoch 1245/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1117 - val_loss: 0.0121 - val_mae: 0.1070\n",
            "Epoch 1246/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1097 - val_loss: 0.0121 - val_mae: 0.1079\n",
            "Epoch 1247/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0133 - mae: 0.1135 - val_loss: 0.0155 - val_mae: 0.1132\n",
            "Epoch 1248/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1092 - val_loss: 0.0138 - val_mae: 0.1149\n",
            "Epoch 1249/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0129 - mae: 0.1127 - val_loss: 0.0128 - val_mae: 0.1076\n",
            "Epoch 1250/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1104 - val_loss: 0.0113 - val_mae: 0.1024\n",
            "Epoch 1251/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0123 - mae: 0.1099 - val_loss: 0.0146 - val_mae: 0.1149\n",
            "Epoch 1252/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1123 - val_loss: 0.0129 - val_mae: 0.1028\n",
            "Epoch 1253/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1101 - val_loss: 0.0152 - val_mae: 0.1109\n",
            "Epoch 1254/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1115 - val_loss: 0.0124 - val_mae: 0.1062\n",
            "Epoch 1255/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1095 - val_loss: 0.0126 - val_mae: 0.1036\n",
            "Epoch 1256/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.1109 - val_loss: 0.0164 - val_mae: 0.1231\n",
            "Epoch 1257/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1110 - val_loss: 0.0152 - val_mae: 0.1192\n",
            "Epoch 1258/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1117 - val_loss: 0.0113 - val_mae: 0.1039\n",
            "Epoch 1259/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1110 - val_loss: 0.0170 - val_mae: 0.1194\n",
            "Epoch 1260/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0125 - mae: 0.1108 - val_loss: 0.0124 - val_mae: 0.1065\n",
            "Epoch 1261/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1101 - val_loss: 0.0141 - val_mae: 0.1122\n",
            "Epoch 1262/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1111 - val_loss: 0.0124 - val_mae: 0.1065\n",
            "Epoch 1263/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1104 - val_loss: 0.0124 - val_mae: 0.1065\n",
            "Epoch 1264/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1117 - val_loss: 0.0122 - val_mae: 0.1043\n",
            "Epoch 1265/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.1099 - val_loss: 0.0173 - val_mae: 0.1172\n",
            "Epoch 1266/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1103 - val_loss: 0.0101 - val_mae: 0.0979\n",
            "Epoch 1267/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1110 - val_loss: 0.0159 - val_mae: 0.1182\n",
            "Epoch 1268/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0125 - mae: 0.1110 - val_loss: 0.0118 - val_mae: 0.1065\n",
            "Epoch 1269/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.1102 - val_loss: 0.0130 - val_mae: 0.1097\n",
            "Epoch 1270/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1108 - val_loss: 0.0149 - val_mae: 0.1203\n",
            "Epoch 1271/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1107 - val_loss: 0.0134 - val_mae: 0.1128\n",
            "Epoch 1272/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0126 - mae: 0.1109 - val_loss: 0.0152 - val_mae: 0.1215\n",
            "Epoch 1273/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.1108 - val_loss: 0.0124 - val_mae: 0.1058\n",
            "Epoch 1274/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1102 - val_loss: 0.0156 - val_mae: 0.1183\n",
            "Epoch 1275/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1119 - val_loss: 0.0140 - val_mae: 0.1156\n",
            "Epoch 1276/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1091 - val_loss: 0.0132 - val_mae: 0.1087\n",
            "Epoch 1277/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1108 - val_loss: 0.0130 - val_mae: 0.1094\n",
            "Epoch 1278/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1117 - val_loss: 0.0126 - val_mae: 0.1088\n",
            "Epoch 1279/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1109 - val_loss: 0.0126 - val_mae: 0.1026\n",
            "Epoch 1280/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.1097 - val_loss: 0.0134 - val_mae: 0.1114\n",
            "Epoch 1281/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1095 - val_loss: 0.0136 - val_mae: 0.1065\n",
            "Epoch 1282/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1113 - val_loss: 0.0118 - val_mae: 0.1022\n",
            "Epoch 1283/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1113 - val_loss: 0.0135 - val_mae: 0.1116\n",
            "Epoch 1284/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1091 - val_loss: 0.0155 - val_mae: 0.1214\n",
            "Epoch 1285/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.1097 - val_loss: 0.0164 - val_mae: 0.1208\n",
            "Epoch 1286/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1113 - val_loss: 0.0133 - val_mae: 0.1100\n",
            "Epoch 1287/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1096 - val_loss: 0.0116 - val_mae: 0.1039\n",
            "Epoch 1288/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1111 - val_loss: 0.0142 - val_mae: 0.1146\n",
            "Epoch 1289/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1098 - val_loss: 0.0147 - val_mae: 0.1152\n",
            "Epoch 1290/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1106 - val_loss: 0.0104 - val_mae: 0.0958\n",
            "Epoch 1291/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1111 - val_loss: 0.0124 - val_mae: 0.1056\n",
            "Epoch 1292/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1095 - val_loss: 0.0127 - val_mae: 0.1110\n",
            "Epoch 1293/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0123 - mae: 0.1096 - val_loss: 0.0155 - val_mae: 0.1155\n",
            "Epoch 1294/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1098 - val_loss: 0.0126 - val_mae: 0.1061\n",
            "Epoch 1295/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0129 - mae: 0.1119 - val_loss: 0.0154 - val_mae: 0.1196\n",
            "Epoch 1296/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1080 - val_loss: 0.0144 - val_mae: 0.1123\n",
            "Epoch 1297/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.1118 - val_loss: 0.0169 - val_mae: 0.1145\n",
            "Epoch 1298/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1104 - val_loss: 0.0120 - val_mae: 0.1035\n",
            "Epoch 1299/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1089 - val_loss: 0.0164 - val_mae: 0.1203\n",
            "Epoch 1300/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0128 - mae: 0.1118 - val_loss: 0.0095 - val_mae: 0.0939\n",
            "Epoch 1301/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1090 - val_loss: 0.0188 - val_mae: 0.1269\n",
            "Epoch 1302/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1086 - val_loss: 0.0126 - val_mae: 0.1096\n",
            "Epoch 1303/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0129 - mae: 0.1122 - val_loss: 0.0133 - val_mae: 0.1025\n",
            "Epoch 1304/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1103 - val_loss: 0.0160 - val_mae: 0.1211\n",
            "Epoch 1305/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1087 - val_loss: 0.0128 - val_mae: 0.1096\n",
            "Epoch 1306/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0124 - mae: 0.1100 - val_loss: 0.0107 - val_mae: 0.0995\n",
            "Epoch 1307/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1092 - val_loss: 0.0146 - val_mae: 0.1161\n",
            "Epoch 1308/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1095 - val_loss: 0.0104 - val_mae: 0.0995\n",
            "Epoch 1309/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1108 - val_loss: 0.0155 - val_mae: 0.1107\n",
            "Epoch 1310/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1092 - val_loss: 0.0143 - val_mae: 0.1138\n",
            "Epoch 1311/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0123 - mae: 0.1103 - val_loss: 0.0115 - val_mae: 0.1040\n",
            "Epoch 1312/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1090 - val_loss: 0.0132 - val_mae: 0.1128\n",
            "Epoch 1313/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1109 - val_loss: 0.0106 - val_mae: 0.0900\n",
            "Epoch 1314/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1067 - val_loss: 0.0146 - val_mae: 0.1154\n",
            "Epoch 1315/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.1116 - val_loss: 0.0157 - val_mae: 0.1169\n",
            "Epoch 1316/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1084 - val_loss: 0.0115 - val_mae: 0.1028\n",
            "Epoch 1317/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1097 - val_loss: 0.0104 - val_mae: 0.0973\n",
            "Epoch 1318/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0124 - mae: 0.1103 - val_loss: 0.0118 - val_mae: 0.1014\n",
            "Epoch 1319/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1097 - val_loss: 0.0115 - val_mae: 0.1036\n",
            "Epoch 1320/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1098 - val_loss: 0.0146 - val_mae: 0.1161\n",
            "Epoch 1321/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1076 - val_loss: 0.0179 - val_mae: 0.1239\n",
            "Epoch 1322/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0124 - mae: 0.1098 - val_loss: 0.0123 - val_mae: 0.0998\n",
            "Epoch 1323/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1099 - val_loss: 0.0165 - val_mae: 0.1167\n",
            "Epoch 1324/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1095 - val_loss: 0.0068 - val_mae: 0.0757\n",
            "Epoch 1325/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1083 - val_loss: 0.0138 - val_mae: 0.1129\n",
            "Epoch 1326/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1095 - val_loss: 0.0123 - val_mae: 0.1065\n",
            "Epoch 1327/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0126 - mae: 0.1111 - val_loss: 0.0153 - val_mae: 0.1124\n",
            "Epoch 1328/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1086 - val_loss: 0.0114 - val_mae: 0.1039\n",
            "Epoch 1329/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1076 - val_loss: 0.0178 - val_mae: 0.1215\n",
            "Epoch 1330/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.1107 - val_loss: 0.0119 - val_mae: 0.1044\n",
            "Epoch 1331/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1095 - val_loss: 0.0120 - val_mae: 0.1030\n",
            "Epoch 1332/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.1105 - val_loss: 0.0120 - val_mae: 0.1049\n",
            "Epoch 1333/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1077 - val_loss: 0.0144 - val_mae: 0.1145\n",
            "Epoch 1334/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0126 - mae: 0.1105 - val_loss: 0.0106 - val_mae: 0.0986\n",
            "Epoch 1335/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1067 - val_loss: 0.0160 - val_mae: 0.1230\n",
            "Epoch 1336/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0126 - mae: 0.1110 - val_loss: 0.0116 - val_mae: 0.1043\n",
            "Epoch 1337/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1079 - val_loss: 0.0132 - val_mae: 0.1111\n",
            "Epoch 1338/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1092 - val_loss: 0.0149 - val_mae: 0.1192\n",
            "Epoch 1339/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1096 - val_loss: 0.0121 - val_mae: 0.1066\n",
            "Epoch 1340/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1081 - val_loss: 0.0140 - val_mae: 0.1135\n",
            "Epoch 1341/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1094 - val_loss: 0.0156 - val_mae: 0.1138\n",
            "Epoch 1342/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1080 - val_loss: 0.0161 - val_mae: 0.1217\n",
            "Epoch 1343/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0125 - mae: 0.1104 - val_loss: 0.0145 - val_mae: 0.1104\n",
            "Epoch 1344/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1091 - val_loss: 0.0116 - val_mae: 0.1046\n",
            "Epoch 1345/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0123 - mae: 0.1099 - val_loss: 0.0163 - val_mae: 0.1161\n",
            "Epoch 1346/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1088 - val_loss: 0.0098 - val_mae: 0.0970\n",
            "Epoch 1347/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1085 - val_loss: 0.0127 - val_mae: 0.1054\n",
            "Epoch 1348/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1100 - val_loss: 0.0137 - val_mae: 0.1063\n",
            "Epoch 1349/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1083 - val_loss: 0.0170 - val_mae: 0.1247\n",
            "Epoch 1350/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.1106 - val_loss: 0.0106 - val_mae: 0.1007\n",
            "Epoch 1351/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1075 - val_loss: 0.0107 - val_mae: 0.0903\n",
            "Epoch 1352/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.1097 - val_loss: 0.0139 - val_mae: 0.1137\n",
            "Epoch 1353/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1087 - val_loss: 0.0121 - val_mae: 0.1051\n",
            "Epoch 1354/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1088 - val_loss: 0.0135 - val_mae: 0.1110\n",
            "Epoch 1355/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1087 - val_loss: 0.0181 - val_mae: 0.1312\n",
            "Epoch 1356/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1094 - val_loss: 0.0103 - val_mae: 0.0994\n",
            "Epoch 1357/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1090 - val_loss: 0.0135 - val_mae: 0.1064\n",
            "Epoch 1358/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1092 - val_loss: 0.0122 - val_mae: 0.1037\n",
            "Epoch 1359/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.1075 - val_loss: 0.0131 - val_mae: 0.1077\n",
            "Epoch 1360/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1089 - val_loss: 0.0165 - val_mae: 0.1247\n",
            "Epoch 1361/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0123 - mae: 0.1102 - val_loss: 0.0104 - val_mae: 0.0962\n",
            "Epoch 1362/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.1070 - val_loss: 0.0146 - val_mae: 0.1171\n",
            "Epoch 1363/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.1100 - val_loss: 0.0149 - val_mae: 0.1178\n",
            "Epoch 1364/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1092 - val_loss: 0.0128 - val_mae: 0.1100\n",
            "Epoch 1365/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.1081 - val_loss: 0.0142 - val_mae: 0.1120\n",
            "Epoch 1366/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1094 - val_loss: 0.0114 - val_mae: 0.1050\n",
            "Epoch 1367/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1082 - val_loss: 0.0164 - val_mae: 0.1159\n",
            "Epoch 1368/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1094 - val_loss: 0.0143 - val_mae: 0.1178\n",
            "Epoch 1369/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1084 - val_loss: 0.0130 - val_mae: 0.1062\n",
            "Epoch 1370/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1081 - val_loss: 0.0106 - val_mae: 0.0995\n",
            "Epoch 1371/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0120 - mae: 0.1085 - val_loss: 0.0131 - val_mae: 0.1115\n",
            "Epoch 1372/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1089 - val_loss: 0.0103 - val_mae: 0.0913\n",
            "Epoch 1373/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0120 - mae: 0.1073 - val_loss: 0.0174 - val_mae: 0.1272\n",
            "Epoch 1374/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1085 - val_loss: 0.0132 - val_mae: 0.1110\n",
            "Epoch 1375/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0123 - mae: 0.1094 - val_loss: 0.0116 - val_mae: 0.0989\n",
            "Epoch 1376/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1072 - val_loss: 0.0116 - val_mae: 0.1058\n",
            "Epoch 1377/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.1103 - val_loss: 0.0151 - val_mae: 0.1160\n",
            "Epoch 1378/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1071 - val_loss: 0.0136 - val_mae: 0.1116\n",
            "Epoch 1379/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1087 - val_loss: 0.0122 - val_mae: 0.1035\n",
            "Epoch 1380/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1091 - val_loss: 0.0125 - val_mae: 0.1092\n",
            "Epoch 1381/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0120 - mae: 0.1091 - val_loss: 0.0127 - val_mae: 0.1065\n",
            "Epoch 1382/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1086 - val_loss: 0.0122 - val_mae: 0.1081\n",
            "Epoch 1383/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0120 - mae: 0.1088 - val_loss: 0.0139 - val_mae: 0.1026\n",
            "Epoch 1384/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1057 - val_loss: 0.0126 - val_mae: 0.1101\n",
            "Epoch 1385/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0124 - mae: 0.1100 - val_loss: 0.0142 - val_mae: 0.1074\n",
            "Epoch 1386/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1072 - val_loss: 0.0134 - val_mae: 0.1102\n",
            "Epoch 1387/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.1098 - val_loss: 0.0141 - val_mae: 0.1102\n",
            "Epoch 1388/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1075 - val_loss: 0.0122 - val_mae: 0.1043\n",
            "Epoch 1389/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1087 - val_loss: 0.0104 - val_mae: 0.0914\n",
            "Epoch 1390/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1076 - val_loss: 0.0159 - val_mae: 0.1201\n",
            "Epoch 1391/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1071 - val_loss: 0.0144 - val_mae: 0.1146\n",
            "Epoch 1392/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0120 - mae: 0.1089 - val_loss: 0.0116 - val_mae: 0.1032\n",
            "Epoch 1393/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1082 - val_loss: 0.0105 - val_mae: 0.0973\n",
            "Epoch 1394/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1073 - val_loss: 0.0148 - val_mae: 0.1167\n",
            "Epoch 1395/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1080 - val_loss: 0.0115 - val_mae: 0.1044\n",
            "Epoch 1396/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.1087 - val_loss: 0.0138 - val_mae: 0.1157\n",
            "Epoch 1397/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1078 - val_loss: 0.0149 - val_mae: 0.1128\n",
            "Epoch 1398/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1089 - val_loss: 0.0136 - val_mae: 0.1108\n",
            "Epoch 1399/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1080 - val_loss: 0.0157 - val_mae: 0.1200\n",
            "Epoch 1400/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0121 - mae: 0.1085 - val_loss: 0.0152 - val_mae: 0.1208\n",
            "Epoch 1401/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1079 - val_loss: 0.0210 - val_mae: 0.1347\n",
            "Epoch 1402/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1077 - val_loss: 0.0091 - val_mae: 0.0913\n",
            "Epoch 1403/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1061 - val_loss: 0.0163 - val_mae: 0.1237\n",
            "Epoch 1404/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1068 - val_loss: 0.0136 - val_mae: 0.1130\n",
            "Epoch 1405/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0124 - mae: 0.1097 - val_loss: 0.0132 - val_mae: 0.1068\n",
            "Epoch 1406/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1071 - val_loss: 0.0148 - val_mae: 0.1176\n",
            "Epoch 1407/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1075 - val_loss: 0.0160 - val_mae: 0.1202\n",
            "Epoch 1408/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0122 - mae: 0.1089 - val_loss: 0.0113 - val_mae: 0.1012\n",
            "Epoch 1409/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.1078 - val_loss: 0.0162 - val_mae: 0.1198\n",
            "Epoch 1410/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1078 - val_loss: 0.0084 - val_mae: 0.0888\n",
            "Epoch 1411/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1068 - val_loss: 0.0149 - val_mae: 0.1121\n",
            "Epoch 1412/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.1089 - val_loss: 0.0140 - val_mae: 0.1147\n",
            "Epoch 1413/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1067 - val_loss: 0.0123 - val_mae: 0.1032\n",
            "Epoch 1414/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1079 - val_loss: 0.0130 - val_mae: 0.1131\n",
            "Epoch 1415/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1084 - val_loss: 0.0151 - val_mae: 0.1073\n",
            "Epoch 1416/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1072 - val_loss: 0.0130 - val_mae: 0.1084\n",
            "Epoch 1417/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1075 - val_loss: 0.0151 - val_mae: 0.1149\n",
            "Epoch 1418/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1081 - val_loss: 0.0110 - val_mae: 0.1027\n",
            "Epoch 1419/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1079 - val_loss: 0.0146 - val_mae: 0.1062\n",
            "Epoch 1420/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1074 - val_loss: 0.0096 - val_mae: 0.0908\n",
            "Epoch 1421/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1081 - val_loss: 0.0092 - val_mae: 0.0932\n",
            "Epoch 1422/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1072 - val_loss: 0.0119 - val_mae: 0.0990\n",
            "Epoch 1423/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1064 - val_loss: 0.0128 - val_mae: 0.1080\n",
            "Epoch 1424/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1085 - val_loss: 0.0120 - val_mae: 0.1025\n",
            "Epoch 1425/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1078 - val_loss: 0.0113 - val_mae: 0.1017\n",
            "Epoch 1426/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1064 - val_loss: 0.0162 - val_mae: 0.1228\n",
            "Epoch 1427/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1079 - val_loss: 0.0138 - val_mae: 0.1117\n",
            "Epoch 1428/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1078 - val_loss: 0.0127 - val_mae: 0.1099\n",
            "Epoch 1429/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1085 - val_loss: 0.0122 - val_mae: 0.1050\n",
            "Epoch 1430/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1062 - val_loss: 0.0119 - val_mae: 0.0999\n",
            "Epoch 1431/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1072 - val_loss: 0.0147 - val_mae: 0.1108\n",
            "Epoch 1432/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1078 - val_loss: 0.0111 - val_mae: 0.1020\n",
            "Epoch 1433/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1077 - val_loss: 0.0153 - val_mae: 0.1200\n",
            "Epoch 1434/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1071 - val_loss: 0.0118 - val_mae: 0.1045\n",
            "Epoch 1435/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1072 - val_loss: 0.0146 - val_mae: 0.1144\n",
            "Epoch 1436/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1079 - val_loss: 0.0121 - val_mae: 0.1057\n",
            "Epoch 1437/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0115 - mae: 0.1065 - val_loss: 0.0160 - val_mae: 0.1136\n",
            "Epoch 1438/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1085 - val_loss: 0.0144 - val_mae: 0.1100\n",
            "Epoch 1439/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1057 - val_loss: 0.0096 - val_mae: 0.0953\n",
            "Epoch 1440/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1057 - val_loss: 0.0127 - val_mae: 0.1113\n",
            "Epoch 1441/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1078 - val_loss: 0.0107 - val_mae: 0.0963\n",
            "Epoch 1442/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1065 - val_loss: 0.0135 - val_mae: 0.1132\n",
            "Epoch 1443/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1085 - val_loss: 0.0140 - val_mae: 0.1062\n",
            "Epoch 1444/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1051 - val_loss: 0.0129 - val_mae: 0.1115\n",
            "Epoch 1445/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1083 - val_loss: 0.0121 - val_mae: 0.1037\n",
            "Epoch 1446/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1063 - val_loss: 0.0124 - val_mae: 0.1068\n",
            "Epoch 1447/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0122 - mae: 0.1092 - val_loss: 0.0098 - val_mae: 0.0909\n",
            "Epoch 1448/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1066 - val_loss: 0.0102 - val_mae: 0.0993\n",
            "Epoch 1449/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1055 - val_loss: 0.0116 - val_mae: 0.1040\n",
            "Epoch 1450/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1081 - val_loss: 0.0124 - val_mae: 0.1082\n",
            "Epoch 1451/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1065 - val_loss: 0.0124 - val_mae: 0.1055\n",
            "Epoch 1452/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1077 - val_loss: 0.0090 - val_mae: 0.0912\n",
            "Epoch 1453/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0113 - mae: 0.1056 - val_loss: 0.0188 - val_mae: 0.1269\n",
            "Epoch 1454/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.1086 - val_loss: 0.0142 - val_mae: 0.1110\n",
            "Epoch 1455/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1061 - val_loss: 0.0117 - val_mae: 0.1034\n",
            "Epoch 1456/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1073 - val_loss: 0.0107 - val_mae: 0.0990\n",
            "Epoch 1457/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1075 - val_loss: 0.0114 - val_mae: 0.0988\n",
            "Epoch 1458/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1052 - val_loss: 0.0125 - val_mae: 0.1102\n",
            "Epoch 1459/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.1069 - val_loss: 0.0135 - val_mae: 0.1045\n",
            "Epoch 1460/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0119 - mae: 0.1077 - val_loss: 0.0150 - val_mae: 0.1201\n",
            "Epoch 1461/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0115 - mae: 0.1052 - val_loss: 0.0134 - val_mae: 0.1086\n",
            "Epoch 1462/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.1075 - val_loss: 0.0120 - val_mae: 0.1029\n",
            "Epoch 1463/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1058 - val_loss: 0.0184 - val_mae: 0.1303\n",
            "Epoch 1464/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1071 - val_loss: 0.0134 - val_mae: 0.1066\n",
            "Epoch 1465/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1058 - val_loss: 0.0176 - val_mae: 0.1272\n",
            "Epoch 1466/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1074 - val_loss: 0.0109 - val_mae: 0.0995\n",
            "Epoch 1467/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1071 - val_loss: 0.0170 - val_mae: 0.1245\n",
            "Epoch 1468/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1054 - val_loss: 0.0137 - val_mae: 0.1093\n",
            "Epoch 1469/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1073 - val_loss: 0.0162 - val_mae: 0.1116\n",
            "Epoch 1470/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.1067 - val_loss: 0.0110 - val_mae: 0.0997\n",
            "Epoch 1471/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1062 - val_loss: 0.0135 - val_mae: 0.1080\n",
            "Epoch 1472/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.1077 - val_loss: 0.0115 - val_mae: 0.1051\n",
            "Epoch 1473/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1065 - val_loss: 0.0139 - val_mae: 0.1091\n",
            "Epoch 1474/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1064 - val_loss: 0.0160 - val_mae: 0.1221\n",
            "Epoch 1475/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1060 - val_loss: 0.0134 - val_mae: 0.1067\n",
            "Epoch 1476/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1067 - val_loss: 0.0145 - val_mae: 0.1167\n",
            "Epoch 1477/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0115 - mae: 0.1066 - val_loss: 0.0212 - val_mae: 0.1270\n",
            "Epoch 1478/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1051 - val_loss: 0.0151 - val_mae: 0.1127\n",
            "Epoch 1479/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1072 - val_loss: 0.0133 - val_mae: 0.1080\n",
            "Epoch 1480/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1064 - val_loss: 0.0121 - val_mae: 0.1049\n",
            "Epoch 1481/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1071 - val_loss: 0.0124 - val_mae: 0.1057\n",
            "Epoch 1482/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0113 - mae: 0.1058 - val_loss: 0.0124 - val_mae: 0.1027\n",
            "Epoch 1483/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1073 - val_loss: 0.0137 - val_mae: 0.1091\n",
            "Epoch 1484/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1065 - val_loss: 0.0133 - val_mae: 0.1129\n",
            "Epoch 1485/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0113 - mae: 0.1054 - val_loss: 0.0104 - val_mae: 0.0961\n",
            "Epoch 1486/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1063 - val_loss: 0.0161 - val_mae: 0.1236\n",
            "Epoch 1487/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1060 - val_loss: 0.0137 - val_mae: 0.1116\n",
            "Epoch 1488/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1063 - val_loss: 0.0133 - val_mae: 0.1095\n",
            "Epoch 1489/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1062 - val_loss: 0.0157 - val_mae: 0.1141\n",
            "Epoch 1490/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1069 - val_loss: 0.0104 - val_mae: 0.0989\n",
            "Epoch 1491/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1053 - val_loss: 0.0150 - val_mae: 0.1107\n",
            "Epoch 1492/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1065 - val_loss: 0.0108 - val_mae: 0.0975\n",
            "Epoch 1493/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.1064 - val_loss: 0.0118 - val_mae: 0.1030\n",
            "Epoch 1494/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1050 - val_loss: 0.0131 - val_mae: 0.1136\n",
            "Epoch 1495/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.1064 - val_loss: 0.0140 - val_mae: 0.1127\n",
            "Epoch 1496/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0117 - mae: 0.1065 - val_loss: 0.0137 - val_mae: 0.1126\n",
            "Epoch 1497/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1056 - val_loss: 0.0098 - val_mae: 0.0946\n",
            "Epoch 1498/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0115 - mae: 0.1064 - val_loss: 0.0134 - val_mae: 0.1068\n",
            "Epoch 1499/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1051 - val_loss: 0.0117 - val_mae: 0.1053\n",
            "Epoch 1500/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1070 - val_loss: 0.0128 - val_mae: 0.1041\n",
            "Epoch 1501/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1053 - val_loss: 0.0116 - val_mae: 0.1027\n",
            "Epoch 1502/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1055 - val_loss: 0.0131 - val_mae: 0.1038\n",
            "Epoch 1503/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.1066 - val_loss: 0.0133 - val_mae: 0.1101\n",
            "Epoch 1504/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0112 - mae: 0.1044 - val_loss: 0.0148 - val_mae: 0.1194\n",
            "Epoch 1505/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0115 - mae: 0.1059 - val_loss: 0.0114 - val_mae: 0.1029\n",
            "Epoch 1506/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0114 - mae: 0.1059 - val_loss: 0.0124 - val_mae: 0.1082\n",
            "Epoch 1507/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1064 - val_loss: 0.0120 - val_mae: 0.1038\n",
            "Epoch 1508/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1054 - val_loss: 0.0136 - val_mae: 0.1134\n",
            "Epoch 1509/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1059 - val_loss: 0.0117 - val_mae: 0.0981\n",
            "Epoch 1510/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1044 - val_loss: 0.0140 - val_mae: 0.1157\n",
            "Epoch 1511/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1061 - val_loss: 0.0117 - val_mae: 0.1066\n",
            "Epoch 1512/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1063 - val_loss: 0.0133 - val_mae: 0.1125\n",
            "Epoch 1513/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0112 - mae: 0.1053 - val_loss: 0.0108 - val_mae: 0.1022\n",
            "Epoch 1514/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1053 - val_loss: 0.0127 - val_mae: 0.1047\n",
            "Epoch 1515/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1059 - val_loss: 0.0141 - val_mae: 0.1145\n",
            "Epoch 1516/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1063 - val_loss: 0.0113 - val_mae: 0.1029\n",
            "Epoch 1517/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1057 - val_loss: 0.0123 - val_mae: 0.1069\n",
            "Epoch 1518/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1052 - val_loss: 0.0142 - val_mae: 0.1098\n",
            "Epoch 1519/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1053 - val_loss: 0.0119 - val_mae: 0.0999\n",
            "Epoch 1520/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1054 - val_loss: 0.0115 - val_mae: 0.1055\n",
            "Epoch 1521/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1060 - val_loss: 0.0148 - val_mae: 0.1100\n",
            "Epoch 1522/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1058 - val_loss: 0.0155 - val_mae: 0.1216\n",
            "Epoch 1523/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1037 - val_loss: 0.0115 - val_mae: 0.1005\n",
            "Epoch 1524/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1059 - val_loss: 0.0129 - val_mae: 0.1094\n",
            "Epoch 1525/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1051 - val_loss: 0.0110 - val_mae: 0.0929\n",
            "Epoch 1526/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1052 - val_loss: 0.0111 - val_mae: 0.1041\n",
            "Epoch 1527/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1050 - val_loss: 0.0131 - val_mae: 0.1094\n",
            "Epoch 1528/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1057 - val_loss: 0.0101 - val_mae: 0.0985\n",
            "Epoch 1529/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1041 - val_loss: 0.0170 - val_mae: 0.1227\n",
            "Epoch 1530/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1051 - val_loss: 0.0125 - val_mae: 0.1053\n",
            "Epoch 1531/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1059 - val_loss: 0.0117 - val_mae: 0.1062\n",
            "Epoch 1532/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0116 - mae: 0.1060 - val_loss: 0.0106 - val_mae: 0.0974\n",
            "Epoch 1533/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1042 - val_loss: 0.0161 - val_mae: 0.1178\n",
            "Epoch 1534/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1047 - val_loss: 0.0116 - val_mae: 0.1025\n",
            "Epoch 1535/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0112 - mae: 0.1051 - val_loss: 0.0121 - val_mae: 0.1066\n",
            "Epoch 1536/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1048 - val_loss: 0.0086 - val_mae: 0.0902\n",
            "Epoch 1537/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1044 - val_loss: 0.0135 - val_mae: 0.1107\n",
            "Epoch 1538/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1051 - val_loss: 0.0132 - val_mae: 0.1097\n",
            "Epoch 1539/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0115 - mae: 0.1054 - val_loss: 0.0177 - val_mae: 0.1230\n",
            "Epoch 1540/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1044 - val_loss: 0.0095 - val_mae: 0.0947\n",
            "Epoch 1541/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1053 - val_loss: 0.0161 - val_mae: 0.1081\n",
            "Epoch 1542/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1047 - val_loss: 0.0147 - val_mae: 0.1164\n",
            "Epoch 1543/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1064 - val_loss: 0.0109 - val_mae: 0.1017\n",
            "Epoch 1544/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1036 - val_loss: 0.0125 - val_mae: 0.1099\n",
            "Epoch 1545/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0113 - mae: 0.1057 - val_loss: 0.0119 - val_mae: 0.0999\n",
            "Epoch 1546/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1039 - val_loss: 0.0125 - val_mae: 0.1038\n",
            "Epoch 1547/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1057 - val_loss: 0.0126 - val_mae: 0.1088\n",
            "Epoch 1548/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1049 - val_loss: 0.0095 - val_mae: 0.0936\n",
            "Epoch 1549/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1056 - val_loss: 0.0140 - val_mae: 0.1113\n",
            "Epoch 1550/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1047 - val_loss: 0.0112 - val_mae: 0.1031\n",
            "Epoch 1551/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1047 - val_loss: 0.0163 - val_mae: 0.1141\n",
            "Epoch 1552/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1054 - val_loss: 0.0080 - val_mae: 0.0850\n",
            "Epoch 1553/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1036 - val_loss: 0.0141 - val_mae: 0.1098\n",
            "Epoch 1554/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0115 - mae: 0.1053 - val_loss: 0.0127 - val_mae: 0.1074\n",
            "Epoch 1555/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1040 - val_loss: 0.0151 - val_mae: 0.1179\n",
            "Epoch 1556/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1055 - val_loss: 0.0126 - val_mae: 0.1084\n",
            "Epoch 1557/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1046 - val_loss: 0.0152 - val_mae: 0.1163\n",
            "Epoch 1558/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1060 - val_loss: 0.0118 - val_mae: 0.1055\n",
            "Epoch 1559/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1048 - val_loss: 0.0121 - val_mae: 0.1032\n",
            "Epoch 1560/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1042 - val_loss: 0.0147 - val_mae: 0.1188\n",
            "Epoch 1561/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1041 - val_loss: 0.0131 - val_mae: 0.1057\n",
            "Epoch 1562/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1057 - val_loss: 0.0140 - val_mae: 0.1139\n",
            "Epoch 1563/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1034 - val_loss: 0.0119 - val_mae: 0.1054\n",
            "Epoch 1564/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1055 - val_loss: 0.0124 - val_mae: 0.1096\n",
            "Epoch 1565/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0112 - mae: 0.1045 - val_loss: 0.0143 - val_mae: 0.1155\n",
            "Epoch 1566/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1050 - val_loss: 0.0131 - val_mae: 0.1116\n",
            "Epoch 1567/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1035 - val_loss: 0.0098 - val_mae: 0.0904\n",
            "Epoch 1568/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0112 - mae: 0.1050 - val_loss: 0.0134 - val_mae: 0.1079\n",
            "Epoch 1569/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1051 - val_loss: 0.0145 - val_mae: 0.1057\n",
            "Epoch 1570/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1050 - val_loss: 0.0118 - val_mae: 0.1053\n",
            "Epoch 1571/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1023 - val_loss: 0.0095 - val_mae: 0.0912\n",
            "Epoch 1572/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.1054 - val_loss: 0.0112 - val_mae: 0.1027\n",
            "Epoch 1573/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1052 - val_loss: 0.0124 - val_mae: 0.1023\n",
            "Epoch 1574/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1032 - val_loss: 0.0123 - val_mae: 0.1056\n",
            "Epoch 1575/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1043 - val_loss: 0.0120 - val_mae: 0.1027\n",
            "Epoch 1576/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1047 - val_loss: 0.0132 - val_mae: 0.1083\n",
            "Epoch 1577/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1041 - val_loss: 0.0126 - val_mae: 0.1045\n",
            "Epoch 1578/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1038 - val_loss: 0.0130 - val_mae: 0.1071\n",
            "Epoch 1579/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.1060 - val_loss: 0.0139 - val_mae: 0.1064\n",
            "Epoch 1580/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1041 - val_loss: 0.0119 - val_mae: 0.1062\n",
            "Epoch 1581/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1040 - val_loss: 0.0126 - val_mae: 0.1010\n",
            "Epoch 1582/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1051 - val_loss: 0.0158 - val_mae: 0.1173\n",
            "Epoch 1583/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.1026 - val_loss: 0.0186 - val_mae: 0.1245\n",
            "Epoch 1584/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0112 - mae: 0.1051 - val_loss: 0.0113 - val_mae: 0.1024\n",
            "Epoch 1585/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1034 - val_loss: 0.0155 - val_mae: 0.1175\n",
            "Epoch 1586/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1050 - val_loss: 0.0136 - val_mae: 0.1080\n",
            "Epoch 1587/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1040 - val_loss: 0.0117 - val_mae: 0.1034\n",
            "Epoch 1588/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1050 - val_loss: 0.0099 - val_mae: 0.0967\n",
            "Epoch 1589/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1033 - val_loss: 0.0098 - val_mae: 0.0968\n",
            "Epoch 1590/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1034 - val_loss: 0.0117 - val_mae: 0.1059\n",
            "Epoch 1591/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1053 - val_loss: 0.0120 - val_mae: 0.1035\n",
            "Epoch 1592/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1032 - val_loss: 0.0116 - val_mae: 0.1029\n",
            "Epoch 1593/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1043 - val_loss: 0.0153 - val_mae: 0.1193\n",
            "Epoch 1594/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1048 - val_loss: 0.0120 - val_mae: 0.1069\n",
            "Epoch 1595/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1034 - val_loss: 0.0105 - val_mae: 0.0958\n",
            "Epoch 1596/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1042 - val_loss: 0.0129 - val_mae: 0.1087\n",
            "Epoch 1597/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1028 - val_loss: 0.0124 - val_mae: 0.1012\n",
            "Epoch 1598/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0112 - mae: 0.1048 - val_loss: 0.0128 - val_mae: 0.1109\n",
            "Epoch 1599/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1041 - val_loss: 0.0138 - val_mae: 0.1095\n",
            "Epoch 1600/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0105 - mae: 0.1012 - val_loss: 0.0120 - val_mae: 0.1062\n",
            "Epoch 1601/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1049 - val_loss: 0.0117 - val_mae: 0.1007\n",
            "Epoch 1602/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1036 - val_loss: 0.0137 - val_mae: 0.1050\n",
            "Epoch 1603/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1035 - val_loss: 0.0122 - val_mae: 0.1046\n",
            "Epoch 1604/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1044 - val_loss: 0.0104 - val_mae: 0.0992\n",
            "Epoch 1605/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1041 - val_loss: 0.0092 - val_mae: 0.0894\n",
            "Epoch 1606/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1035 - val_loss: 0.0114 - val_mae: 0.1042\n",
            "Epoch 1607/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1039 - val_loss: 0.0110 - val_mae: 0.0995\n",
            "Epoch 1608/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1031 - val_loss: 0.0137 - val_mae: 0.1129\n",
            "Epoch 1609/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1037 - val_loss: 0.0130 - val_mae: 0.1035\n",
            "Epoch 1610/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1045 - val_loss: 0.0140 - val_mae: 0.1157\n",
            "Epoch 1611/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1033 - val_loss: 0.0123 - val_mae: 0.1040\n",
            "Epoch 1612/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1039 - val_loss: 0.0102 - val_mae: 0.0963\n",
            "Epoch 1613/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1026 - val_loss: 0.0145 - val_mae: 0.1140\n",
            "Epoch 1614/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1045 - val_loss: 0.0129 - val_mae: 0.1094\n",
            "Epoch 1615/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1028 - val_loss: 0.0175 - val_mae: 0.1167\n",
            "Epoch 1616/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1042 - val_loss: 0.0113 - val_mae: 0.0947\n",
            "Epoch 1617/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1033 - val_loss: 0.0125 - val_mae: 0.1074\n",
            "Epoch 1618/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1034 - val_loss: 0.0136 - val_mae: 0.1115\n",
            "Epoch 1619/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1042 - val_loss: 0.0137 - val_mae: 0.1097\n",
            "Epoch 1620/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1021 - val_loss: 0.0155 - val_mae: 0.1187\n",
            "Epoch 1621/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0112 - mae: 0.1033 - val_loss: 0.0119 - val_mae: 0.1016\n",
            "Epoch 1622/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1040 - val_loss: 0.0091 - val_mae: 0.0910\n",
            "Epoch 1623/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1021 - val_loss: 0.0115 - val_mae: 0.1028\n",
            "Epoch 1624/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1042 - val_loss: 0.0119 - val_mae: 0.1060\n",
            "Epoch 1625/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1034 - val_loss: 0.0103 - val_mae: 0.0981\n",
            "Epoch 1626/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1031 - val_loss: 0.0112 - val_mae: 0.1019\n",
            "Epoch 1627/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1036 - val_loss: 0.0119 - val_mae: 0.1035\n",
            "Epoch 1628/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1036 - val_loss: 0.0128 - val_mae: 0.1089\n",
            "Epoch 1629/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1012 - val_loss: 0.0114 - val_mae: 0.1007\n",
            "Epoch 1630/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1043 - val_loss: 0.0138 - val_mae: 0.1084\n",
            "Epoch 1631/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1032 - val_loss: 0.0113 - val_mae: 0.0987\n",
            "Epoch 1632/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1037 - val_loss: 0.0110 - val_mae: 0.0979\n",
            "Epoch 1633/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1030 - val_loss: 0.0110 - val_mae: 0.0957\n",
            "Epoch 1634/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1040 - val_loss: 0.0131 - val_mae: 0.1070\n",
            "Epoch 1635/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1026 - val_loss: 0.0124 - val_mae: 0.1034\n",
            "Epoch 1636/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1025 - val_loss: 0.0116 - val_mae: 0.1036\n",
            "Epoch 1637/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1025 - val_loss: 0.0117 - val_mae: 0.0978\n",
            "Epoch 1638/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.1050 - val_loss: 0.0163 - val_mae: 0.1237\n",
            "Epoch 1639/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1021 - val_loss: 0.0109 - val_mae: 0.0959\n",
            "Epoch 1640/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1041 - val_loss: 0.0089 - val_mae: 0.0883\n",
            "Epoch 1641/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.1026 - val_loss: 0.0143 - val_mae: 0.1131\n",
            "Epoch 1642/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.1020 - val_loss: 0.0101 - val_mae: 0.0936\n",
            "Epoch 1643/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1037 - val_loss: 0.0116 - val_mae: 0.1041\n",
            "Epoch 1644/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.1036 - val_loss: 0.0103 - val_mae: 0.0964\n",
            "Epoch 1645/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.1020 - val_loss: 0.0132 - val_mae: 0.1020\n",
            "Epoch 1646/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1038 - val_loss: 0.0114 - val_mae: 0.1017\n",
            "Epoch 1647/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1038 - val_loss: 0.0091 - val_mae: 0.0896\n",
            "Epoch 1648/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1024 - val_loss: 0.0127 - val_mae: 0.1082\n",
            "Epoch 1649/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1016 - val_loss: 0.0118 - val_mae: 0.0945\n",
            "Epoch 1650/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1034 - val_loss: 0.0140 - val_mae: 0.1125\n",
            "Epoch 1651/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1018 - val_loss: 0.0158 - val_mae: 0.1162\n",
            "Epoch 1652/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1036 - val_loss: 0.0158 - val_mae: 0.1151\n",
            "Epoch 1653/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1036 - val_loss: 0.0110 - val_mae: 0.0961\n",
            "Epoch 1654/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1035 - val_loss: 0.0183 - val_mae: 0.1310\n",
            "Epoch 1655/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1005 - val_loss: 0.0135 - val_mae: 0.1081\n",
            "Epoch 1656/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1035 - val_loss: 0.0111 - val_mae: 0.0970\n",
            "Epoch 1657/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0111 - mae: 0.1038 - val_loss: 0.0139 - val_mae: 0.1129\n",
            "Epoch 1658/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1011 - val_loss: 0.0146 - val_mae: 0.1133\n",
            "Epoch 1659/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1032 - val_loss: 0.0139 - val_mae: 0.1053\n",
            "Epoch 1660/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1028 - val_loss: 0.0133 - val_mae: 0.1094\n",
            "Epoch 1661/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1030 - val_loss: 0.0149 - val_mae: 0.1111\n",
            "Epoch 1662/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1031 - val_loss: 0.0112 - val_mae: 0.1011\n",
            "Epoch 1663/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1026 - val_loss: 0.0110 - val_mae: 0.0992\n",
            "Epoch 1664/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.1030 - val_loss: 0.0099 - val_mae: 0.0940\n",
            "Epoch 1665/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1027 - val_loss: 0.0129 - val_mae: 0.1059\n",
            "Epoch 1666/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1028 - val_loss: 0.0099 - val_mae: 0.0928\n",
            "Epoch 1667/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1027 - val_loss: 0.0117 - val_mae: 0.1016\n",
            "Epoch 1668/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1028 - val_loss: 0.0116 - val_mae: 0.1003\n",
            "Epoch 1669/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1012 - val_loss: 0.0138 - val_mae: 0.1111\n",
            "Epoch 1670/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1038 - val_loss: 0.0123 - val_mae: 0.1082\n",
            "Epoch 1671/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1032 - val_loss: 0.0126 - val_mae: 0.1077\n",
            "Epoch 1672/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1014 - val_loss: 0.0104 - val_mae: 0.0960\n",
            "Epoch 1673/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1032 - val_loss: 0.0154 - val_mae: 0.1076\n",
            "Epoch 1674/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1032 - val_loss: 0.0092 - val_mae: 0.0922\n",
            "Epoch 1675/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1021 - val_loss: 0.0127 - val_mae: 0.1021\n",
            "Epoch 1676/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.1030 - val_loss: 0.0115 - val_mae: 0.1024\n",
            "Epoch 1677/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1012 - val_loss: 0.0121 - val_mae: 0.1022\n",
            "Epoch 1678/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1025 - val_loss: 0.0112 - val_mae: 0.1037\n",
            "Epoch 1679/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1016 - val_loss: 0.0123 - val_mae: 0.1059\n",
            "Epoch 1680/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.1030 - val_loss: 0.0110 - val_mae: 0.1022\n",
            "Epoch 1681/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.1031 - val_loss: 0.0100 - val_mae: 0.0940\n",
            "Epoch 1682/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1014 - val_loss: 0.0122 - val_mae: 0.1041\n",
            "Epoch 1683/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1028 - val_loss: 0.0089 - val_mae: 0.0893\n",
            "Epoch 1684/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0105 - mae: 0.1015 - val_loss: 0.0108 - val_mae: 0.0968\n",
            "Epoch 1685/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1017 - val_loss: 0.0134 - val_mae: 0.1052\n",
            "Epoch 1686/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1022 - val_loss: 0.0125 - val_mae: 0.1018\n",
            "Epoch 1687/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1023 - val_loss: 0.0114 - val_mae: 0.0975\n",
            "Epoch 1688/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.1024 - val_loss: 0.0111 - val_mae: 0.1024\n",
            "Epoch 1689/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.1018 - val_loss: 0.0138 - val_mae: 0.1122\n",
            "Epoch 1690/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1023 - val_loss: 0.0139 - val_mae: 0.1086\n",
            "Epoch 1691/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.1020 - val_loss: 0.0098 - val_mae: 0.0881\n",
            "Epoch 1692/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1018 - val_loss: 0.0129 - val_mae: 0.1094\n",
            "Epoch 1693/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1025 - val_loss: 0.0117 - val_mae: 0.0940\n",
            "Epoch 1694/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.1027 - val_loss: 0.0127 - val_mae: 0.1001\n",
            "Epoch 1695/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1014 - val_loss: 0.0134 - val_mae: 0.1091\n",
            "Epoch 1696/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1023 - val_loss: 0.0132 - val_mae: 0.1093\n",
            "Epoch 1697/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.1021 - val_loss: 0.0138 - val_mae: 0.1104\n",
            "Epoch 1698/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1020 - val_loss: 0.0095 - val_mae: 0.0940\n",
            "Epoch 1699/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1008 - val_loss: 0.0130 - val_mae: 0.1037\n",
            "Epoch 1700/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.1036 - val_loss: 0.0110 - val_mae: 0.0975\n",
            "Epoch 1701/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1018 - val_loss: 0.0116 - val_mae: 0.1016\n",
            "Epoch 1702/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1018 - val_loss: 0.0135 - val_mae: 0.1066\n",
            "Epoch 1703/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.1003 - val_loss: 0.0109 - val_mae: 0.1008\n",
            "Epoch 1704/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1023 - val_loss: 0.0087 - val_mae: 0.0800\n",
            "Epoch 1705/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1017 - val_loss: 0.0134 - val_mae: 0.1080\n",
            "Epoch 1706/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1019 - val_loss: 0.0130 - val_mae: 0.1062\n",
            "Epoch 1707/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1012 - val_loss: 0.0103 - val_mae: 0.0973\n",
            "Epoch 1708/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1017 - val_loss: 0.0126 - val_mae: 0.1031\n",
            "Epoch 1709/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1014 - val_loss: 0.0113 - val_mae: 0.0977\n",
            "Epoch 1710/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.1040 - val_loss: 0.0124 - val_mae: 0.1080\n",
            "Epoch 1711/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0101 - mae: 0.0992 - val_loss: 0.0122 - val_mae: 0.1008\n",
            "Epoch 1712/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0106 - mae: 0.1023 - val_loss: 0.0118 - val_mae: 0.1058\n",
            "Epoch 1713/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1013 - val_loss: 0.0093 - val_mae: 0.0931\n",
            "Epoch 1714/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1022 - val_loss: 0.0115 - val_mae: 0.1039\n",
            "Epoch 1715/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1015 - val_loss: 0.0097 - val_mae: 0.0951\n",
            "Epoch 1716/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.1023 - val_loss: 0.0134 - val_mae: 0.1094\n",
            "Epoch 1717/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1016 - val_loss: 0.0146 - val_mae: 0.1102\n",
            "Epoch 1718/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1001 - val_loss: 0.0107 - val_mae: 0.0962\n",
            "Epoch 1719/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1028 - val_loss: 0.0134 - val_mae: 0.1095\n",
            "Epoch 1720/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1010 - val_loss: 0.0104 - val_mae: 0.0971\n",
            "Epoch 1721/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0107 - mae: 0.1026 - val_loss: 0.0157 - val_mae: 0.1083\n",
            "Epoch 1722/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1013 - val_loss: 0.0115 - val_mae: 0.1001\n",
            "Epoch 1723/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1016 - val_loss: 0.0112 - val_mae: 0.0994\n",
            "Epoch 1724/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1017 - val_loss: 0.0098 - val_mae: 0.0948\n",
            "Epoch 1725/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1018 - val_loss: 0.0124 - val_mae: 0.1017\n",
            "Epoch 1726/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1011 - val_loss: 0.0107 - val_mae: 0.1006\n",
            "Epoch 1727/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1014 - val_loss: 0.0129 - val_mae: 0.1064\n",
            "Epoch 1728/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.1025 - val_loss: 0.0135 - val_mae: 0.1098\n",
            "Epoch 1729/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1007 - val_loss: 0.0133 - val_mae: 0.1033\n",
            "Epoch 1730/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1013 - val_loss: 0.0104 - val_mae: 0.0963\n",
            "Epoch 1731/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1012 - val_loss: 0.0126 - val_mae: 0.1042\n",
            "Epoch 1732/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1005 - val_loss: 0.0113 - val_mae: 0.0988\n",
            "Epoch 1733/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1011 - val_loss: 0.0147 - val_mae: 0.1076\n",
            "Epoch 1734/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1020 - val_loss: 0.0129 - val_mae: 0.1044\n",
            "Epoch 1735/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1011 - val_loss: 0.0147 - val_mae: 0.1094\n",
            "Epoch 1736/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1014 - val_loss: 0.0088 - val_mae: 0.0877\n",
            "Epoch 1737/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1004 - val_loss: 0.0098 - val_mae: 0.0918\n",
            "Epoch 1738/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1017 - val_loss: 0.0114 - val_mae: 0.1005\n",
            "Epoch 1739/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.1008 - val_loss: 0.0111 - val_mae: 0.0901\n",
            "Epoch 1740/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.1017 - val_loss: 0.0115 - val_mae: 0.1040\n",
            "Epoch 1741/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.1012 - val_loss: 0.0114 - val_mae: 0.1000\n",
            "Epoch 1742/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.1019 - val_loss: 0.0123 - val_mae: 0.1027\n",
            "Epoch 1743/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1012 - val_loss: 0.0118 - val_mae: 0.0995\n",
            "Epoch 1744/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1008 - val_loss: 0.0099 - val_mae: 0.0956\n",
            "Epoch 1745/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1018 - val_loss: 0.0164 - val_mae: 0.1132\n",
            "Epoch 1746/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1011 - val_loss: 0.0106 - val_mae: 0.0980\n",
            "Epoch 1747/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1008 - val_loss: 0.0120 - val_mae: 0.0993\n",
            "Epoch 1748/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1010 - val_loss: 0.0112 - val_mae: 0.0992\n",
            "Epoch 1749/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1012 - val_loss: 0.0109 - val_mae: 0.0911\n",
            "Epoch 1750/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1005 - val_loss: 0.0120 - val_mae: 0.1049\n",
            "Epoch 1751/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1012 - val_loss: 0.0159 - val_mae: 0.1082\n",
            "Epoch 1752/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1017 - val_loss: 0.0096 - val_mae: 0.0926\n",
            "Epoch 1753/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1008 - val_loss: 0.0127 - val_mae: 0.1000\n",
            "Epoch 1754/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.0993 - val_loss: 0.0136 - val_mae: 0.1087\n",
            "Epoch 1755/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.1023 - val_loss: 0.0119 - val_mae: 0.0999\n",
            "Epoch 1756/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1012 - val_loss: 0.0104 - val_mae: 0.0966\n",
            "Epoch 1757/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1011 - val_loss: 0.0145 - val_mae: 0.1075\n",
            "Epoch 1758/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1009 - val_loss: 0.0123 - val_mae: 0.1065\n",
            "Epoch 1759/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.1008 - val_loss: 0.0136 - val_mae: 0.1049\n",
            "Epoch 1760/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1017 - val_loss: 0.0095 - val_mae: 0.0940\n",
            "Epoch 1761/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0986 - val_loss: 0.0157 - val_mae: 0.1189\n",
            "Epoch 1762/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0105 - mae: 0.1013 - val_loss: 0.0127 - val_mae: 0.1056\n",
            "Epoch 1763/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1015 - val_loss: 0.0130 - val_mae: 0.1065\n",
            "Epoch 1764/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1003 - val_loss: 0.0110 - val_mae: 0.0992\n",
            "Epoch 1765/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1017 - val_loss: 0.0171 - val_mae: 0.1150\n",
            "Epoch 1766/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0101 - mae: 0.0994 - val_loss: 0.0112 - val_mae: 0.0987\n",
            "Epoch 1767/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0108 - mae: 0.1027 - val_loss: 0.0147 - val_mae: 0.1110\n",
            "Epoch 1768/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.0998 - val_loss: 0.0105 - val_mae: 0.0982\n",
            "Epoch 1769/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.1003 - val_loss: 0.0135 - val_mae: 0.1049\n",
            "Epoch 1770/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1009 - val_loss: 0.0128 - val_mae: 0.1058\n",
            "Epoch 1771/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1003 - val_loss: 0.0103 - val_mae: 0.0922\n",
            "Epoch 1772/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1011 - val_loss: 0.0110 - val_mae: 0.1011\n",
            "Epoch 1773/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0106 - mae: 0.1017 - val_loss: 0.0136 - val_mae: 0.1040\n",
            "Epoch 1774/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0998 - val_loss: 0.0101 - val_mae: 0.0953\n",
            "Epoch 1775/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1001 - val_loss: 0.0122 - val_mae: 0.1009\n",
            "Epoch 1776/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1004 - val_loss: 0.0128 - val_mae: 0.1069\n",
            "Epoch 1777/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0105 - mae: 0.1019 - val_loss: 0.0154 - val_mae: 0.1060\n",
            "Epoch 1778/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.0990 - val_loss: 0.0151 - val_mae: 0.1186\n",
            "Epoch 1779/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1000 - val_loss: 0.0112 - val_mae: 0.0989\n",
            "Epoch 1780/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1014 - val_loss: 0.0120 - val_mae: 0.1020\n",
            "Epoch 1781/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1004 - val_loss: 0.0131 - val_mae: 0.1034\n",
            "Epoch 1782/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1002 - val_loss: 0.0097 - val_mae: 0.0922\n",
            "Epoch 1783/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.1006 - val_loss: 0.0121 - val_mae: 0.0958\n",
            "Epoch 1784/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1009 - val_loss: 0.0096 - val_mae: 0.0932\n",
            "Epoch 1785/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0101 - mae: 0.0997 - val_loss: 0.0148 - val_mae: 0.1092\n",
            "Epoch 1786/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1004 - val_loss: 0.0089 - val_mae: 0.0892\n",
            "Epoch 1787/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1006 - val_loss: 0.0121 - val_mae: 0.1049\n",
            "Epoch 1788/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1005 - val_loss: 0.0121 - val_mae: 0.1044\n",
            "Epoch 1789/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1006 - val_loss: 0.0133 - val_mae: 0.1045\n",
            "Epoch 1790/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.0996 - val_loss: 0.0156 - val_mae: 0.1189\n",
            "Epoch 1791/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1009 - val_loss: 0.0115 - val_mae: 0.0957\n",
            "Epoch 1792/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0996 - val_loss: 0.0110 - val_mae: 0.1008\n",
            "Epoch 1793/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1004 - val_loss: 0.0099 - val_mae: 0.0931\n",
            "Epoch 1794/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1008 - val_loss: 0.0128 - val_mae: 0.1078\n",
            "Epoch 1795/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.0998 - val_loss: 0.0098 - val_mae: 0.0910\n",
            "Epoch 1796/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.0999 - val_loss: 0.0141 - val_mae: 0.1101\n",
            "Epoch 1797/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0101 - mae: 0.0999 - val_loss: 0.0145 - val_mae: 0.1066\n",
            "Epoch 1798/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.1016 - val_loss: 0.0111 - val_mae: 0.1024\n",
            "Epoch 1799/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0993 - val_loss: 0.0115 - val_mae: 0.1029\n",
            "Epoch 1800/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0106 - mae: 0.1016 - val_loss: 0.0114 - val_mae: 0.0953\n",
            "Epoch 1801/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0988 - val_loss: 0.0184 - val_mae: 0.1233\n",
            "Epoch 1802/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.0999 - val_loss: 0.0110 - val_mae: 0.0969\n",
            "Epoch 1803/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1011 - val_loss: 0.0084 - val_mae: 0.0833\n",
            "Epoch 1804/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0987 - val_loss: 0.0109 - val_mae: 0.0980\n",
            "Epoch 1805/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1003 - val_loss: 0.0127 - val_mae: 0.1035\n",
            "Epoch 1806/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.0999 - val_loss: 0.0125 - val_mae: 0.1069\n",
            "Epoch 1807/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0101 - mae: 0.0996 - val_loss: 0.0122 - val_mae: 0.0991\n",
            "Epoch 1808/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0999 - val_loss: 0.0123 - val_mae: 0.1043\n",
            "Epoch 1809/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1007 - val_loss: 0.0124 - val_mae: 0.1037\n",
            "Epoch 1810/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1001 - val_loss: 0.0106 - val_mae: 0.0954\n",
            "Epoch 1811/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1003 - val_loss: 0.0114 - val_mae: 0.0991\n",
            "Epoch 1812/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.1003 - val_loss: 0.0130 - val_mae: 0.1030\n",
            "Epoch 1813/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0992 - val_loss: 0.0122 - val_mae: 0.1028\n",
            "Epoch 1814/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0105 - mae: 0.1011 - val_loss: 0.0127 - val_mae: 0.1069\n",
            "Epoch 1815/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0994 - val_loss: 0.0146 - val_mae: 0.1086\n",
            "Epoch 1816/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0101 - mae: 0.1001 - val_loss: 0.0128 - val_mae: 0.1002\n",
            "Epoch 1817/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1003 - val_loss: 0.0103 - val_mae: 0.0940\n",
            "Epoch 1818/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.1000 - val_loss: 0.0105 - val_mae: 0.0966\n",
            "Epoch 1819/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1011 - val_loss: 0.0106 - val_mae: 0.0966\n",
            "Epoch 1820/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0984 - val_loss: 0.0131 - val_mae: 0.1086\n",
            "Epoch 1821/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.1008 - val_loss: 0.0100 - val_mae: 0.0864\n",
            "Epoch 1822/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0993 - val_loss: 0.0131 - val_mae: 0.1072\n",
            "Epoch 1823/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1011 - val_loss: 0.0123 - val_mae: 0.0992\n",
            "Epoch 1824/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0995 - val_loss: 0.0114 - val_mae: 0.1017\n",
            "Epoch 1825/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1003 - val_loss: 0.0149 - val_mae: 0.1005\n",
            "Epoch 1826/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.0992 - val_loss: 0.0094 - val_mae: 0.0885\n",
            "Epoch 1827/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.1007 - val_loss: 0.0140 - val_mae: 0.1082\n",
            "Epoch 1828/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0992 - val_loss: 0.0122 - val_mae: 0.1035\n",
            "Epoch 1829/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1006 - val_loss: 0.0105 - val_mae: 0.0933\n",
            "Epoch 1830/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.1002 - val_loss: 0.0124 - val_mae: 0.1026\n",
            "Epoch 1831/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1000 - val_loss: 0.0131 - val_mae: 0.1009\n",
            "Epoch 1832/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0991 - val_loss: 0.0122 - val_mae: 0.0999\n",
            "Epoch 1833/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0993 - val_loss: 0.0140 - val_mae: 0.1132\n",
            "Epoch 1834/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1007 - val_loss: 0.0103 - val_mae: 0.0960\n",
            "Epoch 1835/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0993 - val_loss: 0.0144 - val_mae: 0.1035\n",
            "Epoch 1836/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1010 - val_loss: 0.0090 - val_mae: 0.0859\n",
            "Epoch 1837/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0975 - val_loss: 0.0139 - val_mae: 0.1096\n",
            "Epoch 1838/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1007 - val_loss: 0.0103 - val_mae: 0.0984\n",
            "Epoch 1839/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0996 - val_loss: 0.0111 - val_mae: 0.0954\n",
            "Epoch 1840/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0990 - val_loss: 0.0116 - val_mae: 0.0985\n",
            "Epoch 1841/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.1000 - val_loss: 0.0128 - val_mae: 0.0998\n",
            "Epoch 1842/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1005 - val_loss: 0.0111 - val_mae: 0.0987\n",
            "Epoch 1843/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0988 - val_loss: 0.0127 - val_mae: 0.1079\n",
            "Epoch 1844/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1002 - val_loss: 0.0105 - val_mae: 0.0998\n",
            "Epoch 1845/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.1002 - val_loss: 0.0098 - val_mae: 0.0929\n",
            "Epoch 1846/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1000 - val_loss: 0.0118 - val_mae: 0.1039\n",
            "Epoch 1847/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0984 - val_loss: 0.0121 - val_mae: 0.1030\n",
            "Epoch 1848/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0997 - val_loss: 0.0110 - val_mae: 0.0977\n",
            "Epoch 1849/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.1009 - val_loss: 0.0119 - val_mae: 0.0953\n",
            "Epoch 1850/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0981 - val_loss: 0.0108 - val_mae: 0.0925\n",
            "Epoch 1851/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1004 - val_loss: 0.0126 - val_mae: 0.1036\n",
            "Epoch 1852/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0991 - val_loss: 0.0114 - val_mae: 0.0957\n",
            "Epoch 1853/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0990 - val_loss: 0.0150 - val_mae: 0.1119\n",
            "Epoch 1854/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0999 - val_loss: 0.0101 - val_mae: 0.0909\n",
            "Epoch 1855/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0991 - val_loss: 0.0129 - val_mae: 0.0968\n",
            "Epoch 1856/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0996 - val_loss: 0.0109 - val_mae: 0.1011\n",
            "Epoch 1857/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0992 - val_loss: 0.0116 - val_mae: 0.0999\n",
            "Epoch 1858/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0102 - mae: 0.1000 - val_loss: 0.0108 - val_mae: 0.0922\n",
            "Epoch 1859/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0979 - val_loss: 0.0171 - val_mae: 0.1162\n",
            "Epoch 1860/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0101 - mae: 0.0996 - val_loss: 0.0100 - val_mae: 0.0959\n",
            "Epoch 1861/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0981 - val_loss: 0.0101 - val_mae: 0.0905\n",
            "Epoch 1862/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.1005 - val_loss: 0.0121 - val_mae: 0.1003\n",
            "Epoch 1863/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0982 - val_loss: 0.0178 - val_mae: 0.1185\n",
            "Epoch 1864/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0101 - mae: 0.0993 - val_loss: 0.0105 - val_mae: 0.0922\n",
            "Epoch 1865/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0987 - val_loss: 0.0145 - val_mae: 0.1125\n",
            "Epoch 1866/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0099 - mae: 0.0991 - val_loss: 0.0109 - val_mae: 0.0985\n",
            "Epoch 1867/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0988 - val_loss: 0.0155 - val_mae: 0.1105\n",
            "Epoch 1868/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0994 - val_loss: 0.0096 - val_mae: 0.0933\n",
            "Epoch 1869/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0098 - mae: 0.0985 - val_loss: 0.0111 - val_mae: 0.0947\n",
            "Epoch 1870/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0994 - val_loss: 0.0120 - val_mae: 0.0969\n",
            "Epoch 1871/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0989 - val_loss: 0.0116 - val_mae: 0.0936\n",
            "Epoch 1872/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0977 - val_loss: 0.0134 - val_mae: 0.1092\n",
            "Epoch 1873/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0103 - mae: 0.1006 - val_loss: 0.0107 - val_mae: 0.0973\n",
            "Epoch 1874/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0970 - val_loss: 0.0108 - val_mae: 0.0983\n",
            "Epoch 1875/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0995 - val_loss: 0.0105 - val_mae: 0.0947\n",
            "Epoch 1876/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0981 - val_loss: 0.0107 - val_mae: 0.0991\n",
            "Epoch 1877/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0993 - val_loss: 0.0111 - val_mae: 0.0980\n",
            "Epoch 1878/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0987 - val_loss: 0.0134 - val_mae: 0.1084\n",
            "Epoch 1879/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0990 - val_loss: 0.0113 - val_mae: 0.0992\n",
            "Epoch 1880/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0987 - val_loss: 0.0097 - val_mae: 0.0943\n",
            "Epoch 1881/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0989 - val_loss: 0.0138 - val_mae: 0.1073\n",
            "Epoch 1882/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0986 - val_loss: 0.0086 - val_mae: 0.0855\n",
            "Epoch 1883/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0989 - val_loss: 0.0131 - val_mae: 0.1090\n",
            "Epoch 1884/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0975 - val_loss: 0.0119 - val_mae: 0.1024\n",
            "Epoch 1885/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0997 - val_loss: 0.0151 - val_mae: 0.1121\n",
            "Epoch 1886/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0988 - val_loss: 0.0096 - val_mae: 0.0924\n",
            "Epoch 1887/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0984 - val_loss: 0.0123 - val_mae: 0.1017\n",
            "Epoch 1888/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0990 - val_loss: 0.0095 - val_mae: 0.0877\n",
            "Epoch 1889/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0984 - val_loss: 0.0135 - val_mae: 0.1008\n",
            "Epoch 1890/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0980 - val_loss: 0.0109 - val_mae: 0.0971\n",
            "Epoch 1891/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0993 - val_loss: 0.0127 - val_mae: 0.1013\n",
            "Epoch 1892/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0981 - val_loss: 0.0105 - val_mae: 0.0916\n",
            "Epoch 1893/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0995 - val_loss: 0.0146 - val_mae: 0.1091\n",
            "Epoch 1894/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0984 - val_loss: 0.0096 - val_mae: 0.0931\n",
            "Epoch 1895/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0974 - val_loss: 0.0114 - val_mae: 0.0953\n",
            "Epoch 1896/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0988 - val_loss: 0.0129 - val_mae: 0.1055\n",
            "Epoch 1897/2000\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0099 - mae: 0.0986 - val_loss: 0.0121 - val_mae: 0.0989\n",
            "Epoch 1898/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0981 - val_loss: 0.0122 - val_mae: 0.1022\n",
            "Epoch 1899/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0994 - val_loss: 0.0116 - val_mae: 0.1006\n",
            "Epoch 1900/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0972 - val_loss: 0.0103 - val_mae: 0.0899\n",
            "Epoch 1901/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0987 - val_loss: 0.0140 - val_mae: 0.1028\n",
            "Epoch 1902/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0980 - val_loss: 0.0120 - val_mae: 0.1009\n",
            "Epoch 1903/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0993 - val_loss: 0.0112 - val_mae: 0.1008\n",
            "Epoch 1904/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0977 - val_loss: 0.0107 - val_mae: 0.0944\n",
            "Epoch 1905/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0982 - val_loss: 0.0126 - val_mae: 0.0997\n",
            "Epoch 1906/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0980 - val_loss: 0.0105 - val_mae: 0.0982\n",
            "Epoch 1907/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0985 - val_loss: 0.0108 - val_mae: 0.0943\n",
            "Epoch 1908/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0981 - val_loss: 0.0113 - val_mae: 0.1012\n",
            "Epoch 1909/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0983 - val_loss: 0.0116 - val_mae: 0.0932\n",
            "Epoch 1910/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0979 - val_loss: 0.0096 - val_mae: 0.0899\n",
            "Epoch 1911/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0977 - val_loss: 0.0139 - val_mae: 0.1036\n",
            "Epoch 1912/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0981 - val_loss: 0.0120 - val_mae: 0.1013\n",
            "Epoch 1913/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0980 - val_loss: 0.0103 - val_mae: 0.0895\n",
            "Epoch 1914/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0982 - val_loss: 0.0100 - val_mae: 0.0941\n",
            "Epoch 1915/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0979 - val_loss: 0.0130 - val_mae: 0.1058\n",
            "Epoch 1916/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0986 - val_loss: 0.0133 - val_mae: 0.1024\n",
            "Epoch 1917/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0976 - val_loss: 0.0109 - val_mae: 0.0946\n",
            "Epoch 1918/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0985 - val_loss: 0.0101 - val_mae: 0.0906\n",
            "Epoch 1919/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0974 - val_loss: 0.0146 - val_mae: 0.1022\n",
            "Epoch 1920/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0984 - val_loss: 0.0098 - val_mae: 0.0948\n",
            "Epoch 1921/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0979 - val_loss: 0.0113 - val_mae: 0.1020\n",
            "Epoch 1922/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0981 - val_loss: 0.0102 - val_mae: 0.0978\n",
            "Epoch 1923/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0969 - val_loss: 0.0130 - val_mae: 0.1046\n",
            "Epoch 1924/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0974 - val_loss: 0.0101 - val_mae: 0.0949\n",
            "Epoch 1925/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0985 - val_loss: 0.0123 - val_mae: 0.1045\n",
            "Epoch 1926/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0975 - val_loss: 0.0114 - val_mae: 0.1037\n",
            "Epoch 1927/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0979 - val_loss: 0.0100 - val_mae: 0.0918\n",
            "Epoch 1928/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0970 - val_loss: 0.0112 - val_mae: 0.0999\n",
            "Epoch 1929/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0984 - val_loss: 0.0118 - val_mae: 0.0975\n",
            "Epoch 1930/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0973 - val_loss: 0.0126 - val_mae: 0.1068\n",
            "Epoch 1931/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0971 - val_loss: 0.0141 - val_mae: 0.1091\n",
            "Epoch 1932/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0973 - val_loss: 0.0144 - val_mae: 0.1136\n",
            "Epoch 1933/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0982 - val_loss: 0.0120 - val_mae: 0.1019\n",
            "Epoch 1934/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0982 - val_loss: 0.0114 - val_mae: 0.1018\n",
            "Epoch 1935/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0968 - val_loss: 0.0124 - val_mae: 0.1059\n",
            "Epoch 1936/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0990 - val_loss: 0.0120 - val_mae: 0.1024\n",
            "Epoch 1937/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0976 - val_loss: 0.0108 - val_mae: 0.0998\n",
            "Epoch 1938/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0978 - val_loss: 0.0085 - val_mae: 0.0866\n",
            "Epoch 1939/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0977 - val_loss: 0.0119 - val_mae: 0.1029\n",
            "Epoch 1940/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0977 - val_loss: 0.0086 - val_mae: 0.0864\n",
            "Epoch 1941/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0980 - val_loss: 0.0093 - val_mae: 0.0907\n",
            "Epoch 1942/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0978 - val_loss: 0.0112 - val_mae: 0.0997\n",
            "Epoch 1943/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0092 - mae: 0.0953 - val_loss: 0.0098 - val_mae: 0.0925\n",
            "Epoch 1944/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0987 - val_loss: 0.0100 - val_mae: 0.0917\n",
            "Epoch 1945/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0987 - val_loss: 0.0113 - val_mae: 0.0905\n",
            "Epoch 1946/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0092 - mae: 0.0953 - val_loss: 0.0126 - val_mae: 0.1051\n",
            "Epoch 1947/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0096 - mae: 0.0974 - val_loss: 0.0136 - val_mae: 0.1037\n",
            "Epoch 1948/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0992 - val_loss: 0.0111 - val_mae: 0.0933\n",
            "Epoch 1949/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0095 - mae: 0.0967 - val_loss: 0.0142 - val_mae: 0.1105\n",
            "Epoch 1950/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0969 - val_loss: 0.0115 - val_mae: 0.0982\n",
            "Epoch 1951/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0979 - val_loss: 0.0119 - val_mae: 0.1020\n",
            "Epoch 1952/2000\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0096 - mae: 0.0975 - val_loss: 0.0104 - val_mae: 0.0980\n",
            "Epoch 1953/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0977 - val_loss: 0.0113 - val_mae: 0.0901\n",
            "Epoch 1954/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0096 - mae: 0.0970 - val_loss: 0.0087 - val_mae: 0.0848\n",
            "Epoch 1955/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0978 - val_loss: 0.0118 - val_mae: 0.0961\n",
            "Epoch 1956/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0094 - mae: 0.0963 - val_loss: 0.0097 - val_mae: 0.0923\n",
            "Epoch 1957/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0969 - val_loss: 0.0111 - val_mae: 0.0979\n",
            "Epoch 1958/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0975 - val_loss: 0.0100 - val_mae: 0.0942\n",
            "Epoch 1959/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0978 - val_loss: 0.0092 - val_mae: 0.0875\n",
            "Epoch 1960/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0975 - val_loss: 0.0128 - val_mae: 0.1067\n",
            "Epoch 1961/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0095 - mae: 0.0970 - val_loss: 0.0121 - val_mae: 0.1007\n",
            "Epoch 1962/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0971 - val_loss: 0.0117 - val_mae: 0.0977\n",
            "Epoch 1963/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0988 - val_loss: 0.0087 - val_mae: 0.0840\n",
            "Epoch 1964/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0093 - mae: 0.0954 - val_loss: 0.0121 - val_mae: 0.1003\n",
            "Epoch 1965/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0096 - mae: 0.0975 - val_loss: 0.0129 - val_mae: 0.0945\n",
            "Epoch 1966/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0986 - val_loss: 0.0127 - val_mae: 0.1024\n",
            "Epoch 1967/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0963 - val_loss: 0.0113 - val_mae: 0.0973\n",
            "Epoch 1968/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0971 - val_loss: 0.0130 - val_mae: 0.1089\n",
            "Epoch 1969/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0971 - val_loss: 0.0112 - val_mae: 0.0953\n",
            "Epoch 1970/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0096 - mae: 0.0974 - val_loss: 0.0130 - val_mae: 0.1035\n",
            "Epoch 1971/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0096 - mae: 0.0975 - val_loss: 0.0095 - val_mae: 0.0909\n",
            "Epoch 1972/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0969 - val_loss: 0.0115 - val_mae: 0.0954\n",
            "Epoch 1973/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0969 - val_loss: 0.0118 - val_mae: 0.0976\n",
            "Epoch 1974/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0973 - val_loss: 0.0099 - val_mae: 0.0949\n",
            "Epoch 1975/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0960 - val_loss: 0.0140 - val_mae: 0.1086\n",
            "Epoch 1976/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0976 - val_loss: 0.0094 - val_mae: 0.0890\n",
            "Epoch 1977/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0096 - mae: 0.0971 - val_loss: 0.0163 - val_mae: 0.1148\n",
            "Epoch 1978/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0959 - val_loss: 0.0088 - val_mae: 0.0862\n",
            "Epoch 1979/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0973 - val_loss: 0.0079 - val_mae: 0.0773\n",
            "Epoch 1980/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0095 - mae: 0.0960 - val_loss: 0.0117 - val_mae: 0.0993\n",
            "Epoch 1981/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0968 - val_loss: 0.0108 - val_mae: 0.0923\n",
            "Epoch 1982/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0965 - val_loss: 0.0123 - val_mae: 0.1034\n",
            "Epoch 1983/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0974 - val_loss: 0.0144 - val_mae: 0.1113\n",
            "Epoch 1984/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0972 - val_loss: 0.0105 - val_mae: 0.0986\n",
            "Epoch 1985/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0975 - val_loss: 0.0113 - val_mae: 0.1008\n",
            "Epoch 1986/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0093 - mae: 0.0957 - val_loss: 0.0102 - val_mae: 0.0956\n",
            "Epoch 1987/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0974 - val_loss: 0.0110 - val_mae: 0.0995\n",
            "Epoch 1988/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0966 - val_loss: 0.0147 - val_mae: 0.1114\n",
            "Epoch 1989/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0968 - val_loss: 0.0099 - val_mae: 0.0918\n",
            "Epoch 1990/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0966 - val_loss: 0.0116 - val_mae: 0.1044\n",
            "Epoch 1991/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0968 - val_loss: 0.0132 - val_mae: 0.1068\n",
            "Epoch 1992/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0976 - val_loss: 0.0107 - val_mae: 0.0952\n",
            "Epoch 1993/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0975 - val_loss: 0.0111 - val_mae: 0.0956\n",
            "Epoch 1994/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0971 - val_loss: 0.0098 - val_mae: 0.0958\n",
            "Epoch 1995/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0965 - val_loss: 0.0120 - val_mae: 0.0944\n",
            "Epoch 1996/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0099 - mae: 0.0982 - val_loss: 0.0077 - val_mae: 0.0835\n",
            "Epoch 1997/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0092 - mae: 0.0954 - val_loss: 0.0112 - val_mae: 0.0928\n",
            "Epoch 1998/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0971 - val_loss: 0.0120 - val_mae: 0.1044\n",
            "Epoch 1999/2000\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0093 - mae: 0.0952 - val_loss: 0.0126 - val_mae: 0.1013\n",
            "Epoch 2000/2000\n",
            "35/35 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0975 - val_loss: 0.0118 - val_mae: 0.1037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmc5bJy07Hjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "P7 = model7.predict(XTRAIN_d2)\n",
        "YTRAIN_d2_1=np.exp(YTRAIN_d2_1)\n",
        "P7=np.exp(P7)\n",
        "MAE7 = abs(YTRAIN_d2_1 - P7)\n",
        "print(MAE7)\n",
        "M6=MAE7.mean()\n",
        "print(\"M6=\",M6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85AodgUDNi4y",
        "colab_type": "code",
        "outputId": "0574541d-8e60-4b0c-fe80-e053cacbd78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "#learning curves for 3000 epochs\n",
        "import matplotlib.pyplot as plt \n",
        "plt.figure(figsize=(15, 13))\n",
        "plt.plot(history7.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history7.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "min(history7.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x936 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005372236482799053"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JC-oBijXCdX",
        "colab_type": "text"
      },
      "source": [
        "In the table below we compare the different values of mean MAE when when we have different layer models. As we can observe increasing the number of layers allowed more learning and a lower mean MAE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EckL3BXSIRXp",
        "colab_type": "text"
      },
      "source": [
        "Number of layers | number of neurons | epochs | mean MAE\n",
        "--- | --- | --- | ---\n",
        " 3 | 12,8,1 | 1000 |  400240.3264\n",
        " 6| 256,256,256,256,256,1 | 2000 | 392946.3185\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fESU6FSuUAOP",
        "colab_type": "text"
      },
      "source": [
        "In the table below, We compare different models minimum val_loss when we provide output variable as input variable and when we don't. Our neural network model without output variable as the input has minimum val_loss which is much higher than our neural network model with output variable as input variable. Our learning curves is also much smoother and without fluctuations than the learning curves observed before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjoyPWPUUzLS",
        "colab_type": "text"
      },
      "source": [
        "Neural network | Number of layers | minimum val_loss |mean MAE\n",
        "--- | --- | ---|---\n",
        "Without target output as input | 6 | 0.018305  |379906.062\n",
        "With target output as input | 6 | 0.005372 |345138.504\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4570YUKiS60",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing our neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTUg8hKRfALf",
        "colab_type": "text"
      },
      "source": [
        "The following piece of code was taken from a [stackoverflow answer](https://stackoverflow.com/questions/29888233/how-to-visualize-a-neural-network)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeTzesA0avOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from math import cos, sin, atan\n",
        "\n",
        "\n",
        "class Neuron():\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def draw(self, neuron_radius):\n",
        "        circle = pyplot.Circle((self.x, self.y), radius=neuron_radius, fill=False)\n",
        "        pyplot.gca().add_patch(circle)\n",
        "\n",
        "\n",
        "class Layer():\n",
        "    def __init__(self, network, number_of_neurons, number_of_neurons_in_widest_layer):\n",
        "        self.vertical_distance_between_layers = 6\n",
        "        self.horizontal_distance_between_neurons = 2\n",
        "        self.neuron_radius = 0.5\n",
        "        self.number_of_neurons_in_widest_layer = number_of_neurons_in_widest_layer\n",
        "        self.previous_layer = self.__get_previous_layer(network)\n",
        "        self.y = self.__calculate_layer_y_position()\n",
        "        self.neurons = self.__intialise_neurons(number_of_neurons)\n",
        "\n",
        "    def __intialise_neurons(self, number_of_neurons):\n",
        "        neurons = []\n",
        "        x = self.__calculate_left_margin_so_layer_is_centered(number_of_neurons)\n",
        "        for iteration in range(number_of_neurons):\n",
        "            neuron = Neuron(x, self.y)\n",
        "            neurons.append(neuron)\n",
        "            x += self.horizontal_distance_between_neurons\n",
        "        return neurons\n",
        "\n",
        "    def __calculate_left_margin_so_layer_is_centered(self, number_of_neurons):\n",
        "        return self.horizontal_distance_between_neurons * (self.number_of_neurons_in_widest_layer - number_of_neurons) / 2\n",
        "\n",
        "    def __calculate_layer_y_position(self):\n",
        "        if self.previous_layer:\n",
        "            return self.previous_layer.y + self.vertical_distance_between_layers\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def __get_previous_layer(self, network):\n",
        "        if len(network.layers) > 0:\n",
        "            return network.layers[-1]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def __line_between_two_neurons(self, neuron1, neuron2):\n",
        "        angle = atan((neuron2.x - neuron1.x) / float(neuron2.y - neuron1.y))\n",
        "        x_adjustment = self.neuron_radius * sin(angle)\n",
        "        y_adjustment = self.neuron_radius * cos(angle)\n",
        "        line = pyplot.Line2D((neuron1.x - x_adjustment, neuron2.x + x_adjustment), (neuron1.y - y_adjustment, neuron2.y + y_adjustment))\n",
        "        pyplot.gca().add_line(line)\n",
        "\n",
        "    def draw(self, layerType=0):\n",
        "        for neuron in self.neurons:\n",
        "            neuron.draw( self.neuron_radius )\n",
        "            if self.previous_layer:\n",
        "                for previous_layer_neuron in self.previous_layer.neurons:\n",
        "                    self.__line_between_two_neurons(neuron, previous_layer_neuron)\n",
        "        # write Text\n",
        "        x_text = self.number_of_neurons_in_widest_layer * self.horizontal_distance_between_neurons\n",
        "        if layerType == 0:\n",
        "            pyplot.text(x_text, self.y, 'Input Layer (L0)', fontsize = 12)\n",
        "        elif layerType == -1:\n",
        "            pyplot.text(x_text, self.y, 'Output Layer', fontsize = 12)\n",
        "        else:\n",
        "            pyplot.text(x_text, self.y, 'Hidden Layer (L'+str(layerType)+\")\", fontsize = 12)\n",
        "\n",
        "class NeuralNetwork():\n",
        "    def __init__(self, number_of_neurons_in_widest_layer):\n",
        "        self.number_of_neurons_in_widest_layer = number_of_neurons_in_widest_layer\n",
        "        self.layers = []\n",
        "        self.layertype = 0\n",
        "\n",
        "    def add_layer(self, number_of_neurons ):\n",
        "        layer = Layer(self, number_of_neurons, self.number_of_neurons_in_widest_layer)\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def draw(self):\n",
        "        pyplot.figure()\n",
        "        for i in range( len(self.layers) ):\n",
        "            layer = self.layers[i]\n",
        "            if i == len(self.layers)-1:\n",
        "                i = -1\n",
        "            layer.draw( i )\n",
        "        pyplot.axis('scaled')\n",
        "        pyplot.axis('off')\n",
        "        pyplot.title( 'Neural Network architecture', fontsize=15 )\n",
        "        pyplot.show()\n",
        "\n",
        "class DrawNN():\n",
        "    def __init__( self, neural_network ):\n",
        "        self.neural_network = neural_network\n",
        "\n",
        "    def draw( self ):\n",
        "        widest_layer = max( self.neural_network )\n",
        "        network = NeuralNetwork( widest_layer )\n",
        "        for l in self.neural_network:\n",
        "            network.add_layer(l)\n",
        "        network.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nxo47B1a2YQ",
        "colab_type": "code",
        "outputId": "7d658fef-a313-4e54-8733-287a97360054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "network = DrawNN( [5,12,8,1] )\n",
        "network.draw()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD5CAYAAAAndkJ4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydeZhcRdXGf6d7JjOTTPZACCFJB2QNsoqALIZFVBpBdhBEQDYVEZVlRD42AVtERFGURWWVHREYBBQNArLKnkCQpbMCIfs2yWz1/XFO5dZ0umd6ZrJMknqfp5+Zvreqbt26t8+pc85bp8Q5R0RERERERGp1dyAiIiIiomcgKoSIiIiICCAqhIiIiIgIQ1QIERERERFAVAgREREREYaoECIiIiIigB6iEETkIhFxIvJYkXP3isi41dCtdiEiGevzAR2Uc/bZteD41nZ8bCeve4SIHN/5Hq9YWN9PX9398OjE87hIRGYG3zezYwNWUr/O6ewzjohYXegRCiHAfiKy0+ruxErC+SuonSOA41dQW+sibgS+GHzfDLgQWCkKATgHGLuS2o6IWKHoSQphNvAG8OPV1QERSYtIr5XQ9DhgfxHZbiW0vUohIjVr8jWdc1Odc/9dUe2tSoiienX3I2LtRU9SCA64DDhQRD7dXkERGSkid4rIbBFZLCKPicjmwfmx5j7YuqDeOBG5N/h+k4i8JCJfFZHxwBJgZxEZJiJ/FJH3RaRBRN4RkUu7oSzuByZQhpUgIieJyHgRWSoik0TknLC/wKHA5wNX1EUicoKILBKRyqDsdBGZJSJi31MiMldETg7K7C0iz4vIEhH5WESuFZHa4Lwfxy+KyIMishD4TYl+by0iH4nIrSKSLlFmC3tuU+y5jReRM0UkFZQpeU0RGSUid4jITKv/uoh8reAyvUXkOhGZJyJTReTigvaXuYzMlfOQnfrArpsPyrb7nlmZGhG5wp7VUhH5QER+aufywGDgwuB5jS3l3vLvY2FfRWR3EXkRfT8Pt3N7iMiT1q9ZInKDiPQtNu4REeWiYnV3oAD3AJegVsJRxQqIyCDgaWAWcBqwGKgD/iEimznnGjp5zQxwhV33I+ADYAhqsfwAmIO6FS4C1gNO7WT7oMrucuBWEdnSOfdWsUIicraVuwK1KnYEfiIii51zvwF+AoxE3RvftmpTgWqgN7AD8LyIbAqsD7QCWwHjgW2B/sBTdq0xwKPA31ElMwLIARsDXyro2h+APwFXo0KpsN/bWzv3A6c551pLjMNwYCJwO7AA2A64GKgBftreNUVkfeBZ9HmfBUwBtrZ+h7gCuA84DNgHuMDu/+4i/XnZ2roSOAT4EFhq99The2bK9q/Aruiz+a/d4x7W/sHAv4B7UVcV6MRgUInxKYbewM12X+8A00VkN+AfwAN2n4PRZzfQvkdEdA3OudX+QYXtTPv/eKAF2My+3wuMC8r+BP2RDgqODQTmAd+x72NRIbx1wXXGAfcG32+yctt10L8K4GuoMOxlxzJW94AO6jrgdCANvAvcase3tnNj7Xs/YCFwYUF9r6jSxcYjKDcdOMv+PxEVTs+iAhrgDGBGUP5O4H++XTt2hPVp14Jx/GU797UzqjR/DUgnnrnYuJ4HvB8cL3pNVGEsAoaVaM8/j1sKjr8K3FnsXbPvB1i9TEG9ct6zL1rdA9u5z5nARSX6ekDB8ZuAlwr66oCDCso9Bfyr4NjeFHnn4yd+OvPpSS4jj9uAycCPSpzfF52NzheRChGpQGeb/wU+04XrTXPOvRoeEMWZIjJBRBqAJnRWW4XO0DsN51wLOos7WkQ2LlJkV6APcI+/L7u3fwJDgY06uMRTJDPTPYF/2yc89nRQ/rPAX6xfHvcBzcDuBW3Xl7jmbuizuN45d4Zzrt1MiSJSbS6cd9GZeBPqJhxt99reNfcGHnXOfdjeNYDHC75PoOOxK4Zy3rO9gdnOuQe70H65cMDf/BcR6Y2+K3cXvCdPo+O540rsS8Rajh6nEJxzzah5fKyIjCpSZAhwJPryh5+9WN59UA4+LnLsTNSN8BfgIFR4fsfOdSeodws6k68rcm6I/R1P2/v6lx3v6N6eAnY3N8Ye9j1UErvbd49hFNy7KYdZLO/SKDZGAPuhs/xbOuibx89QF831wP7ATsCldq5wXAuvORh16XSEuQXfG4u0XQ7Kec/K7VN3MMc51xh8H4ham9cW9GspUEnXfgMREUDPiyF4/BENwJ5b5Nxs4EHUpC/EAvvr/dyFQeCBqAkfotis9nDUtbSM8SQiW3XQ5w7hnGsUkZ+jyub+gtOz7e8BFBfAEzto/ilUkH8BGG3fm4HhIrIfamWECuFDNM6wDBYMHhz0ZVnXS1zzUnQm/biI7OGce7+DPh4OXOOcuyK4ZrZE2cJrzkKV2KpCOe9ZV/vU3vtZiMJxmGvHLgIeKVJ+ehf6ExEB9FCF4JxbKiJXon7j/6IzII8nUF/3eFc6gDzV/m6JBg4RkRHAFqjfvCPUYMHFAMeU1/sOcQMaND+n4PizQAOwoXOulIsGSs9430CFxY+Bt51znwCIyJt2bCHwSlD+eeBgETkvcBsdgr4ToWupPTShQcxHgCdEZHfn3LR2yrcZV1NARckDRfAEcIaIDHXOlbJYugI/+y4c03LesyeAc0TkAOfcw+20X9j2DHTstvQHRNldnwMmtddZ59wiEXkO2Nw5d0l7ZSMiOoseqRAM16EBx88BTwbHrwKOBf4pItcA09DZ7+eBp51zdzjnphp97ycishh1jZ3H8jPfUvg7KnyeB95DlcGnVsA94ZxbIiJXoe6T8PhcEbkI+JW5yv5t/d4M2Ms5d7AVfRs4SES+iiq+6c656c65VhF5BsiiY+fxFOru+ntBvOBSVEE8ICK/Q/3sPwMec84924n7aRCRr6Csl3+IyJ5eGRXB34HvWAxhtvWrqsxL/RI4DnhKRC5DWUZbAn1Ci6ML8JbXqSJyJ7DYOfcGZbxndj+PAX8WkUvQyccwYE/nnGejvQ1kReRRVClPdM4tEJG/At8XkUmoIv8hOiEoB+egCrgVJRksQGNbWeDHzrl3ujoYEes4VndU2+KQFxEwP4Lj56Hm8biC4xuilMSP0RlnHg1GjwnKfAplFS1Cf/QHUZxl9FKR69Za+7PtcyMJG2VrK5OhEyyjIu3PImAZBeeORa2iBpS98zzwg+D8EDS2MdvqXxScO9eOfS04dqQdu6BI3/ax9pegs9Zrgdrg/FhKMFcK7wt1d7yKCsX+JcZiqPV9vj27K4CTra3aMq45CrjLxmUx8BpwVHvPo/AZF3vXUGE8CXWx5Tv5ntWgLsCpVuYD4LLg/I7Ac+h7GLLKhqKU1fl27VPK6WtwbmeUNjzf2p6AKrGiYx8/8VPOR5yLW2hGRERERPRAllFERERExOpBVAgREREREUBUCBERERERhqgQIiIiIiKAqBAiIiIiIgxRIUREREREAFEhREREREQYokKIiIiIiACiQoiIiIiIMESFEBEREREBRIUQEREREWGICiEiImKFQUSOF5E3RGSxiHwkIr8TkQGdqJ8XkX1XYH/abU9ExorI1FLn1zVEhRAREbFCICI/RFOonw30B3ZBM9T+XUQKNwOKMNi+ID0CUSFEdAgRGS4ie4jIziLSnS1EI9ZSiEg/4GLgu865R51zTc65PLrJUAZN646I3CQilwb1ls3QReRWdF+Hh0RkoYicIyIZEXEicoqITBeRD0XkrKB+p9rr5D1lReQVEZkvIlNsvxJ/rl5EvltQ/nUROdj+30JE/i4is0VkoogcUdDn34nIIyKyCN2WtUcgKoSIkhCRXUTkIeB1IAf8DpgsIld0xg0QsU7gc+jOcG22hnXOLUR31PtCRw04574OTAa+4pyrdW03PtoL2BTdx/vcctxKHbRXDhahmzINQDcf+pZtTAVwM6bkAERkW2A4UC8ifdDNk/6MblN7FHBtwTa8XwMuA/pS/g6FKx1RIUQUhYgchO4p/FdghHNuN+fcDsCu6L7LT4nI4NXZx4gehSHoZj7NRc59aOe7g4udc4uc7mb3J+DobrbXIZxz45xzbzjnWp1zrwN3oDvmgf42NhORTe3714G7nHON6GZaeefcn5xzzc65V4D70D3FPf7qnHvG2l5CD0FUCBHLQUSGAX8A9nfO3eicW+zPOefeA05Ct478/WrqYkTPw0xgiIgU25Z3mJ3vDqYE/09Cd7NbqTAX6b9E5BMRmQechik2E+J3AceKSApVULda1VHAziIy13/QbXg3CJoP76fHICqEiGI4Cd1q9KViJ51us3chsLeIjFilPYvoqXgW3UL0kPCgiNQCXwaesEOLgN5BkVBIgm4zWgzhezYSmN7N9srBn1FLYIRzrj86AZLg/M2ooN8H3Yvb70U+BXjSOTcg+NQ65761gvq10hAVQkQxHIa+7CXhnFuE+osPaa9cxLoB59w8NKh8jYh8SUQqRSQD3I3uN+1nz68C+4vIIBHZADizoKmPgY2LXOL/RKS3iIwBTkBn591prw1EpLrgI6h/f7ZzbomIfBb1+4f3/CzQCvwiuD+Ah1F30tdtHCpFZCcR2bKjfqxuRIUQUQwDgI/KKPeRlY2IwIK25wFXAvOB59HZ8j7OuaVW7FbgNSAPPE4i2D1+CpxvrpazguNPAu+ilsaVzrnHu9leiOFAQ8FnE+DbwCUisgC4AFVuhbgF+DRwWzAOC9Dg91GoJfMRSsetKnH9HgNR6z8iIoGIvASc5Zwb10G5W4H/OOd+t0o6FrHOwayMD4DKEgHr1QoROQ44xTm3++ruy4pAtBAiiuH2VFWfUzN19SUXzPTf5bCRKJvivlXXrYiIngMR6Y1aEdev7r6sKEQLIWI5DMl+f0yvoZu8murd/7WK2kGfzeeyreH5kT+8fxvX0vRcw3svvlM7Zq8dCs9HRKwo9FQLQUS+iMbQ/gEc2pP61h1EhRDRBpm6+u2Ah51rHSqSqmieN2N6y5KFdVVDN/6Ha2kesPTDd06r6D/0pHSfATWSSgvqVz0+n8s2rOauR0REdBNRIUQsQ6auPosG5RqBga1NS9+SdOUWTbOntrYuXdxcPXyLqob8a4tqMtv2cc59aCsy+6GUw4Pyuewnq7P/ERER3UOMIUQAkKmr/y7KuZ4G1AJPpiqrRksqdVPl4BFLKwcMvd251gXVo7a5A5gvIuOBNPAesD3wfKauvsfT6iIiIkojKoR1HJm6+nSmrv5XwK+Bf6JpKd4HJgCVwC0i0jvdZ+CzIqnxIvIp4GpgX+BHKMf7aaAP8Gymrn7v1XEfERER3UdUCOswMnX1tcADwBnAb9F0ACngRHTxzy2otQCqICYAW6EKYT6a16UOVQ5/Rq2LxzJ19SesuruIiIhYUYgKYR1Fpq5+OPBvYH/gdGA0sDm6Svlw1Dq4DBhjVSYA49HsjWlUKRwKPIoqjjOBK4B/AX/M1NVfnqmrj+9XRMQahPiDXQdhTKLn0XTCB6DKwCuGt9AkXrfkc9n3UIUwLZ/LzkUVAnbMWwkXAKcAz6Dpsf8PuAF1J92RqauvWUW3FRER0U1EhbCOwZhET6PJtXZH3UQ/BH6Tz2V/D5xDYh2Auogm2P/+71b5XHYOiZWwOZrTaAbKzb7Y2jkCeCJTV7/eSr6tiIiIFYCoENYhBEyiicDO6DaHv0M38/h+pq5+GIF1YC6fLUksg6moVeDdSMushHwuOwM40Np8AI1JHEZkIEVErDGICmEdQAGT6GFgT5Ldrd4Hjsznss0sbx1k0NTC4wHyuaxDrYQx9n2ZlZCpq98mn8u+jmaE3BHdxOR+YCyRgRQRsUYgKoS1HAVMol+irp008BD6/L+Sz2XnFFoHVt1v+TchaHJCcBzaxhLI57IPosyjI1DL4XnUGokMpIiIHo6oENZiFDCJvpPPZX9gp+7AGEX5XPZ/dqzQOoC2DCOP8cD6mbr6IbC8lWBlfo4yjy7K1NUfns9l8+ieu5GBFBHRgxF/lGspCplE+Vz2Wjv1M4xRlM9l/2lli1kH0JZh5BEyjTwKrQRHwjy6OVNX/5l8LjsP3ag8MpAiInoookJYC1HIJMrnsn+z49+kLaPIo5h1AG0ZRh4TgnNAcSshn8v67RRnAH/N1NUPz+eyTcCpRAZSRESPRFQIaxkKmUT5XPY1O74nAaMoKF/UOijCMPIoZBp5tLESAAqZR5m6+t75XNblc9mfExlIERE9DlEhrCUoxiTK57LT7dzGLM8o8ihlHYwiYBh5BEyjrQqOF4slUMg8ytTVix2/j8hAiojoUYgKYS1AMSZRPpddZOf6UcAoCuqVih1A8YAywbFCCwGKWAmwPPMoOB4ZSBERPQhRIazhKMYkyueyLXYuTXFGkUcp6wDaVwhtmEYepawEQ8g8OiKokycykCIiegTiD28NRjtMIo8rKGAUBXXbsw5AXUKFDCOP8UGZQpSyEpZjHgXnIgMpIqIHICqENRSlmETB+W8CP2B5RpFHe9YBqIVQzDogOL6c26g9KyFgHn2MMY+Cc5GBFBGxmhEVwhqIUkyi4LxnFD1OwCgKzrdrHbTDMPIoxTTyKGolQBvmUT+MeRSciwykiIjViKgQ1iAUMIkeImASBWXaYxR5dGQdFGUYeZRiGgXn24sllGQeBefvQzffiQykiIhViKgQ1hAUYRId6plEQZlCRtFy/v8yYgfQfkCZ4FwpCwHasRIA8rnsQxRhHgXnXyAykCIiVimiQlgDUMAk+nbIJArKeEbRZhRnFHl0ZB1AeQqhKNPIoyMrwfBz4GYKmEdBG3kiAykiYpUh/rh6OIowiX5XoqhnFH23kFEUtFWOdQDtM4w82mMaeXRkJTg0kLwc8ygoExlIERGrCFEh9GB0xCQKynXEKPIoxzqA9hlGHiWZRh7lWAntMY+CMpGBFBGxChAVQg9FR0yioFy7jKKgXFnWQRkMI4+OmEYe7VoJ0D7zKCgTGUgRESsZUSH0MJTDJArKlsMo8ijXOmiXYeTREdMoKFdOLKFD5lFQLjKQIiJWEqJC6EEoh0kUlO2QURSULTd2AOUFlD06Yhp5dGglQMfMo6BcZCBFRKwERIXQQ1AOkygoWy6jyKNc6wA6pxDaZRp5lGslGNplHgVt5okMpIiIFYr4A+oB6ASTyKNDRlHQdmesAyiPYeRRDtPIo1wroUPmUVA2MpAiIlYgokJYzSiXSRSUL5dR5NEZ6wDKYxh5dMg08uiMlVAO8ygoGxlIERErCFEhrEaUyyQKypfFKArKd8o66ATDyKNcppFHWVYClMc8CspGBlJExApAVAirAZ1hEgV1OsMo8uisdVAWw8ijXKZRUL4zsYSymUdB+chAiojoBqJCWMXoDJMoqFM2oyio09nYAXQuoOxRLtPIo2wrAcpnHgXlIwMpIqKLiAphFaIzTKKgTmcZRR6dtQ6gawqhLKaRR2etBENZzKPgGnkiAykiotOIP5JVhC4wiTzKZhQF1+qKdQCdYxh5dIZp5NFZK6Fs5lFQJzKQIiI6iagQVgE6yyQK6nWWUeTRFesAOscw8iibaeTRFSuhM8yjoE5kIEVEdAJRIaxkdJZJFNTrFKMoqNcl66ALDCOPzjKNPDplJUDnmEdBnchAiogoE1EhrCR0hUkU1O0Ko8ijq9ZBpxhGHp1lGgX1uhJL6DTzKKjnGUi9iQykiIiiiAphJaCASXQVZTCJgrqdZhQFdbsaO4CuBZQ9Oss08ui0lQCdZx4F9TwDaSqRgRQRsRyiQljBKMIk+mFHTKKgblcZRR5dtQ4gmeF3RSF0imnk0VUrwdAp5lFwzUnAbkQGUkTEcog/hBWIbjCJPDrNKAqu3R3rAHSG31mGkUdXmEYeXbUSOs08Cup6BtL1RAZSRMQyRIWwglDAJNqtXCZRUL+rjCKP7lgH0DWGkUenmUYe3bESusI8Cuo2oQr0bCIDKSICiAphhaAIk+j1TtbvEqMoqN8t66AbDCMPzzTqioUAXbQSoGvMo6Cuy+eyVxIZSBERQFQI3UJ3mERBG91hFHl01zroEsPII2AadSWw3N1YQpeZR0H9yECKiCAqhC6jO0yioI0uM4qCNrobO4DuMYw8uqwQDF22EqDrzKOgfmQgRazziAqhC+gOkyhoo7uMIo/uWgfQPYaRR5eYRh7dtRIMXWIeBX2IDKSIdRrxZe8kVgCTyKPLjKKgLyvCOoDuMYw8usM08uiuldBl5lHQRmQgRayziAqhE+gukyhop7uMIo8VYR1A9xhGHl1mGnmsCCuhO8yjoI3IQIpYJxEVQpnoLpMoaKdbjKKgnRViHawAhpFHd5lGHt2yEqB7zKOgjchAWgkQkfEiMrbEubEiMrWdujeJyKUrrXM9ECLyUxE5s5ttVInI2yLS4aQmKoQOsCKYREFbK4JR5LGirINuMYw8uss0CtpZEbGEbjOPgnYiA6lMiEheRPYtOHa8iDztvzvnxjjnxq3yzrWDwj72FJgAPw64zr6XVJgicraIvCkiC0TkAxE5259zzi0F/oiSLtpFVAjtYEUwiYK2us0oCtpaUbEDWDEMI49uKwRDt60E6D7zKGgnMpAiVhpEUUwWHw884pxrKKcZVHkMBL4EnC4iRwXn/wx8Q0Sq2mtknVYIIrKTiPxRRF62z/Uisj10jUkkIikR+bKI3C8ir4nICyJyebrPwNF0kVEkItUi8nUReVxEXheRpxsmvXanc67L1oGIDBKRH4jI03OfueMGgGk3nLqNiFR3pT1rc9SC1x4dBayfrh34po3Bl0u86O0itBJqMtvfGzyfP4rITp1sbhnzaNQ5Dx4pIl8QkXtE5FUReVFErhCRjcvoU1EGkpnjR4vIo/Z8nhGRc0SkS2yrtR2hFSEiNeYGmiMiE4CdCspub899gYjcBVQXnD/AnuNcEfmPiGxTcJ2z7JnME5G7uvJ+i8gJIvKW9eF9ETk1OPemiHwl+F4pIjO9DBGRXaxfc00ejA3KjhORy0TkGWAxUOwd/DLwZDn9dM5d4Zx72TnX7JybCPwVfV/9+anAHGCX9tpZJxWCiPQSkduAe9CYwCkoO2US8Nea0Tvc75zrFJPIzLungUuBR1Dt/gOgpv+uR0ygC4wiERkDvA0cg5qNx0lF1aUV/dbbetH4fzVP+tkBW5R900mb+wPvADsAl1T0HfKjJZNfv6t59rSvAm+LyNZdaPMHwMuL33n2w6Uf/u/6qg02PR0dg0uBZ8rxXRa0VzH1t8eNbl2ysLXPVntWo8/mFPRZ3S0it4lIr3La8swj19L8HK2tf67aaKvfAv8ATgS+h86snheR80SkXbdSIQOppWHBQ1JRNQH4JmqSH4daIlsCE0XkkM7c9zqIC4FN7PNF4Bv+hD3fB4BbgUHob/XQ4Pz26JifCgxGfx8PFsyAj0Bny6OBbdDfZGcxAzgAjUedAPxSRHawc7cAxwZl9wc+dM69IiLDgXr0NzAIOAu4r+C38HX0ve6Lyp5CfBp95zsFe4/3YHk38FvAtu1Wds6tcx/gD8DDQE3huZpNdhow/Ns3L97ojDsWjDr34W3KbK8SeAGlkkrh+WEnXPPtQV84bQ5wYif6OAzdKP7YwnOjzn043WvYZnuhL+sunWhzl/bqoC/3NGBYJ9o8EVUwI4qcE3SG/jxQ2Yk2rwH+PuhL392wyLkae3Z/6ER76XTfwc9ucNxV7404866RJcZ6PPCdctobde7DstHpt10w6tyH3fqHXfTXEtfcAWU6jV1V7/Xq/gB5YCEwN/gsBp4uKLOv/f8+8KXg3CnAVPt/T2B6+HsC/gNcav//DvhJwfUnAp8PrnNscO4K4Pcl+n182McO7vEB4Hv2/4bAAqCffb8XOMf+Pxe4taDuY8A37P9xwCUdXKsJ2CL4PtaPTwf1LgZeA6oKjt8OXNBu3dX9Eq2Gl3Yz+6H2KVVm2PG/+ny6dvAcYDnhUaLNw1HrYDllEJTZHvVBlyUYgZ8C13RQ5kTgb52490fpQCmZML68zPYqUQWyfTtlxMbm8DLbHAnMAvq3U6YPqtg2K7PNA4D/Aql2ymxhbVaX2eb/9dl677+NOvfhkuWBo4Anu/qurmmfUNgHx9oIW9oqhCXAmODcF0kUwlHAiwVt3UGiEB5BlU2h8jm6WF+Ai4DbSvS7TR8Lzn0ZeA6YbddoJFBE9ps6ARgALAKG2/Fr7f7C/i0C6uz8OODkDsZzBrBT8H0sHSgE4HTgA2CjIuceBM5or/666DI6GfiTc65kcHj6n854smXhrFtRV0A5OBUV3q5UAefcK+iD2r+jxkQkjQr733RQ9M/AjiKSKaPNDMq4+XMHRX8DfNP60BGywAd2b0VhY3INOkbl4JvA7c65ee20uQh1F5xcZpunAL9xzrW20+bbwCvAwR01Zib5KYve/OeP8rnsknaK3gdsKiKddu2tI/gQGBF8H1lwbniBGy88PwW4zDk3IPj0ds7dsaI6Z+6n+4ArgaHOuQGoIgr7dDNqWR8OPOucmxb079aC/vVxzuWCuiXlheF1dAJbbn9PREkU+ziNGRRiS9RyKIl1USFsATxbRrlnreyKbrMcLvtgIO00OFQSzrkl6APevIw2NwdetTrttTkRqED9nh1hC9SM7wgrayzLbXNLyu9nOc+nDzDYOfdqe4Wcc03AS5Tfz3UNdwM/EpGBIrIR8N3g3LNAM3CGBWsPAT4bnL8BOE1EdjaWTh8RyYpI3y72RYzAsewD9AKqgE+AZhH5MrBfQb0HUPfg99CYgsdtwFdE5IsikrY2x9p9lotHUMpzYUerCz4iIscAlwNfcM69X6TOcPQ3/Vx7F1wXFUIz+qDbxYC9Tty5YsCwihXZZuX6Gw9C/YIdoQno1VGQM1NXL2jwrdw226WcwbLZbyV6Tx2huZw20bEpd81FM6n0im0zXdnU59P7lrNiuayxTPdbv6lqxKcrR37/7nIC8J2593UNF6PB1A/QhZq3+hPOuUZ0xfnxqLvmSHQNjz//Emoh/gZlz7xL14LGHp8DGop8zkAV1xx0XcuDYSWnlND70MB12L8pwEHAeahCmYKufO+MzL0F2F9EwtQpw4v0cRM0eD0YeFFEFtonzILwNeBmp2sSSkLa8XKslTBGzPbOua+XKpOpq6+2By5l0uoAACAASURBVI2ITEMZDDfkc9mPSrR5K/CKc+6qUm2OOvvBg0ilHqC1ZbakK64ErsvnsrNLtCfAm0jqdNfa8q9SbY44446rSaXOwLmL0jV9f5nPZReUKisiA9L91ps0cO+T9v/kL5c/U6rcsON/dUvDuy98oXbb/UZP/e032rUm+u34lUOqN/7MLdUjt/7s5F8cWnIdQ7/PHHTtglce6edamo4tVQYgU1e/ZePMSbdX9Bu6dapXdb9S7phMXb1M+tlXbgX3cntjbnmnznMtLYeCa5n084NKKu1lY66B5XHFronOUH8IfAWobm1uXjj5yoNKzkhFZCAq7DZzzs0oVS5izYaIXIA+43bf7y62fTkwwzl3dTfaqEI9CXt29B6uiwphEPAeGqx5t1iZEd+/5/V0Ve9PFzn1Nko5vCNUDiKya7rPwDvXP+Lio6b/8bvLuTsydfXS2tQ4Tyoq+waT/lY0sHQV8FjhquX+Ox/6q9odD/hmuqb/7pN/cchyrolMXX1f19Iyl1QqZW0uBW4Crsznsu8WlO0FfN+1NF/mXGtLqqLXkGLKY+QP//JZqah83tqbg9ICbygUzJm6+k2Ai51zXwPENTfOS1VWDTSKZxuMOPOu81NVfX7impdOTlVWH5vPZZ8qaCuNxlXOJ3AJtDQ2vD7lqsOKUuQ2+s7N1zd9MvmExhnvbTFn3E1tFuZl6urXR+mL36Wtf5rWJYt/Ofnqw39Q2F6mrl7mPX/f+XPH/eloNMjp/HGUG38ySmHsF9ZzzuGalu47+apDnyjWTxG5ENjcxiliLYTJk1eArzvn/r26+9NdrHMKAUBETu0zZq9L+u10yC29ho7+cT6XbQS1DJrmfHhjxYChx4A4E4yl3DavAjcC97U2LWltbVjwVqq6tn/zwtln9Bo0/HdeOI784X3rtTYsfLyi35Dt2unSXOBPKB32beB859yFOCetjYsbWhvmHzDtupOXrV8YccafN8e5cane/Tco4VV6HFU0fwf2Bn6LBaecc7Q2zPvYOT4/9ZpjlsUohp964z6p6r4Ppqp690aEoN0ZqDl6A2qu/hgVuG1M3+YFM19NVdXuN/mqQz+xsZTG2dNOq+g75DeSrhRrU1Df6tkoA+MEdMbdxp2j76Sjee7Ht1cOHHaSV0iZuvrKpjkf/rai/9CTEXFmvR2J+un3B74F7FvYN2vTuZZm1zJ/xrmVg4b/Ytnz+cF9g1sbFjxc0X+9XRpnfHBrr/VHfwNVAsfYZ3CxAfZ9bF3asKS1Yf7B06476dFlz+d7d27cPGf67TPuuWhk65IFn3POFeOYR6zhEJGT0QWUtzrnTlvd/VkRWCcVQqaufqhrbny3eeHsmnRN39bGmVNeQ0j1Gjxym9alCyXVZ1BjKl1Rg/rnqlAB4yiuHBzQ4JzrBVQ0zZzckqrus7h59vTXUjX91q8YtOGmtLY4SVfOl3TFANRHLWjgtlibC4FaoNE51yAi/ZvmTG9pWTxvkmtunFbRb/1NUtW1G6Sq+6Rwbqak0j7422ptErTr22oC0gCutWUWIuu1Ll3c2tqw4KPm+TPek3Tlhune/UdXDhqecs7NNZ9lFdDi6wVjIfZptutUupbmua65sZ+kK6RpzvT/tSya93Hl4OHbtS5Z1LtyyIgUSKOItKD5gFqtro9VhP11qKKocS3NS5oXzq5MV9e6pllTXnfOtfYaMmLbloYFqYq+Q5olXVFlZf3fwhTV/sUWYLFzrhJcRdOsqa3p6r5LmmZNeTVVUzu4ctBGm7vmRieV1YslXVGLUgP7FHnOvs1WG5MlzrlGEenXNGtqa2tjw9TWpYsnVfQbkkn1GTg8VVmVal2y6P4pvz760BJtRUT0OKxzQWVzA/xOKnpVVvRb/9+k0gvSNbVD01W160m6oiFdO/gfqXRFJfAyKmS8a2ih/fVBx1Dg9BaRChGhcsjIFklXLkj3W29j6VXdJ1XRS6Sy+m5TBi+hQnCm1V1CImR8e7X2t5eI9AHGVwwYJq2L539QUTtotFRWV6Zr+qZEUvdKKj0EXYzj0AUyzda/wrYqrJ/vSyq9nkjq3nR1bUoqqysrageNbm2YP6li4IYAT4tIBeouWmjt+XQdNbR9X2bavfxX0hUDpFfNXVLRS6Syprai7+DRrmnppMrBIz4USU0VkY+tD43WRi8SZQAqhEGphjXAy5KuqKjoO+Qfkq5oSFXXrpeurh1KKr2got96z0q6Io0qqGq7r1AZNAbPS9A1JxUiMkUk9XHloI3yrqVxarp20KhUdb9BpCtFqvosNWUAbZVBS0GbDXZsPrBARBzwfMWg4S2tSxZ8UNF30GiprKlKV/VOSSp9d7p3v0MsZXpExBqBdU4hoC6Gg4HLJJX6XKqy+tbKQRu9Xzl4o/elotcdkkrvDvwMpZL9CV2N+CoqdGajQrIZFQ7LQUR6pXv337By4LANKwdsUAtMNh76Q8DWKE1tA3Rls1c4ftZdiApgjIikem+689TKwSM+rKgd+DYqQOcD/0MF2Msky98rWf65+vY/ZXVrgYUVtQPfrhw84r3em+5ypmjOoUet3FRro6pEW9g9vIEms3tQRD4FvFQ5YOj/Kgdv9F7loOE/l1RqI+BFlD/ei4SJVWiW9kFXCm+IxkF2AH4mqdRuUtHrzspBwz+oHLzR/FRl9Vx7PhUsbxF4LCER3O+hyb7uQXPFXC6p1CYV/YdOqRy80XoV/YasL+rKKtWWnwTMtPY+QRVvg917FXC/iFTWjN7h3MrBI96r6DvobVShNqNB6uszdfUDS7QfEdGjsE4phExd/VCUpvYCupKxCqWUedyDCqfX7PNlNDfNdmiSqYWoMJqAuj8gUQwhncsHiPuhwnA71E/u7O9taAD1QWB9VMj6IG9rUN+37dC8JztZW2+jlLaT0MDpe6iC2IRktg26chOSGS7oM/+SXWcD1P3xJmppZNHFMJ9BhXdrkb75thajuVaqUMW0E8lY9kZTD4BSB/3Y+OC0BP1stPsbg/Kuv0Qy/rWoD39XO+853I5k9r4oOLYUHfNZqFIbgcYojkLzuPzEyu5NQpf1Fp93gfl7A7VAJqCK6jFUCTUDv7A2zrf7nIy+U74ff0FXR58MDAV+SUTEGoB1RiF4VxEqZI5HE2VNo+1CjXHobPBgKzMEDcaeDeyDzsT/hSbKakW5xV5IeCHi3UCQCC1Q66AGFZy7okL9QCv7ETrDXwLMQ5XOQpLnsyD4vwZdcTwYDfZOQAVeLWrB9LHyC1DBPDvozyckGSNb0OR9u6Krflvt/x1IFN8861Nf62MrqiimkszQP0SFLqiy2tbu8eskCqDBxqja6rZaP9+39lIkq7g3sHu63uoeSGKVNJIoqU/svvpYXUGF/Luo4tgKDapfhSq9zUlYQo0kz8ZbARV2L9i4TbH2NkfTHuxo1zsc3VrzP6gFuR9wTwHD6h671npADvhGdB1FrAlYZxQCiavoAlQRfAm4N5/LLktnYNTP+1EhNBFNL30smrztbOCraF5876f3AqaZxPfcjLptGmirGPxYt6Izeb96tQIV7otRgZmyNnqTWArV1sZiEuHo0IyGY0iCsoNQId7bPvPsWAs6k14PFYAtaO4VH7s4nmSFrrO6PhBdbXX7kSiJ4VZ3Ljp79rP8r1m7TbRdkNUn+L+vlW0iYfAsoi3T6Ghrp9mu2YzO/mut/966mW/lNyBRyJ5qmkItnjBWIXbv1dZeE+pSWogqrw3tnlrt//k2Bn6zkb3QrJU1aGqRA6z9e2iLJ1C30RGoVRJdRxFrBNYJhVDgKroKXVhU6C7y8G6jL6FLwV/DUuuis+T+6Cbu37b/W62cXy4+G/WDV9rnFZS6WYEKndC15AVaJSpkPrQ2G9Gl8F6IvgHcZWXSqEvEK4bFqJDzgm+WlUmhia5eQAX8LPvex85PtzJe4PqZcjXJ7LsfSje93tpYigrZmdZGA4nwF1SY+vtZTOKOeQ9N1tdq93caOsPuH5Tz8YX5JIo0RWLVOHTlZso+j9iYgD7LBcH/jbRdHTyb5F1/CX2Ova3/flyr0XfjZSs7H0221mBj5lMUHAicn89lJ6ICP3QXAcv2ZP6LlQVVuNF1FNHjsdYrhEJXkVkBh7O8u8hjHCrwDrf1CcejrqPnUQF2HZp18Epr4zHgEjRW8CI62z0eFShT7Pgwa9sLfo/a4H8JyvVGE8L1R9cUjEDdQgtRwTiYRGjWoELdWzrhRhu3oLGKe1GBexUJhdbHNBZZ/VoSITrUyregM+HvowJxJrqXgM/pPoy2wfABVqfB7mEgKpw3QdMUPIYqvd+Q5GjpjVoNHv2sH63W1/VILJDjUOE7F3XhnWJ1fDkPr6D8mAyyNhtRCy+PBuCrUMvxXmv/JHRTkeut739Hn+M9aHK+G1FFdnWmrn4Axd1FHt5ttF8+l/0v0XUUsQZgrVcIBK6ifC77lm1luZy7yCN0G2Xq6mvQmfRsVNhdns9lT0PjCH1Rf/WB6OKU3kAGzdZ5tpXfCBUufiVrGlVC3jJJobPVv5H4tJtQVpP3v++Huh+8Lx9UuLxj/wu6P0C4SvJtVLF5Yf0FVIj6Wfj/UCYV6Ox3DupK81ZCC5pX5j2SdQibkcyksXt4jmTtwz/RzI9pK/c+6nLz6w2W2HhsgArihaiCaLA6zWgs4wMSptRN1m4va3MqGqMYYG1MQp+BH8upVt6vFViIjv9862cKteYWoHtJNwG7o+Mtdm+7oDP5JaiSPAVVxpPs/OvW/oEUdxd5hG4jiK6jiDUAa7VCKOIqgvbdRR7ebXQk+sPuiwrH72Tq6vdDZ7fP29/bSZhBS1A2UqOdn4UGIPchcSlthQqJpfbpg7KZ0qjiqbQyPm7g0MCmZzW1oiluN0eFZwPq2hiLCn2HCt29rHwjamn4mMVSVLifi1oH/7N+X4IKwFn2OdbKed/8VuhM29/rEXYMG5u90RXMM+1eN0BXNfvZczXKShISYfsF+z7b7v9EkljMdNTS2ptEWW6EWkfeFTUKtZ5aSRTObkH9fqhAX2BlFqHJxvZAFckbKFPop6irqBcaOxiHKpHZaPqOY+1az6Hurksp4S7yCN1Gmbr6qnwuu5ToOoro4VhrFUIJVxG07y7yGIcKxatRd8dXgMNQ19E9Vn8/1BI4AhUSj6Msm0eBX6HCsj8qgKeTuHIqUWGzGFVMfVEB+yHBojT7m6KtS6aRZMYOmmHRxxU+InFHDQjKFHL/w0yitajbZ5jVbyZhx/jr9qYtzdPHHXzwGRuj6Xav/VGh6s95+mrIuPIxAR/gHWT332h9ctZGiLB+pbXpM7imSNaI+PvcEFWYkCiR/qi7qBql++6IKs5voQFiRxKXGIsqkx2A36Ouoj3QmMp5qBIv5S7yWOY2Aoiuo4iejrVWIVDgKgLoyF0UYBAqEPsDh+Zz2Sfyueyr6Ky/H3BjPpedn89lrwR+jQq/IaigPxh1hfRHBec3UMHtLZQa1BWyGTrTd1ZuMrq24CYSodZs7V9F28DrE6hl4gOpKfv/tySWCChT6kjUxeUF/FzUfeE3EqlFhe2Ddu1wkdyfUN/5HBJF9C9Uqb5D4i56H3X3vIEK62qUjXQ+cKf1z7uFLkLjCU0kgfC/ofvPttpY+syjf0DdQGn75FHL5t/WZqXdz8norN1TWz9CraYvo0rBK6DPo8rrr+hzrAROzeeyv0efl6+/l70z96PKvwbI2aTiNHTCkAIG28SjFArdRhBdRxE9GGtlLiNzFY1HXRm7eesgU1d/DLoobLd8LvufoPw4gHwuO9ayZT6BcvSrgEPyuexfMnX1u6DsojmoMBuTz2VnZ+rqrwTORAXWg+iMfy+SNQEpVKCfhAp0Hwf4ABWCp9M2vxEkTCQ/m/cPaYHVL7QavH+8EGEuohYr662IcBFWYe4en7KiKvgOiWVA0IfwGqBC3TNzwlxN3tXUK6jnlWEh/FqDcP1BS0HfHXrPYVmfwqMJVZjfIlk7ISQrsb+IPscaVClchQasfYB7K4s3+fdlIaoAd8nnsk2ZuvqHUeVSi8Ykzs/nsi58j/yNZOrq/4Bal+ub24hMXf2O6OTitnwue3yR+4+IWC1Y6yyEdlxF0IG7KFAG3k00Ezg8U1dfjc6Wp6Gz+CHAr+xah6GC5jo00LgnGlh+A6U4/ged1fZB+fVY2WZUGcxE3U2eKeSTyE2xNiBJl9EPFXg+p3kjycIuXw6SgHSatgnZXgzqeiXUh7YunQbri09u55PmPUpCdw1XPktQd4n1JVx3AGoxLbS++rqeGusVTEjHbSFRBs9amRoSmi6ohePXd8wP6t2JuojOQJXCFJI0419C4xano8Hhl1AmkScBfM2udXimrn4YyvT6Dxrb2AE4N2AXXUfiPrq0HUuhjdsIousooudirVMIFHEVQVnuokoCZZDPZf9OskjtMjQoe1I+l32GZMHaD0jYKqegwjaNzkD9ytmtSVYfX4Ouwt0RZa34xVlZVGA2kbiWRqJB2KXWt1+gVkVv1P/tUAHrBf4Cktm2ZwI1oYLZP+c9C+o2o8LUL0LzgjdULF5oH0CykKyKZLcm7w7y111KsrLaz9q/SGIZ+bI+0Z2HjzUsou1isl2tH2+hFp9XPseQWAPX2rFW9Dn4lB/j0fxN89B1HZ/YNfcjeT7b2xik0InEa6iL5/c2Fifmc9l70NjCBej6E88uOo1AKVAcxdxGEF1HET0Qa5VCKMEq8miPXVSJ0hm9MvA0Uc82OhPdKOZxO+4XrF2CCryvojTNjUkCzVujQeYlaG6gPUhSKHwGzdtfifrFn0QtmkpUyXg3kJ9Zg8YbBrG8i8XPTMP1DV7h+cVxYbA1rOPbqiqoV4EK3oqC8iFCCqqHs+uFLiwp+OvdPb0KvkNiXYR98UpqY1R4p9HFfm+is/pKdGy8dfWYlWlBnxPo87kXVQ6no0p+G/T5gFJNd0HHfRt09Xe4AA10w525wDkYu8gmFqFSGF04SIVso+B4ZB1F9DisNQqhA1cRlHAXmZtoW1TohMoA1F3Rggr1s/xBW7B2LQmT5oR8LvuNfC67yALNV6HCOwXsk89l383nss+hi8SmBO1fivqrx6L0ygUkC82OyeeyX0LXNvycZJUv6B6uG6GWxkO0Zf5cbeWOQwUXJOmvX0Etm6tI3Cw+/cYTqBV0BEkg1wuwl1F313nobNvDr4H4lJ2fYX3xyulNdMb+Y5IAuFcy9agQ3tzKeYXRgFJ110Mti49ou9n5AahC3R5dLOf78QiwmY3Z1qh14C2NXwBHGxHgt+jsfID1Zb98LvtWPpd9GXUL/cPqLCHYND2fy36C5mzqD0zx7KICpTASGF3EfbSc28jqRtdRRI/CWhNUztTVH4X6lc/N57JXFJzrhwqr3+dz2TOD4z5msBXwRj6X3a6g3s/QGeESYFA+l22wLR//D3Uf+B/+Qflc9kGrsw26OGoAKlTvRt0bY1HrZXOr41Dr4Eh0IdnvUR+2RyOq4AaiQrxwk56/Af9FA6eFu3rNsb/FXBFLUcEaZg5tjynj4dNq9C5yrrAN/73RrlVsg3uHKp5hLG/1/Bv1+3+zSN2P0BXDu6LrOzwWoYyoO9Bndiltg91+p7YB1vYQEiLA4flcttEE+QOoNQk6gTjSExAydfXHoYvvmoEd8rmsj/GQqav3C+OGEQSa7Vwlui9DfT6XbbOXt1kNL6ETiK3zuewcIiJWE9YKhVCKVRScX45dVBBAfgeYW8AO8ayiR9EsnIegFsOfURbReJQ6OhEVLj498z9RBTLNjm+MWgUjUOG4HupCONjKDEUZSUNQBdFqxzx9E1R4vozOnjdD4wA+tcNSdAb9HDpzDv3voD72F1EB2lxw3ifM601b4emxFBXs4eb0/roNFN+ToIkkEV2IRpSe+ikrU1NQpxIN8O5rx4RkAdrbdt0tSOim/sX9J6oYJqLK1o/1BCv/uh1Pk6TAWIxaTwNQNtmDqAV5OPqe+OczBV3PcB6aquRB1Jr0Qf9dzCUELGOrbUZxpbAc2yioF1lHET0Ca7zLqAxXERS4i4qwieaGhQtYRceiTKDT0RQHu6B7Adei7KCvo8L8ZhJlMJaE6dOICqiJqID/J4n76SX0GayPxj0yJFs4VqOBZ1DhOMOO+fvzKaP9tpa7ooJyanArU+zY50hSSEwOzqfRYG+oDMLzVbRVBv660JYCOiM4X0lbZdCCjl8vVDBX2P9+JryUJAi8L4kimG9t+WB5ZXBsodUR1LqbizKgFqBj7dcOPIlaXSl0fD3td561M50kpvAgCavou3Zft6LEgp+hLqn90ODytzDWEcvjHYqzj4q6jSC6jiJ6DtZ4hUAJVpFHIbuoUBkUxAw8LsZYRagQmoT6+Oeguf4noOyie2zB2o2obxtUGWSs3MaoILkcFYY1qE/9E9QqOMj6cjWadC2FCrhrUOUzCg1eX2DX/ww6Y73Rjvsg5nwSoboR6vZ4gCQV9BKSFBQj7e8nwf22kChFf94n0iuFJSTU1fXt2MzgfINdM40qTNDxc3asDxpbmEsSx5hlfellx65DhfaW6LjMQumkVahVczmagmIAqvSWomyi3ujY5O2duAbNWdRg9avRgPIWaDzmdDRe0R9dqDYNeAp9PkcC30GtkErg7Xwuex/GOsrU1X+6yNi0YR+ZUijFNvKIrKOI1Y41WiF0wCryWMYuKkcZmKvoLPQH/TrqxtjRTl+cz2XHoz/qJuCvFjM4nMS9caXVETQucTDqCgKd6f4WtQz8j34eOiOFhFnTBw2Mep79/nYP/hrfRF0XHg+hws7vb/BV+2DfvQAN4YW0X1g2oOB8LW2ZQYWoZnn3lI9l+EVkhdf0K8BBhf6lqHvMYwI6w/bXOxUdB0+t3RRVtCm7xsG0XRMxBJ21v27fT8jU1d+FBtj9HhZ3owpmMqrIJqLKGGv3skxdfS90Rj8G2CKfy16Lugubgd9n6urPQRXLXOAmixEsQxH2kV9FvRzbKKgTWUcRqx1rrEIo01UEibvoPTpWBqGr6CESF9E30dnvgcFitMfR2bR3E/0ZFYgHoEHnF4HZmbr6kSjL5Z8o9fGL6MzfZyf9KpqiwaFK7VXUMlmACqFPo8L/TRLfud828j00Od0xqMB8CxW4hTRTr0jeIcnvEy4QC8u6oLy3KqSgjF+wBm237PRl0iQCGNTt0lSkfFNQ73GUmrslOk5+vcHM4Ppvoy46QQX2FqjldA76zJ5Bx+Tzdn/PoMp7EGoF1KDssAYbhxfR2MzX7V6vRt1H96AuJL9IbQD6HvyOxIX0RzRIXdR1VEIplHQbWZ3oOopYrVhjFQIduIqgjbuoHqUTtucmgsRV9CSa72Y2sFM+l/0jySK13VGB/iwq5B3qqvgGKrDSJCmSQd07PtfQYah7pwoVfh+jwelXSNI3b4+6Rgbatfxsez1UiL1AkpF0NDprbkJnx+EubLNQxdBAskJ4M9Sd5a2GwjQUPg1EpV033LUttBb8JjVNqDUTJr7zSJPEAw4hocX2QZlCkCicVpLFYn6/Ck+L/QMqtGcF99eMpqRusvs6Dn3Gn0GVAygraje7ZiOqbP9iffFumwa7TiM62z8THd8DUTfT01bWp7q+ncSF9AVUyP+DEq6jIkrh87TvNoLoOopYjVgjFUKZriJI3EX70rEy6Ie6iqajgeRbUWUw3s77RWo/RAXSWSRJ7Rzq1tmWZIe1CpRt8gVU8ByICr4q1D+dQhXCtqhAm4a6mxpRS8MrlBQJQ2cyGhcYSZKwDRLXTRqNDfiA7QSS7TB9cDjMEbQUVWIv2jVC6qgPNFegQvMl+z4nKBde1wfR82gwu7WgjL9uI0lw/Ck75+v66zlUIX5Esn3lFJJcRb2CspWoovgCOrbnkiTJm4NSc3tbuaNsfH5r39dHn8t5qGK9jGQx4YGoG20MmrrCL0Zz5kLa1e5lL/t7E0XouwVKoc7aKeo2svLRdRSx2rDGKYROuIpAXSnNqGBuTxmkSPYUHkiw0CwoMw51X/iZbH/7+38of/xvBTusbYZSLJ19b0JnnRvnc9k9UUG3jbW9CxosriAR4LegwuZhVADuam1uSJKDyK/IfZpkwdt6dg9Dgva9UHa0zTFUjQq9nUgSwEFblxCosvRxlEHB8dB/7ymyo6xv4dqCkGbZy66ZQoV4C8nq5BdQF5jvxwb2/9ZoUDll9b+LKu3XSBbljSaxNPyOa7uhiwH3RmmdoOMz2NrbFNsBLZ/LLs7nsufbtZ60sn7WvwcFqa6DhWz3W/93QK2v5VCgFLalHbeRlY+uo4jVgjVOIVCGqwggU1e/MeougnaUgS002xYVaFNRq+CmwnKmeKaQ7D/wD2DLfC57aT6XXRKUexX94a9HMr7XA6PzueyZ+Vx2upW7EmUPQTJ7XoS6DIbnc9kT8rnsOJTpcg4qzP0Wm6AWxQ9QXvseqPI5h7b7Bni8gbKbBqHK4nySWfkGBeWOQamZw1CXiE+dEc5+x6PPwO8S93MSF4+QKI2JaMykBhW015CwmVLomKfRWfNu+Vx253wuuxnqNruVxGrxO6bNQbn/v8nnsrfnc9kdUGX6GIkry+/fsLetQHb5XPZfqLtmb9QdA8lK5dPyueyyMcvnsv9D02YfgroMfV+9kiAoO4/EhdSKWm5DC8tZWa8UbrRDl3eQOju6jiJWOdaohWkdLUALyq2PujhGAGfkc9lrSpTbAJ2B74i6ddYrsAp8uRHoD9nP6m7I57KnFCm3Cer2CRk+nw7cTr7clmi84jASQTsR2C5ULpm6+u1QN8OhtJ1xXwWcZSmXBZ0Fn4kK6dAVsQS1ou6y9lIoLfb/UAEZCqTXUMrl81a2wtq7HFU2Hq1o0PeifLLPRBW6J8HPaZvfaBGqDH+Vz2UnWdk+qMI8mraYigZ8/5TPZT+yshuigeFMUO5ju/8b87msF9hk6ur3RPdq8Ep4LqrQrs/nsguCcoLuMXG6HVps43FtPI5NrgAAIABJREFUOPZWtrddz+83fS7w62LvXaaufm+SrVJ/BFyRL5JE0Z7BBJSG/DPgR/kSm+zEBWsRqxprjEKwH/J9qK9++3YCyZ5auiU6oxxa4oe5DxokXB+dVT9nM+2wTC90g/kL0Rmqz+l/Xz6X/VpQbhOUU/8NEoHUgArH2/O57NfNEtnf2turxG3ejQr2I9GsmpsWnJ9Hks9oHMoqOoLlU1cU4glUCB1F283oQWf2/QrKvo0qq6Kz3QDjrN2DaWu9LGH5xHfPokr6MCvrd0zzwecQL6Mz8qOtD/75hQvoWtBA8nXoOpEnSOI5ofJsQJXSb/K57LuW1trnOQoX0M1AFcgNXjEYu2gGbem1bwLfzueyT1GATF39WySB70eAb+Rz2ZlFyn3ZzkPBiuYiZS9F360D8rlsfbEyERErCmuSQiiZqygoE64zqEBnfWcWlAlzEc1GhenrwJyC1BX7kuQeakQF5xBUCO6ECtYN0R/rcahQS6FKqAp1v2yA+tT/gCqBjUmYPA51QY1ChepQ60vhpjKeofQROuP2C9xCeOFagfrgh1kbC1leqHv3SKvd0wQrH2576eFTSkyxsmNQ4esXr0mRspOsrz5198CCe/LXbkKVxFiUQeR3MCuWW2k6OuP3q5L9mglfttWuVYMyv/YgUSIhm+pv1p/t0WfuU4ssRhVYyq6VQ62YI9AV6K+gz3IYScqO24CzvTUDy1JXhHtPfwwcldeU6QTlfG6jmajSL6kUYq6jiFWJNSKGUA6rqEAZXI0Kl7sLymyALhq7kEQ43EDCyiFTVz8iU1d/t5XrjQrCT1AaapO13Qd1NU1Efe7ef/6AtXkWSc6dVnQdg1/NOxEVyi+gAmEOqhQGk2wM04wKqUVWrq99tqOtMvAC5ENUGdxm1/kEFXDh7LolqDOFZBewQajC6R20h9WrRN1zI1DB+A6qHP0KZe86aQnutdLu/Wwbi3dIFGDYfhU6m25B4zEzrB9LgzZ9fzdEBa1PsOczkoY+fm+RjLA+XGv9mUaSoXUfNDg/3/r2ITq+S1GmlW/r13bfPtX1H1Fl8BN0/N9BlcXETF3998y95vE/69e7NlZPZurqzzFXEdAmJfZQdLJQcpOdyDqKWJXo8QqhHFZRkdxEW1GQ6tpcRH6h2SnozHAaSV4hydTVn4u6Sw5AFVBvVEiNRamrT5PEB8ai1kIr6iI5ChU4r6MulJ1QIRKmoP4VOiOcigq2He2v5+MvRemlFSTJ2D5L2w3tW9DZJahCmYwKzHkk6Rc2DNqcgQooH7ydjfrkG+z6Y6yfC1HBPYFkw5j3SVxBJ6GZRzdFhd0S6+fLJAvMJln5nWyMm1Bm1NMkyu4VEvid3I5EFWMtKtifJHk3/xeU9/st74vSW71F9QKJpeDdX99DhfwQ1GK5j2QXuAV2H7ugz7sPahn8FLUE3rcxHoMqzP4kDK3T7Z6eQt+vq4GXM3X13t3YhOY62hJdrOgXsj2Uqav3q8MhWaT2IB3svBZZRxGrCj1eIdBxrqJCZfAibXMXpTN19RehM/7ZqLD6FMkOaH62uBP6o3scZZgcTZKo7tPoLP7zdnwCKnz2QQXDnujssRalem6FCutm1L3yAirozkAFYIbE7eEXec1CZ7Yb2/EqEteDoLP6WVa2FhVkg0jcN/1JBKTfO6ARFXb9ULfDSNTV5WfdveweN0CVwIfWt36oO2djEmrrZiT00E2s3jskDK3nbYyaUaG4LYkLaCf7+wrqrmm1MQzXW2xNYknsZv8/Z9ddQrJi2WOU/fVBdVD//vrWB09X9ZbIgdavt6z/C1H309HWz4NJ1pP0Q58hqPK71Oqehs7oT0ef/RLUUuiPrjzfAugV5Do6F30vvoMqsVcydfW7Wbs+t9HhFM99VIjIOopY6ejRCqEjV1GJ3ERh7qLQRXQrKpj6kuQqesvcQ9ugAmR/K3sb+mM/Dv2R3meXvB7d7rIfOjt+GBUYb6K+/fdRITAVnZkuReMePtDo8+0/hc6kW+z/VlQ4VpKkVPDlZ6Fxit5WZi7q7tqERFjfatf221bebuNWgQrxC2mbhuJ11FpxqDCfhwa737LrPIeug/DxEEH93M9aG1WocD+HRKBfgy7O8ru05VEh1kjCfHrOxqzCnsPXUCvN43GUVeRdMBvZvYmNp08E6GMHC2z8vJtpG5Qt9Z6d743OxN9FlZ/fPe4Ou+/BqDvoClTgn4e6i64OxstPMKagz2ySjfOZqJI51q57GaqMPpupq/+enZ9rY3IDyUK2Jy0XUguW28j61a5SiK6jiFWBHhtU7ohVVCpRXaau/gE0hcHxqGDvh7JCbrJcRa+gQvJGVHgL6h6Ygs78/okKh6fRWWMz+kN+Ho1J/BoVFl4pLEUFxBuowPsWyb7AVVY/jc6+fbA3ZOH4wHEYLF2ACsxXSbZ5nInORCuD+h+QZDydjs76/YIpUGHrN5iZg1pCb6IzZ+yaH6EC1i/My5PQPCejVsW7JNTTF21856AWirPx8+sZPrL+D0CtkVbr50iSldo+pUZf+/9d66ffGW0pSZDYM3yW2DhW2Pg2Wvk+JAH0GtqyjBqtvles/VBB7Fd5L7XrfYQqyJ9YO34G/pHd1xvoLP9JG5NRNt7PoDN8v5/CU6graqDVudva/L98Lntppq6+Pyr0D0dZRjejlsSB+Vz2IYsz/B6l8BYNNEfWUcTKRE+2EEq6itpRBj530VR0tulzEd1kVX2uIv//46hrYBIqTMaR5A36CjrLPgQVXP1QC8GhgnApiaLwmTi/bedr7dyHJMJqw+AWfOqFaegzWIIK0AZU4My1vvtMn6Az5IUkAePZqDJYTKLAFqMCzNcZbn172u5rsrXpZ79z0RjD2+HwokJ6hl3rPXTm62fhfkXz/fbd2TVb7DPL6k4nCQwPsH68YOPSamPqhfc8+36vlfd7KzfZuekkOZaEZF1AbVDHx118Ur1pQXlIqLkVqIL6iITyOgR1F36ECnPfpqexbo6+KxPRZ7C3jcvh1r8D0cnLEtT6OgRV3j9B360LMnX1ny5YyLYvmvRwAZbbqFhCvCLuo+g6ilhp6JEKoT1XUQcprI9FZ3w7U5CLKFNXfyBJXpxGYP98LntwPpfNowJ+R1QYVNi1NzbK6slWx/up/4v+gA9FheOeds2+6Cz+F6jQnY9aBH4TmhbUfTWZtgLboS6gvVAlNRJlygyyvrxPwln3ygp0hn48KqwWovz+3qjiaURdUx9a2d2sjxui7pFhNj4ZG6uDrdzLqFKsQJXAjjbOb9l1jrbvrWh+H2fX/isqGNNoIHYn1OI4ELVW3iZJ6NfLPv8hSSfh009/DXV3ZUhcXv2DcZyNCt4GEtbW4daPMaiFNwUV8sNJlMHjqACvJElzsT66HuGr6HqGFpL9Iw5FlcNI4BK7t2p0MjEGVY5+5bNPtX2AjVc6n8v+xe7/MpItQh/J1NVXF8mFVAscZtZrh0ohuo4iViZ6nEJoj1XUnjIwFtFVqHA40eciytTV98rU1f+YZEP2S7HcQ5m6+k0ydfV/QYPGgvp7R6MJ7HbM1NV7gQEqtHdEhcWnUD+0xwtobOEgEreNd9W8g/7AN0Jnnv1IFljdiAZuz0ZnlZcEbT6EsmA2RS2T+SSujm+iwulhlP3Tl2SPgAuADfO6D8PxJOyeBnR197moQHueJAA9F2UofSafy+6FKlYfG/gYXWA1CXVv/IhkzUUe2Cqfy34VdaP8zOr0QhXfrHwu+xqqCC4P7u051OWxq43pY3ZcUHfUjvYMRqN+diFhNJ2LKsUTUWXp6/0ddSXtaPcSrg5Po/TgrdF3a5Ed2w5VPM+iQfAfo8JfUKvnfpKd7I4jydL6NPquTCFRDO+iVs3nMnX1ZwKtQW6k19Dnn/dspCAX0tPoc33Ks5DKUAqRdRSxUtDjYgilFqC14yYKF5qBLvM/zs6Fi8sAjsvnsrcGK4uPIwnMvo7+sE9Ak6d53zxo7p/xqIA9gESgez/0dajVEK7WbULjFYehcYXTWH7T+2tQobBbcMz3ZUd0hn0hysyBJHbwGOoSOYYkYNuKzji3Ra2HHCo0fT8dKqTvtHp+Nuz3VPZ+7sNRReUZRT7b6vWoe22fgnt4FnWDLEKF8va03bv5b6jiOMXa8jmHPkGF+83o87uooN0PUAV0IsnGOv5Z3YLOvnuTzNA9GtD3ZzN0F7Vw0vMCOub3oFZLpqCu30/huILjM9F9Mm5GraGNSRhRf0PjSt768xOBcIHbUpSFtLudW7aozRapzUWf63SChWztxRTigrWIlYEepRBK5SpqRxlsQLLp/VPoTHQ3dOb2C9SdMBWdtf8BncF6ReAzes5BhdMQ1D3RBxUqVaiw2cbKDCZZjeuDjT7461kvS9DZ8UvoD3wYiTBrJvHND0ItoJQd837tDDqD/baNwxjUTTIIdaVsZ2PgLQUf0K1B8/iMJQn21tq1amxs9rV7SpPs2/y+jdVkdJOY51H3jQ9mX4sqs7kkK44b0LUBPoX1KBuXWaiLZSI6y65ClZqza/qg9q9R+q0PVL9m93k/6rp6gWQ7TH+fn9iY+0yuKWvzTdS6uwN1Z82yMj4lhk/L8V/ri1d+H9uzWoQKdx+P8AF+7Nn6ALgPVqfQmMCo4Pn4lcsTSSjEm1hfBpMohr+gFk6LPZ8l6CTmtyQTihnW9nnAlUabbk8pxFxHESsUPcZlVMpV1I4yCBeanYAKzmmoT98vLrsY/dF7oTkR9VPfaccXocpnG1R4v4YKoiZUWG6HCvO5JOkW5pAEbn0ytEbUJ+8Fe421ORAVRinr33xU6FeTLC5bROIeeRB1QWDXuA8VHi/bfY2x/nwU/P0uGrR9HhXEG6MC9CpUET6ACtjedq+zUGXwJkmM4SfWv53RWfJddny89W8gyi7yK5rnojPiLVFXVzUq3B+y8fGuK8+weo5kYd1mNiZDUfrvGJI9F/6FWi7HkwTeX0GF/DbWf//c7iShC3vFOBudCKTt2AxrY0c0DlJhff8AFbxb2v1WokruUSvfYn3vZf32472AxDrcAn3PalCluhR172XsPgajcZL3USX4PPp8N0AV7bPYojZ0TUYtqgjaLGRrz30UXUcRKxo9xkL4f/bOO8yKImvjv7oTYMigIkm5iBHMYc2KrvkaMWdMmNacrruKGNCLWdecI4bFBFzXdQ3oGtccwKyNSBzJcdKt74/3lN1cZmDWz13TrecZZuiurq6q7n7POe85daoxqqgxYVBEEX2KrIDxyKwPIYNPorj6cxFVEcD8FhRWOow49fIE9PF3IF6RGlbs9iEOb8TamIe0zrCY7CviRVgFBDofI9DtQpxqooAE0hrE6R9eQ3sCBKdlC2svRNmExHtl1u+eiJIoR47m3RG49bD7T0QgvyZxxE0V0rrXtvMrIeDe2cY9EVlHDUjAbkMsQNshK6mj9a0zEgSb2f0qbe6Xt+MZBOwzrZ/jbL7WsHt9aM8ypOmYbPVGofDiecjimm7nv7B7VSPtvtzqN9gchtxFmxOnzIiQcA9W0SwEtt8S75kQKKta4giygvW7E0qN8Udi6iuE9IYSwmJrbe4K1qeQCC8EJzgE/IMR7bgl8Q52GyOL6lr7XYsExn7IKrvG2jsgymVebcpSKFFHpfJTll+EhdBYVFETwqCxhWazURRJBQKNXZDm+VckDBrs7x0QUDyFwDYsrHoJAW17JFAeRIAZ/A4VCFwuQgAVwkPPRdZGawSWKcQnn44+5F4IsCaiFNZHEPslHrf2b7X+tUcgeKS124FYGNyFaJERxNz1Fkgzf8LarEBpt9dGjusWCJA+QQ7WzREAroQE7u4I8MLK6BmI+98DOcGXR5rxSUi7Hmj9mYYsr9VRZA5Io78symV2tXptEcC9Zm1uibTklnZN2uajFoF7SFO9ARKG2PiPs2vPQxZC2N1sfyS4gqCdg57tXxEwp62d49C7MBcJx6koIOABBPTLoffhTqRcTCDex+E95E8KgQghKusKJHBbICFSb8/nJWJh1RG9K1dY3zZFlt5wJDA/sP68bvO0LvKHlCN/02nIX1O8kA0asRRKUUel8lOWn91CaGwBWhPCIKSrboc49mHo4xmEPtB56CM6E/kIUggMzkJAsL3dcr5duxHS7EFAMgcJl+BsBWmVRyJKZ2dkPXyDaImBRdd/jTS/kEqiDoHr7kgL3M2O32/jTTqLPQK5ZYvuPxjRDXehaKdpyCo6E3HP6yfqvoNAM3n9GXb9MGRJQZwH6FG7PnDg/0aA1j1xfXA0P4A4+hQSJO8jwbwusVLxKqKNOhOvTr4C+WyGEUdrhUVZbxPvguaQ03VNYusLRCGej6yAPmieT0IgHlYOh7ovoWcahHMBOZ+vRODbGlF8FyNBHLK8hhKcvo54L+i/IUrncuL36XpEpT2YuNbbPdYlpsbqkBBvb3MOer/utr9Psd/BxxCCEyBeCPchiy5kOxwpDo1ZCqUFa6Xy/y6/BIGwCFXUSG6i0SxOEXUljh4ahTTEL+3/9ehjX494dfBUYjqonHgxVHsWXTUcVrY+iRycwak8DX3MPYhpqfEIPAPNQaLN2xA33t3uX4/46b2R1r4GEiDBQRq2nAzO6geQFt7Kfnoga2YfpNF3QUDyCQKxhXbfmVb/GQRq2yM+e2dkeZyHgOsPyPqYgARkB8Tt19qxadb2oQj4Dkbgs6/N1TQE0KciPjysfvY259/Y3B2PuPM1EbiugSyB4SgZ4DFIWFYjK80hWm01JLD2sXtNt9/zbEx5pG1fgLTm9kjrboGedWek5fexef0MCatnkYXzGTHt0xG9a/PtOdTYNXPt2bS1Z70C8oVsbP2YjoTOXOLFfkEYhFxKCxBdFZzbU4jXl0y2fr5vczLRnsM7NhcrYtFIyBr8gUKyZ7iIUCAOZihRR6Xyo8vPShkVU0WNCIMxLEoR7Wl//xN9VEehD7YSffAP2vVB856M6J7lEFgsQGBQj0CkAX1EC6z+W8i6COkieiCtLfDP5dan9xFApOweIY6+En2wI9FHnka0zkmIugl1bkBaeUcEsPcgH0gX5NAdgACiDxJQWyHQ/wOiBq5Gmu82Nq5PUKhoSH1xIrKiUkgYnI2AdyLSVj9B3Hw7pFUvj6yeahvnRERxPYKEwWTkoD/Zxr02EpjDETiuibThxxHXvgHSaA9EVlRrJLB3tHsfALwU5TJ32H3TCFivIl54txHSiD9HAmJNRDWdh6xJkFYf5qaFzXvIjroe8gU8iN6NSvSuHIWe49p2313Qu9UaCcTH7Xd7ezbPEu8dvTEKPX3B5iGNqLEziAMMZiMLrAwJgxn2/4LN83wksMPK6rC1aIQEyhbo/chhKbbRO7CF9eMlZCEeT4I+snMDKFFHpfL/KD+bhVBMFSENMCkMIKaITkJ0yiCked2CHJMH2/9DPvutkJZah0A85N+pR9p7SF9QgzTbtogSCtryJwhAw+Ym3xNvtD4LgVagVKYgDXp7pMXVI4CaZ/2fb3VmEguosXbPQOu8jID1BERleASyFcQUy+0IYNe3tmYiIAltXGg/pyMhAdLGHdKwQVrkTsQU0yUIPHogsF83ymWmpLP5QdYWyEqqI97mM7Sxjt3/VCRolkeCp0uUy0xNZ/Pvo2ibVgigW6PIqTIE+DsigHfWxvlIMNYhATgdPctVif0yfZCgKUM00h5Iuy4gAXE+ErBzEPff3q4L6bJfRsK00ub4QavXDSkDV1gbHr2HRyG/yznESlPYDS3QSS8h4erRM78d+ZSWR1bSdcgaCWsPPHqfgsCrRU73sCvebGRVhfoTETW2CXrHPrL5PpKYQhqA/A9JS+FiStRRqfzI8nNaCD/kKmJRYbAHciaGdNUnIcDNIZ56FNJU90cmvENg0NfacejD78CiG7IEDe4F9KEfij6u4Qjo0+jjC2GiYQ1ByPvTFpnsYXObbRF4noUoorCwbVuk8ReQtr0ssdbaB1FFU5HmuxOxMLgfAcC+SKCcjwDkGGQ53GHjTCPh9bT1eygCz0uQln6OtbGP/f020iJ7I966AQHHNESrfBblMiEEdlerf4b1YV/r0yPWxjpIa/0eWRwLkLbvEK0BElhv27yE+fjQ5ugMpBGfhiytG5BmH0Im70Dgepk9gxsRkPe0sQ5HmnEP4qyxV2LpH9AzfgEJ7/7EwiCs3Uihd2Z/a2Ma0vAHI2EzFL1zI5HSsJO1GaKuwmrhychfBQL2MUi4hb0XJqP3tQE4FlkJIUliKAUW9WFUo/cPm9/p6B3oa/MShFwNov+2Q/6N+1jUUijlOiqVH11+FoFQRBXdTywMDkMv+wXIeghUSDDdt0UCYwz62ELe/PlI+w+LxyBOP30NcSjijUhrvBaB6msI4NoRh5MGLboGWQOtEPgcg6yFt5Cm+y8EbpcjDS5cN404jn4+0uR7I6Bcy8YUUi+cQSwM3kUUSR0CoTOJo15SKEVFDQLXLRFQjkQgczcC5xNR6odQjrH/N9j5K4l5742Jd3ojnc33QjTNo0igzbS+HG7zHDazydncgvwTjyFaIzitAXyUy1yJQBJkIWWI96S+BAm2OgTmbZD2u72Nc0RiHtJIiLZFzyqky96PeKVxCmn5xxILhcno3dnC6oaV7JvbfMyzcWyLwLgBadaf2JgGI4rqUPRezEXvXjUSJq3tWMidNR09ny5I6/87oqVuQhbb2+h9Go4oo5Y27rDAsDeikeZbv9ZEvov5NicViJrcD30j16NnPxpFVQWhMIgSdVQqP7L8zwVC0QK00xHQ90Yv8g1IS/obopJ2QUDZA/HlExDQ9iHW+IvLv9GHOhGB7fF2rxH296oIVNdBvoJJCOiqEEiEVcXD0cf4AtLCbkXWw5tIY56MhMPZ6EP+0u7fBYFDpbUbKJgb0Ed6HPpQt7H+PYLA7hqkvX5DnNI5bNBei6iW95C22Q+Bxt8Q6G5qv69GwJyzuVrZ5mGW9et9BJptiKmJUAK9NByBTXtkwc1H8z8WCZVVbC6vQUC1jfWjn/mAkmVbG8PO1t+UjaGttf8Qer5/s+fwIhK27dB7sS96JuNtbrLE6wHGElOCT1p7w5HQD0LhLpuHO5EwnIAA9FFiOmkiEtAp68su1t+/2bzegN7N3oie2dOex1ssuvsbxNuQTkfWRSV6145Bwuspm+fu6NmDLMUg5MIaGJCAam1jnIeE6Y7o+Yed/hYgCyhnbd6HhEJ/fqEL1pxzY5xz/Zo41885990Srr3HOXfJf61zv8DinLvMOXfq0msusY0WzrlPnXPLLa3uz2EhBKpoKPIF9EYf3+VIw5qMgKAaaUVrI4CvIOaNyxGoYf8PK25PQzzvbKSRDSHOcrk7ApZOCNTmWxvt7doUAhmQ4OiMPtBHEIB8iD7WsDVjb+SYnYCsgNC3AAIfIxCbbG3nETB9jrjuixHtszGiat5Emn9n9KG3Qx//58DUKJd5NjGH+9qcfIW07ZHWxr7I2jjBxhYWVKUQ3baWzcs8LOVyUZtv23wfjITLRUhQvoU01gqUjG13G8MXCHRH2T0CbUQ6m69CtNMTNsYWyGG7IRKUHxHnDAp7Bzxs7dxh/1+ROMtsg81XGRIAK9vzmIA093Kbj0ttHDU2L0PQO3EBEhibomf4OhK+4T2aZ2OvQEJsX/TsatC7+Sh65reid3cjJHzeRBRg2LcZ4n0vapDSEYIW9rCx9kDK0D3In/Iu0v49emYQZ8kNf3e18xUoWms6erbbICVoOySARyChEBZI/s+oI+dc5JzbrujYAOfcK+H/3vu+3vvR/4v+NLcU9/GXUgzAD8PCkZckMJ1z2zjnXnTOzXLORclz3vsa9J1ml3bP/6lASFBF7yLw6I3ohsOIN2MJKz97EIeJhkRrYTVqCC0FCYFeyMw/DwFHDQLI8YiDDTlmulrbYVUwVudrBBCvIqqiFaIvHkAf/Zd2j7XQx78REihh163Qt7/b39cj6gjiSJHDbXwvIXB6y+7RDgHGRsQby3xofWqPYvg3NEoHYr5+FBKoAWz2tf4fioRFK5u3J63NaVb3Frs2cOxJumiknf/Y+rYmArCNUMTOJATubyGtebSN6XAWp412QmD7jj2XkYiu+d7mKczlWsSLyW60Od/e+lxX1OZ+6Pk9iwRvntg3UIae9bdIEC1E78IQJIjOQlRjCzsfAg9etz59gN618O4V0Lu4otU7HIU997a5e9f6+xQS4rsiC2wK8d4RbYmT8nW14yujZz4TUTuvIQEbHNqz7JnVEC/Ua0m8PiLsGR2i1OYiujKs3M4gAXGO/S5RR7/w4lQaw+IBwNPe+wWNnCsu8xDon9XE+WHA4c65Fk2cB/6LAsE5t4xz7kDn3EDn3K4VnbpVElNFbZGWvhB9xLXEH2FrYgAPO1+VA/WF2vkvz/3w2dsn3Dbw9Pq50+Z67ycgbX4q0pTKEIgub9eF3+0S7YQFRncAm4y7Yo8D62dX19XPru7kG+oORCb4JQiUj7K2VyemlUJbQXubgh5CD2BP7/339bOmnlg/u7pr/dzp3bz3WyMAPQ59/McgIRSESicEbikEWDsiLXZvBEjrACyI3h9UP3tq14b5s3va8YVW73MEcBMQ4M5BmuODwGqWBvssBDqfI6tmAbBsw4I5PetnT+26IHo/8OvrWdshHHKO/T4erfVYF/HfG9kYjkGAejzwlve+X/3c6d3qZ1d3rZ819UTv/fd2bgbxngdbR7nMLmiB2zSb0zKkKVfbnH9kz+Bl31B3UP3s6i71s6u7FOpqDrH7DbG53IN45XNI190l8bu9zWs/e46ne+8n1M+dflz97Oqu9XOmdfXebw/cG+UyW6BorgeRwhHWh3h7trU2FwvRu9sWo968937hd2P+Uj97aqv6OdNmfJ+/pg8SzC9bX8JHWEmcKC+sYdkMWQU7IV/X+sjCbTH7radGVD+VG7xw/JhHvC+EwITwTYS1M63sWCVSTuYiq2o88lO9gVGeJ+oCAAAgAElEQVRHzrnuzrlDnXPHOOe2c86FvEz/s5K0IpxzVUYDzXDOjUXvVbLues65d51zc5xzjxCPOZzf1Tn3vnNupnPuNefc2kX3OdM596FpzY845xa5vpn9PcI594n14Wvn3LGJcx8753ZL/L/COfe9c249+/8m1q+ZzrkPklSZc260c26Ic+5VhAMrNXL7nZECudTivf+39/5+4pTwxee/Q9/hJo2dD6V8SSd/THHOdUA88N5Ig/weWLVFtzXuBzp47yc753oR71ZVwaLc6Q9NIQ3v+dopXz035dFB2xXmz9oAmOwqWm6Yqmy1WV11VFvZuVd39AFVoI+tnvgDDCmYQ7Kz55EUfWrc0F03Qpp8l5pJn89LVbZqUd5uuW51MyZ1KG+/fLlLpYKfohsCm0AthLb/hUILR0W5TION/ZBlMqdXtlr5D/0WfPvhZ+Vtl+tU3qZTqmHB7H1SLdpMd6nU5ggEelgboc33sPUViS0T3+959ohLXapsUN3MyQ2pFq33rJ305YSK5Xou78orcWXlh5JKTXIutTHSJoPw+xo4MaRQBohymSvT2TzAFd4XJlEoHOoLDRQWzO5QVz3uu7J2y+5ZN3NSQ0WHrnt67yc551a1+Z8BbBflMu9bU9PT2fweyCobisBnM18ozCgsnLtPWat2qYY509rWz66eVtVz7X511VF9Zede6yBtuAbYJux+F+UyL6Sz+XVRxNhge9Zdrc01vC8U6mdO3rSiY7dWddMnLPC+UKhKr5uumz6hc3mHruUulTrS5n0uMDSdzd+InOpnIyHbyt6FjsR5kLrUVUcLyzt06bowev+zVJuO7crbLlMx5dFBm7ihu67svX8XOMJSRRyDNtwJq6EDeLaxttLe+2nOuV3qZ0ysT7VovXvtpC+/9Q11VfM+fv6jeR8//ziwT89zRrVHFvDRxKvYw3cXFrJ1RhbLRt4XJuL9Ib6uxpe1XWb/+Z++8tz8T19ZFujUstcGt3TeZ1C1S5UdTAwgQakL+baCotLdxr25LxSmFWrmDk+1bFNTWDj3WSTojwWWcc5d4r2/k5+nXIAsrt5I+AYLG+dcJbKUrkWswh7I5zTUzq+HvuXdEEV4CDDCObeaUSQgizJEir2KNO5b/sM+TkXW39corP3vzrm37F25z+470uruAkzy3r/nnOuOLNhDkRL1R+Ax59zq3vtqq38oAv3PWBz/QNbzZ/9hf5dUPkEKZpNC5ie1EJxz7ZEQqAFW9t7v6b0/2nu/VZu1t7+oUDO/HvzyxIm/wkucnIyCdXgAsOy4obueNOmeU04rzJ/1LLCi9/6gQu2Cw/F+WVxqRKGu1ntfaEOc2yYp5BzSlLLAClEus0OUyzw8buiuWyM++UpgpeonLu0z5ZHzetfPm7k6zn0KVHrvg4YY5imFtMQ7gLWiXGbbKJd5KiEMzgAGz//i9UPBLVP9+JC+k+49tWvdzMk7+ob6mS6V6uS16CM4M0F0yo7AZlEu82xy/1znXGr8NfuuXDPxs5m+dsGFLbqu0mXqE0PWrOjUvVP97CkDCrULapxLhbDFENF0Etrk5gdhEEqUy1xZqJn/F+dSXQu1C2rqZ00eUNGpe6epTwxZs0XXVbv42oWDCzXz6sCH3cn+BmyQEAahHR/lMlcjf8d0733BpVIdfaFhVt3MyTtMuvfUrtVPDFkT3DI4HinULfSF2oVlJIRBoq1ai0ZanXjbytbe+xSeSnCfNsyftdqUh//Se+oj569SmD+nl2+of3Pmy/fVjhu6a6+ituZGucxQFKKaRULoB+D1vtCmUF/rvUuNwPtlpz5+SZ/J953Ro3bqN+sujN57AnjZBCFRLlMd5TKXWlv7I8AJpYJYkelSqJnfUKivuaxyuXTnqU8MWbN6xOW9ia3fl8YN3XVmlMtcjCyZrZCPJwBWeA/KrT2cS3Ur1C6orZ899djWq2/R276f7YBNFn7zzkrfXrHHGuOG7roqslYuQe93sqQSv6u897hUahkKhXnL7HrGZt77/bz3R3nvN7SxnemcO4+frjxpGvFM59xMFGXVVNkPGOK9n+69H48UtFA2QXNyrfe+zns/HFnaoQwEbvXev+m9b/De34vmNakBX++9n+i9D6HE6/IfFu993nv/lVd5CdGVW9rpB4BdnHOBNTgUPV+QoHjae/+0977gvf8neo92STR/j/d+jPe+3ntfx+KlAxLeP1UJlHST5SddmOacC3HlA30jDa9w6iMnpFq0vtHqJk959LBvAZ6IcpmZiTZfBR7w3t/c2D1XOOXhEamWbXYraq8G+RSuB/5dBLStkGm+l/d+MeBMZ/OuULvg21RlVY/E4e9RWOMdUS4zvZFxr4GE2PpmmhW32bJQXzczVV4RrIsPkCabtAiK2zwQOKusdafN6+dOW4xD7Hn2iJWBz1yqLIU0lbMT6wkaLc65y9tvuv+W7Tbdd/dvr9q7uvj8Cqc+sr9LlQ9b8PVbd7defctjmupbYlydFo7/+NOKZVb0Za3a9YxymcUiv7oOuO7waflrrq77ftwW3vtPGmsn0d623vvbnHO9CzXzo1SLVis11geXKt8c3/Ak0NN7P7+Rpkhn822QxXAe0MZ7T2HhvFHjr9t/t8bqO+dOAA7y3hdHX4X21idOH1IWXu/CwrnHj7/ugMW0TqcX8lagxnt/UlFbrZEf4jTiRYt47/VPoWHtcVfu+XEjbbZAkVh3eO/vSrTXF/k4DiWmzH4ohYb6ulRZeccol5nXSJtdkD9kV9N6f3QxZ+bR3vvnEscG2LEtius45xYCG3jvx9i5HYE7vfc9nHMHAGd47zdKtPUQ8JX3/jzn3NOICkyu7agEjvLeP1TcF+fcYKSkHtJIvxfpY9G5nZElExZKtgKGeu/Pt/PPoMCTJxBtu6r3foJz7iZE2SW/iQrgYu99zjk3GnjQe3/7EuZzKpDx3r9l/++HsLDHEq7ZDr0f6UbOjQCe895fv9iFoc5PJRCcc22R822txkAxlJ5nj6h1qbJA5XyKlu0PSwqBRJvroaiJXt77+uLzIAD3vtBgrplPULjd36JcplFHjHPuCGBv7/2uTfUxnc2v4AuFb33t/Amplm1OAkYES6CJNq8HZoWXpLGywqmP7F6YP+vx+pmTB1attMHdSwNbi3q42nv/eFN1lj/w0iNmvfrQ1TXjP+62NMeTc64KPZ9NvPdfNVWvomO3g+tnTjrOe79lU3USba4OvLTMrmes8f3IKxcTlIl6lwDtvPcnL63NspZtDmq70Z6DO2x+4IZRLjO7qXrOuTww3Ht/d1N1QIJh7pjRz7Ts0XeV8vbLdVmCAA57WezmvX+/sTrW3nLA6YW6mrMoNEz79pp9l2+qrnOuB/JF9fTeN6rppbP5nsCp3vujnHNtG2oXfjr+6r3XWEKbOyMfygaNKV0mHE5CaUPaARTqa+/49sq9jllCm38GVvLeH91UneaUHyEQvgGO994/Y+eOAS4wgbA1ooi6h3GacviiCYRbgW+990Oa05cfIxBMAM9AlN9T3vs659yTwMfe+/OszoGIDnwY2N+sOZxz56I5bXTeTSA84L2/Ywnz+Rxwt/f+Qft/P/5/AuELG2fTfgnv/U/yg7i6F5dWr8fJD+3ZbrMD6pc/5Iplm9HmuQgUl1iv0w4nHl3WrvPYZvbzb8AhS6tXscyKpwH3NrPNL4G+zah3M3BKM+qFhXLlzaj7BrBVM+ptBbzZjHohjXjbZtQ9FbilGfX6Al82cy7vRRbm0uodAvytmW1+CGzUjHpXAec2a45SZXXL7nbmcs2o+yKw01Lrpco2rFplk697njOqw1LaC5stLb+0Nlv16XfRsntf8Hkz+tgLmNicuVxKOxGwXdGxAcArjdVB/oCXkJ8nCM/v7FzYl/sUeyf7Iz/LJXZ+Q0SXbYyot9YowqptY31BfqoHmuj3AORjaFn00xb5tra2e+xs38YliWurkND4GDgscXwFFLa8I6JgWyKLpoedH43AeUnzeTpwW+L//dAOkMX9dPZetLQ+jrO/KxPXdkdBHC2WdM+f0ocQdtJaYhl/3QFPzn7t4YVTHjirZml1m9vm9GdvfLlh9tTKpdWzUsWiMeONlrpp304kdvr9JG1anea0WQXM801YRT+yzWbNpReXOa+ZbVY1p02a38fQ5k85l9DMsf8Hbbak0FBTPeKKxWi3H91moaHVgi/emNCYpZws3vuQqn2pbc4fO3ra949d+MzS6jW7jz99uRCB1zeImw/8O977WiQEBiABuD8KHw7n30aO/xsQIH9pdX9sCdF3xT8nozUoM1CuqhHJi7ws88eQUE32bzxyhP8ZRc+NR9F+/wnm3od8FFWJY90b6WNvpPAtQGt1VrS/k2uXDkIK7pJx9/+rFSQk0IZooZJbUr1uA28f0nG7YxescPrwzs1o8xiaoQV23P74y8o7dHmlmf28iWZogWXtlrsCuKqZbb5Oc7RAxf8f3Ix6legj7baUemVIi+rTjDb7oJeybCn1utm9K5rR5sFAvhn1dgLeaOZcXol41qXVOxe4uZltvgD0b0a9R4FjmlHPAdNb9+m3zlLqpeyb2HCpbZZV9GrZa/3p3Y+7e82ltLksiqprvaR6Pc8Z5dptuv+5yx9y1fSe54xaorVnYPJhc+ay9NPo/A2iCevjJ2j7UkQp/n/aaIHo+aVi7k/pQ3DI5DvNJzjEZEln82XeF+qcSznkSB6N+NAXbe/Y4jY7IO2hj/d+UvF5a7OPl1PKO+ceAwYVR7MUtRny9azsvW/UL7DiGY8PdGXltzbMnfFQebtlT4pymWmN1Uu0ORDYxXu/Z1N1ug+87YJ5Y0efXTPpiy4LvnprqZEDzrlbUAjbhU3VabPmtsfNG/PiAO/9EmOLE22+iaI6RiyhzgVAF+/98c1orzUSSBt476Ml1HsKCY7bmtHmmq6ixT+7HnbtZhPuOO6bJuqUIY1wP28OtyWVqvR6p7bbZJ9sVXrdDaNcpqmVnl3RYse0936JFko6m9+0fnb1U6mWbVqnKqvaNeVfMj73amAd38SHZlvC9kcJ/XoX6mpmfXtV/yYjQZxzZyN68vAm2uuANOUzscy8hbqaT7+9qv+S/BIPITrx2qbqlErjxTnXCYWNH+q9f3lp9X/p5aeOMjoAhcJt5b2fWHy+6xF/HVbZudeBVjd5ajKK6b8rymWmJk8453LI+tjdF0WUpLP5Ng0L541LtWjVqajNZ4BLGgu/tHr/QPG9pxR/qCue/nhvnPvElVdUWHvzUJqJ65fgqA6b1jca093jpPv3Latq/4hLlTkUejYgymXGNNZWos3V0VqHvbz3iy2r73HifdeVtel4cs13Y4e1XGHNQ5bmpLY2dwf+6lq02rqwcF6UPJfO5l3NpC9u+n7kFfvVz5i4mfe+WfHPzrlB7f7Q/9A26+x4zITbBo4uajM1buiuR6KkcWt57+curb10Nt+lbtp3n5S16dQSl1rz26v3XsQBborH9cBq3vsdltKWQzztNUDrQu38GWUtWveMcplFBLJFno0A3vbeN7m8P53Nr4p47z3Da1NYMOejslbt1i1WaJxz3dDCtL947x9ppK0qBNx/IbFLnfeehrnT7/ruxsOOKr7GlJmngT967z8sGufGyJm8L/H6G7VZaGBh9N46Ux694EOKinPuIBvTWt775tBqpWLFnODXAvd774/7ufvzU5SffD8E59xZyNl4PYrTnYZCtgaWtem0f7ejbpqeatlmVatevCCtAS1GuRmzGkwbvButIr0ahXctAP7Qao2tL1x2tzO2BldjUSJlRe2+gaKORiY/WOdcR7RopAY90OcAt0zm9CFVK214XFmrdpXe+3oTCCGWfQL6eB9oTCN0zq2G8tG8CtzUaaeTP2254lq7NMybcUR5x65blrVqX2aWUT1aazEYuCLKZZr0EzjndrA5HLb8gZeNL19mhbcK82eug/fHl7VZZrVUy9bepcrKEPd6jO2vu8TinPtTx22PzrXsufa3pMpvKatq90H97Op+qap2J5S1ar8cvjA+1aLV2lEu0xwen55nPZUhlRpZmD+roW76pH+Vtel4d6qyalLd9Am7lHfocvTU4YPn1E39ZtvmCBiLkMl777s55yoaFsyuq50aPVbRqfujzqXqZ7/91Oqz3xy+M3KYZbz3Te4Kls7mV0RrRrYHGrz8MS0KC+curKsed3t5h+Ufm3DzER+hvFqnodDLIxqzGi3lyiC0mCs48PCFQo1vqKssLJwzY9brjx4w972n/4VWCx+CuOdrvfdXFLW1DMo1dSpxNtvwETpfaKivnzXFTbr31JyvmX8HShfSC0WyHA4c6b0faW11QLTdn9BajmTxWIbauR8//8a0/DXLoRQWjyIfxLpoFfm2yLr9qKm5LJXfT/mvbJDjnNsAxYDvgTz1E7GMoT3PGTUDAVh/5LEPDhOPPrQA5t+gOO67xw3dtZp474B+iGP/HLhthVMe6Zhq2fpC9OF0Id6+sBwJmDJkDVyBwLzG+tgCLYw5HluwUrXyxl923vv8tbz371rI6wzilan1dt+wUck/irVyo7iOAI4pa7NM7x4n3lu54NuPJlatuFY37/0XTqsXy6yt1mjtxRFLshaccyumqtr9aYWTh501d8yLhTZ9t0nVTvnqu4rOvZZzLjXX5mtZpI32Xxq9lc7mO3tfGFc35Zvqyi69V5g7ZnShdZ+tUoV5s75PVbWrcWVly6O9KHZbUqittdUXeN3b6uYw1gVfv1Mo79SjvrxtJ4/3+XFX7rX3ktqxtrZHi9Ma0Ir295xz6y8cP2ZGRafuHX19ra+tjqZVP3bR6cCjvgnnWLAKUMRQC6QtTwa6+kLDe8Ca9TMnNdTPmtpi6qOD5iHa8ibgmWJr0dYynI6cgWFB4QL7eyLQxRcaxhcWzm373Y2HzaHQ0A2B7VPAjd77dxJt9USCZyBx+oqQUnwO+k6qgYqZrww7ZNarwzJozUMHO/4gcHPPc0ZFyBoYiEJLQzqG8N3U2Zjn2e8jxw3ddRiKlDkBRb20RFE4dwB3ee+X+M6Uyu+n/Cw7pqWz+RTS3M9CYVQ9iD+KGvQhBzCvQ1bDrTTiazAAuAfFCr+N6KXQZvG+yZOQRXBrYxqwtTWaOG10H2urN/oouxDvj/s8WgzW6GIea2sG0sj2QEJpVWLBElIrVLEUayGdzW+IhMcJCLzORxEaDyOK4DO0OvZbYJcol/mysXasrcvRPgwXICostJlFz+ROlE/omiiXOX0J7SyLkqdVIcfpaggI90ORH1kEymehld1NCr10Nn8Msgq/Ik613c3abYkUhwVAjyiXWWcJ7SStgvEo9C+8E4+j53AD0vRvinKZM5poJ2zPOphFn/kERO+8jvJIhbk6PMpl7muirXVsDsJGQgX7XYsUjRko7HIsWn28Y5TLPN9IO8EaGIiysobvo95+h72gA61ZC+wV5TL/amq+SqVUisvPskFOlMsUolzmbPRhdkXWwDz0kodQvpADvgwlZnsO+DydzZ+TzLtvWvpAlOysL8rqF2KawwcSwL8l4kvHp7P5y9PZ/A/cbaKtwQiMnkQfaxUSEl0QKId9cjcE3kln8w8mMpEWtzUWCYGhaLn7IKTNf43Au5X181LgNdO4Gyt97Pdo4s2AhqHc/GEXsjyiIN5IZ/NNrbbtjCy3YdbGfGsTJCzHoAR5fwVOS2fzjS5USmfzlSjUrhsSLFsS79w2xsZdhtIFzEMCrLF2UiagbrN+tEJz+4S1PdjGPtZ+VjOwLm7HmVD5GIUPfoiEwYPonXgNKRx1SIi2JM6WW9xOSFF9i9VvsHmK0DtwJxIGdyAa80ubz+J2tk1n88+gDKj7IMBOIUUjRIfNQcrBEyjHzElJYWDtbJLO5u+y624g3gNiofXPo2fX0sZdie3oVhIGpfKflp9zC02iXOY2lNsjpJDOIzAfj4AhbGIfzJiOSIv9Lp3NP5rO5v+YzuZTRgPthYRJP8T1r4k+4vdQ4rdPiDNizkBA+k06m78rnc0nIzBGI/rlBKR9L4uEwi0oG+PLdp/21vZewKfpbP5q44eTZQwCpFtQkqx90XL2kEL6ZWLttRfwbjqbP7cR0AsZYb+wcfRFzvuWCPiuRBTcX7HtSNPZ/MGLzzhn2jWXWBufWJthP+MLERf9JvKH3JzO5rdONmCWz00oVDHs7zvVxtjXxhysge7Wp/2KhV06m2+FFgmehay/Vug92AcJrZeQxdA20WYLirJCmlXwD+JtTCP07P+MMuBWI77+EOtjUCbGFLWzKXLiP4med7Awwr7EnRDlc4j17RlENV4cLLt0Nl+Wzub3RZbT8yivzjTr9zconr4rEko90dqIy5FVdWOUy9xs7XRIZ/MnImHyOoohD9bjXPtpjQRXwfo7HGVKfRMJg5AdtVRKpdnlZxUIALbxy+ZIg9oObcqSQoLhGeJVfmOJHdBhF64frAY7vhvxTl/7oI9uRaSBr4i0p1EI5BsQIB4AjE1n80+ls/nNi6yEDZAjbzMEWKchLnY2AsV10Ef+PFpR+ZVZMMEvMsbu1QZp0NshzXAIorieRppmfwRGeRq3FvqivY/DPhB9o1zmM6SZnoiomVFIE88ijfiBdDY/yAB8EevAru0LjLE2w/8fsz6fh0DoS+CxdDbfO9GXUxFNcomNZTsbWxsb61hrr2BtXk2RlZDO5rsgwRscuq2Q1n0YEpDBOghzkBQyfa2NYqtgCHrePVGm3f7oXdgN+YnqEPiGNsdaO6ums/nHbM56o4ybPdA7eLGNr8ba+wuijfaxOfoSGJbO5qvS2fzxNu5HkQIS9rP4Hgn+vmgR1g3onXsXvTMXovf41EasgWWJt+mchJSjzjbmD5AA+Kf97IMCEHZYmh+pVEqlqfKzCwSAKJf5GGlTYxBw3Iic0Dshbf5W9KG3RdpZLQKgyQh4cojrP8/+3gCtbNwCCZGTUUjeOyiV7b+RdtoXCYYXkFB6JZ3Nv4r44pfR4qeRiBY5DH2YeyFtOkO8Gc3OCExDVNPn6Wz+cLQYBKsfrIQLEHX0BHJ0P442M9kLAcnRLG4tBNoEm6NuxikHK+F0BOCfoJTAf0IpIC4E7k1n8y1IWAd2bbeiNvuYfyZYCTsiMHXAyHQ23z6dze+CrJHHbBwXEFsHgdYaY0nuvrI2vydhJZige8Pmfi/r06E2J6Nszl+KcpnRiTbH2tgA+hRZBW/bsz3Fzm+BAHcDm5N59uxuiXKZScR+oSpLmT0W7fVwK9LYd0bv3o3offoYWRpXIk18N/SurIuids5FQH+T3evfyLJoaW10RMJuMBICp6FkaEei6LlxNpZ3kDWwHxImIfX6hzb2VZG1c7vde0W0x0Ybu+YC4LDmRJqVSqk0VX4RAgEgymUmI7rnCaQlL0AfX1sEkncQb5q+DNLEJiFn6vfIVN4OaXVhqftBiJ75wq59DGnJG1nbFyLtflskZIYR+w962d/HEe99fBmir7ZC1sbNiHq6EmmlayDgnYQc3Vfb8PpGucx8YithMwSCHyL6YBSiXtZHVMceSBBdisCzF7GGHH73KbISAljVIyFzGhKuh6J8OknroE9RW2OAXkbjBCthEKI59rE5Hml9/YDYatoOGGpj69tIm+FYsBJuQJp4pc0hNsaHkXA7mtg6wK6fGuUy30e5zFwEnrsTWwUn2FjvQFFnG9vc7Q+cG+UyI5BWH6wDUI75hUi7H4gA9k67d1vi3dYutba3RRbY2kjQfIKskZlIoF+EnuMI6+8adv5Vm/MJSKBsgSyrIch39jRSPHpYO+WIRqxC4P93ZEVtZv3KIp/DMcgi2AUpApsBh0S5zEXNWYtSKqWypPKLEQgABiz7og/kBPvZFGlspyAQ2R/l6NgP8bFXI81rCxRm9zTxhvdnI0vgfETH/BV9bOsgjSzsGbw3ApugUV5OvAXmVUgLPAVpo8MQwGyM+OqnkMDZAgmxK5FvYQDxZjpZS5/8g5VgqYh3t2tGoo+/H9L48ki73B/RGBA7VINWH8A2WAlnRrlMhLTuXjbuoTamPyBa5v6iawN4BzpujSIrYb8ol3kRWTBbovdlD+t70joIbc4i3t96DLBKOptvYVbCv2x8YRvOeuT0fRtpyy1Y1DoIbY6BH3wFrW0sb6NnuBp6pqPQu7G59f0+4HKjug6zPlans/nj7LqVkVZ+gF13il2zKQLx44m5/XNtTs9AVM6L1q+2SHG4xa7bBT2zkxBo74mE6v7Iktna2p6M/BMrYRtAIaHfx+b8VuQP2AOlxj4XCdLBSNgcip7rKKQYbRflMg9SKqXyE5RflECAxSKQdkAv/gWIommPNPXPELh8hbSkFRG3/RSiOjZAGttU9LGOQh/cK+jjvwaB8YkIRO5BVMs+SHs9G4HbdWiOhiDQfwv5D0Yii2ILJJxuRaCxPhIIRyNh8yekZS+PBNDt9rNdOpvfIsplQgKs7kgzfw+B5URrtxWiLUAhh6/Zsfk2HpJWQjqb7xzlMq8gzfePKMT2eSTAaoCH0tn8lnbtfCQEIWF12O8frIR0Nt/S+tiAAHlHi2JKWgfh2jEJLTVEGq1qkUQ7Wxsf29yNRFr2HrYCfBHrwHwffZB/J/gK2iNB0t+eYXiW/RGY3mtzNND6EayDD5ADNuypMRRZFI9Ymxn0juVRyOrAKJc5B8X5/wUpGTshJ++W1u/BNgfHofdrM8Tv34Osgg3tGb6CKKTn0LvxVyRMXrU+ZNDmOYOR4BiAFJTriGm7HLIKkhTndEqRRKXyE5dfnEAIJRGBlEZ00BQUPXIf0ppuQrTInki7vRb5Gfaxc9uhD3QhMrWrEYA3ID/Cu0iArIXA+jYEpDshQdEHAU41+vj+jj7+5RCA/x0B2+52v7OQBn4BsbXwNALiOYiCCPsbz0eaPVEu8ybSkLdCGuY4JKReQhzzwXafA5Hm/w7yq6yZmK4frARr8x4EPicgR2MlApbvETD9Eck/LpwAACAASURBVPgksabjSwScfe36pJXwtPVtABZ5hEA4aR1AQpu3Ev6+w8Z8E7L8+qNggWWB3aNcZpIJnWLroAcCzm2JfQV/RtTKqwhIT7S1EssjBaAaxd7XJKyD6TaPDgl2iDX/+2wep6B3rCewc5TL3G5RR3ejZ7cL0tYfQN/MQkQjfoIEeKD99kZWwcaI5/8XWljWFgmSsPPaHPSMWyLF53KkPJyBKNM+SKiMJrYK9kCU0zBkUZQiiUrlJy+/WIEAi0Qg1SIn79ZRLnMksbXwOvr41kdgvQr6oLoj3nYQAua2CPjPQCk15iLaIEKgfwCxtfA+Asfe6KNvi0IOO9u9bkVCZT1kNWyMPubTEOCPRlbBegiUV7Pr37f+3Y9oqq3T2fzN6Wy+KsplhiGwOho4xVIg74zAdFMbw5MIdEfa+LYOkUjFVoJNXxZpqNsDL0S5zD+trddsLspDBFJRpFEojyF6YxtgSJTLPGDzFLTfO4J1YPcMEUahhLw4f7C5+ROi3xoQWB6WWNTXmHUQFo2lkWDbDllOILpl1yiXucn8Hk9hEUVRLjPVcg49jyyUcgS666PnC6KnMvYubY3erVqk5b+Szub/jMC8Agm+Y5FA7m/XT0cCdh8b2+OJefmnzfG9dv0nxEAfNh36GCkyFyA67mrkh9gQWZb3oXcnWAWPIuF0MaVIolL5L5ZftECAxSKQnkhn86ci7TxpLbyFNP6V0Ue2E9IiuyAguAXRHVch6yCL/AoFJBC+QxTUscTWwnAEyCsh3rsfMtUnImAfjaiAV+znGwQYfZG22TvKZc5CgAH6qAchiusPCICOI45IGoxA46p0Nr9zlMvUIYtlOgK75wEf5TL7IPCvYNFIpGIroYEYoP+QzuZXjbT95352bB3gPotAwuY3UEbYHAbhMtbanGlz5YH+6Wy+vZ1fxEmdzubXRCDrgdeiXOZao3CORgDtsaihYusgEUH0Q9SQxefvhIQxSBj93QTHXcQRRVMSkUM9kcLQG1Fxb6FnOM+e0d/T2fxpNucfW/v9kYUWLIlTkAW4i81/K+SAXsfmfwyyCi5FgH2/3XNDRGfujQTLEKTlz7O2zkVU1MN2bGdEj/ZDikPSKqix+TicUiRRqfyXy8+SuuLHFNMEQw6km5AmXW+hkLch8L8cUR0diJORLUBUBXZuItJGp6CPeC/kaJ6PhMZXiG/eAWmzZyBK5QWkxa1tbQxCH3J/RFV0Jo5DP9ra2geB03eIqtnW/j4aaelXIWBcw+55PhIMKyFtfhyyZh5GGuVEZB2tzKKO6LdQDqWs9SesnP4GgcmWSLBsYvd6FWmah2A5kJAWfiFyavdCwPYl0qZTSACHxVs3E0e77IYE2w3IcumLhOk8m48uUS6zhq0AfsJ+dgDyUS5zQDqb/xPi1bdBgvYqu98HwMpRLrO8LdK6HoFlZ+BfUS5zUDqbH2R9HoQoobOQUPwSWRaro3fgbGTthOiiXa2945Fy8bXNXyviWP9DkfVwFHo35trvzRE9eYCN7xPE9VcRp7i41+ZtP/QOzbMxHWj33JU4TPoBe553IQtlJHCsUWm9EWWXBo4sOY9L5b9dfjUCARbLgfR34IAol5ltcfVXo496LEov/VY6m18NaW/90Yf+DQK1ixDVsyP60KcgTfIZBApbIdpoJvIZPIu09BUQUAxB4DoWabzdkTl/AKJDpiDrozMC2stRRM0DSAithgBgNwR8t6OQ1pWQtbEGcmoPRIJkb0RJjED+gBOtvWMQCN2IgOgG5Fy/yqbsDKS9L4cE2ssIrG+2e21i/fkWAeRfETVzOwK4P1idR5EGfiQSiL1sHm5B/oSWdv5sJKzHINA7FgmpTZDwGotANiyg2wBx7yGNw/Yoiidw5QuQED7Fxn6Q9aW7PYNHEZ+eRgrBYza2f9i5dWz8dyPLaQKy+lZGFsFYexbe7rfQ5jwI0Uobz9vIGr0egXon4txWcxGIb4yCGwL1NgdZNOshof0set/moGd9PbIST0XWXdid68Eol/HpbH5zRIVBKSdRqfyPyi+eMkqWRiKQ/pXO5leIcpmZxb6FdDZ/KRBFuczeSKv7ipiPzyKTfV300aURgO9kvzdA4BjSaW+PqKduCGA2Q9p/BbIuKtCHvZP16yMUEusRKCxAaxFeJ/YtDEDCJHDjayDgWx2FE6aR5QMw1pzPIQLpXgQmfaNc5lFi38LpyOH8JxLrDooij47DIoyiXOYhO9YJCTSQUOkG7GlRUCHi6DISkUVRLnMrArXTrI25NtZnEc0znkVzGiUjisK6hDvsXmsTryvYDvl2+iDB80MkkYW7jrW5esDmdROk9W9mdNqhNu/7YRFE9m50RIJrfwTMIAC/DgnH522OFtj5UXafU4kDAU5GvpIyJFyORZbbLoiiKrdnl0XKQwubm4L9vg5RiUPt3i+T8BVEucwDJgwOpBRJVCo/Q/lVCYRQiiOQ0tn8Bnb8aRb1LbybzuY3inKZ15DGtyf6kCuR42+FKJc5BFkHNyCQ7Ye01FeQJnowomTCpiPXIdB5AgHxiQjcuiAu+rsol9keCZXHEDh1AbZMZ/PrRbnMAvMtbEGcyO9hoGWUy1yPtNdLUXjlSnb9dBtfRByBVAnsYbmcphoY7o+eaRWydC5LzNk9CHzWAb4PEUaRNhHaBDlPQQLpSBNAyYijnshqSUYWnYHAbFWbq5tQ5FDYgCZEwXSy45Osze8R/be+nX8TZUS92e63AbJ4emKRRFGcirvCxl6JnuWewFZRLvN6OpvfE3Ht5VgEUZTLPJ3WrmQhdcZyNo6/IFA+Ez3je+z8W8DGUS6zP4rKegbRe63Q+3En8hFshSyofyLB8y2iAtNIgN2E1iSA1oSsbhFRM9PZ/BkU+QqMInLpbP48SpFEpfIzlV+lQIDFI5CMo2YJ1kJllMs8hT7CixGwjExn848DLaJc5hSkrd6PIoseR2kIFiLttQ9yXKeQhj4ZaeTDEXANR9rjx+ls/jpgfJTLHIAA/mu77t10Nv+M5Ux6HVkooxGYfp7O5rePcplZUS7zFyQMZiNufFzIkZSIQPoCadDDzDGLWQtbECcDfKAoJ1LWxrNCOpvfLjGXXyIADWWVEIFkZbL9rrGfUJZFIZ/Yc7gqihO9OWLH8IgQUZTIQXSknfscLa76xs6vg+hAgHOiXOYmO75qOpt/MtHmI2gh3VNApT3jsMn5IfYO1FiOoe+QoAAJya5RLnMpEuhv27F6JBj6Aal0Nv8gEgg72HxeYuM9F9Fh1YjamovCW4MfYA9ETR6EBPnGUS5zcJTLfGMUZlNWQSWlSKJS+ZnLr8qH0FixRGkjkNZ2OnCdRbSEHPKL+Rbs3H5IMw+a523ARVEuMyWdzW+MNMP2CJC/QB/xfeiDXo94J7Xkfg07IY3TI6DIIQfkFoiXrkeCIYUslMuRj2A8ohdaWT/OMt/I13YsgG7SEXmmtY+1tWeUy1Sn4/0OQOBdhu23QJy6ezKiTzaOcpnPzTE/EtFR7ZFAfAA42mL6/4nSfbQHDopymYcskiiP/CQtETc+HlE3s9LZfBYB7TRgdJTL7JNedL+CWgSq3bD9Eqwfj9g8dUDafBlxgIC3/zvgvCiXGZLO5jdC2n0fO38LsgZOQBr6cjYXc4A5US7TPZ3Nr25zt4c9v3pEVa1HvN+AJ9606UgkuE9HQiAkL3wehb8uTCsr7BU2Tw0oMm3tKJeZYRZK0ldwEqLzwnvaCVmT/bB9KqJSGopS+RnKr14gQNMRSInzi0UiGdCdg4DhLURfhIikqxH4jURa/HhEL0yxY0cj4NoNCYY64giluQhQ/k3M+V+NBMpQpKl2QJx6F+SEfB/RPcOQY/o75AcYgTTG3RAt8zWixD5CFsmFiPo43+5zKNI8g6bcH4HWbjbG6xDQH2Xjnmn9+Qfi4UchgXMxAuGXrc95JICOQIB8KnLazkNC8hyUcuQhu/8d1r9HkLBY3eYgRBCNsvHuaf3Jo+ilEEn0OeLcbyCOHHoXUTTnILB/w+YjRBCNQQ7r+5Cm3wpFafVEYNvbxvs5ceTQeOvbc4hSrEJafSfk7G9hz/U1G1/Yr6MbcmoPQhZnDlkNE2zeWxML2xBAsJk9z+MCdQZQiiQqlV9S+U0IBGg6AilxfjFrAdEF9yCT/1TEC4eIpAsQoN2PAPUxpGHviIAhJN8bhEImP7RjGyPNsgFxyVsijr5g/ToeAWJfRBFsiIROAQmU41HU0GrW9RAa+hYCsSFoxW7YF+BiBKgjkBCrYNEsoVfZtTchQVSOwju7IMdlPaKmNkKAO9z6tKr1L4x1RUTDPWp9/RiB4LmIHumItOuwscz7CKCHIuHm7H4n2O8volymXzqbvwxRWdgYDkXrBnogP8FjNv7rENgPQMJjAyQo7kIC7WFrowFx9isgy+xyZKkEfw1IYK2GnhtIiL9m425rc1qG3gGQdfEQ0uB72Tj/iQTyEXY+h96fHZCl+CJLsAoASpFEpfJLK79aH0JxaSoCKXF+Md8CAtc/ITC4DDlzQ0TSrUgLvRvRPnsjmmNT9LG3Qdr3eAQgvREQD0LWSAoJpy5IC66ze9+PolWeRZbGP5GQ+RIB9QikMYadsy5HWuweSDM9DFkgp9r58629oxCAOuSMTGZCfQkJoG/smmEIxL5GWvG/LCoomUn1IeK9CqoQWG5k5xcgR+54Fs1h9KS1W4GE6SE2RmdztL39dAMGp7Vn8XrW5mdIOL+JhN00pFVfhsD2NXtWQ+x4SyQYu9u9nM375sRrJo5HVsKXSBB+jgD4SCQMvkf02jPonRmHLKS9kDBosHvsaT+dkcKwCqIRD8Uih1B00c4I+McT+wqeRb6CB4uEQSmSqFR+ceU3YyEkSzqb3wFpifNQOoN3is4XWwunodj7cgR6kxAA55Am+QoSDqcjKmFXRMusiYCoFfq4OyDq6VkUD/8IcuK2Q1p1AWmjHax/NQg0H0da5+dIcATeGwRSvRDY/Rtpt3eiNQjvIuHWBQmDFLJ6NkLA+QAC+auiXObsdDb/LAKvdogWSSHrIoPA9lZkhVwd5TJZ8x2sh/wOK1n9fyABFnwJ1Sji6mSbg3VtTte3ufk3sjwOQGD8FQLTg5CltA4W2WPj/cr6eILVfwtZMccgi6sP8WI+kODoaH2/E1F6rZEQPxCBd1iMiI2vBbJghiJaqqM9s76Iugl7Jx+FrKf7rY2HkMKxLBKq55mz+AhkqdyEhOySrAKHaL6LsUWBJedxqfxSym9SIMAP6RNGIXA9yKJRiuskfQt3IwAZi3ImLUjHm61fiBy7ryLAm2HHbkecdgviGPVv0BqEOrR47DjiXDv97NYzkIUBslRC4rM8cgDvj8CqJwLVLxEgf4eE00FIOK2HVj/vglJulCEA+wyB8CNIy90TCZX3EF/+JVqcBwLcedaHnZGgjOz+/7L+7E4cInohWoNRhrTsSUigbkC8TeXBNr75SDh9jATUVLS+42hrtyMC5s0RzfYOsrCeRhr7pQj4HyKmZhbY/IKEbmu05iBQbbORr2cd5DOoIk5DPhgJmvlImPa3/lchIf26jXuw9f8u68Nn1kYaCb2zg5Jh2WOft3mEJnwFVrcSvW+Hk3DaUyql8gspv1mBAEuOQErUSVoL4xF3/ShwYCIKpI1dfzYChvARf4M07d5Iez4cOV9XQsBVRazx3km89eRW9lNAgF9r10+xa96zaz6wnz8hSiK0GSFO/17r9/VWZw8kgDIo1r49Ar51kSZ8MhJ8hyN65xHiVc4zbGyvIYrqayRw5tu9D0M+k8ORZrsV0nLPT4wtjPUFJHCeQIDbAvlYNkYafVhfUUXsyG+L6JsrbJ6fIE7X0R1ZWi2RxXEdErZXozDUV6w/sxCw1yNrby7S5HsgAVGNfCM1NjcNWPgxcHmUy7xi4ctPIppta2In80fWr38k3ote1h9v/W/UKrC6pUiiUvnFl9+0QIClRyAl6gVroSsC54uiXOaCojrLo495IALy8HNSlMvcYHXKkL/hbKQ1h/DFUPdPUS5zo4U+HoOANCSJC87oENI6KMplLk5n860R8J+JrAasXj0C24XA8CiXOdT60A/5HjayNhfamFog0PoU2DLKZeZZptIbkdZfj0A0hNsuRIJityiXeaeI7gj5fTon+l2D/Ca3RrlMIZ3Nb4OomECJLJ+YjwKLhvoG62qq1WtNvJ7CIathKPJ3+HQ2H9k9exKvKA/lPWSpPBTlMnPS2fy7SKgsR7wvdz16L66Mcpmwv7JDAngVJHwgEeqbWBxHOptvh6y6lez+jVoFVrcUSVQqv4rymxcIsPQIpES9pLUA2oYx10i91RA47WGHaoDlEit0A7hsgwTIVonLn7OVzKFeSySszkKafLLsE+UyjyXqlqPwx8FI0w3Fo0VanxXdf18bT/dE3e+B9c0hnBzTvgigOyQOf4RSPxTXPZA4vXMoo4EjbDV1su6xLLq6GaSBnxPlMp8X1b0URS0lx/UwcFmUy3xUVPcNYr8DiKJ7CLg+6TMyAR0sMNCzugG4JsplJiSuJ53Nn0W81eYCRI9dHyndRrJeBRIcayAa63gasQqsbimSqFR+NeV3IRBCSWfzA5GVMJZGgC5Rb3fk9K1EPPIJjXG9ae0c9gTyHdQgOuXRRuiCda2dEFHzNgLPj4vqrY7CRHexQw2IJ78kymWmJOo5q3Mn8aK14cCpjYBcJaJ1ws5rn9jYv6GomAX0KRIKBWCTsJCvqJ4jpqlADt0TonjDnWS9/RBtk0JWxQ6R0mUU19sB0VnBP/AUsrzGF9XbzO4dfBoLkH/i+iKBXI4E+3WImvL29+Aol5lVdP/2yAk9wA4NR9r+Ys5eUwZeQE7qD4GdGrMKrO6BKHJqHJrzUhqKUvlFl9+VQIClRyAl6q2MHJ6tkVPxkCiXebuReg5FpQQg+zeipd5opO7LxJukgJyRF2E0SKLeDShcNJQCCo28Bm12U7B6lyPLIllvGHBplMuE/QYccn4flajXgEB1SAC9ImotlHrk5L0ikZJiRSTc/lhUb0CSCklrx7HriENVw33/GOUyL1mdMrvfYBbdi8Fjq5etXgfkqD6LmDILZbWkpWHjOBIJwc6JettHucxzyQtNWB6HKLB2dnholMtkKSqJ1caXIcvon8COTVgFpUiiUvlVlt+dQIDmRSBZvbVRXHwZ0nCHIs67pqjeNsSLvEJqiseAPxeB1akI1CF2KDu7x+XAU1Eu05DO5kchDTgImeCDAPHst1r//40W0S2HnJpJzn2EtfkHRBuFbUQD5+5RRM5lyLn8KHK+O2uzDFk+jni/hc2QBVNF7OeYYvduhYD9IWuzP3Gobbn9nmHXbImcq2cgJzRIWDQgq2yB9f9a4t3KQqRQ8ImUWd29olzmSfNBnIgc550SbQafSPtAEybotJByHLvnZGDVYh9T0Wpjj6Kv/tiEL6oUSVQqv9ryuxQIsFgE0hnAtU1oe7sjzjtCoZtjkDb8dqKOQxz66kgoLEsMhEnH6Q4ojv9uBLBfs2hEUsiZ9GcEwluhKJ1ViTe5LyAwDAJlOAK3UYhGmozojBCVg7W1kbV9OgK0rRFAdyQG40+QEHrZ5mWujbkeadCOOJIojOESREe9jhaDJQG7mngbyW4oimtTBORliXF/bfe5G2n3LxKvIk5GDLVGNM2ayC9xIhJQLYhzDIX8TdVW/2Vg3SiXWcGeVTLnUBj/K2hV8+FRLvNDkr+iHEQ1SNBPQlRaEG4k6ndCa0q2phRJVCq/wvKbWan8n5Yol5mMtNQnkAZ9g/HOxfVGIEdnL6TxdQDeSGfzQ9K2/aR99IMRRRE2iKlEIHks8GVau3sF3v4d5CzthYCtgMCxEmn/PZFWez0KlzwJafjzkDUBenYNSBiAwjPHIm39LmsLBKiBtqm0+26EADRE8ng7tw4Sfh9ZH/azvoWFdSBh8LSNAUQzTUUO3iCkqpAQuNnm5Gbr7zZ2Llgo021OV7J5C3TaNol+LbAxt0Fg+wFyID9l83G6zXHg8ceikNHl0WK47sCYdDbfN53Nh13mulm9jsj/0AatzRhmbQSrIKw2fgEJ2gZEMzYmDHoTC8VDolzmopIwKJVfW/ndWgihNCcCySyAe1As/gCkAR5BwlpIWAkro9QSd6O4/fsQ4IQcSe2trTMQcPVBoH4WAsKxxHz6XASk7yAOPeRAegdRQSAgDNRSHQKtWQhMQ7bQ5MreqcQ7qPWzevNQaGigkz5CewC8gfIweeKommCdvGfjnIUW9kEcu19Awq+D9WcZYnrsG2Ka5jmUZTRo6gXrS9jzIIWEwcaI/rod+XO+Q+sw6q1+nc3rxYi6yqLFcn+1OfzS5nQOEsC723MaaPd+ErMOGslMejISLDshB/IifggoRRKVym+n/G4thFAayYH0SjIHktXxCDxeQ9rujWjx1w/WAgKwwUj7PBDlw7kWCZEKBHxfIQ35cLvXnmg17S1o9fEJxJz6jQhkWiLN+Ta0bmE0EgZjkSCZZ/WnID9ALdKOu6AopBsRleWRpfMhAuY/ImDdgTg1xXC00Cv04Q/IOXsaComtR5FSbyOQrkICaTsEtlvbmE9HMffLIKC+AYG/Q1bJ6UgwhD0ZIqSdO2ThjEAhvQXrw3FIAL2B3tmWyBn/tbU/HlFcXyNhcAcSyH8lzrZ6nc3XEUiA7ohCZwdj1kGRVRBSWayDnvVJTQiDUk6iUvnNlN+9hZAszciB1Bnx8SHn0XzidQtjkPVwFdI+e0fKkx82iA85kO5B6SbKEHd9BxIy7yGQvpZ44duzyPH5NPFm98HvAKJQjkCpIZZHQukbREWFUofAuk0j5z0C+WkIvCuKztcjUJ6GrIryxP0Ldh60tqGr9Tl5Pizkmkq8FuI7tHI4LE4DCZUe9vdQ9AxGIauhkni1Mii653YkZJaxeeyLaK3RyKJ4EvlhlrVr+lu9kJMoE+UynyZWJQ+wuovkILLjdwE3RrlMCLEFSpFEpfLbLL97CyFZoiZ2YUucn4pooPYISGqiOINqB6TBjkdWwtF2zY12zSoIrN5H4HSmHbsHCYvNkBXQAwH8CdaXEQgcU8R8Oyi2fS+keb+BQPlZBOYF4tw6r1rfKhFA90JWyfPI+fsssiYqEEj3QpTUGASw3xKDPXb/kM31dmuzG7Fw6IH8FCmbo3IE5kE4lFvfF6I1D2XWfoi+moUAtqXVcfZ36O88ZAlNQNlGsbl70sa1IhLSHyKhAaK//obSeGxiwsAh62AcEsCLZCZFTuZbbX5DZlngh0iiuyntblYqv7FSshAaKUuLQEpEHv2Q86holfN8BFwrRrnMQrtmHZS8rhOiWrZB1EvIkVSFQHQmypdzgOXKudPq1iJNuxsCokOJcwItQNx5WK/wHRJIISLJWZ9asrgSMAFp/5XImgirj2db2+2JtfkyYj9FS/s7hOTW231Cgr2WLOrYLrc5mUu8mG4i8SY4tYnjBWtzpM3HIcTRSxU2/hyymuYgC6YDsf/jbBTN9QCinlqj0NoBieexF7Kw6qxPP+QgSuQomk5RRFEpkqhUfsulZCE0UpYWgZSIPNof27w9WnS/hfkIZJ9MRCJ9gHj3r6yZ46NcZm6Uy1yEOPtbEeh1ANZIZ/OtbTXxdshaAGnfn6CUCqva/T9FwgAEjgOjXOZYFJr5DLFm75CDeA1EYS20490RWJ+DhNVJKGSzHXGOpVut3jYoNDaEs1agENGt7Xzgz9shYfAF8s10QlRQawT6tYhuWSXKZS6zuQzCwCMg7xvlMrsjGgf0rn4FbBjlMhdHuUwd8lMEp/UMRPGsF+UyYfvT3eyeQ9B6kyAMVkP0ETZHP+xXYDmKRtqc7FYkDEqRRKXymy4lC2EJZUkRSEWRR/tFuczfEtd1QMDdBTl/Dw/rFixz6gwEONcBZ4Skaels/gC0sAtEAf0FuCvKZerT2fwdxKuNnwWOiXKZb21B1qcIFEHx8jciX8TOyGEdhMKniKr6iMVXGxeQVRQhjXzZxLlpCEC7oyR4LnHuZQSSeyPfSShhlfPNyCkd0oSD/BQ7oqimc5FPJZTbo1xmoM3HXoiWCmNbN8plPkhn892RUDzS+jIb6BJyDpmGPwpFFv0jymV2suMhguhSJLBuQSk3fOL8UzQSUVSKJCqV30MpCYRmlKZyIJn2/wKKvNmyKKlaWL08E0XO/LDKOZ3Nv4a2eOyBtNGDolxmbjqbPxwJmelIs22BQPwyBKyfoAyqCxDgno0imkKSt2mIUgox/ClEy3RCdEo9oqaSmVLfQxx7oJZgURoqpNFOlimIaulRdDwsNPsWOYTbEtNFDXa8F6KOWib6lEKC7AsUynqajekAG1Mbq/cPm4/TkHVSjnwdKwOtbZX3xkiwtUSWytFRLnNn0WrjWTbHi6xKTmfzVyCBeUKUy9ycOF7KSVQqv4tSooyaUaJc5ja0Crgn8GY6m9/Ajtcgx241MCKdzXdLXDYaac8LUO7+PwPvpLP5DRGItUDJ4TLIgd0NabS1SLMvIPBLofDIVkjrn4qcvm8jIbEVsmDG2M9tCNgDr98Nge1NCKyxtsO+Dg8gYP2/9s49Sq6qSuO/Xd3pzgsTQgh5TdJEQJAACbiE0QAZnoFeZhCRGZUJ6KCioogB08grijg9iIooAWdUREBFcMCRJuigRAccFspT0sM7ndjkYSYPSCf9rNrzx3cO93bRna5AJ3GR861Vq7ruPXfXudVVe5+997f3MaTkI2IYahRZwhhkLPZCxiB/vBjktyIjt1vZx7gJrdqhd2vrbuSRDAtzfwwlmE8Lz6NRyOpBxBb6QvhcS6ju4RvhXqbVNTSdhj73NrJ9mv+3rqFpPkrmH4BCgKNQk7u8MYjtxa+LxqCuocnqGpouQYyjhxCtNBmDhDctkkGoEP0xkMqZR3UNTcPC8Vi9PAExfvJMpKkox/BTejOQjgCeaWmsfxiFovZHDKQuFPO/GRW3Bux1cgAAEtNJREFUzSLb/7gbxci7UN5gJpmH8Ceylg/nkSnh74fnIYgm2xOuvyccj55CpI7mK7jzXkTsUVRCBXggQ/GpIPMl5NWUwr1/Oox5IHdPw5ABBBnXmchQtSEvqoQKyU4Ic/kdqoloRWGqJ8O1l5BjEpG18f46vesKjuG1VclHUsYoSkyihF0RySBsA1rUrvoIpIzvrGtoOr+uoclaGuufRIVl7wBuDPkFyLyEi1D4aDpSnHE/hFNbGuvvQQreUAHahvBedyAWy/uR4n5XeB2Lxs5FrKX9kbdwBDI+05FifW84NxIp7mcQJRaU6AUp5D+i70EN2f4OzSjUVCDbfKZXa+sw38dQ+KVAtofEX5CSjnTTg8j2et6IDMksRK3dF3k/kT56FMo7zAjXnxbufRMyGt8IY0aghO86FGYCGdDbUF5kfbjWUfL9DFQE+M4g+4pc99a9EWtoGcoF9QQm0a9QAeHlwLzUoC5hV0AyCNuI/hhI/TCPopcwEcWyIxNpXhC3KFQ5Px1kGnBkKGYDJT2L4fiUwEg6mYzTfwxqaXENWnETxo4Lj2iYulBS9/u5cfF4Z04eKEG7AXkwERtRX6N/K/s4xqHVdj4R1YkMTf7YM0ix3pWbUxXylGpz4/6E6g2+SrbndDPKm/yKrP3Goy2N9c0heX9HOPYUMspTkRE+FIXyYl0B5KqSgbjrWS9GUWISJezKSEnl14m+GEhoJfsDcsyjsh5HsXrZkJJdiVbxS1HS+YdknUm/icJBnwvnp6Gw040ovh/rBmLP/9WI1fQ8GdsndiaN50Ar+KH0rhMAUWWH0xsrUKHXSmTUQMp9Elq555X5ZrRyz2M5UtBryQxM7FbahpK+xSB/S5h3VZA1DOUI/g55Bu0of3Af8gLmhOP7orCUo5BarDYeCXyrpbF+PkCuKjnfs6gXoygxiRJ2dSQP4XWirx5IKH4eex7dVNfQdFi5lxCudaTk15DlFn4QRH8UrfjPQ2yanyKltRGxbCai0M6VZMZgA1L4jrj5neExNRwbT7YXwTikiHuQMo6hoGgM4gohVv2CQlFtYexbkbKuJSteg97GIO61MDVcMyY8tyEWUSHMYSMyAJORMSgh76I6zO9DqGbifGQMvotYVXG/hImIvvqHIDfmCuqRwcrvlbyQ3rmDRnI9ilJPooSEZBDeMMoZSGQx/DzzaAkhl1CnPZRBBuHtIYcwnSxJfGt43IeU5cFkm9TUolX3s2T7NLeikMrjYVw18gxeJGMPLSPLH4A8hhVkVcYtKF6+niykszS8Jhx7Chmw6nDdE0jpx/GLUUI2hrhGomrfWOEMYkfFWHwpzHkzGSvqGpRkrw3XHIsMYolsf+XZyLOpDXM+FHlkhqrKTyHzRuJnOpdc7iDPKAJuqGtoupTEJEpISCGjwUL5LmxICf8erVKPRknf36AV6bdzu6eNa2msXxt2STsQrWzHIyX4IEpUFxGL6WeIWbMOrbpjV9AtSGG+gOLssf1EfheyuOtakYz/X41CJH+PksNVKFH8brLFQle4bkhORrw2Pjeh1fZ6pKibyXZfg95tLSJim4w4n98hI/d/yHv4I0qkt4Vj3ShUNRwZmunhvsfmro27p12Eis9GoTDeo8hAHYByA79G4ai5KE8zj7S7WUJC8hAGC+UMJLS6fZV5xGu9hOZw6YG55+hhNCNlOQnVD8RagN8gxb0HYsbExGtneD09XPcgUpZxm8m4Cgd5B79GivxlFIbqCe+xCIWHCoi981S4fggK00TELTojXkIJ4THIE/klmfH5CZkxKOXkDEEGbGV4vQ/KAYwNY+9DBmZkmMeTyBi8guixNWHsAmSMyj/L1lBV/qp3gGiskVH0MeTVzCMxiRISgOQhDDrKNqu/HinIryCl898ELwEZjVbE2b8JrYQvQ3z4ZSh8cSAqAluLVrrTkBJvDec6UGjo7Uj5/hnlEEDJ4/wm86Dk694oobwUxe5HIcX8FuTdrEVewSRkVDaFOUTvABSy2i/8/TBKglu4t6ORQv89CmXVokT0FJR7iI3riki5x41xloe5eZAZq6/vQSE5UN+hE8N73YtouneHRoAtwIMtjfUfqmtoejTc/0lk3sE7w+c/CVF5rwuf1UdyLKSEhF0aySBsB5QxkO5FCd0PIOrmuQTGEVqt34o8iD+gcNARKBb+LsSrH0dWYZxnAnUgZWtkSjY+g7yGWrRCbiBTzh7ODe1DZg/Z9pZRTmxHcRLwCaScq8OYbjKmUl5OZzge52O582ejfSFOyX1kMfQU72to7u84Z4KcWMz2jfB3A6p1uAop+8OQcV2EPLK438H7UXJ+PoEWTGISJexgmNmeaGEy093bBxq/FTlfA5539+sHHLwNSCGj7YAyBtLxSGH9EXkCPyJjHDWjlX4MdaxGHsNPkIIbj0IcIOUbW1xDpjTziEbh16ht9hbE5HkX8lJiD6J4balMZkxCF5Ah6CYrVhuH2FAPI2MXE9ig1X6eslpLlkyOyvzHyCu5gKx2YC7yRvItMOLcYovtaJxiK46OcP35yAvYjBR8M6LwvjVc10zGLDoIhZVuQp9rYhJtB5hZi5kdN/DIN/w+C83slr+GubwONAA/iMbAzJaY2dl9DTSzGWb2iJltCc8zcqevBr5gZjV9Xft6kQzCdkSOgTQFxa9fRmGhh1AR29Mo3BN7GL2XrD7gKBQ3/xAKBQ0JYwr0XjFHxM3oH0fKNPLzL0OK82QUHnqRbLezKCsvM7bFXowU+onIMMR5PoPi7v+Dwkub6ft7VBXmVAj3+8/heX+ypniTw71eFea0tux66J3c9nBvc8Nn81WUFD8deWG1qG4BlM+YgXI388Nn8xESkyhhB8DMqvs4FplxWzVmYWwN+m7fgsKqNwE/jwbA3Vch/TF3EKedDML2Rq4HUgdSyGPcfTQwsX3FkycCe7a3PH5B9/qV7sWez3ip+ARqu7ASJaS7yIrCopLM9xPaDBTcS83A4R2tzdN6Nq07vmfTuuM6/rx0GnCce6kVxeS3kO24ViqTFdlDteG9T/VS8Qkv9ny6e8Oq0pZlj10IjO3QnCe6+5hwP1Hxl6OEjNtmFAZbCZzlpWJrcfOGC7xUoq15ybcBOlc/92H3Umyst7Gfj7IGfV/HopDUwWHsSe6ljs41yz4B0Lb0/kUAPZvWXejF4ir0A1wV7j/1JNpBMLOzzOwBM7vazDaY2TIzOyl3fomZ/YuZPWxmr5jZz81sTDg328xay+S1mNlxZjYH1aT8g5m1mdkT2ziv3c3sbjNbG+Z1t5lNDufeb2aPlI3/nJn9PPxdG+5nhZmtMbMbzGxYfs5mtsDMVqMwcDkOBza6e2sf58oxG3ng17h7p7tfi36j+VbxS8gIFYOCZBB2AHIMpKfcvRbYv7h5Q48Vqp7u3rBqXs3YKXOKbeu/U+raUgSb6V7qRIncSPeM/6cqZFhuQiwfA2rdvduscFixfVO3F3vuwUvvA38fpeLiYvumbrPCoe7eTbZxTYGMmroYFXxFVpIB4929E2xmqau9WGxb952aPaee1L1h1TwK1U8XN2/oAd4W7mUIWY5jKdoBbTlZ7iCGkiZ6qdTjxe5JXuyha80LVwydcsixXWtbPm2F6k2l9k1DvFQag8JSRaTsFyFPJCKuukYiYzjWS6VRpY62oVYobOla23L+sKmHHNu56vmFXuwpebFrvJeKJcScSkyiHY/DkUc5FnmB3zOzvFc7D3ltE9Bi5NqBBLr7vSj8eZu7j3T3Q7ZxTgWkrKciz72dbKvV/wT2NrMDcuP/iaxxYyMiU8xAecBJyAOPGI8806mIxVaOg9DnUQkOBJ703kneJ8nCy6AIwLbe/1bxGrcmYfugpbF+dV1D0+yuNS88MmSPKfu5l963+pbP56mb/1XX0HRxsaOtpVA7Yg93J/x24g/oGdQ76cctjfWbAOoamk5GynxCqbuz26qq91vz44tacjLvnPK5O75Q6u581qpr8rHGIkpm/2tLY32s5r0EKc2Pu3sBqC11d6yvGrbb1D/fuqAtd+3Nk8/94Sl46T+sUBXppGsQ/fOWsCfBZ1GC/DLCF9jdwazWuzsfr37Lnoe1LjoreihLgG9P/tQPr8ZsfjjWBJzT0li/Ksxtf5TQPhsZmEypmFV5T/d3Vn7vk+fk5rikrqHpSz1t6++vqhpydEdr84LVt1x41Vb/QQnbA8vd/d8BzOwmZOD3QrkygJvd/alw/lLgcTM7c3tOyN3XoXoewvteiXb9w907zew21AzxYjM7EDHR7g6G7GPAwe6+Plz7FZQTvCiIKwGXazHVJ0Yj1l4lGIlCzHm8TO+28pvIuvoOChLLaAfCzHYDWz5mzrlz1y2+9oG+xtQ1NO3j7s8FY9CDWDKN+c138hhWN+PIEQcdv3j4vofPXfH1037T15gpF9x1nlVVXwP0mNkNQd5L/bz/27o3rL69arc9DixUD9knbOP5GvzNZ39ya6G69oNeKi4s1Ay7Ku5WVibLUEz/K8DhXuzpsarq2pbG+vLOqQBM+PC1t7c9fu87qkbsPm3jA7e+5osZ6jdOQyGDAwC8p3vz8qtPGVk+Nr7/mtsu/VpHy2O7uftH+xqTMHgwsxbgbHe/z8zOCn/Pyp13YF93f97MlgC3u/t14dwIxA4bj/63t7j75H5kLwT2cfczKplL2fHhiKE2B8XmQUq22t2LZnYEIkBMQxtT7e7uHzezcWjhk1fSBlS5+0gzmw3c6u6TtjKnTwL17l6fO7Yk3Ot3y8aeDxzv7ifnjv0CWOLuXwuvTwUucfdD+3vPbYa7p8cOeiD6410DjZtw1rd+MfroM1+cuuDu3SqQ+U3gsoHGjT7qzJ9Vjdj9+grn+buavfb5wNbGTF1wtxVGjG4CzqxAXlXNXtNeGXf6FacNMK6AajAOHkjm7sd87MSxp17aPvn8248ZQOZe6Ec8dGf//9/sD9QC5bjw91nAA2XnHSlykGfYmDt3AMqXVaG6lvX57w/KRUXZlyMlWtFcyo5fGt57fHg9I8yrOjfmGUTqWAHMyn03twCT+nm/2UDrAHOaBTxXdmwJMlzlY09A9UaWO7YcmJN7fTFw46D+D3f2l2hXeqAQypcrGLc3crcrkXkncGoF406txBiFsS3A3hWM+3IlxgjFVTdW+N5NwHsqGHcscH+FMlcCk3f2///N/ngdBqEVMdeGo82NfhTOjQrKNzYpvBx5y1H2OaiZZGGAuZxE1tl3KAqRX4XyZkPD9/LOPgzCxShe/0KZzG+i3lrjwutJwInh70oMQg1i0k3KHVsS7ic/zyFh7HLU5DLurrgcqMld+yvg9MH8H6ak8o7FFpTYHQjxB1EJ2neizLdUKLMdGFohZ7pSmRV9lmZWheKxld57wo7DzajL72qkCD8D4O4vA59E+bGXkHeQZ+bcHp7XmdmjW5F/D/ruxcdC1EBxGOqP9RAqHO1rXtN5LT10AaprecjMXkHtVd424F0GuHsXut/yUNf1ZfO8MYw9BSXeN6Lk+ynhOGY2ARnTuyp9/0qQcgg7EGY2HfX5qXOxfvob1wgMcff5/Y3JjT0DOMPd5www7pcoiVcJB/rrQKe7X7SVMUPQKuwEd1/a37jc+PuB6939p1sZMxV1RJ3i7ltV4IHTvQI40t2f3cq49wAXu/sRA80xYcehv9j5XwMClfQvwKHuPqj1KoNcqfyCuy8atMmRaKc7FC5GxXPIRewTZjYFrQZuqFDsHcAMMzuqvwHh3AyyCuGBcANwdphLfzgHxUMHNAYB16HKyvJNeOIcDYUGbh7IGIAYIWgF+aUyKmNe5lC01/Kg/mgS3vT4BPCHwTYGAO6+1t33fyPGIMiZP9jGAJJB2Bk4G7jIzC7MK0cTZiEK3JWVfhndvQNxpe8ws9NDiCTKrDKz05EhOCOMrUTms2gDnvvN7N15hWtmw83sQkS167Pkvh/8DLXWXmxm++VPhFXT9choXdbHtf3hSsT5vtHM9iqT+Va0PeYyKqgMTUiAV9lJ56Hq9l0OKWS0E2Bm01CC6m9RYqgdNWUbDix09x9t5fL+ZM5CrRwmoq6joKrGl4DPu3ufNNcBZH4Q+CKK4T6CYq8noGKx89z9xW2UV0C9XD6DimqeR0VLs5HBmB/ix9sicyS6739ErvgalJQ/BHklV7h7sX8JCQkJEckg7ESYWR1qF12DlONv3b1Pjv42yJwJzEQc6Ufd/bE3KK8Q5rgPogX+1t1b3qDMWtQjaQJqgf1LD8U+b0DmaMQtH4WMwr2VekQJCQlCMggJCQkJCUDKISQkJCQkBCSDkJCQkJAAJIOQkJCQkBCQDEJCQkJCApAMQkJCQkJCQDIICQkJCQlAMggJCQkJCQHJICQkJCQkAMkgJCQkJCQEJIOQkJCQkAAkg5CQkJCQEJAMQkJCQkICkAxCQkJCQkJAMggJCQkJCUAyCAkJCQkJAf8PVPIGw1rRrL0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgSK1XempO6A",
        "colab_type": "text"
      },
      "source": [
        "Our first layer L0 that is the input layer has 5 input, 5 neurons (N0-N4)\n",
        "\n",
        "Our second layer L1 is a hidden layer that has 12 neurons (N0-N12)\n",
        "\n",
        "Our third layer L2 is also a hiddent layer that has 8 neurons (N0-N8)\n",
        "\n",
        "Our output layer has 1 neuron.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQMEbgnAue7o",
        "colab_type": "text"
      },
      "source": [
        "#Building a function for our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFwUQdc_uiID",
        "colab_type": "text"
      },
      "source": [
        "For building the function I decided to set a seed so I can reproduce the same result if I need to. We set the seed by running the bottom 4 lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ4VF2P0uoUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "import numpy as np\n",
        "seed(1)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXWdwFGqxo5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = np.genfromtxt('USA_Housing_project.csv', delimiter=\",\", skip_header = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asIL3XW2xta9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWudxFQTxtnR",
        "colab_type": "code",
        "outputId": "6b68f9c0-4bef-403f-bf6a-60a0a702aacd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Index for 30%\n",
        "index_30percent = int(0.3 * len(dataset[:, 0]))\n",
        "print(index_30percent)\n",
        "# Split into training and validation\n",
        "XVALID_f = dataset[:index_30percent, [0,1,2,3,4]]\n",
        "YVALID_f = dataset[:index_30percent, 5]\n",
        "XTRAIN_f = dataset[index_30percent:, [0,1,2,3,4]]\n",
        "YTRAIN_f = dataset[index_30percent:, 5]\n",
        "#print(XVALID)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt8VqHFjx0O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Applying mean and std from xtrain to xvalid\n",
        "mean = XTRAIN_f.mean(axis = 0)\n",
        "XTRAIN_f -= mean\n",
        "std = XTRAIN_f.std(axis = 0)\n",
        "XTRAIN_f /= std\n",
        "\n",
        "XVALID_f -= mean\n",
        "XVALID_f /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA3HyggYyA1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "YTRAIN_f = np.log(YTRAIN_f)\n",
        "YVALID_f = np.log(YVALID_f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbmrtAEByG-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "model9 = Sequential()\n",
        "model9.add(Dense(12,input_dim =5, activation='relu'))\n",
        "model9.add(Dense(8, activation='relu'))\n",
        "model9.add(Dense(1, activation='linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b9DpDRtyVPu",
        "colab_type": "code",
        "outputId": "4be2fb26-c688-4260-84fe-ac7c990437d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model9.compile(loss='mse', optimizer = 'rmsprop', metrics=['mae'])\n",
        "history9=model9.fit(XTRAIN_f, YTRAIN_f,validation_data=(XVALID_f, YVALID_f), epochs = 500, batch_size=100, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 199.5161 - mae: 14.1078 - val_loss: 193.2507 - val_mae: 13.8858\n",
            "Epoch 2/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 189.4739 - mae: 13.7485 - val_loss: 184.1715 - val_mae: 13.5535\n",
            "Epoch 3/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 180.4791 - mae: 13.4139 - val_loss: 174.6983 - val_mae: 13.1939\n",
            "Epoch 4/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 170.7083 - mae: 13.0371 - val_loss: 164.2665 - val_mae: 12.7822\n",
            "Epoch 5/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 159.8019 - mae: 12.5981 - val_loss: 152.5635 - val_mae: 12.2980\n",
            "Epoch 6/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 147.6794 - mae: 12.0852 - val_loss: 139.4115 - val_mae: 11.7224\n",
            "Epoch 7/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 133.8056 - mae: 11.4596 - val_loss: 124.3812 - val_mae: 11.0160\n",
            "Epoch 8/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 118.3897 - mae: 10.7077 - val_loss: 108.1149 - val_mae: 10.1795\n",
            "Epoch 9/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 101.8716 - mae: 9.8199 - val_loss: 91.1224 - val_mae: 9.2054\n",
            "Epoch 10/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 84.9979 - mae: 8.8061 - val_loss: 74.2410 - val_mae: 8.0981\n",
            "Epoch 11/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 68.5708 - mae: 7.7054 - val_loss: 58.4974 - val_mae: 6.9852\n",
            "Epoch 12/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 53.4033 - mae: 6.6553 - val_loss: 44.5314 - val_mae: 5.9667\n",
            "Epoch 13/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 40.2130 - mae: 5.6719 - val_loss: 32.8535 - val_mae: 5.0473\n",
            "Epoch 14/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 29.1961 - mae: 4.7621 - val_loss: 23.4972 - val_mae: 4.2083\n",
            "Epoch 15/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 20.4768 - mae: 3.9098 - val_loss: 16.4780 - val_mae: 3.4737\n",
            "Epoch 16/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 14.1284 - mae: 3.1676 - val_loss: 11.7098 - val_mae: 2.8630\n",
            "Epoch 17/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 10.1880 - mae: 2.6465 - val_loss: 8.9471 - val_mae: 2.4612\n",
            "Epoch 18/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 8.1336 - mae: 2.3511 - val_loss: 7.4859 - val_mae: 2.2334\n",
            "Epoch 19/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.9262 - mae: 2.1650 - val_loss: 6.4928 - val_mae: 2.0697\n",
            "Epoch 20/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 6.0039 - mae: 2.0124 - val_loss: 5.6694 - val_mae: 1.9280\n",
            "Epoch 21/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 5.2142 - mae: 1.8716 - val_loss: 4.9199 - val_mae: 1.7980\n",
            "Epoch 22/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 4.5144 - mae: 1.7407 - val_loss: 4.2630 - val_mae: 1.6813\n",
            "Epoch 23/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.8838 - mae: 1.6140 - val_loss: 3.6577 - val_mae: 1.5508\n",
            "Epoch 24/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.2992 - mae: 1.4825 - val_loss: 3.1058 - val_mae: 1.4263\n",
            "Epoch 25/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.7698 - mae: 1.3583 - val_loss: 2.6137 - val_mae: 1.2936\n",
            "Epoch 26/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.3193 - mae: 1.2364 - val_loss: 2.1540 - val_mae: 1.1895\n",
            "Epoch 27/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.8964 - mae: 1.1158 - val_loss: 1.7603 - val_mae: 1.0604\n",
            "Epoch 28/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.5243 - mae: 0.9936 - val_loss: 1.3913 - val_mae: 0.9609\n",
            "Epoch 29/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.2058 - mae: 0.8783 - val_loss: 1.0895 - val_mae: 0.8388\n",
            "Epoch 30/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9434 - mae: 0.7685 - val_loss: 0.8401 - val_mae: 0.7199\n",
            "Epoch 31/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7272 - mae: 0.6686 - val_loss: 0.6458 - val_mae: 0.6236\n",
            "Epoch 32/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5624 - mae: 0.5761 - val_loss: 0.4935 - val_mae: 0.5212\n",
            "Epoch 33/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4297 - mae: 0.4924 - val_loss: 0.3735 - val_mae: 0.4577\n",
            "Epoch 34/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3330 - mae: 0.4286 - val_loss: 0.2879 - val_mae: 0.3982\n",
            "Epoch 35/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2628 - mae: 0.3768 - val_loss: 0.2381 - val_mae: 0.3753\n",
            "Epoch 36/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2167 - mae: 0.3422 - val_loss: 0.1906 - val_mae: 0.3278\n",
            "Epoch 37/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1807 - mae: 0.3126 - val_loss: 0.1647 - val_mae: 0.2934\n",
            "Epoch 38/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1542 - mae: 0.2889 - val_loss: 0.1405 - val_mae: 0.2777\n",
            "Epoch 39/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1340 - mae: 0.2715 - val_loss: 0.1244 - val_mae: 0.2614\n",
            "Epoch 40/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1196 - mae: 0.2570 - val_loss: 0.1120 - val_mae: 0.2488\n",
            "Epoch 41/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1072 - mae: 0.2438 - val_loss: 0.0975 - val_mae: 0.2373\n",
            "Epoch 42/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0957 - mae: 0.2312 - val_loss: 0.0890 - val_mae: 0.2231\n",
            "Epoch 43/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0874 - mae: 0.2204 - val_loss: 0.0805 - val_mae: 0.2160\n",
            "Epoch 44/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0800 - mae: 0.2111 - val_loss: 0.0739 - val_mae: 0.2073\n",
            "Epoch 45/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0725 - mae: 0.2010 - val_loss: 0.0696 - val_mae: 0.2021\n",
            "Epoch 46/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0660 - mae: 0.1903 - val_loss: 0.0637 - val_mae: 0.1877\n",
            "Epoch 47/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0616 - mae: 0.1828 - val_loss: 0.0587 - val_mae: 0.1813\n",
            "Epoch 48/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0575 - mae: 0.1764 - val_loss: 0.0550 - val_mae: 0.1786\n",
            "Epoch 49/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0533 - mae: 0.1692 - val_loss: 0.0520 - val_mae: 0.1734\n",
            "Epoch 50/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0496 - mae: 0.1632 - val_loss: 0.0477 - val_mae: 0.1639\n",
            "Epoch 51/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0471 - mae: 0.1586 - val_loss: 0.0457 - val_mae: 0.1567\n",
            "Epoch 52/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0434 - mae: 0.1520 - val_loss: 0.0454 - val_mae: 0.1590\n",
            "Epoch 53/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0416 - mae: 0.1479 - val_loss: 0.0401 - val_mae: 0.1458\n",
            "Epoch 54/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1413 - val_loss: 0.0377 - val_mae: 0.1405\n",
            "Epoch 55/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0365 - mae: 0.1374 - val_loss: 0.0356 - val_mae: 0.1351\n",
            "Epoch 56/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0339 - mae: 0.1316 - val_loss: 0.0350 - val_mae: 0.1323\n",
            "Epoch 57/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0318 - mae: 0.1265 - val_loss: 0.0325 - val_mae: 0.1301\n",
            "Epoch 58/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0293 - mae: 0.1205 - val_loss: 0.0306 - val_mae: 0.1202\n",
            "Epoch 59/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0284 - mae: 0.1182 - val_loss: 0.0300 - val_mae: 0.1230\n",
            "Epoch 60/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0265 - mae: 0.1132 - val_loss: 0.0275 - val_mae: 0.1171\n",
            "Epoch 61/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0256 - mae: 0.1125 - val_loss: 0.0268 - val_mae: 0.1154\n",
            "Epoch 62/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0246 - mae: 0.1102 - val_loss: 0.0261 - val_mae: 0.1115\n",
            "Epoch 63/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0239 - mae: 0.1082 - val_loss: 0.0265 - val_mae: 0.1106\n",
            "Epoch 64/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0226 - mae: 0.1047 - val_loss: 0.0243 - val_mae: 0.1088\n",
            "Epoch 65/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0219 - mae: 0.1037 - val_loss: 0.0237 - val_mae: 0.1036\n",
            "Epoch 66/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0210 - mae: 0.1007 - val_loss: 0.0249 - val_mae: 0.1125\n",
            "Epoch 67/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0206 - mae: 0.0997 - val_loss: 0.0208 - val_mae: 0.0973\n",
            "Epoch 68/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0198 - mae: 0.0988 - val_loss: 0.0254 - val_mae: 0.1182\n",
            "Epoch 69/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0201 - mae: 0.0994 - val_loss: 0.0201 - val_mae: 0.0952\n",
            "Epoch 70/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0195 - mae: 0.0980 - val_loss: 0.0204 - val_mae: 0.0950\n",
            "Epoch 71/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0188 - mae: 0.0958 - val_loss: 0.0226 - val_mae: 0.1036\n",
            "Epoch 72/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.0945 - val_loss: 0.0216 - val_mae: 0.1054\n",
            "Epoch 73/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.0952 - val_loss: 0.0186 - val_mae: 0.0923\n",
            "Epoch 74/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.0921 - val_loss: 0.0189 - val_mae: 0.0906\n",
            "Epoch 75/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0177 - mae: 0.0934 - val_loss: 0.0189 - val_mae: 0.0945\n",
            "Epoch 76/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0175 - mae: 0.0928 - val_loss: 0.0187 - val_mae: 0.0915\n",
            "Epoch 77/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0171 - mae: 0.0912 - val_loss: 0.0213 - val_mae: 0.1058\n",
            "Epoch 78/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0168 - mae: 0.0914 - val_loss: 0.0178 - val_mae: 0.0887\n",
            "Epoch 79/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0167 - mae: 0.0897 - val_loss: 0.0176 - val_mae: 0.0890\n",
            "Epoch 80/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.0896 - val_loss: 0.0174 - val_mae: 0.0876\n",
            "Epoch 81/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0919 - val_loss: 0.0184 - val_mae: 0.0942\n",
            "Epoch 82/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0885 - val_loss: 0.0229 - val_mae: 0.1145\n",
            "Epoch 83/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.0911 - val_loss: 0.0175 - val_mae: 0.0891\n",
            "Epoch 84/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0892 - val_loss: 0.0179 - val_mae: 0.0923\n",
            "Epoch 85/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0905 - val_loss: 0.0174 - val_mae: 0.0900\n",
            "Epoch 86/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0159 - mae: 0.0891 - val_loss: 0.0168 - val_mae: 0.0859\n",
            "Epoch 87/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0158 - mae: 0.0877 - val_loss: 0.0203 - val_mae: 0.1042\n",
            "Epoch 88/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0892 - val_loss: 0.0165 - val_mae: 0.0854\n",
            "Epoch 89/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0883 - val_loss: 0.0174 - val_mae: 0.0908\n",
            "Epoch 90/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0157 - mae: 0.0883 - val_loss: 0.0167 - val_mae: 0.0848\n",
            "Epoch 91/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - mae: 0.0884 - val_loss: 0.0171 - val_mae: 0.0885\n",
            "Epoch 92/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0873 - val_loss: 0.0162 - val_mae: 0.0856\n",
            "Epoch 93/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0156 - mae: 0.0882 - val_loss: 0.0178 - val_mae: 0.0928\n",
            "Epoch 94/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0866 - val_loss: 0.0197 - val_mae: 0.1014\n",
            "Epoch 95/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0857 - val_loss: 0.0197 - val_mae: 0.0964\n",
            "Epoch 96/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0871 - val_loss: 0.0171 - val_mae: 0.0881\n",
            "Epoch 97/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0155 - mae: 0.0891 - val_loss: 0.0159 - val_mae: 0.0834\n",
            "Epoch 98/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0884 - val_loss: 0.0196 - val_mae: 0.1023\n",
            "Epoch 99/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0863 - val_loss: 0.0181 - val_mae: 0.0920\n",
            "Epoch 100/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0875 - val_loss: 0.0189 - val_mae: 0.0961\n",
            "Epoch 101/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0153 - mae: 0.0873 - val_loss: 0.0187 - val_mae: 0.0979\n",
            "Epoch 102/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0865 - val_loss: 0.0170 - val_mae: 0.0901\n",
            "Epoch 103/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0876 - val_loss: 0.0163 - val_mae: 0.0867\n",
            "Epoch 104/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0872 - val_loss: 0.0174 - val_mae: 0.0916\n",
            "Epoch 105/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0858 - val_loss: 0.0185 - val_mae: 0.0935\n",
            "Epoch 106/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0856 - val_loss: 0.0169 - val_mae: 0.0890\n",
            "Epoch 107/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0864 - val_loss: 0.0160 - val_mae: 0.0858\n",
            "Epoch 108/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0876 - val_loss: 0.0156 - val_mae: 0.0842\n",
            "Epoch 109/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0857 - val_loss: 0.0171 - val_mae: 0.0916\n",
            "Epoch 110/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0865 - val_loss: 0.0168 - val_mae: 0.0901\n",
            "Epoch 111/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0860 - val_loss: 0.0180 - val_mae: 0.0956\n",
            "Epoch 112/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0867 - val_loss: 0.0156 - val_mae: 0.0844\n",
            "Epoch 113/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0857 - val_loss: 0.0187 - val_mae: 0.0953\n",
            "Epoch 114/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0856 - val_loss: 0.0214 - val_mae: 0.1074\n",
            "Epoch 115/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0875 - val_loss: 0.0170 - val_mae: 0.0855\n",
            "Epoch 116/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0852 - val_loss: 0.0155 - val_mae: 0.0827\n",
            "Epoch 117/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0864 - val_loss: 0.0203 - val_mae: 0.1032\n",
            "Epoch 118/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0872 - val_loss: 0.0154 - val_mae: 0.0832\n",
            "Epoch 119/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0854 - val_loss: 0.0172 - val_mae: 0.0907\n",
            "Epoch 120/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0859 - val_loss: 0.0176 - val_mae: 0.0943\n",
            "Epoch 121/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0868 - val_loss: 0.0191 - val_mae: 0.0987\n",
            "Epoch 122/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0872 - val_loss: 0.0183 - val_mae: 0.0977\n",
            "Epoch 123/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0861 - val_loss: 0.0156 - val_mae: 0.0838\n",
            "Epoch 124/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0854 - val_loss: 0.0165 - val_mae: 0.0896\n",
            "Epoch 125/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0862 - val_loss: 0.0156 - val_mae: 0.0836\n",
            "Epoch 126/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0150 - mae: 0.0875 - val_loss: 0.0159 - val_mae: 0.0856\n",
            "Epoch 127/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0845 - val_loss: 0.0200 - val_mae: 0.1013\n",
            "Epoch 128/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0865 - val_loss: 0.0152 - val_mae: 0.0815\n",
            "Epoch 129/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0865 - val_loss: 0.0213 - val_mae: 0.1081\n",
            "Epoch 130/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0859 - val_loss: 0.0153 - val_mae: 0.0830\n",
            "Epoch 131/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0861 - val_loss: 0.0157 - val_mae: 0.0846\n",
            "Epoch 132/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0857 - val_loss: 0.0165 - val_mae: 0.0897\n",
            "Epoch 133/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0856 - val_loss: 0.0173 - val_mae: 0.0904\n",
            "Epoch 134/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0851 - val_loss: 0.0152 - val_mae: 0.0824\n",
            "Epoch 135/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0857 - val_loss: 0.0152 - val_mae: 0.0825\n",
            "Epoch 136/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0863 - val_loss: 0.0160 - val_mae: 0.0869\n",
            "Epoch 137/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0856 - val_loss: 0.0169 - val_mae: 0.0895\n",
            "Epoch 138/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0845 - val_loss: 0.0204 - val_mae: 0.1068\n",
            "Epoch 139/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0868 - val_loss: 0.0159 - val_mae: 0.0854\n",
            "Epoch 140/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0856 - val_loss: 0.0185 - val_mae: 0.0945\n",
            "Epoch 141/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0866 - val_loss: 0.0163 - val_mae: 0.0856\n",
            "Epoch 142/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0869 - val_loss: 0.0158 - val_mae: 0.0854\n",
            "Epoch 143/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0856 - val_loss: 0.0195 - val_mae: 0.0998\n",
            "Epoch 144/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0864 - val_loss: 0.0152 - val_mae: 0.0824\n",
            "Epoch 145/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0868 - val_loss: 0.0172 - val_mae: 0.0898\n",
            "Epoch 146/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0839 - val_loss: 0.0159 - val_mae: 0.0855\n",
            "Epoch 147/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0863 - val_loss: 0.0214 - val_mae: 0.1106\n",
            "Epoch 148/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0854 - val_loss: 0.0164 - val_mae: 0.0892\n",
            "Epoch 149/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0864 - val_loss: 0.0168 - val_mae: 0.0896\n",
            "Epoch 150/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0851 - val_loss: 0.0159 - val_mae: 0.0851\n",
            "Epoch 151/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0854 - val_loss: 0.0150 - val_mae: 0.0826\n",
            "Epoch 152/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0867 - val_loss: 0.0153 - val_mae: 0.0842\n",
            "Epoch 153/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0854 - val_loss: 0.0163 - val_mae: 0.0884\n",
            "Epoch 154/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0860 - val_loss: 0.0151 - val_mae: 0.0822\n",
            "Epoch 155/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0850 - val_loss: 0.0163 - val_mae: 0.0896\n",
            "Epoch 156/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0841 - val_loss: 0.0182 - val_mae: 0.0981\n",
            "Epoch 157/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0148 - mae: 0.0866 - val_loss: 0.0197 - val_mae: 0.0996\n",
            "Epoch 158/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0862 - val_loss: 0.0175 - val_mae: 0.0917\n",
            "Epoch 159/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0859 - val_loss: 0.0153 - val_mae: 0.0845\n",
            "Epoch 160/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0840 - val_loss: 0.0175 - val_mae: 0.0925\n",
            "Epoch 161/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0853 - val_loss: 0.0179 - val_mae: 0.0939\n",
            "Epoch 162/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0865 - val_loss: 0.0158 - val_mae: 0.0857\n",
            "Epoch 163/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0853 - val_loss: 0.0165 - val_mae: 0.0884\n",
            "Epoch 164/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0848 - val_loss: 0.0165 - val_mae: 0.0898\n",
            "Epoch 165/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0873 - val_loss: 0.0157 - val_mae: 0.0865\n",
            "Epoch 166/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0864 - val_loss: 0.0161 - val_mae: 0.0887\n",
            "Epoch 167/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0843 - val_loss: 0.0197 - val_mae: 0.1057\n",
            "Epoch 168/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0849 - val_loss: 0.0175 - val_mae: 0.0937\n",
            "Epoch 169/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0859 - val_loss: 0.0173 - val_mae: 0.0946\n",
            "Epoch 170/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0854 - val_loss: 0.0147 - val_mae: 0.0818\n",
            "Epoch 171/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0865 - val_loss: 0.0150 - val_mae: 0.0824\n",
            "Epoch 172/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0854 - val_loss: 0.0213 - val_mae: 0.1072\n",
            "Epoch 173/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0862 - val_loss: 0.0154 - val_mae: 0.0842\n",
            "Epoch 174/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0853 - val_loss: 0.0175 - val_mae: 0.0917\n",
            "Epoch 175/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0852 - val_loss: 0.0169 - val_mae: 0.0904\n",
            "Epoch 176/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0843 - val_loss: 0.0180 - val_mae: 0.0959\n",
            "Epoch 177/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0867 - val_loss: 0.0199 - val_mae: 0.1035\n",
            "Epoch 178/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0874 - val_loss: 0.0180 - val_mae: 0.0968\n",
            "Epoch 179/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0860 - val_loss: 0.0161 - val_mae: 0.0855\n",
            "Epoch 180/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0861 - val_loss: 0.0183 - val_mae: 0.0992\n",
            "Epoch 181/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0866 - val_loss: 0.0164 - val_mae: 0.0854\n",
            "Epoch 182/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0858 - val_loss: 0.0177 - val_mae: 0.0965\n",
            "Epoch 183/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0867 - val_loss: 0.0149 - val_mae: 0.0822\n",
            "Epoch 184/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0846 - val_loss: 0.0149 - val_mae: 0.0824\n",
            "Epoch 185/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0853 - val_loss: 0.0151 - val_mae: 0.0837\n",
            "Epoch 186/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0856 - val_loss: 0.0157 - val_mae: 0.0854\n",
            "Epoch 187/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0858 - val_loss: 0.0150 - val_mae: 0.0828\n",
            "Epoch 188/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0859 - val_loss: 0.0159 - val_mae: 0.0881\n",
            "Epoch 189/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0841 - val_loss: 0.0149 - val_mae: 0.0818\n",
            "Epoch 190/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0865 - val_loss: 0.0148 - val_mae: 0.0820\n",
            "Epoch 191/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0871 - val_loss: 0.0161 - val_mae: 0.0887\n",
            "Epoch 192/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0859 - val_loss: 0.0169 - val_mae: 0.0904\n",
            "Epoch 193/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0834 - val_loss: 0.0154 - val_mae: 0.0852\n",
            "Epoch 194/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0872 - val_loss: 0.0149 - val_mae: 0.0824\n",
            "Epoch 195/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0848 - val_loss: 0.0161 - val_mae: 0.0854\n",
            "Epoch 196/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0855 - val_loss: 0.0172 - val_mae: 0.0898\n",
            "Epoch 197/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0849 - val_loss: 0.0153 - val_mae: 0.0844\n",
            "Epoch 198/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0854 - val_loss: 0.0150 - val_mae: 0.0833\n",
            "Epoch 199/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0839 - val_loss: 0.0179 - val_mae: 0.0954\n",
            "Epoch 200/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0871 - val_loss: 0.0164 - val_mae: 0.0875\n",
            "Epoch 201/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0846 - val_loss: 0.0207 - val_mae: 0.1055\n",
            "Epoch 202/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0850 - val_loss: 0.0154 - val_mae: 0.0851\n",
            "Epoch 203/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0855 - val_loss: 0.0178 - val_mae: 0.0928\n",
            "Epoch 204/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0849 - val_loss: 0.0170 - val_mae: 0.0922\n",
            "Epoch 205/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0863 - val_loss: 0.0151 - val_mae: 0.0836\n",
            "Epoch 206/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0842 - val_loss: 0.0149 - val_mae: 0.0829\n",
            "Epoch 207/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0848 - val_loss: 0.0175 - val_mae: 0.0938\n",
            "Epoch 208/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0850 - val_loss: 0.0165 - val_mae: 0.0895\n",
            "Epoch 209/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0862 - val_loss: 0.0153 - val_mae: 0.0845\n",
            "Epoch 210/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0836 - val_loss: 0.0180 - val_mae: 0.0941\n",
            "Epoch 211/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0885 - val_loss: 0.0160 - val_mae: 0.0872\n",
            "Epoch 212/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0836 - val_loss: 0.0221 - val_mae: 0.1090\n",
            "Epoch 213/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0848 - val_loss: 0.0162 - val_mae: 0.0890\n",
            "Epoch 214/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0840 - val_loss: 0.0151 - val_mae: 0.0840\n",
            "Epoch 215/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0861 - val_loss: 0.0150 - val_mae: 0.0829\n",
            "Epoch 216/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0846 - val_loss: 0.0164 - val_mae: 0.0905\n",
            "Epoch 217/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0855 - val_loss: 0.0169 - val_mae: 0.0916\n",
            "Epoch 218/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0857 - val_loss: 0.0160 - val_mae: 0.0876\n",
            "Epoch 219/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0858 - val_loss: 0.0149 - val_mae: 0.0827\n",
            "Epoch 220/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0844 - val_loss: 0.0162 - val_mae: 0.0849\n",
            "Epoch 221/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0841 - val_loss: 0.0164 - val_mae: 0.0888\n",
            "Epoch 222/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0856 - val_loss: 0.0180 - val_mae: 0.0949\n",
            "Epoch 223/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0861 - val_loss: 0.0159 - val_mae: 0.0880\n",
            "Epoch 224/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0861 - val_loss: 0.0173 - val_mae: 0.0948\n",
            "Epoch 225/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0862 - val_loss: 0.0240 - val_mae: 0.1161\n",
            "Epoch 226/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0847 - val_loss: 0.0155 - val_mae: 0.0855\n",
            "Epoch 227/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0147 - mae: 0.0865 - val_loss: 0.0151 - val_mae: 0.0836\n",
            "Epoch 228/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0853 - val_loss: 0.0156 - val_mae: 0.0859\n",
            "Epoch 229/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0834 - val_loss: 0.0180 - val_mae: 0.0981\n",
            "Epoch 230/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0860 - val_loss: 0.0148 - val_mae: 0.0816\n",
            "Epoch 231/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0858 - val_loss: 0.0166 - val_mae: 0.0895\n",
            "Epoch 232/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0854 - val_loss: 0.0161 - val_mae: 0.0887\n",
            "Epoch 233/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0849 - val_loss: 0.0156 - val_mae: 0.0859\n",
            "Epoch 234/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0859 - val_loss: 0.0191 - val_mae: 0.0998\n",
            "Epoch 235/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0851 - val_loss: 0.0161 - val_mae: 0.0871\n",
            "Epoch 236/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0852 - val_loss: 0.0158 - val_mae: 0.0879\n",
            "Epoch 237/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0863 - val_loss: 0.0171 - val_mae: 0.0912\n",
            "Epoch 238/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0842 - val_loss: 0.0258 - val_mae: 0.1290\n",
            "Epoch 239/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0868 - val_loss: 0.0169 - val_mae: 0.0916\n",
            "Epoch 240/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0855 - val_loss: 0.0154 - val_mae: 0.0851\n",
            "Epoch 241/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0849 - val_loss: 0.0153 - val_mae: 0.0835\n",
            "Epoch 242/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0855 - val_loss: 0.0149 - val_mae: 0.0820\n",
            "Epoch 243/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0853 - val_loss: 0.0195 - val_mae: 0.1051\n",
            "Epoch 244/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0863 - val_loss: 0.0149 - val_mae: 0.0826\n",
            "Epoch 245/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0864 - val_loss: 0.0175 - val_mae: 0.0957\n",
            "Epoch 246/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0862 - val_loss: 0.0169 - val_mae: 0.0919\n",
            "Epoch 247/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0862 - val_loss: 0.0154 - val_mae: 0.0859\n",
            "Epoch 248/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0865 - val_loss: 0.0159 - val_mae: 0.0873\n",
            "Epoch 249/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0863 - val_loss: 0.0156 - val_mae: 0.0858\n",
            "Epoch 250/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0850 - val_loss: 0.0184 - val_mae: 0.0983\n",
            "Epoch 251/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0852 - val_loss: 0.0164 - val_mae: 0.0878\n",
            "Epoch 252/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0833 - val_loss: 0.0184 - val_mae: 0.1003\n",
            "Epoch 253/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0855 - val_loss: 0.0151 - val_mae: 0.0834\n",
            "Epoch 254/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0849 - val_loss: 0.0158 - val_mae: 0.0875\n",
            "Epoch 255/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0862 - val_loss: 0.0150 - val_mae: 0.0837\n",
            "Epoch 256/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0842 - val_loss: 0.0157 - val_mae: 0.0868\n",
            "Epoch 257/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0145 - mae: 0.0862 - val_loss: 0.0169 - val_mae: 0.0911\n",
            "Epoch 258/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0879 - val_loss: 0.0184 - val_mae: 0.0997\n",
            "Epoch 259/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0845 - val_loss: 0.0151 - val_mae: 0.0826\n",
            "Epoch 260/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0857 - val_loss: 0.0151 - val_mae: 0.0845\n",
            "Epoch 261/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0864 - val_loss: 0.0176 - val_mae: 0.0930\n",
            "Epoch 262/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0840 - val_loss: 0.0181 - val_mae: 0.0974\n",
            "Epoch 263/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0839 - val_loss: 0.0150 - val_mae: 0.0840\n",
            "Epoch 264/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0879 - val_loss: 0.0171 - val_mae: 0.0908\n",
            "Epoch 265/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0850 - val_loss: 0.0208 - val_mae: 0.1078\n",
            "Epoch 266/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0857 - val_loss: 0.0148 - val_mae: 0.0827\n",
            "Epoch 267/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0838 - val_loss: 0.0180 - val_mae: 0.0938\n",
            "Epoch 268/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0848 - val_loss: 0.0148 - val_mae: 0.0825\n",
            "Epoch 269/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0144 - mae: 0.0869 - val_loss: 0.0152 - val_mae: 0.0848\n",
            "Epoch 270/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0850 - val_loss: 0.0188 - val_mae: 0.1009\n",
            "Epoch 271/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0847 - val_loss: 0.0151 - val_mae: 0.0841\n",
            "Epoch 272/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0855 - val_loss: 0.0159 - val_mae: 0.0862\n",
            "Epoch 273/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0849 - val_loss: 0.0148 - val_mae: 0.0830\n",
            "Epoch 274/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0846 - val_loss: 0.0170 - val_mae: 0.0914\n",
            "Epoch 275/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0854 - val_loss: 0.0167 - val_mae: 0.0924\n",
            "Epoch 276/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0869 - val_loss: 0.0172 - val_mae: 0.0926\n",
            "Epoch 277/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0856 - val_loss: 0.0155 - val_mae: 0.0845\n",
            "Epoch 278/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0855 - val_loss: 0.0150 - val_mae: 0.0825\n",
            "Epoch 279/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0828 - val_loss: 0.0148 - val_mae: 0.0831\n",
            "Epoch 280/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0144 - mae: 0.0869 - val_loss: 0.0147 - val_mae: 0.0817\n",
            "Epoch 281/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0856 - val_loss: 0.0196 - val_mae: 0.1044\n",
            "Epoch 282/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0846 - val_loss: 0.0152 - val_mae: 0.0839\n",
            "Epoch 283/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0864 - val_loss: 0.0145 - val_mae: 0.0815\n",
            "Epoch 284/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0836 - val_loss: 0.0160 - val_mae: 0.0889\n",
            "Epoch 285/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0849 - val_loss: 0.0151 - val_mae: 0.0847\n",
            "Epoch 286/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0858 - val_loss: 0.0212 - val_mae: 0.1085\n",
            "Epoch 287/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0848 - val_loss: 0.0188 - val_mae: 0.1016\n",
            "Epoch 288/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0852 - val_loss: 0.0152 - val_mae: 0.0854\n",
            "Epoch 289/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0848 - val_loss: 0.0209 - val_mae: 0.1065\n",
            "Epoch 290/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0861 - val_loss: 0.0233 - val_mae: 0.1157\n",
            "Epoch 291/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0858 - val_loss: 0.0172 - val_mae: 0.0935\n",
            "Epoch 292/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0862 - val_loss: 0.0155 - val_mae: 0.0835\n",
            "Epoch 293/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0830 - val_loss: 0.0170 - val_mae: 0.0939\n",
            "Epoch 294/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0860 - val_loss: 0.0147 - val_mae: 0.0819\n",
            "Epoch 295/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0848 - val_loss: 0.0153 - val_mae: 0.0852\n",
            "Epoch 296/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0878 - val_loss: 0.0150 - val_mae: 0.0829\n",
            "Epoch 297/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0847 - val_loss: 0.0146 - val_mae: 0.0823\n",
            "Epoch 298/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0841 - val_loss: 0.0151 - val_mae: 0.0837\n",
            "Epoch 299/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0864 - val_loss: 0.0164 - val_mae: 0.0915\n",
            "Epoch 300/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0849 - val_loss: 0.0160 - val_mae: 0.0868\n",
            "Epoch 301/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0858 - val_loss: 0.0152 - val_mae: 0.0858\n",
            "Epoch 302/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0847 - val_loss: 0.0154 - val_mae: 0.0859\n",
            "Epoch 303/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0844 - val_loss: 0.0194 - val_mae: 0.1000\n",
            "Epoch 304/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0832 - val_loss: 0.0206 - val_mae: 0.1058\n",
            "Epoch 305/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0849 - val_loss: 0.0152 - val_mae: 0.0841\n",
            "Epoch 306/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0855 - val_loss: 0.0147 - val_mae: 0.0821\n",
            "Epoch 307/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0850 - val_loss: 0.0192 - val_mae: 0.0977\n",
            "Epoch 308/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0851 - val_loss: 0.0168 - val_mae: 0.0931\n",
            "Epoch 309/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0864 - val_loss: 0.0155 - val_mae: 0.0860\n",
            "Epoch 310/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0848 - val_loss: 0.0207 - val_mae: 0.1075\n",
            "Epoch 311/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0143 - mae: 0.0859 - val_loss: 0.0158 - val_mae: 0.0866\n",
            "Epoch 312/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0863 - val_loss: 0.0155 - val_mae: 0.0867\n",
            "Epoch 313/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0850 - val_loss: 0.0172 - val_mae: 0.0937\n",
            "Epoch 314/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0841 - val_loss: 0.0154 - val_mae: 0.0858\n",
            "Epoch 315/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0142 - mae: 0.0870 - val_loss: 0.0153 - val_mae: 0.0843\n",
            "Epoch 316/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0841 - val_loss: 0.0157 - val_mae: 0.0871\n",
            "Epoch 317/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0849 - val_loss: 0.0153 - val_mae: 0.0858\n",
            "Epoch 318/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0833 - val_loss: 0.0148 - val_mae: 0.0825\n",
            "Epoch 319/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0858 - val_loss: 0.0165 - val_mae: 0.0901\n",
            "Epoch 320/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0831 - val_loss: 0.0183 - val_mae: 0.1003\n",
            "Epoch 321/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0139 - mae: 0.0852 - val_loss: 0.0159 - val_mae: 0.0864\n",
            "Epoch 322/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0862 - val_loss: 0.0158 - val_mae: 0.0887\n",
            "Epoch 323/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0844 - val_loss: 0.0181 - val_mae: 0.0970\n",
            "Epoch 324/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0858 - val_loss: 0.0157 - val_mae: 0.0879\n",
            "Epoch 325/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0852 - val_loss: 0.0160 - val_mae: 0.0884\n",
            "Epoch 326/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0845 - val_loss: 0.0180 - val_mae: 0.0952\n",
            "Epoch 327/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0847 - val_loss: 0.0169 - val_mae: 0.0935\n",
            "Epoch 328/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0840 - val_loss: 0.0208 - val_mae: 0.1052\n",
            "Epoch 329/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0852 - val_loss: 0.0156 - val_mae: 0.0849\n",
            "Epoch 330/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0828 - val_loss: 0.0167 - val_mae: 0.0930\n",
            "Epoch 331/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0852 - val_loss: 0.0147 - val_mae: 0.0833\n",
            "Epoch 332/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0856 - val_loss: 0.0188 - val_mae: 0.0991\n",
            "Epoch 333/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0836 - val_loss: 0.0145 - val_mae: 0.0815\n",
            "Epoch 334/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0846 - val_loss: 0.0165 - val_mae: 0.0918\n",
            "Epoch 335/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0854 - val_loss: 0.0166 - val_mae: 0.0921\n",
            "Epoch 336/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0855 - val_loss: 0.0158 - val_mae: 0.0847\n",
            "Epoch 337/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0850 - val_loss: 0.0146 - val_mae: 0.0820\n",
            "Epoch 338/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0856 - val_loss: 0.0159 - val_mae: 0.0882\n",
            "Epoch 339/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0843 - val_loss: 0.0151 - val_mae: 0.0834\n",
            "Epoch 340/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0845 - val_loss: 0.0150 - val_mae: 0.0839\n",
            "Epoch 341/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0859 - val_loss: 0.0164 - val_mae: 0.0897\n",
            "Epoch 342/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0835 - val_loss: 0.0165 - val_mae: 0.0920\n",
            "Epoch 343/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0852 - val_loss: 0.0169 - val_mae: 0.0928\n",
            "Epoch 344/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0852 - val_loss: 0.0159 - val_mae: 0.0883\n",
            "Epoch 345/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0841 - val_loss: 0.0165 - val_mae: 0.0894\n",
            "Epoch 346/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0850 - val_loss: 0.0174 - val_mae: 0.0915\n",
            "Epoch 347/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0848 - val_loss: 0.0156 - val_mae: 0.0846\n",
            "Epoch 348/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0847 - val_loss: 0.0181 - val_mae: 0.0933\n",
            "Epoch 349/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0856 - val_loss: 0.0151 - val_mae: 0.0830\n",
            "Epoch 350/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0843 - val_loss: 0.0194 - val_mae: 0.0956\n",
            "Epoch 351/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - mae: 0.0854 - val_loss: 0.0150 - val_mae: 0.0844\n",
            "Epoch 352/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0822 - val_loss: 0.0156 - val_mae: 0.0882\n",
            "Epoch 353/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0853 - val_loss: 0.0157 - val_mae: 0.0864\n",
            "Epoch 354/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0833 - val_loss: 0.0152 - val_mae: 0.0856\n",
            "Epoch 355/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0858 - val_loss: 0.0149 - val_mae: 0.0845\n",
            "Epoch 356/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0829 - val_loss: 0.0147 - val_mae: 0.0827\n",
            "Epoch 357/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0861 - val_loss: 0.0179 - val_mae: 0.0982\n",
            "Epoch 358/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0859 - val_loss: 0.0147 - val_mae: 0.0831\n",
            "Epoch 359/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0843 - val_loss: 0.0196 - val_mae: 0.1064\n",
            "Epoch 360/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0835 - val_loss: 0.0157 - val_mae: 0.0886\n",
            "Epoch 361/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0846 - val_loss: 0.0162 - val_mae: 0.0877\n",
            "Epoch 362/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0850 - val_loss: 0.0171 - val_mae: 0.0926\n",
            "Epoch 363/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0834 - val_loss: 0.0174 - val_mae: 0.0967\n",
            "Epoch 364/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0842 - val_loss: 0.0146 - val_mae: 0.0822\n",
            "Epoch 365/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0844 - val_loss: 0.0159 - val_mae: 0.0872\n",
            "Epoch 366/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0854 - val_loss: 0.0156 - val_mae: 0.0873\n",
            "Epoch 367/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0848 - val_loss: 0.0151 - val_mae: 0.0857\n",
            "Epoch 368/500\n",
            "35/35 [==============================] - 0s 8ms/step - loss: 0.0138 - mae: 0.0852 - val_loss: 0.0152 - val_mae: 0.0844\n",
            "Epoch 369/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0847 - val_loss: 0.0144 - val_mae: 0.0818\n",
            "Epoch 370/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0848 - val_loss: 0.0150 - val_mae: 0.0846\n",
            "Epoch 371/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0838 - val_loss: 0.0158 - val_mae: 0.0884\n",
            "Epoch 372/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0859 - val_loss: 0.0159 - val_mae: 0.0890\n",
            "Epoch 373/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0840 - val_loss: 0.0157 - val_mae: 0.0877\n",
            "Epoch 374/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0838 - val_loss: 0.0159 - val_mae: 0.0877\n",
            "Epoch 375/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0856 - val_loss: 0.0148 - val_mae: 0.0843\n",
            "Epoch 376/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0829 - val_loss: 0.0196 - val_mae: 0.1063\n",
            "Epoch 377/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0851 - val_loss: 0.0203 - val_mae: 0.1050\n",
            "Epoch 378/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0831 - val_loss: 0.0148 - val_mae: 0.0841\n",
            "Epoch 379/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0839 - val_loss: 0.0171 - val_mae: 0.0916\n",
            "Epoch 380/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0830 - val_loss: 0.0148 - val_mae: 0.0837\n",
            "Epoch 381/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0855 - val_loss: 0.0143 - val_mae: 0.0812\n",
            "Epoch 382/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0832 - val_loss: 0.0146 - val_mae: 0.0834\n",
            "Epoch 383/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0851 - val_loss: 0.0153 - val_mae: 0.0855\n",
            "Epoch 384/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0843 - val_loss: 0.0151 - val_mae: 0.0853\n",
            "Epoch 385/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0838 - val_loss: 0.0173 - val_mae: 0.0909\n",
            "Epoch 386/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0865 - val_loss: 0.0154 - val_mae: 0.0866\n",
            "Epoch 387/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0845 - val_loss: 0.0154 - val_mae: 0.0866\n",
            "Epoch 388/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0827 - val_loss: 0.0169 - val_mae: 0.0949\n",
            "Epoch 389/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0847 - val_loss: 0.0168 - val_mae: 0.0940\n",
            "Epoch 390/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0858 - val_loss: 0.0174 - val_mae: 0.0929\n",
            "Epoch 391/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0843 - val_loss: 0.0160 - val_mae: 0.0868\n",
            "Epoch 392/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0839 - val_loss: 0.0146 - val_mae: 0.0830\n",
            "Epoch 393/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0854 - val_loss: 0.0152 - val_mae: 0.0855\n",
            "Epoch 394/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0846 - val_loss: 0.0151 - val_mae: 0.0853\n",
            "Epoch 395/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0828 - val_loss: 0.0179 - val_mae: 0.0936\n",
            "Epoch 396/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0141 - mae: 0.0866 - val_loss: 0.0183 - val_mae: 0.0976\n",
            "Epoch 397/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0852 - val_loss: 0.0176 - val_mae: 0.0984\n",
            "Epoch 398/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0854 - val_loss: 0.0152 - val_mae: 0.0870\n",
            "Epoch 399/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0836 - val_loss: 0.0200 - val_mae: 0.1007\n",
            "Epoch 400/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0836 - val_loss: 0.0145 - val_mae: 0.0830\n",
            "Epoch 401/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0844 - val_loss: 0.0208 - val_mae: 0.1109\n",
            "Epoch 402/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0847 - val_loss: 0.0151 - val_mae: 0.0855\n",
            "Epoch 403/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0845 - val_loss: 0.0146 - val_mae: 0.0824\n",
            "Epoch 404/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0852 - val_loss: 0.0147 - val_mae: 0.0829\n",
            "Epoch 405/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0849 - val_loss: 0.0160 - val_mae: 0.0880\n",
            "Epoch 406/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0830 - val_loss: 0.0165 - val_mae: 0.0902\n",
            "Epoch 407/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0858 - val_loss: 0.0188 - val_mae: 0.0990\n",
            "Epoch 408/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0829 - val_loss: 0.0166 - val_mae: 0.0890\n",
            "Epoch 409/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0838 - val_loss: 0.0159 - val_mae: 0.0860\n",
            "Epoch 410/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0839 - val_loss: 0.0158 - val_mae: 0.0884\n",
            "Epoch 411/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0836 - val_loss: 0.0192 - val_mae: 0.0999\n",
            "Epoch 412/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0852 - val_loss: 0.0170 - val_mae: 0.0955\n",
            "Epoch 413/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0848 - val_loss: 0.0172 - val_mae: 0.0965\n",
            "Epoch 414/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0844 - val_loss: 0.0159 - val_mae: 0.0896\n",
            "Epoch 415/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0847 - val_loss: 0.0145 - val_mae: 0.0818\n",
            "Epoch 416/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0837 - val_loss: 0.0152 - val_mae: 0.0850\n",
            "Epoch 417/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0866 - val_loss: 0.0141 - val_mae: 0.0810\n",
            "Epoch 418/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0857 - val_loss: 0.0166 - val_mae: 0.0936\n",
            "Epoch 419/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0840 - val_loss: 0.0176 - val_mae: 0.0954\n",
            "Epoch 420/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0841 - val_loss: 0.0145 - val_mae: 0.0820\n",
            "Epoch 421/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0864 - val_loss: 0.0151 - val_mae: 0.0829\n",
            "Epoch 422/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0834 - val_loss: 0.0170 - val_mae: 0.0931\n",
            "Epoch 423/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0858 - val_loss: 0.0160 - val_mae: 0.0857\n",
            "Epoch 424/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0846 - val_loss: 0.0145 - val_mae: 0.0822\n",
            "Epoch 425/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0854 - val_loss: 0.0154 - val_mae: 0.0853\n",
            "Epoch 426/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0841 - val_loss: 0.0153 - val_mae: 0.0879\n",
            "Epoch 427/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0845 - val_loss: 0.0142 - val_mae: 0.0812\n",
            "Epoch 428/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0839 - val_loss: 0.0156 - val_mae: 0.0883\n",
            "Epoch 429/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0839 - val_loss: 0.0147 - val_mae: 0.0844\n",
            "Epoch 430/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0142 - mae: 0.0868 - val_loss: 0.0149 - val_mae: 0.0844\n",
            "Epoch 431/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0834 - val_loss: 0.0146 - val_mae: 0.0836\n",
            "Epoch 432/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0843 - val_loss: 0.0145 - val_mae: 0.0836\n",
            "Epoch 433/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0847 - val_loss: 0.0145 - val_mae: 0.0822\n",
            "Epoch 434/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0136 - mae: 0.0850 - val_loss: 0.0188 - val_mae: 0.1038\n",
            "Epoch 435/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0139 - mae: 0.0855 - val_loss: 0.0144 - val_mae: 0.0828\n",
            "Epoch 436/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0841 - val_loss: 0.0185 - val_mae: 0.1023\n",
            "Epoch 437/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0848 - val_loss: 0.0145 - val_mae: 0.0833\n",
            "Epoch 438/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0834 - val_loss: 0.0157 - val_mae: 0.0898\n",
            "Epoch 439/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0858 - val_loss: 0.0161 - val_mae: 0.0883\n",
            "Epoch 440/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0854 - val_loss: 0.0147 - val_mae: 0.0848\n",
            "Epoch 441/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0851 - val_loss: 0.0151 - val_mae: 0.0873\n",
            "Epoch 442/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0844 - val_loss: 0.0154 - val_mae: 0.0876\n",
            "Epoch 443/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0842 - val_loss: 0.0145 - val_mae: 0.0833\n",
            "Epoch 444/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0138 - mae: 0.0850 - val_loss: 0.0143 - val_mae: 0.0814\n",
            "Epoch 445/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0834 - val_loss: 0.0155 - val_mae: 0.0892\n",
            "Epoch 446/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0841 - val_loss: 0.0147 - val_mae: 0.0834\n",
            "Epoch 447/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0858 - val_loss: 0.0145 - val_mae: 0.0839\n",
            "Epoch 448/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0840 - val_loss: 0.0148 - val_mae: 0.0851\n",
            "Epoch 449/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0840 - val_loss: 0.0146 - val_mae: 0.0832\n",
            "Epoch 450/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0849 - val_loss: 0.0148 - val_mae: 0.0850\n",
            "Epoch 451/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0840 - val_loss: 0.0150 - val_mae: 0.0854\n",
            "Epoch 452/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0834 - val_loss: 0.0148 - val_mae: 0.0849\n",
            "Epoch 453/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0846 - val_loss: 0.0174 - val_mae: 0.0976\n",
            "Epoch 454/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0849 - val_loss: 0.0146 - val_mae: 0.0842\n",
            "Epoch 455/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0847 - val_loss: 0.0180 - val_mae: 0.1013\n",
            "Epoch 456/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0833 - val_loss: 0.0177 - val_mae: 0.0955\n",
            "Epoch 457/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0840 - val_loss: 0.0141 - val_mae: 0.0814\n",
            "Epoch 458/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0135 - mae: 0.0837 - val_loss: 0.0165 - val_mae: 0.0942\n",
            "Epoch 459/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0846 - val_loss: 0.0148 - val_mae: 0.0857\n",
            "Epoch 460/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0855 - val_loss: 0.0147 - val_mae: 0.0850\n",
            "Epoch 461/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0829 - val_loss: 0.0176 - val_mae: 0.0935\n",
            "Epoch 462/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0853 - val_loss: 0.0143 - val_mae: 0.0823\n",
            "Epoch 463/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0852 - val_loss: 0.0144 - val_mae: 0.0821\n",
            "Epoch 464/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0832 - val_loss: 0.0156 - val_mae: 0.0888\n",
            "Epoch 465/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0832 - val_loss: 0.0144 - val_mae: 0.0835\n",
            "Epoch 466/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0854 - val_loss: 0.0144 - val_mae: 0.0830\n",
            "Epoch 467/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0845 - val_loss: 0.0142 - val_mae: 0.0818\n",
            "Epoch 468/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0842 - val_loss: 0.0175 - val_mae: 0.0990\n",
            "Epoch 469/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0847 - val_loss: 0.0149 - val_mae: 0.0834\n",
            "Epoch 470/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0835 - val_loss: 0.0154 - val_mae: 0.0887\n",
            "Epoch 471/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0839 - val_loss: 0.0178 - val_mae: 0.0999\n",
            "Epoch 472/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0138 - mae: 0.0858 - val_loss: 0.0146 - val_mae: 0.0843\n",
            "Epoch 473/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0843 - val_loss: 0.0176 - val_mae: 0.0951\n",
            "Epoch 474/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0133 - mae: 0.0839 - val_loss: 0.0250 - val_mae: 0.1241\n",
            "Epoch 475/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0831 - val_loss: 0.0146 - val_mae: 0.0840\n",
            "Epoch 476/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - mae: 0.0828 - val_loss: 0.0152 - val_mae: 0.0882\n",
            "Epoch 477/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0854 - val_loss: 0.0141 - val_mae: 0.0818\n",
            "Epoch 478/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0835 - val_loss: 0.0157 - val_mae: 0.0897\n",
            "Epoch 479/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0845 - val_loss: 0.0161 - val_mae: 0.0904\n",
            "Epoch 480/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0840 - val_loss: 0.0174 - val_mae: 0.0981\n",
            "Epoch 481/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0846 - val_loss: 0.0145 - val_mae: 0.0819\n",
            "Epoch 482/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0840 - val_loss: 0.0146 - val_mae: 0.0838\n",
            "Epoch 483/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0132 - mae: 0.0839 - val_loss: 0.0149 - val_mae: 0.0857\n",
            "Epoch 484/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0844 - val_loss: 0.0209 - val_mae: 0.1076\n",
            "Epoch 485/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0841 - val_loss: 0.0142 - val_mae: 0.0818\n",
            "Epoch 486/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0837 - val_loss: 0.0165 - val_mae: 0.0940\n",
            "Epoch 487/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0828 - val_loss: 0.0147 - val_mae: 0.0847\n",
            "Epoch 488/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0853 - val_loss: 0.0147 - val_mae: 0.0839\n",
            "Epoch 489/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0832 - val_loss: 0.0145 - val_mae: 0.0829\n",
            "Epoch 490/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0851 - val_loss: 0.0148 - val_mae: 0.0853\n",
            "Epoch 491/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0129 - mae: 0.0822 - val_loss: 0.0150 - val_mae: 0.0850\n",
            "Epoch 492/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0839 - val_loss: 0.0160 - val_mae: 0.0890\n",
            "Epoch 493/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0134 - mae: 0.0840 - val_loss: 0.0188 - val_mae: 0.0983\n",
            "Epoch 494/500\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.0137 - mae: 0.0846 - val_loss: 0.0141 - val_mae: 0.0811\n",
            "Epoch 495/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - mae: 0.0829 - val_loss: 0.0147 - val_mae: 0.0847\n",
            "Epoch 496/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0843 - val_loss: 0.0151 - val_mae: 0.0867\n",
            "Epoch 497/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0837 - val_loss: 0.0144 - val_mae: 0.0834\n",
            "Epoch 498/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0844 - val_loss: 0.0153 - val_mae: 0.0876\n",
            "Epoch 499/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0848 - val_loss: 0.0158 - val_mae: 0.0904\n",
            "Epoch 500/500\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0131 - mae: 0.0825 - val_loss: 0.0145 - val_mae: 0.0827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udG9sWqDydNC",
        "colab_type": "code",
        "outputId": "c8e6ae18-aa15-4d28-ec2b-efb232779863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "Prediction_by_training = model9.predict(XVALID_f)\n",
        "YVALID_exp=np.exp(YVALID_f)\n",
        "P9=np.exp(Prediction_by_training)\n",
        "MAE9 = abs(YVALID_exp - P9)\n",
        "print(MAE9)\n",
        "M_f=MAE9.mean()\n",
        "print(\"M_f=\",M_f)\n",
        "#M3 = math.exp(temp3)\n",
        "#print(M3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 87523.808  117617.513  659711.132  ... 391463.629  398462.511\n",
            "   90131.148 ]\n",
            " [115263.058   89878.263  687450.382  ... 419202.879  426201.761\n",
            "   62391.898 ]\n",
            " [442167.1295 647308.4505 130020.1945 ... 138227.3085 131228.4265\n",
            "  619822.0855]\n",
            " ...\n",
            " [334649.692  539791.013  237537.632  ...  30709.871   23710.989\n",
            "  512304.648 ]\n",
            " [336181.817  541323.138  236005.507  ...  32241.996   25243.114\n",
            "  513836.773 ]\n",
            " [317488.433  112347.112  889675.757  ... 621428.254  628427.136\n",
            "  139833.477 ]]\n",
            "M_f= 387731.6032675041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiSm4OBny1mk",
        "colab_type": "code",
        "outputId": "c88719a0-bd30-4f82-f172-0b18539e1d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "plt.figure(figsize=(15, 13))\n",
        "plt.plot(history9.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history9.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()\n",
        "min(history9.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x936 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01409974880516529"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKg8je9ry9Oa",
        "colab_type": "code",
        "outputId": "af8be00c-a285-4d06-cf3a-9ced18a6aa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "print('Model weights - w0(slope m), bias):')\n",
        "w0 = model9.layers[0].get_weights()[0][0]\n",
        "b0 = model9.layers[0].get_weights()[1]\n",
        "print(w0)\n",
        "print(b0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model weights - w0(slope m), bias):\n",
            "[ 0.00162209  0.10702916 -0.26774508 -0.16035765  0.35236275  0.2384685\n",
            "  0.17833774 -0.25553334  0.18515661  0.17232168  0.37353498 -0.1821907 ]\n",
            "[ 0.5489715   0.72693896  1.2581751   1.1520798   1.0913702   1.3306127\n",
            "  1.121404    0.85133547  0.86179423  1.2070845   1.0539273  -0.51312214]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vWW8pt9wRj2",
        "colab_type": "text"
      },
      "source": [
        "The following piece of code was taken from the article \"T81-558: Applications of Deep Neural Networks\" by Jeff heaton that can be found at the following: [link](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_03_5_weights.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2Xjb4Y1ANDw",
        "colab_type": "code",
        "outputId": "cd826e70-a6a0-4120-985d-335e2a26e214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for layerNum, layer in enumerate(model9.layers):\n",
        "    weights = layer.get_weights()[0]\n",
        "    biases = layer.get_weights()[1]\n",
        "    \n",
        "    for toNeuronNum, bias in enumerate(biases):\n",
        "         print(f'B{layerNum}L{layerNum+1}N{toNeuronNum}= {bias}')\n",
        "        #print(f'{layerNum}B -> L{layerNum+1}N{toNeuronNum}= {bias}')\n",
        "    \n",
        "    for fromNeuronNum, wgt in enumerate(weights):\n",
        "        for toNeuronNum, wgt2 in enumerate(wgt):\n",
        "             print(f'L{layerNum}N{fromNeuronNum}L{layerNum+1}N{toNeuronNum} = {wgt2}')\n",
        "            #print(f'L{layerNum}N{fromNeuronNum} -> L{layerNum+1}N{toNeuronNum} = {wgt2}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B0L1N0= 0.5489714741706848\n",
            "B0L1N1= 0.7269389629364014\n",
            "B0L1N2= 1.2581751346588135\n",
            "B0L1N3= 1.1520798206329346\n",
            "B0L1N4= 1.0913702249526978\n",
            "B0L1N5= 1.3306126594543457\n",
            "B0L1N6= 1.1214040517807007\n",
            "B0L1N7= 0.8513354659080505\n",
            "B0L1N8= 0.8617942333221436\n",
            "B0L1N9= 1.2070845365524292\n",
            "B0L1N10= 1.0539273023605347\n",
            "B0L1N11= -0.5131221413612366\n",
            "L0N0L1N0 = 0.0016220943070948124\n",
            "L0N0L1N1 = 0.10702916234731674\n",
            "L0N0L1N2 = -0.26774507761001587\n",
            "L0N0L1N3 = -0.16035765409469604\n",
            "L0N0L1N4 = 0.3523627519607544\n",
            "L0N0L1N5 = 0.2384684979915619\n",
            "L0N0L1N6 = 0.17833773791790009\n",
            "L0N0L1N7 = -0.2555333375930786\n",
            "L0N0L1N8 = 0.18515661358833313\n",
            "L0N0L1N9 = 0.17232167720794678\n",
            "L0N0L1N10 = 0.3735349774360657\n",
            "L0N0L1N11 = -0.1821907013654709\n",
            "L0N1L1N0 = 0.1645156443119049\n",
            "L0N1L1N1 = 0.07426043599843979\n",
            "L0N1L1N2 = -0.020702680572867393\n",
            "L0N1L1N3 = 0.08904264122247696\n",
            "L0N1L1N4 = 0.22531826794147491\n",
            "L0N1L1N5 = -0.11259951442480087\n",
            "L0N1L1N6 = -0.09119870513677597\n",
            "L0N1L1N7 = -0.2075468897819519\n",
            "L0N1L1N8 = 0.29205065965652466\n",
            "L0N1L1N9 = -0.0940713882446289\n",
            "L0N1L1N10 = 0.07671551406383514\n",
            "L0N1L1N11 = -0.29331180453300476\n",
            "L0N2L1N0 = -0.023014618083834648\n",
            "L0N2L1N1 = 0.008401459082961082\n",
            "L0N2L1N2 = 0.05315321311354637\n",
            "L0N2L1N3 = 0.23498572409152985\n",
            "L0N2L1N4 = 0.3350667655467987\n",
            "L0N2L1N5 = -0.08612523227930069\n",
            "L0N2L1N6 = -0.23842483758926392\n",
            "L0N2L1N7 = 0.27257731556892395\n",
            "L0N2L1N8 = 0.010739324614405632\n",
            "L0N2L1N9 = 0.064210444688797\n",
            "L0N2L1N10 = -0.0979783684015274\n",
            "L0N2L1N11 = -0.04041393846273422\n",
            "L0N3L1N0 = 0.19288980960845947\n",
            "L0N3L1N1 = 0.04242799058556557\n",
            "L0N3L1N2 = 0.07050857692956924\n",
            "L0N3L1N3 = -0.30290085077285767\n",
            "L0N3L1N4 = 0.21972142159938812\n",
            "L0N3L1N5 = 0.17447520792484283\n",
            "L0N3L1N6 = -0.0526302233338356\n",
            "L0N3L1N7 = 0.04947732388973236\n",
            "L0N3L1N8 = -0.18823543190956116\n",
            "L0N3L1N9 = 0.30401068925857544\n",
            "L0N3L1N10 = 0.13671322166919708\n",
            "L0N3L1N11 = 0.15967682003974915\n",
            "L0N4L1N0 = -0.044796932488679886\n",
            "L0N4L1N1 = 0.13881424069404602\n",
            "L0N4L1N2 = -0.247073695063591\n",
            "L0N4L1N3 = 0.009818323887884617\n",
            "L0N4L1N4 = -0.14859987795352936\n",
            "L0N4L1N5 = 0.46681666374206543\n",
            "L0N4L1N6 = 0.10945077985525131\n",
            "L0N4L1N7 = 0.1599600613117218\n",
            "L0N4L1N8 = -0.05846742168068886\n",
            "L0N4L1N9 = 0.055684901773929596\n",
            "L0N4L1N10 = 0.0030583918560296297\n",
            "L0N4L1N11 = -0.07187709957361221\n",
            "B1L2N0= 1.02090322971344\n",
            "B1L2N1= -0.39803919196128845\n",
            "B1L2N2= -0.24621909856796265\n",
            "B1L2N3= 0.7709031105041504\n",
            "B1L2N4= -0.03734928369522095\n",
            "B1L2N5= 1.0608630180358887\n",
            "B1L2N6= 1.0258808135986328\n",
            "B1L2N7= -0.11504744738340378\n",
            "L1N0L2N0 = 0.6112263798713684\n",
            "L1N0L2N1 = 0.4761679172515869\n",
            "L1N0L2N2 = -0.10865473747253418\n",
            "L1N0L2N3 = 0.5538785457611084\n",
            "L1N0L2N4 = 0.005797660909593105\n",
            "L1N0L2N5 = 0.09469141066074371\n",
            "L1N0L2N6 = -0.05546670779585838\n",
            "L1N0L2N7 = -0.256847083568573\n",
            "L1N1L2N0 = 0.5833340883255005\n",
            "L1N1L2N1 = 0.031266409903764725\n",
            "L1N1L2N2 = 0.32026681303977966\n",
            "L1N1L2N3 = 0.3472670316696167\n",
            "L1N1L2N4 = -0.2212761640548706\n",
            "L1N1L2N5 = 0.3991275131702423\n",
            "L1N1L2N6 = 1.172556757926941\n",
            "L1N1L2N7 = -0.05409945920109749\n",
            "L1N2L2N0 = 0.5236108303070068\n",
            "L1N2L2N1 = -0.6879777312278748\n",
            "L1N2L2N2 = -0.46976161003112793\n",
            "L1N2L2N3 = 0.49481457471847534\n",
            "L1N2L2N4 = 0.09813914448022842\n",
            "L1N2L2N5 = 0.8086812496185303\n",
            "L1N2L2N6 = 0.29834961891174316\n",
            "L1N2L2N7 = -0.16347365081310272\n",
            "L1N3L2N0 = 0.2000885307788849\n",
            "L1N3L2N1 = 0.06764540076255798\n",
            "L1N3L2N2 = 0.1577172726392746\n",
            "L1N3L2N3 = 0.47969624400138855\n",
            "L1N3L2N4 = -0.4395045042037964\n",
            "L1N3L2N5 = 1.1988623142242432\n",
            "L1N3L2N6 = 0.7306505441665649\n",
            "L1N3L2N7 = -0.4754568934440613\n",
            "L1N4L2N0 = 0.11014901846647263\n",
            "L1N4L2N1 = 0.2846999168395996\n",
            "L1N4L2N2 = -0.5018507242202759\n",
            "L1N4L2N3 = -0.12151593714952469\n",
            "L1N4L2N4 = -0.4565874934196472\n",
            "L1N4L2N5 = 0.2789407968521118\n",
            "L1N4L2N6 = -0.030737370252609253\n",
            "L1N4L2N7 = 0.3427312970161438\n",
            "L1N5L2N0 = 0.026015330106019974\n",
            "L1N5L2N1 = 0.040927886962890625\n",
            "L1N5L2N2 = -0.20818236470222473\n",
            "L1N5L2N3 = 0.23867206275463104\n",
            "L1N5L2N4 = 0.38425660133361816\n",
            "L1N5L2N5 = 0.642910361289978\n",
            "L1N5L2N6 = -0.14593280851840973\n",
            "L1N5L2N7 = 0.5785748958587646\n",
            "L1N6L2N0 = 0.838621199131012\n",
            "L1N6L2N1 = 0.12304975092411041\n",
            "L1N6L2N2 = 0.06084774434566498\n",
            "L1N6L2N3 = 0.7645573019981384\n",
            "L1N6L2N4 = -0.3268386125564575\n",
            "L1N6L2N5 = 0.7276155948638916\n",
            "L1N6L2N6 = 0.6422820687294006\n",
            "L1N6L2N7 = 0.01778552681207657\n",
            "L1N7L2N0 = -0.3096639811992645\n",
            "L1N7L2N1 = 0.3455849289894104\n",
            "L1N7L2N2 = -0.37491172552108765\n",
            "L1N7L2N3 = -0.2504478096961975\n",
            "L1N7L2N4 = -0.22169634699821472\n",
            "L1N7L2N5 = 0.420504629611969\n",
            "L1N7L2N6 = 0.3945345878601074\n",
            "L1N7L2N7 = 0.12866787612438202\n",
            "L1N8L2N0 = 0.1990014910697937\n",
            "L1N8L2N1 = 0.5070098638534546\n",
            "L1N8L2N2 = -0.094373419880867\n",
            "L1N8L2N3 = 0.4396563768386841\n",
            "L1N8L2N4 = -0.26730671525001526\n",
            "L1N8L2N5 = 0.09056444466114044\n",
            "L1N8L2N6 = 0.7775736451148987\n",
            "L1N8L2N7 = 0.6599646210670471\n",
            "L1N9L2N0 = 0.5300455689430237\n",
            "L1N9L2N1 = 0.15172867476940155\n",
            "L1N9L2N2 = 0.07058562338352203\n",
            "L1N9L2N3 = -0.0351838581264019\n",
            "L1N9L2N4 = -0.17913812398910522\n",
            "L1N9L2N5 = 0.7227892875671387\n",
            "L1N9L2N6 = 0.7349284887313843\n",
            "L1N9L2N7 = 0.4484848380088806\n",
            "L1N10L2N0 = 0.5140796303749084\n",
            "L1N10L2N1 = -0.16185809671878815\n",
            "L1N10L2N2 = -0.4720611274242401\n",
            "L1N10L2N3 = 0.002161172451451421\n",
            "L1N10L2N4 = -0.42455577850341797\n",
            "L1N10L2N5 = 0.37338122725486755\n",
            "L1N10L2N6 = 0.6171148419380188\n",
            "L1N10L2N7 = 0.4764833450317383\n",
            "L1N11L2N0 = -0.41971370577812195\n",
            "L1N11L2N1 = -0.14615049958229065\n",
            "L1N11L2N2 = -0.27186113595962524\n",
            "L1N11L2N3 = -0.6013220548629761\n",
            "L1N11L2N4 = -0.5189006924629211\n",
            "L1N11L2N5 = -0.3612832725048065\n",
            "L1N11L2N6 = -0.20507045090198517\n",
            "L1N11L2N7 = -1.4032186269760132\n",
            "B2L3N0= 1.0565176010131836\n",
            "L2N0L3N0 = 0.5694129467010498\n",
            "L2N1L3N0 = -0.6433073282241821\n",
            "L2N2L3N0 = -0.6336038112640381\n",
            "L2N3L3N0 = 0.41806894540786743\n",
            "L2N4L3N0 = -0.3452877104282379\n",
            "L2N5L3N0 = 0.8852108716964722\n",
            "L2N6L3N0 = 0.5239742994308472\n",
            "L2N7L3N0 = -0.5171682834625244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anuIE4nQnvJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "B0L1N0= 0.5489714741706848\n",
        "B0L1N1= 0.7269389629364014\n",
        "B0L1N2= 1.2581751346588135\n",
        "B0L1N3= 1.1520798206329346\n",
        "B0L1N4= 1.0913702249526978\n",
        "B0L1N5= 1.3306126594543457\n",
        "B0L1N6= 1.1214040517807007\n",
        "B0L1N7= 0.8513354659080505\n",
        "B0L1N8= 0.8617942333221436\n",
        "B0L1N9= 1.2070845365524292\n",
        "B0L1N10= 1.0539273023605347\n",
        "B0L1N11= -0.5131221413612366\n",
        "L0N0L1N0 = 0.0016220943070948124\n",
        "L0N0L1N1 = 0.10702916234731674\n",
        "L0N0L1N2 = -0.26774507761001587\n",
        "L0N0L1N3 = -0.16035765409469604\n",
        "L0N0L1N4 = 0.3523627519607544\n",
        "L0N0L1N5 = 0.2384684979915619\n",
        "L0N0L1N6 = 0.17833773791790009\n",
        "L0N0L1N7 = -0.2555333375930786\n",
        "L0N0L1N8 = 0.18515661358833313\n",
        "L0N0L1N9 = 0.17232167720794678\n",
        "L0N0L1N10 = 0.3735349774360657\n",
        "L0N0L1N11 = -0.1821907013654709\n",
        "L0N1L1N0 = 0.1645156443119049\n",
        "L0N1L1N1 = 0.07426043599843979\n",
        "L0N1L1N2 = -0.020702680572867393\n",
        "L0N1L1N3 = 0.08904264122247696\n",
        "L0N1L1N4 = 0.22531826794147491\n",
        "L0N1L1N5 = -0.11259951442480087\n",
        "L0N1L1N6 = -0.09119870513677597\n",
        "L0N1L1N7 = -0.2075468897819519\n",
        "L0N1L1N8 = 0.29205065965652466\n",
        "L0N1L1N9 = -0.0940713882446289\n",
        "L0N1L1N10 = 0.07671551406383514\n",
        "L0N1L1N11 = -0.29331180453300476\n",
        "L0N2L1N0 = -0.023014618083834648\n",
        "L0N2L1N1 = 0.008401459082961082\n",
        "L0N2L1N2 = 0.05315321311354637\n",
        "L0N2L1N3 = 0.23498572409152985\n",
        "L0N2L1N4 = 0.3350667655467987\n",
        "L0N2L1N5 = -0.08612523227930069\n",
        "L0N2L1N6 = -0.23842483758926392\n",
        "L0N2L1N7 = 0.27257731556892395\n",
        "L0N2L1N8 = 0.010739324614405632\n",
        "L0N2L1N9 = 0.064210444688797\n",
        "L0N2L1N10 = -0.0979783684015274\n",
        "L0N2L1N11 = -0.04041393846273422\n",
        "L0N3L1N0 = 0.19288980960845947\n",
        "L0N3L1N1 = 0.04242799058556557\n",
        "L0N3L1N2 = 0.07050857692956924\n",
        "L0N3L1N3 = -0.30290085077285767\n",
        "L0N3L1N4 = 0.21972142159938812\n",
        "L0N3L1N5 = 0.17447520792484283\n",
        "L0N3L1N6 = -0.0526302233338356\n",
        "L0N3L1N7 = 0.04947732388973236\n",
        "L0N3L1N8 = -0.18823543190956116\n",
        "L0N3L1N9 = 0.30401068925857544\n",
        "L0N3L1N10 = 0.13671322166919708\n",
        "L0N3L1N11 = 0.15967682003974915\n",
        "L0N4L1N0 = -0.044796932488679886\n",
        "L0N4L1N1 = 0.13881424069404602\n",
        "L0N4L1N2 = -0.247073695063591\n",
        "L0N4L1N3 = 0.009818323887884617\n",
        "L0N4L1N4 = -0.14859987795352936\n",
        "L0N4L1N5 = 0.46681666374206543\n",
        "L0N4L1N6 = 0.10945077985525131\n",
        "L0N4L1N7 = 0.1599600613117218\n",
        "L0N4L1N8 = -0.05846742168068886\n",
        "L0N4L1N9 = 0.055684901773929596\n",
        "L0N4L1N10 = 0.0030583918560296297\n",
        "L0N4L1N11 = -0.07187709957361221\n",
        "B1L2N0= 1.02090322971344\n",
        "B1L2N1= -0.39803919196128845\n",
        "B1L2N2= -0.24621909856796265\n",
        "B1L2N3= 0.7709031105041504\n",
        "B1L2N4= -0.03734928369522095\n",
        "B1L2N5= 1.0608630180358887\n",
        "B1L2N6= 1.0258808135986328\n",
        "B1L2N7= -0.11504744738340378\n",
        "L1N0L2N0 = 0.6112263798713684\n",
        "L1N0L2N1 = 0.4761679172515869\n",
        "L1N0L2N2 = -0.10865473747253418\n",
        "L1N0L2N3 = 0.5538785457611084\n",
        "L1N0L2N4 = 0.005797660909593105\n",
        "L1N0L2N5 = 0.09469141066074371\n",
        "L1N0L2N6 = -0.05546670779585838\n",
        "L1N0L2N7 = -0.256847083568573\n",
        "L1N1L2N0 = 0.5833340883255005\n",
        "L1N1L2N1 = 0.031266409903764725\n",
        "L1N1L2N2 = 0.32026681303977966\n",
        "L1N1L2N3 = 0.3472670316696167\n",
        "L1N1L2N4 = -0.2212761640548706\n",
        "L1N1L2N5 = 0.3991275131702423\n",
        "L1N1L2N6 = 1.172556757926941\n",
        "L1N1L2N7 = -0.05409945920109749\n",
        "L1N2L2N0 = 0.5236108303070068\n",
        "L1N2L2N1 = -0.6879777312278748\n",
        "L1N2L2N2 = -0.46976161003112793\n",
        "L1N2L2N3 = 0.49481457471847534\n",
        "L1N2L2N4 = 0.09813914448022842\n",
        "L1N2L2N5 = 0.8086812496185303\n",
        "L1N2L2N6 = 0.29834961891174316\n",
        "L1N2L2N7 = -0.16347365081310272\n",
        "L1N3L2N0 = 0.2000885307788849\n",
        "L1N3L2N1 = 0.06764540076255798\n",
        "L1N3L2N2 = 0.1577172726392746\n",
        "L1N3L2N3 = 0.47969624400138855\n",
        "L1N3L2N4 = -0.4395045042037964\n",
        "L1N3L2N5 = 1.1988623142242432\n",
        "L1N3L2N6 = 0.7306505441665649\n",
        "L1N3L2N7 = -0.4754568934440613\n",
        "L1N4L2N0 = 0.11014901846647263\n",
        "L1N4L2N1 = 0.2846999168395996\n",
        "L1N4L2N2 = -0.5018507242202759\n",
        "L1N4L2N3 = -0.12151593714952469\n",
        "L1N4L2N4 = -0.4565874934196472\n",
        "L1N4L2N5 = 0.2789407968521118\n",
        "L1N4L2N6 = -0.030737370252609253\n",
        "L1N4L2N7 = 0.3427312970161438\n",
        "L1N5L2N0 = 0.026015330106019974\n",
        "L1N5L2N1 = 0.040927886962890625\n",
        "L1N5L2N2 = -0.20818236470222473\n",
        "L1N5L2N3 = 0.23867206275463104\n",
        "L1N5L2N4 = 0.38425660133361816\n",
        "L1N5L2N5 = 0.642910361289978\n",
        "L1N5L2N6 = -0.14593280851840973\n",
        "L1N5L2N7 = 0.5785748958587646\n",
        "L1N6L2N0 = 0.838621199131012\n",
        "L1N6L2N1 = 0.12304975092411041\n",
        "L1N6L2N2 = 0.06084774434566498\n",
        "L1N6L2N3 = 0.7645573019981384\n",
        "L1N6L2N4 = -0.3268386125564575\n",
        "L1N6L2N5 = 0.7276155948638916\n",
        "L1N6L2N6 = 0.6422820687294006\n",
        "L1N6L2N7 = 0.01778552681207657\n",
        "L1N7L2N0 = -0.3096639811992645\n",
        "L1N7L2N1 = 0.3455849289894104\n",
        "L1N7L2N2 = -0.37491172552108765\n",
        "L1N7L2N3 = -0.2504478096961975\n",
        "L1N7L2N4 = -0.22169634699821472\n",
        "L1N7L2N5 = 0.420504629611969\n",
        "L1N7L2N6 = 0.3945345878601074\n",
        "L1N7L2N7 = 0.12866787612438202\n",
        "L1N8L2N0 = 0.1990014910697937\n",
        "L1N8L2N1 = 0.5070098638534546\n",
        "L1N8L2N2 = -0.094373419880867\n",
        "L1N8L2N3 = 0.4396563768386841\n",
        "L1N8L2N4 = -0.26730671525001526\n",
        "L1N8L2N5 = 0.09056444466114044\n",
        "L1N8L2N6 = 0.7775736451148987\n",
        "L1N8L2N7 = 0.6599646210670471\n",
        "L1N9L2N0 = 0.5300455689430237\n",
        "L1N9L2N1 = 0.15172867476940155\n",
        "L1N9L2N2 = 0.07058562338352203\n",
        "L1N9L2N3 = -0.0351838581264019\n",
        "L1N9L2N4 = -0.17913812398910522\n",
        "L1N9L2N5 = 0.7227892875671387\n",
        "L1N9L2N6 = 0.7349284887313843\n",
        "L1N9L2N7 = 0.4484848380088806\n",
        "L1N10L2N0 = 0.5140796303749084\n",
        "L1N10L2N1 = -0.16185809671878815\n",
        "L1N10L2N2 = -0.4720611274242401\n",
        "L1N10L2N3 = 0.002161172451451421\n",
        "L1N10L2N4 = -0.42455577850341797\n",
        "L1N10L2N5 = 0.37338122725486755\n",
        "L1N10L2N6 = 0.6171148419380188\n",
        "L1N10L2N7 = 0.4764833450317383\n",
        "L1N11L2N0 = -0.41971370577812195\n",
        "L1N11L2N1 = -0.14615049958229065\n",
        "L1N11L2N2 = -0.27186113595962524\n",
        "L1N11L2N3 = -0.6013220548629761\n",
        "L1N11L2N4 = -0.5189006924629211\n",
        "L1N11L2N5 = -0.3612832725048065\n",
        "L1N11L2N6 = -0.20507045090198517\n",
        "L1N11L2N7 = -1.4032186269760132\n",
        "B2L3N0= 1.0565176010131836\n",
        "L2N0L3N0 = 0.5694129467010498\n",
        "L2N1L3N0 = -0.6433073282241821\n",
        "L2N2L3N0 = -0.6336038112640381\n",
        "L2N3L3N0 = 0.41806894540786743\n",
        "L2N4L3N0 = -0.3452877104282379\n",
        "L2N5L3N0 = 0.8852108716964722\n",
        "L2N6L3N0 = 0.5239742994308472\n",
        "L2N7L3N0 = -0.5171682834625244"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMIedPSFp7oP",
        "colab_type": "text"
      },
      "source": [
        "I am naming all the output from layers using the naming convention O_L{Layernumber}N{Neuronnumber}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4l4mIOLvCNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zero=0\n",
        "def activation_func(fg):\n",
        "  if int(fg) < zero:\n",
        "    return 0\n",
        "  else:\n",
        "    return fg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Md31xu3l5Ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def fun(input):\n",
        "  i1=input[0]\n",
        "  i2=input[1]\n",
        "  i3=input[2]\n",
        "  i4=input[3]\n",
        "  i5=input[4]\n",
        "  #Layer1\n",
        "  O_L1N0= activation_func(i1*L0N0L1N0 + i2 *L0N1L1N0 + i3 * L0N2L1N0 + i4 * L0N3L1N0 + i5 *L0N4L1N0 +B0L1N0)\n",
        "  O_L1N1= activation_func(i1*L0N0L1N1 + i2 *L0N1L1N1 + i3 * L0N2L1N1 + i4 * L0N3L1N1 + i5 *L0N4L1N1 +B0L1N1)\n",
        "  O_L1N2= activation_func(i1*L0N0L1N2 + i2 *L0N1L1N2 + i3 * L0N2L1N2 + i4 * L0N3L1N2 + i5 *L0N4L1N2 +B0L1N2)\n",
        "  O_L1N3= activation_func(i1*L0N0L1N3 + i2 *L0N1L1N3 + i3 * L0N2L1N3 + i4 * L0N3L1N3 + i5 *L0N4L1N3 +B0L1N3)\n",
        "  O_L1N4= activation_func(i1*L0N0L1N4 + i2 *L0N1L1N4 + i3 * L0N2L1N4 + i4 * L0N3L1N4 + i5 *L0N4L1N4 +B0L1N4)\n",
        "  O_L1N5= activation_func(i1*L0N0L1N5 + i2 *L0N1L1N5 + i3 * L0N2L1N5 + i4 * L0N3L1N5 + i5 *L0N4L1N5 +B0L1N5)\n",
        "  O_L1N6= activation_func(i1*L0N0L1N6 + i2 *L0N1L1N6 + i3 * L0N2L1N6 + i4 * L0N3L1N6 + i5 *L0N4L1N0 +B0L1N6)\n",
        "  O_L1N7= activation_func(i1*L0N0L1N7 + i2 *L0N1L1N7 + i3 * L0N2L1N7 + i4 * L0N3L1N7 + i5 *L0N4L1N0 +B0L1N7)\n",
        "  O_L1N8= activation_func(i1*L0N0L1N8 + i2 *L0N1L1N8 + i3 * L0N2L1N8 + i4 * L0N3L1N8 + i5 *L0N4L1N0 +B0L1N8)\n",
        "  O_L1N9= activation_func(i1*L0N0L1N9 + i2 *L0N1L1N9 + i3 * L0N2L1N9 + i4 * L0N3L1N9 + i5 *L0N4L1N0 +B0L1N9)\n",
        "  O_L1N10= activation_func(i1*L0N0L1N10 + i2 *L0N1L1N10 + i3 * L0N2L1N10 + i4 * L0N3L1N10 + i5 *L0N4L1N0 +B0L1N10)\n",
        "  O_L1N11= activation_func(i1*L0N0L1N11 + i2 *L0N1L1N11 + i3 * L0N2L1N11 + i4 * L0N3L1N11 + i5 *L0N4L1N0 +B0L1N11)\n",
        "\n",
        "  #Layer2\n",
        "  O_L2N0= activation_func(O_L1N0 * L1N0L2N0 + O_L1N1 *L1N1L2N0 + O_L1N2 *L1N2L2N0 + O_L1N3 * L1N3L2N0+  O_L1N4 * L1N4L2N0 + O_L1N5 * L1N5L2N0+ O_L1N6 * L1N6L2N0+ O_L1N7 * L1N7L2N0 + O_L1N8 * L1N8L2N0+ O_L1N9 * L1N9L2N0+ O_L1N10 * L1N10L2N0+ O_L1N11 * L1N11L2N0+B1L2N0 )\n",
        "  O_L2N1=activation_func(O_L1N0 * L1N0L2N1 + O_L1N1 *L1N1L2N1 + O_L1N2 *L1N2L2N1 + O_L1N3 * L1N3L2N1+  O_L1N4 * L1N4L2N1 + O_L1N5 * L1N5L2N1+ O_L1N6 * L1N6L2N1+ O_L1N7 * L1N7L2N1 + O_L1N8 * L1N8L2N1+ O_L1N9 * L1N9L2N1+ O_L1N10 * L1N10L2N1+ O_L1N11 * L1N11L2N1+B1L2N1 )\n",
        "  O_L2N2=activation_func(O_L1N0 * L1N0L2N2 + O_L1N1 *L1N1L2N2 + O_L1N2 *L1N2L2N2 + O_L1N3 * L1N3L2N2+  O_L1N4 * L1N4L2N2 + O_L1N5 * L1N5L2N2+ O_L1N6 * L1N6L2N2+ O_L1N7 * L1N7L2N2 + O_L1N8 * L1N8L2N2+ O_L1N9 * L1N9L2N2+ O_L1N10 * L1N10L2N2+ O_L1N11 * L1N11L2N2+B1L2N2 )\n",
        "  O_L2N3=activation_func(O_L1N0 * L1N0L2N3 + O_L1N1 *L1N1L2N3 + O_L1N2 *L1N2L2N3 + O_L1N3 * L1N3L2N3+  O_L1N4 * L1N4L2N3 + O_L1N5 * L1N5L2N3+ O_L1N6 * L1N6L2N3+ O_L1N7 * L1N7L2N3 + O_L1N8 * L1N8L2N3+ O_L1N9 * L1N9L2N3+ O_L1N10 * L1N10L2N3+ O_L1N11 * L1N11L2N3+B1L2N3 )\n",
        "  O_L2N4=activation_func(O_L1N0 * L1N0L2N4 + O_L1N1 *L1N1L2N4 + O_L1N2 *L1N2L2N4 + O_L1N3 * L1N3L2N4+  O_L1N4 * L1N4L2N4 + O_L1N5 * L1N5L2N4+ O_L1N6 * L1N6L2N4+ O_L1N7 * L1N7L2N4 + O_L1N8 * L1N8L2N4+ O_L1N9 * L1N9L2N4+ O_L1N10 * L1N10L2N4+ O_L1N11 * L1N11L2N4+B1L2N4 )\n",
        "  O_L2N5=activation_func(O_L1N0 * L1N0L2N5 + O_L1N1 *L1N1L2N5 + O_L1N2 *L1N2L2N5 + O_L1N3 * L1N3L2N5+  O_L1N4 * L1N4L2N5 + O_L1N5 * L1N5L2N5+ O_L1N6 * L1N6L2N5+ O_L1N7 * L1N7L2N5 + O_L1N8 * L1N8L2N5+ O_L1N9 * L1N9L2N5+ O_L1N10 * L1N10L2N5+ O_L1N11 * L1N11L2N5+B1L2N5 )\n",
        "  O_L2N6=activation_func(O_L1N0 * L1N0L2N6 + O_L1N1 *L1N1L2N6 + O_L1N2 *L1N2L2N6 + O_L1N3 * L1N3L2N6+  O_L1N4 * L1N4L2N6 + O_L1N5 * L1N5L2N6+ O_L1N6 * L1N6L2N6+ O_L1N7 * L1N7L2N6 + O_L1N8 * L1N8L2N6+ O_L1N9 * L1N9L2N6+ O_L1N10 * L1N10L2N6+ O_L1N11 * L1N11L2N6+B1L2N6 )\n",
        "  O_L2N7=activation_func(O_L1N0 * L1N0L2N7 + O_L1N1 *L1N1L2N7 + O_L1N2 *L1N2L2N7 + O_L1N3 * L1N3L2N7+  O_L1N4 * L1N4L2N7 + O_L1N5 * L1N5L2N7+ O_L1N6 * L1N6L2N7+ O_L1N7 * L1N7L2N7 + O_L1N8 * L1N8L2N7+ O_L1N9 * L1N9L2N7+ O_L1N10 * L1N10L2N7+ O_L1N11 * L1N11L2N7+B1L2N7 )\n",
        "  \n",
        "  #Layer3\n",
        "  #O_L3N=activation_func(O_L2N0* L2N0L3N0+ O_L2N1 * L2N1L3N0 + O_L2N2 * L2N2L3N0+O_L2N3 * L2N3L3N0+O_L2N4*L2N4L3N0+ O_L2N5*L2N5L3N0 +O_L2N6*L2N6L3N0+ O_L2N7*L2N7L3N0+B2L3N0 )\n",
        "  O_L3N=O_L2N0* L2N0L3N0+ O_L2N1 * L2N1L3N0 + O_L2N2 * L2N2L3N0+O_L2N3 * L2N3L3N0+O_L2N4*L2N4L3N0+ O_L2N5*L2N5L3N0 +O_L2N6*L2N6L3N0+ O_L2N7*L2N7L3N0+B2L3N0\n",
        "\n",
        "  return(O_L3N)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AnoDcgo_6n_",
        "colab_type": "code",
        "outputId": "a11015ea-1cc8-4013-ff3b-304c75ef143a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#comparing the outputs of the first 10 values from Xvalid\n",
        "print(\"Prediction by function | Prediction by training\")\n",
        "for x in range(0,10):\n",
        "  temp=fun(XVALID_f[x])\n",
        "  print(temp, Prediction_by_training[x])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction by function | Prediction by training\n",
            "14.034068347656216 [14.221711]\n",
            "13.96186188531922 [14.240022]\n",
            "13.864968635714236 [13.786507]\n",
            "13.603162937087989 [13.758002]\n",
            "14.40800418111987 [13.962963]\n",
            "14.112935908028573 [12.858111]\n",
            "14.699887463187517 [14.459498]\n",
            "13.734147384209122 [13.902208]\n",
            "14.171679212653501 [14.256341]\n",
            "13.19280376274179 [13.926971]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-5CQbw6QRB2",
        "colab_type": "text"
      },
      "source": [
        "Prediction by function | Prediction by training\n",
        "--- | ---\n",
        "14.034068347656216 | 14.221711\n",
        "13.96186188531922 | 14.240022\n",
        "13.864968635714236 | 13.786507\n",
        "13.603162937087989 | 13.758002\n",
        "14.40800418111987 | 13.962963\n",
        "14.112935908028573 | 12.858111\n",
        "14.699887463187517 | 14.459498\n",
        "13.734147384209122 | 13.902208\n",
        "14.171679212653501 | 14.256341\n",
        "13.19280376274179 | 13.926971"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMFON7I1CMJm",
        "colab_type": "code",
        "outputId": "9457142a-b1ea-4447-e948-2e761904203e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(XVALID_f.shape)\n",
        "P_func=np.empty(0)\n",
        "for x in range(0,1500):\n",
        "  P_func=np.append(P_func, fun(XVALID_f[x]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crIB-v7dCr3u",
        "colab_type": "code",
        "outputId": "acae9acd-2625-46cf-ef2c-0add05450e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(P_func,Prediction_by_training)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3ed41bac50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKXw5rBrLn0G",
        "colab_type": "code",
        "outputId": "49739de1-2f09-41fc-bfca-673d37fbe865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "error_rate=abs(P_func-Prediction_by_training)\n",
        "print(error_rate)\n",
        "e=error_rate.mean()\n",
        "print(e)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.18764281 0.25984927 0.35674252 ... 0.20018537 0.74152585 0.34816731]\n",
            " [0.20595336 0.27815982 0.37505307 ... 0.21849592 0.7598364  0.36647786]\n",
            " [0.24756169 0.17535523 0.07846198 ... 0.23501914 0.30632134 0.0870372 ]\n",
            " ...\n",
            " [0.1425879  0.07038144 0.02651181 ... 0.13004534 0.41129514 0.0179366 ]\n",
            " [0.14400888 0.07180241 0.02509084 ... 0.13146632 0.40987416 0.01651562]\n",
            " [0.33018088 0.40238734 0.49928059 ... 0.34272344 0.88406392 0.49070538]]\n",
            "0.36859845381090184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94sWUmOIOR9Z",
        "colab_type": "code",
        "outputId": "f80c324a-a91a-4077-9944-23153a39111c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(error_rate,bins=[0,0.5,1,1.5,2])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpjyYelDPMCM",
        "colab_type": "text"
      },
      "source": [
        "Even though our outputs for the trained model and the equation (function fun) does not match the mean error is 0.36 which is not very bad. In the above plot we can see that most of our error rate is between 0-1.5 which is small and less than 100 values that have error rate between 1.5-2. I will keep working on my function and the model to try and get the outputs closer to each other. "
      ]
    }
  ]
}